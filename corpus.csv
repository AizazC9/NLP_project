topic,content,URL,type,vocabulary size,word count
HTML Basics, From Wikipedia the free encyclopedia HyperText Markup Language htm and html redirect here For other uses see HTM HTMLHyperText Markup LanguageThe official logo of the latest version HTML51Filename extensionhtmlhtmInternet media type textHTMLType codeTEXTUniform Type Identifier UTIpublichtmlDeveloped byWHATWGWorld Wide Web Consortium W3C formerlyInitial release1993 30 years ago 1993Latest releaseLiving Standard Type of formatDocument file formatContainer forHTML elementsContained byWeb browserExtended fromSGMLExtended toXHTMLOpen formatYesWebsitehtmlspecwhatwgorg HTML Dynamic HTML HTML5 article audio canvas video XHTML Basic Mobile Profile HTML element meta div and span blink marquee HTML attribute alt attribute HTML frame HTML editor Character encodings named characters Unicode Language code Document Object Model Browser Object Model Style sheets CSS Font family Web colors JavaScript WebCL Web3D WebGL WebGPU WebXR W3C Validator WHATWG Quirks mode Web storage Rendering engine Comparisons Document markup languages Comparison of browser engines vte The HyperText Markup Language or HTML is the standard markup language for documents designed to be displayed in a web browser It defines the content and structure of web content It is often assisted by technologies such as Cascading Style Sheets CSS and scripting languages such as JavaScript Web browsers receive HTML documents from a web server or from local storage and render the documents into multimedia web pages HTML describes the structure of a web page semantically and originally included cues for its appearance HTML elements are the building blocks of HTML pages With HTML constructs images and other objects such as interactive forms may be embedded into the rendered page HTML provides a means to create structured documents by denoting structural semantics for text such as headings paragraphs lists links quotes and other items HTML elements are delineated by tags written using angle brackets Tags such as img and input directly introduce content into the page Other tags such as p and p surround and provide information about document text and may include subelement tags Browsers do not display the HTML tags but use them to interpret the content of the page HTML can embed programs written in a scripting language such as JavaScript which affects the behavior and content of web pages The inclusion of CSS defines the look and layout of content The World Wide Web Consortium W3C former maintainer of the HTML and current maintainer of the CSS standards has encouraged the use of CSS over explicit presentational HTML since 1997update2 A form of HTML known as HTML5 is used to display video and audio primarily using the canvas element together with JavaScript History Development Tim BernersLee in April 2009 In 1980 physicist Tim BernersLee a contractor at CERN proposed and prototyped ENQUIRE a system for CERN researchers to use and share documents In 1989 BernersLee wrote a memo proposing an Internetbased hypertext system3 BernersLee specified HTML and wrote the browser and server software in late 1990 That year BernersLee and CERN data systems engineer Robert Cailliau collaborated on a joint request for funding but the project was not formally adopted by CERN In his personal notes of 1990 BernersLee listed some of the many areas in which hypertext is used an encyclopedia is the first entry4 The first publicly available description of HTML was a document called HTML Tags5 first mentioned on the Internet by Tim BernersLee in late 199167 It describes 18 elements comprising the initial relatively simple design of HTML Except for the hyperlink tag these were strongly influenced by SGMLguid an inhouse Standard Generalized Markup Language SGMLbased documentation format at CERN Eleven of these elements still exist in HTML 48 HTML is a markup language that web browsers use to interpret and compose text images and other material into visible or audible web pages Default characteristics for every item of HTML markup are defined in the browser and these characteristics can be altered or enhanced by the web page designers additional use of CSS Many of the text elements are mentioned in the 1988 ISO technical report TR 9537 Techniques for using SGML which describes the features of early text formatting languages such as that used by the RUNOFF command developed in the early 1960s for the CTSS Compatible TimeSharing System operating system These formatting commands were derived from the commands used by typesetters to manually format documents However the SGML concept of generalized markup is based on elements nested annotated ranges with attributes rather than merely print effects with separate structure and markup HTML has been progressively moved in this direction with CSS BernersLee considered HTML to be an application of SGML It was formally defined as such by the Internet Engineering Task Force IETF with the mid1993 publication of the first proposal for an HTML specification the Hypertext Markup Language HTML Internet Draft by BernersLee and Dan Connolly which included an SGML Document type definition to define the syntax910 The draft expired after six months but was notable for its acknowledgment of the NCSA Mosaic browsers custom tag for embedding inline images reflecting the IETFs philosophy of basing standards on successful prototypes Similarly Dave Raggetts competing Internet Draft HTML Hypertext Markup Format from late 1993 suggested standardizing alreadyimplemented features like tables and fillout forms11 After the HTML and HTML drafts expired in early 1994 the IETF created an HTML Working Group In 1995 this working group completed HTML 20 the first HTML specification intended to be treated as a standard against which future implementations should be based12 Further development under the auspices of the IETF was stalled by competing interests Since 1996update the HTML specifications have been maintained with input from commercial software vendors by the World Wide Web Consortium W3C13 In 2000 HTML became an international standard ISOIEC 154452000 HTML 401 was published in late 1999 with further errata published through 2001 In 2004 development began on HTML5 in the Web Hypertext Application Technology Working Group WHATWG which became a joint deliverable with the W3C in 2008 and was completed and standardized on 28 October 201414 HTML version timeline HTML 2 November 24 1995 HTML 20 was published as RFC 1866 Supplemental RFCs added capabilities November 25 1995 RFC 1867 formbased file upload May 1996 RFC 1942 tables August 1996 RFC 1980 clientside image maps January 1997 RFC 2070 internationalization HTML 3 January 14 1997 HTML 3215 was published as a W3C Recommendation It was the first version developed and standardized exclusively by the W3C as the IETF had closed its HTML Working Group on September 12 199616 Initially codenamed Wilbur17 HTML 32 dropped math formulas entirely reconciled overlap among various proprietary extensions and adopted most of Netscapes visual markup tags Netscapes blink element and Microsofts marquee element were omitted due to a mutual agreement between the two companies13 A markup for mathematical formulas similar to that of HTML was standardized 14 months later in MathML HTML 4 December 18 1997 HTML 4018 was published as a W3C Recommendation It offers three variations Strict in which deprecated elements are forbidden Transitional in which deprecated elements are allowed Frameset in which mostly only frame related elements are allowed Initially codenamed Cougar17 HTML 40 adopted many browserspecific element types and attributes but also sought to phase out Netscapes visual markup features by marking them as deprecated in favor of style sheets HTML 4 is an SGML application conforming to ISO 8879  SGML19 April 24 1998 HTML 4020 was reissued with minor edits without incrementing the version number December 24 1999 HTML 40121 was published as a W3C Recommendation It offers the same three variations as HTML 40 and its last errata22 were published on May 12 2001 May 2000 ISOIEC 15445200023 ISO HTML based on HTML 401 Strict was published as an ISOIEC international standard24 In the ISO this standard is in the domain of the ISOIEC JTC 1SC 34 ISOIEC Joint Technical Committee 1 Subcommittee 34  Document description and processing languages23 After HTML 401 there were no new versions of HTML for many years as the development of the parallel XMLbased language XHTML occupied the W3Cs HTML Working Group HTML 5 Main article HTML5 October 28 2014 HTML525 was published as a W3C Recommendation26 November 1 2016 HTML 5127 was published as a W3C Recommendation2829 December 14 2017 HTML 5230 was published as a W3C Recommendation3132 HTML draft version timeline October 1991 HTML Tags6 an informal CERN document listing 18 HTML tags was first mentioned in public June 1992 First informal draft of the HTML DTD33 with seven subsequent revisions July 15 August 6 August 18 November 17 November 19 November 20 November 22343536 November 1992 HTML DTD 11 the first with a version number based on RCS revisions which start with 11 rather than 10 an informal draft36 June 1993 Hypertext Markup Language37 was published by the IETF IIIR Working Group as an Internet Draft a rough proposal for a standard It was replaced by a second version38 one month later November 1993 HTML was published by the IETF as an Internet Draft and was a competing proposal to the Hypertext Markup Language draft It expired in July 199439 November 1994 First draft revision 00 of HTML 20 published by IETF itself40 called as HTML 20 from revision 0241 that finally led to the publication of RFC 1866 in November 199542 April 1995 authored March 1995 HTML 3043 was proposed as a standard to the IETF but the proposal expired five months later 28 September 199544 without further action It included many of the capabilities that were in Raggetts HTML proposal such as support for tables text flow around figures and the display of complex mathematical formulas44 W3C began development of its own Arena browser as a test bed for HTML 3 and Cascading Style Sheets454647 but HTML 30 did not succeed for several reasons The draft was considered very large at 150 pages and the pace of browser development as well as the number of interested parties had outstripped the resources of the IETF13 Browser vendors including Microsoft and Netscape at the time chose to implement different subsets of HTML 3s draft features as well as to introduce their own extensions to it13 See browser wars These included extensions to control stylistic aspects of documents contrary to the belief of the academic engineering community that such things as text color background texture font size and font face were definitely outside the scope of a language when their only intent was to specify how a document would be organized13 Dave Raggett who has been a W3C Fellow for many years has commented for example To a certain extent Microsoft built its business on the Web by extending HTML features13 Logo of HTML5 January 2008 HTML5 was published as a Working Draft by the W3C48 Although its syntax closely resembles that of SGML HTML5 has abandoned any attempt to be an SGML application and has explicitly defined its own html serialization in addition to an alternative XMLbased XHTML5 serialization49 2011 HTML5  Last Call On 14 February 2011 the W3C extended the charter of its HTML Working Group with clear milestones for HTML5 In May 2011 the working group advanced HTML5 to Last Call an invitation to communities inside and outside W3C to confirm the technical soundness of the specification The W3C developed a comprehensive test suite to achieve broad interoperability for the full specification by 2014 which was the target date for recommendation50 In January 2011 the WHATWG renamed its HTML5 living standard to HTML The W3C nevertheless continues its project to release HTML551 2012 HTML5  Candidate Recommendation In July 2012 WHATWG and W3C decided on a degree of separation W3C will continue the HTML5 specification work focusing on a single definitive standard which is considered a snapshot by WHATWG The WHATWG organization will continue its work with HTML5 as a Living Standard The concept of a living standard is that it is never complete and is always being updated and improved New features can be added but functionality will not be removed52 In December 2012 W3C designated HTML5 as a Candidate Recommendation53 The criterion for advancement to W3C Recommendation is two 100 complete and fully interoperable implementations54 2014 HTML5  Proposed Recommendation and Recommendation In September 2014 W3C moved HTML5 to Proposed Recommendation55 On 28 October 2014 HTML5 was released as a stable W3C Recommendation56 meaning the specification process is complete57 XHTML versions Main article XHTML XHTML is a separate language that began as a reformulation of HTML 401 using XML 10 It is now referred to as the XML syntax for HTML and no longer being developed as a separate standard58 XHTML 10 was published as a W3C Recommendation on January 26 200059 and was later revised and republished on August 1 2002 It offers the same three variations as HTML 40 and 401 reformulated in XML with minor restrictions XHTML 1160 was published as a W3C Recommendation on May 31 2001 It is based on XHTML 10 Strict but includes minor changes can be customized and is reformulated using modules in the W3C recommendation Modularization of XHTML which was published on April 10 200161 XHTML 20 was a working draft work on it was abandoned in 2009 in favor of work on HTML5 and XHTML5626364 XHTML 20 was incompatible with XHTML 1x and therefore would be more accurately characterized as an XHTMLinspired new language than an update to XHTML 1x Transition of HTML Publication to WHATWG See also HTML5  W3C and WHATWG conflict On 28 May 2019 the W3C announced that WHATWG would be the sole publisher of the HTML and DOM standards65666768 The W3C and WHATWG had been publishing competing standards since 2012 While the W3C standard was identical to the WHATWG in 2007 the standards have since progressively diverged due to different design decisions69 The WHATWG Living Standard had been the de facto web standard for some time70 Markup HTML markup consists of several key components including those called tags and their attributes characterbased data types character references and entity references HTML tags most commonly come in pairs like h1 and h1 although some represent empty elements and so are unpaired for example img The first tag in such a pair is the start tag and the second is the end tag they are also called opening tags and closing tags Another important component is the HTML document type declaration which triggers standards mode rendering The following is an example of the classic Hello World program DOCTYPE html html head titleThis is a titletitle head body div pHello worldp div body html The text between html and html describes the web page and the text between body and body is the visible page content The markup text titleThis is a titletitle defines the browser page title shown on browser tabs and window titles and the tag div defines a division of the page used for easy styling Between head and head a meta element can be used to define webpage metadata The Document Type Declaration DOCTYPE html is for HTML5 If a declaration is not included various browsers will revert to quirks mode for rendering71 Elements Main article HTML element HTML element content categories HTML documents imply a structure of nested HTML elements These are indicated in the document by HTML tags enclosed in angle brackets thus p72better source needed In the simple general case the extent of an element is indicated by a pair of tags a start tag p and end tag p The text content of the element if any is placed between these tags Tags may also enclose further tag markup between the start and end including a mixture of tags and text This indicates further nested elements as children of the parent element The start tag may also include the elements attributes within the tag These indicate other information such as identifiers for sections within the document identifiers used to bind style information to the presentation of the document and for some tags such as the img used to embed images the reference to the image resource in the format like this img srcexamplecomexamplejpg Some elements such as the line break br  or br  do not permit any embedded content either text or further tags These require only a single empty tag akin to a start tag and do not use an end tag Many tags particularly the closing end tag for the very commonly used paragraph element p are optional An HTML browser or other agent can infer the closure for the end of an element from the context and the structural rules defined by the HTML standard These rules are complex and not widely understood by most HTML authors The general form of an HTML element is therefore tag attribute1value1 attribute2value2contenttag Some HTML elements are defined as empty elements and take the form tag attribute1value1 attribute2value2 Empty elements may enclose no content for instance the br  tag or the inline img tag The name of an HTML element is the name used in the tags The end tags name is preceded by a slash character  and that in empty elements the end tag is neither required nor allowed If attributes are not mentioned default values are used in each case Element examples See also HTML element Header of the HTML document headhead The title is included in the head for example head titleThe Titletitle link relstylesheet hrefstylebyjimbowalescss   Imports Stylesheets  head Headings HTML headings are defined with the h1 to h6 tags with H1 being the highest or most important level and H6 the least h1Heading level 1h1 h2Heading level 2h2 h3Heading level 3h3 h4Heading level 4h4 h5Heading level 5h5 h6Heading level 6h6 The effects are Heading Level 1 Heading Level 2 Heading Level 3 Heading Level 4 Heading Level 5 Heading Level 6 CSS can drastically change the rendering ParagraphspParagraph 1p pParagraph 2p Line breaks br  The difference between br  and p is that br  breaks a line without altering the semantic structure of the page whereas p sections the page into paragraphs The element br  is an empty element in that although it may have attributes it can take no content and it may not have an end tag pThis br  is a paragraph br  with br  line breaksp This is a link in HTML To create a link the a tag is used The href attribute holds the URL address of the link a hrefhttpswwwwikipediaorgA link to Wikipediaa Inputs There are many possible ways a user can give inputs likeinput typetext   This is for text input  input typefile   This is for uploading files  input typecheckbox   This is for checkboxes  Comments  This is a comment  Comments can help in the understanding of the markup and do not display in the webpage There are several types of markup elements used in HTML Structural markup indicates the purpose of text For example h2Golfh2 establishes Golf as a secondlevel heading Structural markup does not denote any specific rendering but most web browsers have default styles for element formatting Content may be further styled using Cascading Style Sheets CSS73 Presentational markup indicates the appearance of the text regardless of its purpose For example bbold textb indicates that visual output devices should render boldface in bold text but gives a little indication what devices that are unable to do this such as aural devices that read the text aloud should do In the case of both bbold textb and iitalic texti there are other elements that may have equivalent visual renderings but that are more semantic in nature such as strongstrong textstrong and ememphasized textem respectively It is easier to see how an aural user agent should interpret the latter two elements However they are not equivalent to their presentational counterparts it would be undesirable for a screen reader to emphasize the name of a book for instance but on a screen such a name would be italicized Most presentational markup elements have become deprecated under the HTML 40 specification in favor of using CSS for styling Hypertext markup makes parts of a document into links to other documents An anchor element creates a hyperlink in the document and its href attribute sets the links target URL For example the HTML markup a hrefhttpsenwikipediaorgWikipediaa will render the word Wikipedia as a hyperlink To render an image as a hyperlink an img element is inserted as content into the a element Like br img is an empty element with attributes but no content or closing tag a hrefhttpsexampleorgimg srcimagegif altdescriptive text width50 height50 border0a Attributes Main article HTML attribute Most of the attributes of an element are namevalue pairs separated by  and written within the start tag of an element after the elements name The value may be enclosed in single or double quotes although values consisting of certain characters can be left unquoted in HTML but not XHTML7475 Leaving attribute values unquoted is considered unsafe76 In contrast with namevalue pair attributes there are some attributes that affect the element simply by their presence in the start tag of the element6 like the ismap attribute for the img element77 There are several common attributes that may appear in many elements  The id attribute provides a documentwide unique identifier for an element This is used to identify the element so that stylesheets can alter its presentational properties and scripts may alter animate or delete its contents or presentation Appended to the URL of the page it provides a globally unique identifier for the element typically a subsection of the page For example the ID Attributes in httpsenwikipediaorgwikiHTMLAttributes The class attribute provides a way of classifying similar elements This can be used for semantic or presentation purposes For example an HTML document might semantically use the designation classnotation to indicate that all elements with this class value are subordinate to the main text of the document In presentation such elements might be gathered together and presented as footnotes on a page instead of appearing in the place where they occur in the HTML source Class attributes are used semantically in microformats Multiple class values may be specified for example classnotation important puts the element into both the notation and the important classes An author may use the style attribute to assign presentational properties to a particular element It is considered better practice to use an elements id or class attributes to select the element from within a stylesheet though sometimes this can be too cumbersome for a simple specific or ad hoc styling The title attribute is used to attach a subtextual explanation to an element In most browsers this attribute is displayed as a tooltip The lang attribute identifies the natural language of the elements contents which may be different from that of the rest of the document For example in an Englishlanguage document pOh well span langfrcest la viespan as they say in Francep The abbreviation element abbr can be used to demonstrate some of these attributes abbr idanId classjargon stylecolorpurple titleHypertext Markup LanguageHTMLabbr This example displays as HTML in most browsers pointing the cursor at the abbreviation should display the title text Hypertext Markup Language Most elements take the languagerelated attribute dir to specify text direction such as with rtl for righttoleft text in for example Arabic Persian or Hebrew78 Character and entity references See also List of XML and HTML character entity references and Unicode and HTML As of version 40 HTML defines a set of 252 character entity references and a set of 1114050 numeric character references both of which allow individual characters to be written via simple markup rather than literally A literal character and its markup counterpart are considered equivalent and are rendered identically The ability to escape characters in this way allows for the characters  and  when written as lt and amp respectively to be interpreted as character data rather than markup For example a literal  normally indicates the start of a tag and  normally indicates the start of a character entity reference or numeric character reference writing it as amp or x26 or 38 allows  to be included in the content of an element or in the value of an attribute The doublequote character  when not used to quote an attribute value must also be escaped as quot or x22 or 34 when it appears within the attribute value itself Equivalently the singlequote character  when not used to quote an attribute value must also be escaped as x27 or 39 or as apos in HTML5 or XHTML documents7980 when it appears within the attribute value itself If document authors overlook the need to escape such characters some browsers can be very forgiving and try to use context to guess their intent The result is still invalid markup which makes the document less accessible to other browsers and to other user agents that may try to parse the document for search and indexing purposes for example Escaping also allows for characters that are not easily typed or that are not available in the documents character encoding to be represented within the element and attribute content For example the acuteaccented e é a character typically found only on Western European and South American keyboards can be written in any HTML document as the entity reference eacute or as the numeric references xE9 or 233 using characters that are available on all keyboards and are supported in all character encodings Unicode character encodings such as UTF8 are compatible with all modern browsers and allow direct access to almost all the characters of the worlds writing systems81 Example HTML Escape Sequences Named Decimal Hexadecimal Result Description Notes amp 38 x26  Ampersand lt 60 x3C  Less Than gt 62 x3e  Greater Than quot 34 x22  Double Quote apos 39 x27  Single Quote nbsp 160 xA0 NonBreaking Space copy 169 xA9  Copyright reg 174 xAE  Registered Trademark dagger 8224 x2020  Dagger Dagger 8225 x2021  Double dagger Names are case sensitive ddagger 8225 x2021  Double dagger Names may have synonyms trade 8482 x2122  Trademark Data types HTML defines several data types for element content such as script data and stylesheet data and a plethora of types for attribute values including IDs names URIs numbers units of length languages media descriptors colors character encodings dates and times and so on All of these data types are specializations of character data Document type declaration HTML documents are required to start with a Document Type Declaration informally a doctype In browsers the doctype helps to define the rendering modeparticularly whether to use quirks mode The original purpose of the doctype was to enable the parsing and validation of HTML documents by SGML tools based on the Document Type Definition DTD The DTD to which the DOCTYPE refers contains a machinereadable grammar specifying the permitted and prohibited content for a document conforming to such a DTD Browsers on the other hand do not implement HTML as an application of SGML and as consequence do not read the DTD HTML5 does not define a DTD therefore in HTML5 the doctype declaration is simpler and shorter82 DOCTYPE html An example of an HTML 4 doctype DOCTYPE HTML PUBLIC W3CDTD HTML 401EN httpswwww3orgTRhtml4strictdtd This declaration references the DTD for the strict version of HTML 401 SGMLbased validators read the DTD in order to properly parse the document and to perform validation In modern browsers a valid doctype activates standards mode as opposed to quirks mode In addition HTML 401 provides Transitional and Frameset DTDs as explained below The transitional type is the most inclusive incorporating current tags as well as older or deprecated tags with the Strict DTD excluding deprecated tags The frameset has all tags necessary to make frames on a page along with the tags included in transitional type83 Semantic HTML Main article Semantic HTML Semantic HTML is a way of writing HTML that emphasizes the meaning of the encoded information over its presentation look HTML has included semantic markup from its inception84 but has also included presentational markup such as font i and center tags There are also the semantically neutral div and span tags Since the late 1990s when Cascading Style Sheets were beginning to work in most browsers web authors have been encouraged to avoid the use of presentational HTML markup with a view to the separation of content and presentation85 In a 2001 discussion of the Semantic Web Tim BernersLee and others gave examples of ways in which intelligent software agents may one day automatically crawl the web and find filter and correlate previously unrelated published facts for the benefit of human users86 Such agents are not commonplace even now but some of the ideas of Web 20 mashups and price comparison websites may be coming close The main difference between these web application hybrids and BernersLees semantic agents lies in the fact that the current aggregation and hybridization of information is usually designed by web developers who already know the web locations and the API semantics of the specific data they wish to mash compare and combine An important type of web agent that does crawl and read web pages automatically without prior knowledge of what it might find is the web crawler or searchengine spider These software agents are dependent on the semantic clarity of web pages they find as they use various techniques and algorithms to read and index millions of web pages a day and provide web users with search facilities without which the World Wide Webs usefulness would be greatly reduced In order for search engine spiders to be able to rate the significance of pieces of text they find in HTML documents and also for those creating mashups and other hybrids as well as for more automated agents as they are developed the semantic structures that exist in HTML need to be widely and uniformly applied to bring out the meaning of the published text87 Presentational markup tags are deprecated in current HTML and XHTML recommendations The majority of presentational features from previous versions of HTML are no longer allowed as they lead to poorer accessibility higher cost of site maintenance and larger document sizes88 Good semantic HTML also improves the accessibility of web documents see also Web Content Accessibility Guidelines For example when a screen reader or audio browser can correctly ascertain the structure of a document it will not waste the visually impaired users time by reading out repeated or irrelevant information when it has been marked up correctly Delivery HTML documents can be delivered by the same means as any other computer file However they are most often delivered either by HTTP from a web server or by email HTTP Main article Hypertext Transfer Protocol The World Wide Web is composed primarily of HTML documents transmitted from web servers to web browsers using the Hypertext Transfer Protocol HTTP However HTTP is used to serve images sound and other content in addition to HTML To allow the web browser to know how to handle each document it receives other information is transmitted along with the document This meta data usually includes the MIME type eg texthtml or applicationxhtmlxml and the character encoding see Character encoding in HTML In modern browsers the MIME type that is sent with the HTML document may affect how the document is initially interpreted A document sent with the XHTML MIME type is expected to be wellformed XML syntax errors may cause the browser to fail to render it The same document sent with the HTML MIME type might be displayed successfully since some browsers are more lenient with HTML The W3C recommendations state that XHTML 10 documents that follow guidelines set forth in the recommendations Appendix C may be labeled with either MIME Type89 XHTML 11 also states that XHTML 11 documents should90 be labeled with either MIME type91 HTML email Main article HTML email Most graphical email clients allow the use of a subset of HTML often illdefined to provide formatting and semantic markup not available with plain text This may include typographic information like colored headings emphasized and quoted text inline images and diagrams Many such clients include both a GUI editor for composing HTML email messages and a rendering engine for displaying them Use of HTML in email is criticized by some because of compatibility issues because it can help disguise phishing attacks because of accessibility issues for blind or visually impaired people because it can confuse spam filters and because the message size is larger than plain text Naming conventions The most common filename extension for files containing HTML is html A common abbreviation of this is htm which originated because some early operating systems and file systems such as DOS and the limitations imposed by FAT data structure limited file extensions to three letters92 HTML Application Main article HTML Application An HTML Application HTA file extension hta is a Microsoft Windows application that uses HTML and Dynamic HTML in a browser to provide the applications graphical interface A regular HTML file is confined to the security model of the web browsers security communicating only to web servers and manipulating only web page objects and site cookies An HTA runs as a fully trusted application and therefore has more privileges like creationeditingremoval of files and Windows Registry entries Because they operate outside the browsers security model HTAs cannot be executed via HTTP but must be downloaded just like an EXE file and executed from local file system HTML4 variations Since its inception HTML and its associated protocols gained acceptance relatively quicklyby whom However no clear standards existed in the early years of the language Though its creators originally conceived of HTML as a semantic language devoid of presentation details93 practical uses pushed many presentational elements and attributes into the language driven largely by the various browser vendors The latest standards surrounding HTML reflect efforts to overcome the sometimes chaotic development of the language94 and to create a rational foundation for building both meaningful and wellpresented documents To return HTML to its role as a semantic language the W3C has developed style languages such as CSS and XSL to shoulder the burden of presentation In conjunction the HTML specification has slowly reined in the presentational elements There are two axes differentiating various variations of HTML as currently specified SGMLbased HTML versus XMLbased HTML referred to as XHTML on one axis and strict versus transitional loose versus frameset on the other axis SGMLbased versus XMLbased HTML One difference in the latestwhen HTML specifications lies in the distinction between the SGMLbased specification and the XMLbased specification The XMLbased specification is usually called XHTML to distinguish it clearly from the more traditional definition However the root element name continues to be html even in the XHTMLspecified HTML The W3C intended XHTML 10 to be identical to HTML 401 except where limitations of XML over the more complex SGML require workarounds Because XHTML and HTML are closely related they are sometimes documented in parallel In such circumstances some authors conflate the two names as XHTML or XHTML Like HTML 401 XHTML 10 has three subspecifications strict transitional and frameset Aside from the different opening declarations for a document the differences between an HTML 401 and XHTML 10 documentin each of the corresponding DTDsare largely syntactic The underlying syntax of HTML allows many shortcuts that XHTML does not such as elements with optional opening or closing tags and even empty elements which must not have an end tag By contrast XHTML requires all elements to have an opening tag and a closing tag XHTML however also introduces a new shortcut an XHTML tag may be opened and closed within the same tag by including a slash before the end of the tag like this br The introduction of this shorthand which is not used in the SGML declaration for HTML 401 may confuse earlier software unfamiliar with this new convention A fix for this is to include a space before closing the tag as such br 95 To understand the subtle differences between HTML and XHTML consider the transformation of a valid and wellformed XHTML 10 document that adheres to Appendix C see below into a valid HTML 401 document Making this translation requires the following steps The language for an element should be specified with a lang attribute rather than the XHTML xmllang attribute XHTML uses XMLs builtin languagedefining functionality attribute Remove the XML namespace xmlnsURI HTML has no facilities for namespaces Change the document type declaration from XHTML 10 to HTML 401 see DTD section for further explanation If present remove the XML declaration Typically this is xml version10 encodingutf8 Ensure that the documents MIME type is set to texthtml For both HTML and XHTML this comes from the HTTP ContentType header sent by the server Change the XML emptyelement syntax to an HTML style empty element br  to br Those are the main changes necessary to translate a document from XHTML 10 to HTML 401 To translate from HTML to XHTML would also require the addition of any omitted opening or closing tags Whether coding in HTML or XHTML it may just be best to always include the optional tags within an HTML document rather than remembering which tags can be omitted A wellformed XHTML document adheres to all the syntax requirements of XML A valid document adheres to the content specification for XHTML which describes the document structure The W3C recommends several conventions to ensure an easy migration between HTML and XHTML see HTML Compatibility Guidelines The following steps can be applied to XHTML 10 documents only Include both xmllang and lang attributes on any elements assigning language Use the emptyelement syntax only for elements specified as empty in HTML Include an extra space in emptyelement tags for example br  instead of br  Include explicit close tags for elements that permit content but are left empty for example divdiv not div  Omit the XML declaration By carefully following the W3Cs compatibility guidelines a user agent should be able to interpret the document equally as HTML or XHTML For documents that are XHTML 10 and have been made compatible in this way the W3C permits them to be served either as HTML with a texthtml MIME type or as XHTML with an applicationxhtmlxml or applicationxml MIME type When delivered as XHTML browsers should use an XML parser which adheres strictly to the XML specifications for parsing the documents contents Transitional versus strict HTML 4 defined three different versions of the language Strict Transitional once called Loose and Frameset The Strict version is intended for new documents and is considered best practice while the Transitional and Frameset versions were developed to make it easier to transition documents that conformed to older HTML specifications or did not conform to any specification to a version of HTML 4 The Transitional and Frameset versions allow for presentational markup which is omitted in the Strict version Instead cascading style sheets are encouraged to improve the presentation of HTML documents Because XHTML 1 only defines an XML syntax for the language defined by HTML 4 the same differences apply to XHTML 1 as well The Transitional version allows the following parts of the vocabulary which are not included in the Strict version A looser content model Inline elements and plain text are allowed directly in body blockquote form noscript and noframes Presentation related elements underline uDeprecated can confuse a visitor with a hyperlink strikethrough s center Deprecated use CSS instead font Deprecated use CSS instead basefont Deprecated use CSS instead Presentation related attributes background Deprecated use CSS instead and bgcolor Deprecated use CSS instead attributes for body required element according to the W3C element align Deprecated use CSS instead attribute on div form paragraph p and heading h1h6 elements align Deprecated use CSS instead noshade Deprecated use CSS instead size Deprecated use CSS instead and width Deprecated use CSS instead attributes on hr element align Deprecated use CSS instead border vspace and hspace attributes on img and object caution the object element is only supported in Internet Explorer from the major browsers elements align Deprecated use CSS instead attribute on legend and caption elements align Deprecated use CSS instead and bgcolor Deprecated use CSS instead on table element nowrap Obsolete bgcolor Deprecated use CSS instead width height on td and th elements bgcolor Deprecated use CSS instead attribute on tr element clear Obsolete attribute on br element compact attribute on dl dir and menu elements type Deprecated use CSS instead compact Deprecated use CSS instead and start Deprecated use CSS instead attributes on ol and ul elements type and value attributes on li element width attribute on pre element Additional elements in Transitional specification menu Deprecated use CSS instead list no substitute though the unordered list is recommended dir Deprecated use CSS instead list no substitute though the unordered list is recommended isindex Deprecated element requires serverside support and is typically added to documents serverside form and input elements can be used as a substitute applet Deprecated use the object element instead The language Obsolete attribute on script element redundant with the type attribute Frame related entities iframe noframes target Deprecated in the map link and form elements attribute on a clientside imagemap map link form and base elements The Frameset version includes everything in the Transitional version as well as the frameset element used instead of body and the frame element Frameset versus transitional In addition to the above transitional differences the frameset specifications whether XHTML 10 or HTML 401 specify a different content model with frameset replacing body that contains either frame elements or optionally noframes with a body Summary of specification versions As this list demonstrates the loose versions of the specification are maintained for legacy support However contrary to popular misconceptions the move to XHTML does not imply a removal of this legacy support Rather the X in XML stands for extensible and the W3C is modularizing the entire specification and opens it up to independent extensions The primary achievement in the move from XHTML 10 to XHTML 11 is the modularization of the entire specification The strict version of HTML is deployed in XHTML 11 through a set of modular extensions to the base XHTML 11 specification Likewise someone looking for the loose transitional or frameset specifications will find similar extended XHTML 11 support much of it is contained in the legacy or frame modules Modularization also allows for separate features to develop on their own timetable So for example XHTML 11 will allow quicker migration to emerging XML standards such as MathML a presentational and semantic math language based on XML and XFormsa new highly advanced webform technology to replace the existing HTML forms In summary the HTML 4 specification primarily reined in all the various HTML implementations into a single clearly written specification based on SGML XHTML 10 ported this specification as is to the new XMLdefined specification Next XHTML 11 takes advantage of the extensible nature of XML and modularizes the whole specification XHTML 20 was intended to be the first step in adding new features to the specification in a standardsbodybased approach WHATWG HTML versus HTML5 Main article  Transition of HTML Publication to WHATWG The HTML Living Standard which is developed by WHATWG is the official version while W3C HTML5 is no longer separate from WHATWG WYSIWYG editors This article is missing information about contenteditable Please expand the article to include this information Further details may exist on the talk page January 2021 There are some WYSIWYG editors What You See Is What You Get in which the user lays out everything as it is to appear in the HTML document using a graphical user interface GUI often similar to word processors The editor renders the document rather than showing the code so authors do not require extensive knowledge of HTML The WYSIWYG editing model has been criticized9697 primarily because of the low quality of the generated code there are voiceswho advocating a change to the WYSIWYM model What You See Is What You Mean WYSIWYG editors remain a controversial topic because of their perceived flaws such as Relying mainly on the layout as opposed to meaning often using markup that does not convey the intended meaning but simply copies the layout98 Often producing extremely verbose and redundant code that fails to make use of the cascading nature of HTML and CSS Often producing ungrammatical markup called tag soup or semantically incorrect markup such as em for italics As a great deal of the information in HTML documents is not in the layout the model has been criticized for its what you see is all you getnature99 See also Breadcrumb navigation Comparison of HTML parsers Dynamic web page EMML Motorola HTML character references List of document markup languages List of XML and HTML character entity references Microdata HTML Microformat Polyglot markup Semantic HTML W3C XHTML Validator Web colors References  W3C Html  HTML 40 Specification  W3C Recommendation  Conformance requirements and recommendations World Wide Web Consortium December 18 1997 Archived from the original on July 5 2015 Retrieved July 6 2015  Tim BernersLee Information Management A Proposal CERN March 1989 May 1990 W3C  BernersLee Tim Intended Uses W3C  Tags used in HTML infocernch October 1991 Retrieved 2 March 2023  a b c Tags used in HTML World Wide Web Consortium November 3 1992 Archived from the original on January 31 2010 Retrieved November 16 2008  BernersLee Tim October 29 1991 Re status Re X11 BROWSER for WWW World Wide Web Consortium Archived from the original on May 24 2007 Retrieved April 8 2007  Index of the HTML 4 elements World Wide Web Consortium December 24 1999 Archived from the original on May 5 2007 Retrieved April 8 2007  BernersLee Tim December 9 1991 Re SGMLHTML docs X Browser w3 Archived from the original on December 22 2007 Retrieved June 16 2007 SGML is very general HTML is a specific application of the SGML basic syntax applied to hypertext documents with simple structure  BernersLee Tim Connolly Daniel June 1993 Hypertext Markup Language HTML A Representation of Textual Information and MetaInformation for Retrieval and Interchange w3 Archived from the original on January 3 2017 Retrieved January 4 2017  Raggett Dave A Review of the HTML Document Format w3 Archived from the original on February 29 2000 Retrieved May 22 2020 The hypertext markup language HTML was developed as a simple nonproprietary delivery format for global hypertext HTML is a set of modular extensions to HTML and has been developed in response to a growing understanding of the needs of information providers These extensions include text flow around floating figures fillout forms tables and mathematical equations  BernersLee Tim Connelly Daniel November 1995 Hypertext Markup Language  20 ietforg Internet Engineering Task Force doi1017487RFC1866 RFC 1866 S2CID 6628570 Archived from the original on August 11 2010 Retrieved December 1 2010 This document thus defines an HTML 20 to distinguish it from the previous informal specifications Future generally upwardly compatible versions of HTML with new features will be released with higher version numbers  a b c d e f Raggett Dave 1998 Raggett on HTML 4 Archived from the original on August 9 2007 Retrieved July 9 2007  HTML5  Hypertext Markup Language  50 Internet Engineering Task Force 28 October 2014 Archived from the original on October 28 2014 Retrieved November 25 2014 This document recommends HTML 50 after completion  HTML 32 Reference Specification World Wide Web Consortium January 14 1997 Retrieved November 16 2008  IETF HTML WG Retrieved June 16 2007 Note This working group is closed  a b Engelfriet Arnoud Introduction to Wilbur htmlhelpcom Retrieved June 16 2007  HTML 40 Specification World Wide Web Consortium December 18 1997 Retrieved November 16 2008  HTML 4  4 Conformance requirements and recommendations Retrieved December 30 2009  HTML 40 Specification World Wide Web Consortium April 24 1998 Retrieved November 16 2008  HTML 401 Specification World Wide Web Consortium December 24 1999 Retrieved November 16 2008  HTML 4 Errata W3C Retrieved March 2 2023  a b ISO 2000 ISOIEC 154452000  Information technology  Document description and processing languages  HyperText Markup Language HTML Retrieved March 1 2023  ISOIEC 154452000E ISOHTML wwwscsstcdie Geneva CH ISOIEC May 15 2000 Retrieved March 1 2023  HTML5 A vocabulary and associated APIs for HTML and XHTML World Wide Web Consortium 28 October 2014 Retrieved 31 October 2014  Open Web Platform Milestone Achieved with HTML5 Recommendation Press release World Wide Web Consortium 28 October 2014 Retrieved 31 October 2014  HTML 51 World Wide Web Consortium 1 November 2016 Retrieved 6 January 2017  HTML 51 is a W3C Recommendation World Wide Web Consortium 1 November 2016 Retrieved 6 January 2017  Philippe le Hegaret 17 November 2016 HTML 51 is the gold standard World Wide Web Consortium Retrieved 6 January 2017  HTML 52 World Wide Web Consortium 14 December 2017 Retrieved 15 December 2017  HTML 52 is now a W3C Recommendation World Wide Web Consortium 14 December 2017 Retrieved 15 December 2017  Charles McCathie Nevile 14 December 2017 HTML 52 is done HTML 53 is coming World Wide Web Consortium Retrieved 15 December 2017  Connolly Daniel 6 June 1992 MIME as a hypertext architecture CERN Retrieved 24 October 2010  Connolly Daniel 15 July 1992 HTML DTD enclosed CERN Retrieved 24 October 2010  Connolly Daniel 18 August 1992 document type declaration subset for Hyper Text Markup Language as defined by the World Wide Web project CERN Retrieved 24 October 2010  a b Connolly Daniel 24 November 1992 Document Type Definition for the Hyper Text Markup Language as used by the World Wide Web application CERN Retrieved 24 October 2010 See section Revision History  BernersLee Tim Connolly Daniel June 1993 Hyper Text Markup Language HTML InternetDraft version 11 IETF IIIR Working Group Retrieved 18 September 2010  BernersLee Tim Connolly Daniel June 1993 Hypertext Markup Language HTML InternetDraft version 12 IETF IIIR Working Group Retrieved 18 September 2010  Raggett Dave 19931108 History for draftraggettwwwhtml00 datatrackerietforg Retrieved 20191118  BernersLee Tim Connolly Daniel 28 November 1994 HyperText Markup Language Specification  20 INTERNET DRAFT Internet Engineering Task Force Retrieved 24 October 2010  Connolly connollyw3org Daniel W 19950516 Hypertext Markup Language  20 toolsietforg Retrieved 20191118cite journal CS1 maint numeric names authors list link  BernersLee Tim Connolly Daniel W November 1995 History for draftietfhtmlspec05 datatrackerietforg Retrieved 20191118  HTML 30 Draft Expired Materials World Wide Web Consortium December 21 1995 Retrieved November 16 2008  a b HyperText Markup Language Specification Version 30 Retrieved June 16 2007  Raggett Dave 28 March 1995 HyperText Markup Language Specification Version 30 HTML 30 Internet Draft Expires in six months World Wide Web Consortium Retrieved 17 June 2010  Bowers N 1998 Weblint just another perl hack PDF 1998 USENIX Annual Technical Conference USENIX ATC 98  Lie Håkon Wium Bos Bert April 1997 Cascading style sheets designing for the Web Addison Wesley Longman p 263 ISBN 9780201419986 Retrieved 9 June 2010  HTML5 World Wide Web Consortium June 10 2008 Retrieved November 16 2008  HTML5 one vocabulary two serializations 15 January 2008 Retrieved February 25 2009  W3C Confirms May 2011 for HTML5 Last Call Targets 2014 for HTML5 Standard World Wide Web Consortium 14 February 2011 Retrieved 18 February 2011  Hickson Ian January 19 2011 HTML Is the New HTML5 The WHATWG Blog Archived from the original on 6 October 2019 Retrieved 21 January 2011  Grannell Craig July 23 2012 HTML5 gets the splits Net magazine Archived from the original on Jul 25 2012 Retrieved 23 July 2012  HTML5 W3C 20121217 Retrieved 20130615  When Will HTML5 Be Finished FAQ WHAT Working Group Retrieved 29 November 2009  Call for Review HTML5 Proposed Recommendation Published W3C News W3C 20140916 Retrieved 20140927  Open Web Platform Milestone Achieved with HTML5 Recommendation W3C 28 October 2014 Retrieved 29 October 2014  HTML5 specification finalized squabbling over specs continues Ars Technica 20141029 Retrieved 20141029  HTML vs XML syntax WHATWG Retrieved 22 March 2023  XHTML 10 The Extensible HyperText Markup Language Second Edition World Wide Web Consortium January 26 2000 Retrieved November 16 2008  XHTML 11  Modulebased XHTML  Second Edition World Wide Web Consortium February 16 2007 Retrieved November 16 2008  Modularization of XHTML W3C Retrieved 20170104  XHTM 20 World Wide Web Consortium July 26 2006 Retrieved November 16 2008  XHTML 2 Working Group Expected to Stop Work End of 2009 W3C to Increase Resources on HTML5 World Wide Web Consortium July 17 2009 Retrieved November 16 2008  W3C XHTML FAQ  Jaffe Jeff 28 May 2019 W3C and WHATWG to Work Together to Advance the Open Web Platform W3C Blog Archived from the original on 29 May 2019 Retrieved 29 May 2019  W3C and the WHATWG Signed an Agreement to Collaborate on a Single Version of HTML and DOM W3C 28 May 2019 Archived from the original on 29 May 2019 Retrieved 29 May 2019  Memorandum of Understanding Between W3C and WHATWG W3C 28 May 2019 Archived from the original on 29 May 2019 Retrieved 29 May 2019  Cimpanu Catalin 29 May 2019 Browser vendors Win War with W3C over HTML and DOM standards ZDNet Archived from the original on 29 May 2019 Retrieved 29 May 2019  W3C  WHATWG Wiki WHATWG Wiki Archived from the original on 29 May 2019 Retrieved 29 May 2019  Shankland Stephen July 9 2009 An epitaph for the Web standard XHTML 2 CNET CBS INTERACTIVE INC  Activating Browser Modes with Doctype Hsivonenikifi Retrieved on 20120216  HTML Elements w3schools Retrieved 16 March 2015  CSS Introduction W3schools Retrieved 16 March 2015  On SGML and HTML World Wide Web Consortium Retrieved November 16 2008  XHTML 10  Differences with HTML 4 World Wide Web Consortium Retrieved November 16 2008  Korpela Jukka July 6 1998 Why attribute values should always be quoted in HTML Cstutfi Retrieved November 16 2008  Objects Images and Applets in HTML documents World Wide Web Consortium December 24 1999 Retrieved November 16 2008  H56 Using the dir attribute on an inline element to resolve problems with nested directional runs Techniques for WCAG 20 W3C Retrieved 18 September 2010  Character Entity Reference Chart World Wide Web Consortium October 24 2012  The Named Character Reference  World Wide Web Consortium January 26 2000  The Unicode Standard A Technical Introduction Unicode Retrieved 20100316  The HTML syntax HTML Standard Retrieved 20130819  HTML 4 Frameset Document Type Definition W3C Retrieved 20211225  BernersLee Tim Fischetti Mark 2000 Weaving the Web The Original Design and Ultimate Destiny of the World Wide Web by Its Inventor San Francisco Harper ISBN 9780062515872  Raggett Dave 2002 Adding a touch of style W3C Retrieved October 2 2009 This article notes that presentational HTML markup may be useful when targeting browsers before Netscape 40 and Internet Explorer 40 See the list of web browsers to confirm that these were both released in 1997  BernersLee Tim Hendler James Lassila Ora May 1 2001 The Semantic Web Scientific American Retrieved October 2 2009  Nigel Shadbolt Wendy Hall and Tim BernersLee 2006 The Semantic Web Revisited PDF IEEE Intelligent Systems Retrieved October 2 2009  HTML The Living Standard WHATWG Retrieved 27 September 2018  XHTML 10 The Extensible HyperText Markup Language Second Edition World Wide Web Consortium 2002 2000 Retrieved December 7 2008 XHTML Documents which follow the guidelines set forth in Appendix C HTML Compatibility Guidelines may be labeled with the Internet Media Type texthtml RFC2854 as they are compatible with most HTML browsers Those documents and any other document conforming to this specification may also be labeled with the Internet Media Type applicationxhtmlxml as defined in RFC3236  Bradner Scott O 1997 Key words for use in RFCs to Indicate Requirement Levels Internet Engineering Task Force doi1017487RFC2119 RFC 2119 Retrieved December 7 2008 3 SHOULD This word or the adjective RECOMMENDED mean that there may exist valid reasons in particular circumstances to ignore a particular item but the full implications must be understood and carefully weighed before choosing a different course  XHTML 11  Modulebased XHTML  Second Edition World Wide Web Consortium 2007 Retrieved December 7 2008 XHTML 11 documents SHOULD be labeled with the Internet Media Type texthtml as defined in RFC2854 or applicationxhtmlxml as defined in RFC3236  Naming Files Paths and Namespaces Microsoft Retrieved 16 March 2015  HTML Design Constraints W3C Archives  WWW BTB  HTML Pris Sears  Freeman E 2005 Head First HTML OReilly  Sauer C WYSIWIKI  Questioning WYSIWYG in the Internet Age In Wikimania 2006  Spiesser J Kitchen L Optimization of HTML automatically generated by WYSIWYG programs In 13th International Conference on World Wide Web pp 355364 WWW 04 ACM New York NY New York NY US May 1720 2004  XHTML Reference blockquote Archived 20100325 at the Wayback Machine Xhtmlcom Retrieved on 20120216  Doug Engelbarts INVISIBLE REVOLUTION Invisiblerevolutionnet Retrieved on 20120216 External links Wikibooks has more on the topic of HTML HTML at Wikipedias sister projects Definitions from WiktionaryMedia from CommonsTextbooks from WikibooksResources from WikiversityData from WikidataDiscussions from MetaWikiDocumentation from MediaWiki HTML at Curlie WHATWGs HTML Living Standard Dave Raggetts Introduction to HTML Tim BernersLee Gives the Web a New Definition archived 12 April 2011 List of all HTML elements from all major versions HTML Entities Sean B Palmer Early History of HTML  1990 to 1992 Infomesh Retrieved 20220413 Timeframe 19801995 vteWeb browsers Features standards protocols Features Bookmarks Extensions Privacy mode Web standards HTML v5 CSS DOM JavaScript IndexedDB Web storage WebAssembly WebGL Protocols HTTP Cookies Encryption OCSP WebRTC WebSocket ActiveBlinkbased Google Chrome Chromium Arc Avast Blisk Brave Citrio Coc Coc Dragon Epic Falkon Maxthon Microsoft Edge Opera Otter Puffin Samsung Internet Silk Sleipnir Sputnik SRWare UC Vivaldi Whale Yandex Geckobased Firefox GNU IceCat PirateBrowser SlimBrowser Tor Browser Gecko forks Basilisk KMeleon LibreWolf Pale Moon SeaMonkey Waterfox WebKitbased Safari Dolphin Dooble GNOME Web iCab Konqueror Midori Roccat surf Other 360 DuckDuckGo eww Flow Links Lunascape Lynx NetFront NetSurf QQ browser qutebrowser w3m DiscontinuedBlinkbased Beaker Flock Redcore Rockmelt SalamWeb Torch Geckobased Beonex Communicator Camino Classilla Conkeror Firefox Lite Galeon Ghostzilla IceDragon Kazehakase Kylo Lotus MicroB Minimo Mozilla suite Pogo Strata Swiftfox Swiftweasel TenFourFox Timberwolf xB MSHTMLbased Internet Explorer AOL Deepnet GreenBrowser MediaBrowser NeoPlanet NetCaptor SpaceTime ZAC WebKitbased Arora BOLT Opera Coast Fluid Google TV Iris Mercury OmniWeb Origyn QtWeb rekonq Shiira Steel Browser for Symbian Uzbl WebPositive xombrero Other abaco Amaya Arachne Arena Avant Blazer Cake Charon CM Browser Deepfish Dillo Edge Legacy ELinks Gazelle HotJava IBM Home Page Reader IBM WebExplorer IBrowse KidZui Line Mode Mosaic MSN TV NetPositive Netscape Skweezer Skyfire ThunderHawk Vision WinWAP WorldWideWeb Category Comparisons List vteWorld Wide Web Consortium W3CProducts andstandardsRecommendations ActivityPub Activity Streams ARIA Canonical XML CDF CSS Animations Flexbox Grid DOM Geolocation API HTML HTML5 IndexedDB ITS JSONLD Linked Data Notifications MathML Micropub OWL PLS RDF Schema SISR SKOS SMIL SOAP SRGS SRI SSML SVG Filter Effects SCXML SHACL SPARQL Timed text VoiceXML WoT TD Web storage WSDL Webmention WebSub XHTML RDFa XML Base Encryption Events Information Set Namespace Schema Signature XForms XInclude XLink XOP XPath 20 3x XPointer XProc XQuery XSL XSLFO XSLT elements Notes IndieAuth XAdES XBL XHTMLSMIL XUP Working drafts CCXML CURIE EME InkML MSE RIF SMIL Timesheets sXBL WebGPU WebXR XFDL XFrames XMLHttpRequest Guidelines Web Content Accessibility Guidelines Initiative Markup Validation Service Web Accessibility Initiative Web Components Deprecated CHTML HDML JSSS PGML VML WebPlatform Obsoleted P3P XHTMLMathMLSVG Organizations World Wide Web Foundation Working groups TAG CSS SVG WebAssembly WebAuthn WHATWG Community  business groups Web Advertising BG WebAssembly CG Closed groups Device Description DDWG HTML Multimodal Interaction Activity MMI Software CERN httpd Libwww Browsers Line Mode 1990 Arena 199398 Agora 199497 Argo 199497 Amaya browsereditor 19962012 Conferences International World Wide Web Conference IW3C Steering Committee IW3C2 First conference WWW1 1994 vteDocument markup languagesOffice suite Compound Document Format OOXML SpreadsheetML PresentationML WordprocessingML ODF UOF Wellknown HTML XHTML MathML RTF TeX LaTeX Markdown Lesserknown AmigaGuide AsciiDoc BBCode CML CHTML ConTeXt CrossMark DITA Djot DocBook eLML EAD Enriched text FHTML GML GuideML HDML HyTime IPF LilyPond LinuxDoc Lout MIF MAML MEI MusicXML OMDoc OpenMath Orgmode POD ReStructuredText RTML RFT S1000D Setext TEI Texinfo troff Wikitext WML WapTV XAML List of document markup languages vteISO standards by standard numberList of ISO standards  ISO romanizations  IEC standards19999 1 2 3 4 6 7 9 16 17 31 0 1 3 4 5 6 7 8 9 10 11 12 13 681 128 216 217 226 228 233 259 261 262 302 306 361 500 518 519 639 1 2 3 5 6 646 657 668 690 704 732 764 838 843 860 898 965 999 1000 1004 1007 10731 10732 1155 1413 1538 1629 1745 1989 2014 2015 2022 2033 2047 2108 2145 2146 2240 2281 2533 2709 2711 2720 2788 2848 2852 3029 3103 3166 1 2 3 3297 3307 3601 3602 3864 3901 3950 3977 4031 4157 4165 4217 4909 5218 5426 5427 5428 5725 5775 5776 5800 5807 5964 6166 6344 6346 6373 6385 6425 6429 6438 6523 6709 6943 7001 7002 7010 7027 7064 7098 7185 7200 7498 1 7637 7736 7810 7811 7812 7813 7816 7942 8000 8093 8178 8217 8373 85011 8571 8583 8601 8613 8632 8651 8652 8691 88058806 8807 88205 8859 1 2 3 4 5 6 7 8 8I 9 10 11 12 13 14 15 16 8879 90009001 9036 9075 9126 9141 9227 9241 9293 9314 9362 9407 9496 9506 9529 9564 95929593 9594 9660 97971 9897 9899 9945 9984 9985 9995 1000019999 10006 10007 10116 101183 10160 10161 10165 10179 10206 10218 10279 10303 11 21 22 28 238 10383 10585 10589 10628 10646 10664 10746 10861 10957 10962 10967 11073 11170 11179 11404 11544 11783 11784 11785 11801 11889 11898 11940 2 11941 11941 TR 11992 12006 12052 12182 12207 122342 12620 13211 1 2 13216 13250 13399 134062 13450 13485 13490 13567 13568 13584 13616 13816 14000 14031 14224 14289 14396 14443 14496 2 3 6 10 11 12 14 17 20 14617 14644 14649 14651 14698 14764 14882 14971 15022 15189 15288 15291 15292 15398 15408 15444 3 9 15445 15438 15504 15511 15686 15693 15706 2 15707 15897 15919 15924 15926 15926 WIP 15930 16023 16262 163551 16485 166122 16750 16949 TS 17024 17025 17100 17203 17369 17442 17506 17799 18004 18014 18181 18245 18629 18916 19005 19011 19092 1 2 19114 19115 19125 19136 19407 19439 19500 19501 19502 19503 19505 19506 19507 19508 19509 19510 19600 19752 19757 19770 197751 197945 19831 2000029999 20000 20022 20121 20400 20802 21000 21047 21122 21500 21827 22000 22275 22300 22395 22537 23000 230903 23270 23271 23360 24517 24613 24617 24707 25178 25964 26000 26262 26300 26324 27000 series 27000 27001 27002 27005 27006 27729 28000 29110 29148 291992 29500 30000 30170 31000 32000 37001 38500 40500 42010 45001 50001 55000 56000 80000 Category vteIEC standardsIEC 60027 60034 60038 60062 60063 60068 60112 60228 60269 60297 60309 60320 60364 60446 60559 60601 60870 608705 608706 609061 60908 60929 60958 61030 61131 611313 611319 61158 61162 61334 61355 61360 61400 61499 61508 61511 61784 61850 61851 61883 61960 61968 61970 620144 62026 62056 62061 62196 62262 62264 62304 62325 62351 62365 62366 62379 62386 62455 62680 62682 62700 63110 63119 63382 ISOIEC 646 1989 2022 4909 5218 6429 6523 7810 7811 7812 7813 7816 7942 8613 8632 8652 8859 9126 9293 9496 9529 9592 9593 9899 9945 9995 10021 10116 10165 10179 10279 10646 10967 11172 11179 11404 11544 11801 12207 13250 13346 135225 13568 13816 13818 14443 14496 14651 14882 15288 15291 15408 15444 15445 15504 15511 15693 15897 15938 16262 16485 17024 17025 18004 18014 18181 19752 19757 19770 19788 20000 20802 21000 21827 22275 22537 23000 23003 23008 23270 23360 24707 24727 24744 24752 26300 27000 27000series 27002 27040 29110 29119 33001 38500 42010 80000 81346 Related International Electrotechnical Commission Authority control databases National Spain France BnF data Germany Israel United States Czech Republic Portal Computer programming Retrieved from httpsenwikipediaorgwindexphptitleHTMLoldid1190480010 Categories HTMLComputerrelated introductions in 1990Markup languagesOpen formatsTechnical communicationWorld Wide Web Consortium standardsSGMLHidden categories CS1 maint numeric names authors listWebarchive template wayback linksArticles with short descriptionShort description is different from WikidataWikipedia pages semiprotected against vandalismArticles containing potentially dated statements from 1997All articles containing potentially dated statementsArticles containing potentially dated statements from 1996All articles lacking reliable referencesArticles lacking reliable references from February 2019Articles with specifically marked weaselworded phrases from March 2017All articles with vague or ambiguous timeVague or ambiguous time from March 2022Articles to be expanded from January 2021All articles with specifically marked weaselworded phrasesArticles with specifically marked weaselworded phrases from June 2020Pages using Sister project links with wikidata namespace mismatchPages using Sister project links with hidden wikidataArticles with Curlie linksArticles with BNE identifiersArticles with BNF identifiersArticles with BNFdata identifiersArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with NKC identifiersArticles with example code ,https://en.wikipedia.org/wiki/HTML,Front-End Development,3166,10712
CSS for Styling, From Wikipedia the free encyclopedia Style sheet language Cascading Style Sheets and Pseudoelement redirect here For pseudoelement symbols in chemistry see Skeletal formula  Pseudoelement symbols For other uses see CSS disambiguation Cascading Style Sheets CSSThe official logo of the latest version CSS 3Example of CSS source codeFilename extension cssInternet media type textcssUniform Type Identifier UTIpubliccssDeveloped byWorld Wide Web Consortium W3CInitial release17 December 1996 27 years ago 19961217Latest releaseCSS 21  Level 2 Revision 112 April 2016 7 years ago 20160412 Type of formatStyle sheet languageContainer forStyle rules for HTML elements tagsContained byHTML DocumentsOpen formatYesWebsitewwww3orgTRCSScss Cascading Style Sheets Style sheet CSS Zen Garden Concepts animations box model image replacement flexbox grid Philosophies Tableless Responsive Holy grail Tools Sass Less Stylus CSSTidy Comparisons Stylesheet languages Cascading Style Sheetsvte HTML Dynamic HTML HTML5 article audio canvas video XHTML Basic Mobile Profile HTML element meta div and span blink marquee HTML attribute alt attribute HTML frame HTML editor Character encodings named characters Unicode Language code Document Object Model Browser Object Model Style sheets CSS Font family Web colors JavaScript WebCL Web3D WebGL WebGPU WebXR W3C Validator WHATWG Quirks mode Web storage Rendering engine Comparisons Document markup languages Comparison of browser engines vte Cascading Style Sheets CSS is a style sheet language used for specifying the presentation and styling of a document written in a markup language such as HTML or XML including XML dialects such as SVG MathML or XHTML1 CSS is a cornerstone technology of the World Wide Web alongside HTML and JavaScript2 CSS is designed to enable the separation of content and presentation including layout colors and fonts3 This separation can improve content accessibility provide more flexibility and control in the specification of presentation characteristics enable multiple web pages to share formatting by specifying the relevant CSS in a separate css file which reduces complexity and repetition in the structural content and enable the css file to be cached to improve the page load speed between the pages that share the file and its formatting Separation of formatting and content also makes it feasible to present the same markup page in different styles for different rendering methods such as onscreen in print by voice via speechbased browser or screen reader and on Braillebased tactile devices CSS also has rules for alternate formatting if the content is accessed on a mobile device4 The name cascading comes from the specified priority scheme to determine which style rule applies if more than one rule matches a particular element This cascading priority scheme is predictable The CSS specifications are maintained by the World Wide Web Consortium W3C Internet media type MIME type textcss is registered for use with CSS by RFC 2318 March 1998 The W3C operates a free CSS validation service for CSS documents5 In addition to HTML other markup languages support the use of CSS including XHTML plain XML SVG and XUL CSS is also used in the GTK widget toolkit Syntaxedit CSS has a simple syntax and uses a number of English keywords to specify the names of various style properties Style sheetedit Main article Style sheet web development A style sheet consists of a list of rules Each rule or ruleset consists of one or more selectors and a declaration block Selectoredit CSS class redirects here For nonCSS use of element classes in HTML see class attribute HTML In CSS selectors declare which part of the markup a style applies to by matching tags and attributes in the markup itself Selector typesedit Selectors may apply to the following all elements of a specific type eg the secondlevel headers h2 elements specified by attribute in particular id an identifier unique within the document denoted in the selector language by a hash prefix eg id class an identifier that can annotate multiple elements in a document denoted by a dot prefix eg classname the phrase CSS class although sometimes used is a misnomer as element classesspecified with the HTML class attributeis a markup feature that is distinct from browsers CSS subsystem and the related W3CWHATWG standards work on document styles see RDF and microformats for the origins of the class system of the Web content model elements depending on how they are placed relative to others in the document tree Classes and IDs are casesensitive start with letters and can include alphanumeric characters hyphens and underscores A class may apply to any number of instances of any element An ID may only be applied to a single element Pseudoclassesedit Pseudoclasses are used in CSS selectors to permit formatting based on information that is not contained in the document tree One example of a widely used pseudoclass is hover which identifies content only when the user points to the visible element usually by holding the mouse cursor over it It is appended to a selector as in ahover or elementidhover A pseudoclass classifies document elements such as link or visited whereas a pseudoelement makes a selection that may consist of partial elements such as firstline or firstletter6 Note the distinction between the doublecolon notation used for pseudoelements and the singlecolon notation used for pseudoclasses Combinatorsedit Multiple simple selectors may be joined using combinators to specify elements by location element type id class or any combination thereof7 The order of the selectors is important For example div myClass color red applies to all elements of class myClass that are inside div elements whereas myClass div color red applies to all div elements that are inside elements of class myClass This is not to be confused with concatenated identifiers such as divmyClass color red which applies to div elements of class myClass Summary of selector syntaxedit The following table provides a summary of selector syntax indicating usage and the version of CSS that introduced it8 Pattern Matches First definedin CSS level E an element of type E 1 Elink an E element that is the source anchor of a hyperlink whose target is either not yet visited link or already visited visited 1 Eactive an E element during certain user actions 1 Efirstline the first formatted line of an E element 1 Efirstletter the first formatted letter of an E element 1 c all elements with classc 1 myid the element with idmyid 1 Ewarning an E element whose class is warning the document language specifies how class is determined 1 Emyid an E element with ID equal to myid 1 cmyid the element with classc and ID equal to myid 1 E F an F element descendant of an E element 1  any element 2 Efoo an E element with a foo attribute 2 Efoobar an E element whose foo attribute value is exactly equal to bar 2 Efoobar an E element whose foo attribute value is a list of whitespaceseparated values one of which is exactly equal to bar 2 Efooen an E element whose foo attribute has a hyphenseparated list of values beginning from the left with en 2 Efirstchild an E element first child of its parent 2 Elangfr an element of type E in language fr the document language specifies how language is determined 2 Ebefore generated content before an E elements content 2 Eafter generated content after an E elements content 2 E  F an F element child of an E element 2 E  F an F element immediately preceded by an E element 2 Efoobar an E element whose foo attribute value begins exactly with the string bar 3 Efoobar an E element whose foo attribute value ends exactly with the string bar 3 Efoobar an E element whose foo attribute value contains the substring bar 3 Eroot an E element root of the document 3 Enthchildn an E element the nth child of its parent 3 Enthlastchildn an E element the nth child of its parent counting from the last one 3 Enthoftypen an E element the nth sibling of its type 3 Enthlastoftypen an E element the nth sibling of its type counting from the last one 3 Elastchild an E element last child of its parent 3 Efirstoftype an E element first sibling of its type 3 Elastoftype an E element last sibling of its type 3 Eonlychild an E element only child of its parent 3 Eonlyoftype an E element only sibling of its type 3 Eempty an E element that has no children including text nodes 3 Etarget an E element being the target of the referring URI 3 Eenabled a user interface element E that is enabled 3 Edisabled a user interface element E that is disabled 3 Echecked a user interface element E that is checked for instance a radio button or checkbox 3 Enots an E element that does not match simple selector s 3 E  F an F element preceded by an E element 3 Declaration blockedit A declaration block consists of a pair of braces  enclosing a semicolonseparated list of declarations9 Declarationedit Each declaration itself consists of a property a colon  and a value Optional whitespace may be around the declaration block declarations colons and semicolons for readability10 Propertiesedit Properties are specified in the CSS standard Each property has a set of possible values Some properties can affect any type of element and others apply only to particular groups of elements1112 Valuesedit Values may be keywords such as center or inherit or numerical values such as 200px 200 pixels 50vw 50 percent of the viewport width or 80 80 percent of the parent elements width Color values can be specified with keywords eg red hexadecimal values eg FF0000 also abbreviated as F00 RGB values on a 0 to 255 scale eg rgb255 0 0 RGBA values that specify both color and alpha transparency eg rgba255 0 0 08 or HSL or HSLA values eg hsl000 100 50 hsla000 100 50 8013 Nonzero numeric values representing linear measures must include a length unit which is either an alphabetic code or abbreviation as in 200px or 50vw or a percentage sign as in 80 Some units  cm centimetre in inch mm millimetre pc pica and pt point  are absolute which means that the rendered dimension does not depend upon the structure of the page others  em em ex ex and px pixelclarification needed  are relative which means that factors such as the font size of a parent element can affect the rendered measurement These eight units were a feature of CSS 114 and retained in all subsequent revisions The proposed CSS Values and Units Module Level 3 will if adopted as a W3C Recommendation provide seven further length units ch Q rem vh vmax vmin and vw15 Useedit Before CSS nearly all presentational attributes of HTML documents were contained within the HTML markup All font colors background styles element alignments borders and sizes had to be explicitly described often repeatedly within the HTML CSS lets authors move much of that information to another file the style sheet resulting in considerably simpler HTML And additionally as more and more devices are able to access responsive web pages different screen sizes and layouts begin to appear Customizing a website for each device size is costly and increasingly difficult The modular nature of CSS means that styles can be reused in different parts of a site or even across sites promoting consistency and efficiency For example headings h1 elements subheadings h2 subsubheadings h3 etc are defined structurally using HTML In print and on the screen choice of font size color and emphasis for these elements is presentational Before CSS document authors who wanted to assign such typographic characteristics to say all h2 headings had to repeat HTML presentational markup for each occurrence of that heading type This made documents more complex larger and more errorprone and difficult to maintain CSS allows the separation of presentation from structure CSS can define color font text alignment size borders spacing layout and many other typographic characteristics and can do so independently for onscreen and printed views CSS also defines nonvisual styles such as reading speed and emphasis for aural text readers The W3C has now deprecated the use of all presentational HTML markup16 For example under preCSS HTML a heading element defined with red text would be written as h1font colorredChapter 1fonth1 Using CSS the same element can be coded using style properties instead of HTML presentational attributes h1 stylecolor redChapter 1h1 The advantages of this may not be immediately clear but the power of CSS becomes more apparent when the style properties are placed in an internal style element or even better an external CSS file For example suppose the document contains the style element style h1  color red  style All h1 elements in the document will then automatically become red without requiring any explicit code If the author later wanted to make h1 elements blue instead this could be done by changing the style element to style h1  color blue  style rather than by laboriously going through the document and changing the color for each individual h1 element The styles can also be placed in an external CSS file as described below and loaded using syntax similar to link hrefpathtofilecss relstylesheet typetextcss This further decouples the styling from the HTML document and makes it possible to restyle multiple documents by simply editing a shared external CSS file Sourcesedit CSS or Cascading Style Sheets offers a flexible way to style web content with styles originating from browser defaults user preferences or web designers These styles can be applied inline within an HTML document or through external css files for broader consistency Not only does this simplify web development by promoting reusability and maintainability it also improves site performance because styles can be offloaded into dedicated css files that browsers can cache Additionally even if the styles cannot be loaded or are disabled this separation maintains the accessibility and readability of the content ensuring that the site is usable for all users including those with disabilities Its multifaceted approach including considerations for selector specificity rule order and media types ensures that websites are visually coherent and adaptive across different devices and user needs striking a balance between design intent and user accessibility Multiple style sheetsedit Multiple style sheets can be imported Different styles can be applied depending on the output device being used for example the screen version can be quite different from the printed version so authors can tailor the presentation appropriately for each medium Cascadingedit The style sheet with the highest priority controls the content display Declarations not set in the highest priority source are passed on to a source of lower priority such as the user agent style The process is called cascading One of the goals of CSS is to allow users greater control over presentation Someone who finds red italic headings difficult to read may apply a different style sheet Depending on the browser and the website a user may choose from various style sheets provided by the designers or may remove all added styles and view the site using the browsers default styling or may override just the red italic heading style without altering other attributes Browser extensions like Stylish and Stylus have been created to facilitate the management of such user style sheets In the case of large projects cascading can be used to determine which style has a higher priority when developers do integrate thirdparty styles that have conflicting priorities and to further resolve those conflicts Additionally cascading can help create themed designs which help designers finetune aspects of a design without compromising the overall layout CSS priority schemeedit CSS priority scheme highest to lowest Priority CSS source type Description 1 Importance The important annotation overwrites the previous priority types 2 Inline A style applied to an HTML element via HTML style attribute 3 Media Type A property definition applies to all media types unless a mediaspecific CSS is defined 4 User defined Most browsers have the accessibility feature a userdefined CSS 5 Selector specificity A specific contextual selector heading p overwrites generic definition 6 Rule order Last rule declaration has a higher priority 7 Parent inheritance If a property is not specified it is inherited from a parent element 8 CSS property definition in HTML document CSS rule or CSS inline style overwrites a default browser value 9 Browser default The lowest priority browser default value is determined by W3C initial value specifications Specificityedit Specificity refers to the relative weights of various rules17 It determines which styles apply to an element when more than one rule could apply Based on the specification a simple selector eg H1 has a specificity of 1 class selectors have a specificity of 10 and ID selectors have a specificity of 100 Because the specificity values do not carry over as in the decimal system commas are used to separate the digits18 a CSS rule having 11 elements and 11 classes would have a specificity of 1111 not 121 Thus the selectors of the following rule result in the indicated specificity Selectors Specificity h1 color white 0 0 0 1 p em color green 0 0 0 2 grape color red 0 0 1 0 pbright color blue 0 0 1 1 pbright emdark color yellow 0 0 2 2 id218 color brown 0 1 0 0 style  1 0 0 0 Examplesedit Consider this HTML fragment DOCTYPE html html head meta charsetutf8 style xyz  color blue  style head body p idxyz stylecolor greenTo demonstrate specificityp body html In the above example the declaration in the style attribute overrides the one in the style element because it has a higher specificity and thus the paragraph appears green To demonstrate specificity Inheritanceedit Inheritance is a key feature in CSS it relies on the ancestordescendant relationship to operate Inheritance is the mechanism by which properties are applied not only to a specified element but also to its descendants17 Inheritance relies on the document tree which is the hierarchy of XHTML elements in a page based on nesting Descendant elements may inherit CSS property values from any ancestor element enclosing them In general descendant elements inherit textrelated properties but their boxrelated properties are not inherited Properties that can be inherited are color font letter spacing lineheight liststyle textalign textindent texttransform visibility whitespace and wordspacing Properties that cannot be inherited are background border display float and clear height and width margin min and maxheight and width outline overflow padding position textdecoration verticalalign and zindex Inheritance can be used to avoid declaring certain properties over and over again in a style sheet allowing for shorter CSS Inheritance in CSS is not the same as inheritance in classbased programming languages where it is possible to define class B as like class A but with modifications19 With CSS it is possible to style an element with class A but with modifications However it is not possible to define a CSS class B like that which could then be used to style multiple elements without having to repeat the modifications Exampleedit Given the following style sheet p  color pink  Suppose there is a p element with an emphasizing element em inside p This is to emillustrateem inheritance p If no color is assigned to the em element the emphasized word illustrate inherits the color of the parent element p The style sheet p has the color pink hence the em element is likewise pink This is to illustrate inheritance Whitespaceedit The whitespace between properties and selectors is ignored This code snippet bodyoverflowhiddenbackground000000backgroundimageurlimagesbggifbackgroundrepeatnorepeatbackgroundpositionleft top is functionally equivalent to this one body  overflow hidden backgroundcolor 000000 backgroundimage urlimagesbggif backgroundrepeat norepeat backgroundposition left top  Indentationedit Main article Indentation style One common way to format CSS for readability is to indent each property and give it its own line In addition to formatting CSS for readability shorthand properties can be used to write out the code faster which also gets processed more quickly when being rendered20 body  overflow hidden background 000 urlimagesbggif norepeat left top  Sometimes multiple property values are indented onto their own linefontface  fontfamily Comic Sans fontsize 20px src urlfirstexamplecom urlsecondexamplecom urlthirdexamplecom urlfourthexamplecom  Positioningedit CSS 21 defines three positioning schemes Normal flow Inline items are laid out in the same way as the letters in words in the text one after the other across the available space until there is no more room then starting a new line below Block items stack vertically like paragraphs and like the items in a bulleted list Normal flow also includes the relative positioning of block or inline items and runin boxes Floats A floated item is taken out of the normal flow and shifted to the left or right as far as possible in the space available Other content then flows alongside the floated item Absolute positioning An absolutely positioned item has no place in and no effect on the normal flow of other items It occupies its assigned position in its container independently of other items21 Position propertyedit There are five possible values of the position property If an item is positioned in any way other than static then the further properties top bottom left and right are used to specify offsets and positionsThe element having position static is not affected by the top bottom  left or right properties Staticedit The default value places the item in the normal flow Relativeedit The item is placed in the normal flow and then shifted or offset from that position Subsequent flow items are laid out as if the item had not been moved Absoluteedit Specifies absolute positioning The element is positioned in relation to its nearest nonstatic ancestor Fixededit The item is absolutely positioned in a fixed position on the screen even as the rest of the document is scrolled21 Float and clearedit The float property may have one of three values Absolutely positioned or fixed items cannot be floated Other elements normally flow around floated items unless they are prevented from doing so by their clear property left The item floats to the left of the line that it would have appeared in other items may flow around its right side right The item floats to the right of the line that it would have appeared in other items may flow around its left side clear Forces the element to appear underneath clear floated elements to the left clearleft right clearright or both sides clearboth2122 Historyedit Håkon Wium Lie chief technical officer of the Opera Software company and cocreator of the CSS web standards CSS was first proposed by Håkon Wium Lie on 10 October 199423 At the time Lie was working with Tim BernersLee at CERN24 Several other style sheet languages for the web were proposed around the same time and discussions on public mailing lists and inside World Wide Web Consortium resulted in the first W3C CSS Recommendation CSS125 being released in 1996 In particular a proposal by Bert Bos was influential he became coauthor of CSS1 and is regarded as cocreator of CSS26 Style sheets have existed in one form or another since the beginnings of Standard Generalized Markup Language SGML in the 1980s and CSS was developed to provide style sheets for the web27 One requirement for a web style sheet language was for style sheets to come from different sources on the web Therefore existing style sheet languages like DSSSL and FOSI were not suitable CSS on the other hand let a documents style be influenced by multiple style sheets by way of cascading styles27 As HTML grew it came to encompass a wider variety of stylistic capabilities to meet the demands of web developers This evolution gave the designer more control over site appearance at the cost of more complex HTML Variations in web browser implementations such as ViolaWWW and WorldWideWeb28 made consistent site appearance difficult and users had less control over how web content was displayed The browsereditor developed by Tim BernersLee had style sheets that were hardcoded into the program The style sheets could therefore not be linked to documents on the web24 Robert Cailliau also of CERN wanted to separate the structure from the presentation so that different style sheets could describe different presentation for printing screenbased presentations and editors28 Improving web presentation capabilities was a topic of interest to many in the web community and nine different style sheet languages were proposed on the wwwstyle mailing list27 Of these nine proposals two were especially influential on what became CSS Cascading HTML Style Sheets23 and Streambased Style Sheet Proposal SSP2629 Two browsers served as testbeds for the initial proposals Lie worked with Yves Lafon to implement CSS in Dave Raggetts Arena browser303132 Bert Bos implemented his own SSP proposal in the Argo browser26 Thereafter Lie and Bos worked together to develop the CSS standard the H was removed from the name because these style sheets could also be applied to other markup languages besides HTML24 Lies proposal was presented at the Mosaic and the Web conference later called WWW2 in Chicago Illinois in 1994 and again with Bert Bos in 199524 Around this time the W3C was already being established and took an interest in the development of CSS It organized a workshop toward that end chaired by Steven Pemberton This resulted in W3C adding work on CSS to the deliverables of the HTML editorial review board ERB Lie and Bos were the primary technical staff on this aspect of the project with additional members including Thomas Reardon of Microsoft participating as well In August 1996 Netscape Communication Corporation presented an alternative style sheet language called JavaScript Style Sheets JSSS24 The spec was never finished and is deprecated33 By the end of 1996 CSS was ready to become official and the CSS level 1 Recommendation was published in December Development of HTML CSS and the DOM had all been taking place in one group the HTML Editorial Review Board ERB Early in 1997 the ERB was split into three working groups HTML Working Group chaired by Dan Connolly of W3C DOM Working group chaired by Lauren Wood of SoftQuad and CSS Working Group chaired by Chris Lilley of W3C The CSS Working Group began tackling issues that had not been addressed with CSS level 1 resulting in the creation of CSS level 2 on November 4 1997 It was published as a W3C Recommendation on May 12 1998 CSS level 3 which was started in 1998 is still under development as of 2014update In 2005 the CSS Working Groups decided to enforce the requirements for standards more strictly This meant that already published standards like CSS 21 CSS 3 Selectors and CSS 3 Text were pulled back from Candidate Recommendation to Working Draft level Difficulty with adoptionedit The CSS 1 specification was completed in 1996 Microsofts Internet Explorer 324 was released that year featuring some limited support for CSS IE 4 and Netscape 4x added more support but it was typically incomplete and had many bugs that prevented CSS from being usefully adopted It was more than three years before any web browser achieved nearfull implementation of the specification Internet Explorer 50 for the Macintosh shipped in March 2000 was the first browser to have full better than 99 percent CSS 1 support34 surpassing Opera which had been the leader since its introduction of CSS support fifteen months earlier Other browsers followed soon afterward and many of them additionally implemented parts of CSS 2 However even when later version 5 web browsers began to offer a fairly full implementation of CSS they were still incorrect in certain areas They were fraught with inconsistencies bugs and other quirks Microsoft Internet Explorer 5 x for Windows as opposed to the very different IE for Macintosh had a flawed implementation of the CSS box model as compared with the CSS standards Such inconsistencies and variation in feature support made it difficult for designers to achieve a consistent appearance across browsers and platforms without the use of workarounds termed CSS hacks and filters The IE Windows box model bugs were so serious that when Internet Explorer 6 was released Microsoft introduced a backwardcompatible mode of CSS interpretation quirks mode alongside an alternative corrected standards mode Other nonMicrosoft browsers also provided modeswitch capabilities It therefore became necessary for authors of HTML files to ensure they contained special distinctive standardscompliant CSS intended marker to show that the authors intended CSS to be interpreted correctly in compliance with standards as opposed to being intended for the now longobsolete IE5Windows browser Without this marker web browsers with the quirks modeswitching capability will size objects in web pages as IE 5 on Windows would rather than following CSS standards Problems with the patchy adoption of CSS and errata in the original specification led the W3C to revise the CSS 2 standards into CSS 21 which moved nearer to a working snapshot of current CSS support in HTML browsers Some CSS 2 properties that no browser successfully implemented were dropped and in a few cases defined behaviors were changed to bring the standard into line with the predominant existing implementations CSS 21 became a Candidate Recommendation on February 25 2004 but CSS 21 was pulled back to Working Draft status on June 13 200535 and only returned to Candidate Recommendation status on July 19 200736 In addition to these problems the css extension was used by a software product used to convert PowerPoint files into Compact Slide Show files37 so some web servers served all css38 as MIME type applicationxpointplus39 rather than textcss Vendor prefixesedit Individual browser vendors occasionally introduced new parameters ahead of standardization and universalization To prevent interfering with future implementations vendors prepended unique names to the parameters such as moz for Mozilla Firefox webkit named after the browsing engine of Apple Safari o for Opera Browser and ms for Microsoft Internet Explorer and early versions of Microsoft Edge that use EdgeHTML Occasionally the parameters with vendor prefixes such as mozradialgradient and webkitlineargradient have slightly different syntax as compared to their nonvendorprefix counterparts40 Prefixed properties are rendered obsolete by the time of standardization Programs are available to automatically add prefixes for older browsers and to point out standardized versions of prefixed parameters Since prefixes are limited to a small subset of browsers removing the prefix allows other browsers to see the functionality An exception is certain obsolete webkit prefixed properties which are so common and persistent on the web that other families of browsers have decided to support them for compatibility41 Variationsedit CSS Snapshot 2021 CSS has various levels and profiles Each level of CSS builds upon the last typically adding new features and typically denotedcitation needed as CSS 1 CSS 2 CSS 3 and CSS 4 Profiles are typically a subset of one or more levels of CSS built for a particular device or user interface Currently there are profiles for mobile devices printers and television sets Profiles should not be confused with media types which were added in CSS 2 CSS 1edit The first CSS specification to become an official W3C Recommendation is CSS level 1 published on 17 December 1996 Håkon Wium Lie and Bert Bos are credited as the original developers4243 Among its capabilities are support for Font properties such as typeface and emphasis Color of text backgrounds and other elements Text attributes such as spacing between words letters and lines of text Alignment of text images tables and other elements Margin border padding and positioning for most elements Unique identification and generic classification of groups of attributes The W3C no longer maintains the CSS 1 Recommendation44 CSS 2edit CSS level 2 specification was developed by the W3C and published as a recommendation in May 1998 A superset of CSS 1 CSS 2 includes a number of new capabilities like absolute relative and fixed positioning of elements and zindex the concept of media types support for aural style sheets which were later replaced by the CSS 3 speech modules45 and bidirectional text and new font properties such as shadows The W3C no longer maintains the CSS 2 recommendation46 CSS 21edit CSS level 2 revision 1 often referred to as CSS 21 fixes errors in CSS 2 removes poorly supported or not fully interoperable features and adds already implemented browser extensions to the specification To comply with the W3C Process for standardizing technical specifications CSS 21 went back and forth between Working Draft status and Candidate Recommendation status for many years CSS 21 first became a Candidate Recommendation on 25 February 2004 but it was reverted to a Working Draft on 13 June 2005 for further review It returned to Candidate Recommendation on 19 July 2007 and then updated twice in 2009 However because changes and clarifications were made it again went back to Last Call Working Draft on 7 December 2010 CSS 21 went to Proposed Recommendation on 12 April 201147 After being reviewed by the W3C Advisory Committee it was finally published as a W3C Recommendation on 7 June 201148 CSS 21 was planned as the first and final revision of level 2but lowpriority work on CSS 22 began in 2015 CSS 3edit CSS3 redirects here For other uses see CSS3 disambiguation Unlike CSS 2 which is a large single specification defining various features CSS 3 is divided into several separate documents called modules Each module adds new capabilities or extends features defined in CSS 2 preserving backward compatibility Work on CSS level 3 started around the time of publication of the original CSS 2 recommendation The earliest CSS 3 drafts were published in June 199949 Due to the modularization different modules have different stability and statuses50 Some modules have Candidate Recommendation CR status and are considered moderately stable At CR stage implementations are advised to drop vendor prefixes51 Summary of main modulespecifications52 Module Specification title Status Date css3background CSS Backgrounds and Borders Module Level 3 Candidate Rec Feb 2023 cssbox3 CSS Box Model Module Level 3 Recommendation Apr 2023 csscascade3 CSS Cascading and Inheritance Level 3 Recommendation Feb 2021 csscolor3 CSS Color Module Level 3 Recommendation Jan 2022 css3content CSS Generated Content Module Level 3 Working Draft Aug 2019 cssfonts3 CSS Fonts Module Level 3 Recommendation Sep 2018 css3gcpm CSS Generated Content for Paged Media Module Working Draft May 2014 css3layout CSS Template Layout Module Note Mar 2015 css3mediaqueries Media Queries Recommendation Jun 2012 mediaqueries4 Media Queries Level 4 Candidate Rec Dec 2021 css3multicol Multicolumn Layout Module Level 1 Candidate Rec Oct 2021 css3page CSS Paged Media Module Level 3 Working Draft and part migrated to css3break Oct 2018 css3break CSS Fragmentation Module Level 3 Candidate Rec Dec 2018 selectors3 Selectors Level 3 Recommendation Nov 2018 selectors4 Selectors Level 4 Working Draft Nov 2022 css3ui CSS Basic User Interface Module Level 3 CSS3 UI Recommendation Jun 2018 CSS 4edit CSS4 redirects here For other uses see CSS4 disambiguation Jen Simmons discussing the state of CSS in 2019 as several CSS 4 modules were being advanced There is no single integrated CSS4 specification53 because the specification has been split into many separate modules which level independently Modules that build on things from CSS Level 2 started at Level 3 Some of them have already reached Level 4 or are already approaching Level 5 Other modules that define entirely new functionality such as Flexbox54 have been designated as Level 1 and some of them are approaching Level 2 The CSS Working Group sometimes publishes Snapshots a collection of whole modules and parts of other drafts that are considered stable enough to be implemented by browser developers So far five such best current practices documents have been published as Notes in 200755 201056 201557 201758 and 201859 Since these specification snapshots are primarily intended for developers there has been a growing demand for a similar versioned reference document targeted at authors which would present the state of interoperable implementations as meanwhile documented by sites like Can I Use60 and the MDN Web Docs61 A W3C Community Group has been established in early 2020 in order to discuss and define such a resource62 The actual kind of versioning is also up to debate which means that the document once produced might not be called CSS4 Browser supportedit Each web browser uses a layout engine to render web pages and support for CSS functionality is not consistent between them Because browsers do not parse CSS perfectly multiple coding techniques have been developed to target specific browsers with workarounds commonly known as CSS hacks or CSS filters The adoption of new functionality in CSS can be hindered by a lack of support in major browsers For example Internet Explorer was slow to add support for many CSS 3 features which slowed the adoption of those features and damaged the browsers reputation among developers Additionally a proprietary syntax for the nonvendorprefixed filter property was used in some versions63 In order to ensure a consistent experience for their users web developers often test their sites across multiple operating systems browsers and browser versions increasing development time and complexity Tools such as BrowserStack have been built to reduce the complexity of maintaining these environments In addition to these testing tools many sites maintain lists of browser support for specific CSS properties including CanIUse and the MDN Web Docs Additionally CSS 3 defines feature queries which provide an supports directive that will allow developers to target browsers with support for certain functionality directly within their CSS64 CSS that is not supported by older browsers can also sometimes be patched in using JavaScript polyfills which are pieces of JavaScript code designed to make browsers behave consistently These workaroundsand the need to support fallback functionalitycan add complexity to development projects and consequently companies frequently define a list of browser versions that they will and will not support As websites adopt newer code standards that are incompatible with older browsers these browsers can be cut off from accessing many of the resources on the web sometimes intentionally65 Many of the most popular sites on the internet are not just visually degraded on older browsers due to poor CSS support but do not work at all in large part due to the evolution of JavaScript and other web technologies Limitationsedit Some noted limitations of the current capabilities of CSS include Cannot explicitly declare new scope independently of positionedit Scoping rules for properties such as zindex look for the closest parent element with a position absolute or position relative attribute This odd coupling has undesired effects For example it is impossible to avoid declaring a new scope when one is forced to adjust an elements position preventing one from using the desired scope of a parent element Pseudoclass dynamic behavior not controllableedit CSS implements pseudoclasses that allow a degree of user feedback by conditional application of alternate styles One CSS pseudoclass hover is dynamic equivalent of JavaScript onmouseover and has potential for misuse eg implementing cursorproximity popups66 but CSS has no ability for a client to disable it no disablelike property or limit its effects no nochangelike values for each property Cannot name rulesedit There is no way to name a CSS rule which would allow for example clientside scripts to refer to the rule even if its selector changes Cannot include styles from a rule into another ruleedit CSS styles often must be duplicated in several rules to achieve the desired effect causing additional maintenance and requiring more thorough testing Some new CSS features were proposed to solve this but were abandoned afterward6768 Instead authors may gain this ability by using more sophisticated stylesheet languages which compile to CSS such as Sass Less or Stylus Cannot target specific text without altering markupedit Besides the firstletter pseudoelement one cannot target specific ranges of text without needing to utilize placeholder elements Advantagesedit Separation of content from presentationedit Main article Separation of content and presentation CSS facilitates the publication of content in multiple presentation formats based on nominal parameters Nominal parameters include explicit user preferences different web browsers the type of device being used to view the content a desktop computer or mobile device the geographic location of the user and many other variables Sitewide consistencyedit Main article Style sheet web development When CSS is used effectively in terms of inheritance and cascading a global style sheet can be used to affect and style elements sitewide If the situation arises that the styling of the elements should be changed or adjusted these changes can be made by editing rules in the global style sheet Before CSS this sort of maintenance was more difficult expensive and timeconsuming Bandwidthedit A stylesheet internal or external specifies the style once for a range of HTML elements selected by class type or relationship to others This is much more efficient than repeating style information inline for each occurrence of the element An external stylesheet is usually stored in the browser cache and can therefore be used on multiple pages without being reloaded further reducing data transfer over a network Page reformattingedit Main article Progressive enhancement With a simple change of one line a different style sheet can be used for the same page This has advantages for accessibility as well as providing the ability to tailor a page or site to different target devices Furthermore devices not able to understand the styling still display the content Accessibilityedit Main article Tableless web design  Accessibility Without CSS web designers must typically lay out their pages with techniques such as HTML tables that hinder accessibility for visionimpaired users see Tableless web designAccessibility Standardizationedit Frameworksedit Main article CSS framework CSS frameworks are preprepared libraries that are meant to allow for easier more standardscompliant styling of web pages using the Cascading Style Sheets language CSS frameworks include Blueprint Bootstrap Foundation and Materialize Like programming and scripting language libraries CSS frameworks are usually incorporated as external css sheets referenced in the HTML head They provide a number of readymade options for designing and laying out the web page Although many of these frameworks have been published some authors use them mostly for rapid prototyping or for learning from and prefer to handcraft CSS that is appropriate to each published site without the design maintenance and download overhead of having many unused features in the sites styling69 Blueprintedit This paragraph is an excerpt from Blueprint CSS frameworkedit Blueprint is a CSS framework designed to reduce development time and ensure crossbrowser compatibility when working with Cascading Style Sheets CSS It also serves as a foundation for many tools designed to make CSS development easier and more accessible to beginners Bootstrapedit This paragraph is an excerpt from Bootstrap frontend frameworkedit Bootstrap is a free and opensource CSS framework directed at responsive mobilefirst frontend web development It contains HTML CSS and optionally JavaScriptbased design templates for typography forms buttons navigation and other interface components Foundationedit This paragraph is an excerpt from Foundation frameworkedit Foundation is a free responsive frontend framework providing a responsive grid and HTML and CSS UI components templates and code snippets including typography forms buttons navigation and other interface elements as well as optional functionality provided by JavaScript extensions Foundation is an open source project and was formerly maintained by ZURB Since 2019 Foundation has been maintained by volunteers70 Design methodologiesedit As the size of CSS resources used in a project increases a development team often needs to decide on a common design methodology to keep them organized The goals are ease of development ease of collaboration during development and performance of the deployed stylesheets in the browser Popular methodologies include OOCSS objectoriented CSS ACSS atomic CSS CSS organic Cascade Style Sheet SMACSS scalable and modular architecture for CSS and BEM block element modifier71 See alsoedit Flash of unstyled content Referencesedit  CSS developer guide MDN Web Docs Archived from the original on 20150925 Retrieved 20150924  Flanagan David 18 April 2011 JavaScript the definitive guide Beijing Farnham OReilly p 1 ISBN 9781449393854 OCLC 686709345 JavaScript is part of the triad of technologies that all Web developers must learn HTML to specify the content of web pages CSS to specify the presentation of web pages and JavaScript to specify the behavior of web pages  What is CSS World Wide Web Consortium Archived from the original on 20101129 Retrieved 20101201  Clark Scott 23 July 2010 Webbased Mobile Apps of the Future Using HTML 5 CSS and JavaScript HTML Goodies HTMLGoodies Archived from the original on 20141020 Retrieved 20141016  W3C CSS validation service Archived from the original on 20110214 Retrieved 20120630  W3C CSS21 specification for pseudoelements and pseudoclasses World Wide Web Consortium 7 June 2011 Archived from the original on 30 April 2012 Retrieved 30 April 2012  Selectors Cascading Style Sheets Level 2 Revision 1 CSS 21 Specification W3C Archived from the original on 20060423  Selectors Level 3 W3C Archived from the original on 20140603 Retrieved 20140530  CSS Syntax Module Level 3 W3C Archived from the original on 1 October 2023 Retrieved 1 October 2023  W3C CSS21 specification for rule sets declaration blocks and selectors World Wide Web Consortium 7 June 2011 Archived from the original on 28 March 2008 Retrieved 20090620  Full property table W3C Archived from the original on 20140530 Retrieved 20140530  Index of CSS properties W3C Retrieved 20200809  CSS Color MDN Web Docs 20160628 Archived from the original on 20160921 Retrieved 20160823  61 Length units Cascading Style Sheets level 1 17 December 1996 Archived from the original on 14 June 2019 Retrieved 20 June 2019  5 Distance Units the length type CSS Values and Units Module Level 3 6 June 2019 Archived from the original on 7 June 2019 Retrieved 20 June 2019  W3C HTML Working Group HTML 5 A vocabulary and associated APIs for HTML and XHTML World Wide Web Consortium Archived from the original on 15 July 2014 Retrieved 28 June 2014cite web CS1 maint numeric names authors list link  a b Meyer Eric A 2006 Cascading Style Sheets The Definitive Guide 3rd ed OReilly Media Inc ISBN 0596527330 Archived from the original on 20140215 Retrieved 20140216  Assigning property values Cascading and Inheritance Archived from the original on 20140611 Retrieved 20140610  Can a CSS class inherit one or more other classes StackOverflow Archived from the original on 20171014 Retrieved 20170910  Shorthand properties Tutorial Mozilla Developers 20171207 Archived from the original on 20180130 Retrieved 20180130  a b c Bos Bert et al 7 December 2010 93 Positioning schemes Cascading Style Sheets Level 2 Revision 1 CSS 21 Specification W3C Archived from the original on 18 February 2011 Retrieved 16 February 2011  Holzschlag Molly E 2005 Spring into HTML and CSS Pearson Education Inc ISBN 0131855867  a b Lie Hakon W 10 October 1994 Cascading HTML style sheets  a proposal Proposal CERN Archived from the original on 4 June 2014 Retrieved 25 May 2014  a b c d e f Lie Håkon Wium Bos Bert 1999 Cascading Style Sheets designing for the Web Addison Wesley ISBN 0201596253 Retrieved 23 June 2010  Cascading Style Sheets level 1 World Wide Web Consortium Archived from the original on 20140409 Retrieved 20140307  a b c Bos Bert 14 April 1995 Simple style sheets for SGML  HTML on the web World Wide Web Consortium Archived from the original on 23 September 2009 Retrieved 20 June 2010  a b c Cascading Style Sheets University of Oslo Archived from the original on 20060906 Retrieved 3 September 2014  a b Petrie Charles Cailliau Robert November 1997 Interview Robert Cailliau on the WWW Proposal How It Really Happened Institute of Electrical and Electronics Engineers Archived from the original on 6 January 2011 Retrieved 18 August 2010  Bos Bert 31 March 1995 Streambased Style sheet Proposal Archived from the original on 12 October 2014 Retrieved 3 September 2014  Nielsen Henrik Frystyk 7 June 2002 Libwww Hackers World Wide Web Consortium Archived from the original on 2 December 2009 Retrieved 6 June 2010  Yves Lafon World Wide Web Consortium Archived from the original on 24 June 2010 Retrieved 17 June 2010  The W3C Team Technology and Society World Wide Web Consortium 18 July 2008 Archived from the original on 28 May 2010 Retrieved 22 January 2011  Lou Montulli Brendan Eich Scott Furman Donna Converse Troy Chevalier 22 August 1996 JavaScriptBased Style Sheets W3C Archived from the original on 27 May 2010 Retrieved 23 June 2010  CSS software W3C Archived from the original on 20101125 Retrieved 20110115  Anne van Kesteren CSS 21  Annes Weblog Archived from the original on 20051210 Retrieved 20110216  Archive of W3C News in 2007 World Wide Web Consortium Archived from the original on 20110628 Retrieved 20110216  Nitot Tristan 18 March 2002 Incorrect MIME Type for CSS Files Mozilla Developer Center Mozilla Archived from the original on 20110520 Retrieved 20 June 2010  McBride Don 27 November 2009 File Types Archived from the original on 29 October 2010 Retrieved 20 June 2010  css file extension details File extension database 12 March 2010 Archived from the original on 18 July 2011 Retrieved 20 June 2010  How and why you would want to use CSS vendor prefixes in your website Lifewire 20191112  Compatibility Standard WHATWG  Bos Bert Wium Lie Håkon 1997 Cascading style sheets designing for the Web 1st print ed Harlow England Reading MA Addison Wesley Longman ISBN 020141998X  W3C Cascading Style Sheets level 1 Archived 20110209 at the Wayback Machine CSS 1 specification  W3C Cascading Style Sheets level 1 specification Archived 20110211 at the Wayback Machine CSS level 1 specification  Aural style sheets W3C Archived from the original on 20141026 Retrieved 20141026  W3C Cascading Style Sheets level 2 Archived 20110116 at the Wayback Machine CSS 2 specification 1998 recommendation  W3CCascading Style Sheets level 2 revision 1 Archived 20111109 at the Wayback Machine CSS 21 specification W3C Proposed Recommendation  W3C Cascading Style Sheets Standard Boasts Unprecedented Interoperability Archived 20110610 at the Wayback Machine  Bos Bert 18 February 2011 Descriptions of all CSS specifications World Wide Web Consortium Archived from the original on 31 March 2011 Retrieved 3 March 2011  Bos Bert 26 February 2011 CSS current work World Wide Web Consortium Archived from the original on 3 March 2011 Retrieved 3 March 2011  Etemad Elika J 12 December 2010 Cascading Style Sheets CSS Snapshot 2010 World Wide Web Consortium Archived from the original on 16 March 2011 Retrieved 3 March 2011  All CSS specifications W3C 20140522 Archived from the original on 20140530 Retrieved 20140530  Atkins Tab Jr A Word About CSS4 Archived from the original on 31 October 2012 Retrieved 18 October 2012  CSS Flexible Box Layout Module Level 1 W3C 19 November 2018 Archived from the original on 19 October 2012 Retrieved 18 October 2012  Cascading Style Sheets CSS Snapshot 2007 12 May 2011 Archived from the original on 8 August 2016 Retrieved 18 July 2016  Cascading Style Sheets CSS Snapshot 2010 12 May 2011 Archived from the original on 16 March 2011 Retrieved 3 March 2011  CSS Snapshot 2015 W3C 13 October 2015 Archived from the original on 27 January 2017 Retrieved 13 February 2017  CSS Snapshot 2017 W3C 31 January 2017 Archived from the original on 13 February 2017 Retrieved 13 February 2017  CSS Snapshot 2018 W3C 22 January 2019 Archived from the original on 1 February 2019 Retrieved 2 January 2019  CSS Can I Use Support tables for HTML5 CSS3 etc Archived from the original on 20180219 Retrieved 20190126  CSS MDN Web Docs 21 July 2023 Archived from the original on Nov 26 2023  Call for Participation in CSS4 Community Group W3C 24 February 2020 Archived from the original on Feb 10 2023 Retrieved 20200227  Lazaris Louis 20100428 CSS3 Solutions for Internet Explorer Smashing Magazine Archived from the original on 20161012 Retrieved 20161012  Simmons Jen August 17 2016 Using Feature Queries in CSS Mozilla Hacks Archived from the original on 20161011 Retrieved 20161012  Hutchinson Lee 2019 Looking at the Web with Internet Explorer 6 one last time Ars Technica Archived from the original on 20161012 Retrieved 20161012  Pure CSS Popups meyerwebcom Archived from the original on 20091209 Retrieved 20091119  Tab Atkins Jr CSS apply rule GitHub Archived from the original on 20160222 Retrieved 20160227  Why I Abandoned apply  Tab Completion  Cederholm Dan Ethan Marcotte 2009 Handcrafted CSS More Bulletproof Web Design New Riders p 114 ISBN 9780321643384 Archived from the original on 20 December 2012 Retrieved 19 June 2010  Is Zurb Foundation in active development GitHub Retrieved 21 Nov 2019  Antti Hiljá OOCSS ACSS BEM SMACSS what are they What should I use clubmatefi Hiljá Archived from the original on 2 June 2015 Retrieved 2 June 2015 Further readingedit Meyer Eric A Weyl Estelle 2017 Cascading Style Sheets The Definitive Guide Fourth Edition OReilly Media Inc ISBN 9781449393199 Grant Keith J 2018 CSS in Depth Manning Publications Co ISBN 9781617293450 MDN CSS reference MDN Getting Started with CSS External linksedit CSS at Wikipedias sister projects Definitions from WiktionaryMedia from CommonsTextbooks from WikibooksResources from WikiversityData from WikidataDiscussions from MetaWikiDocumentation from MediaWiki Official website vteWeb browsers Features standards protocols Features Bookmarks Extensions Privacy mode Web standards HTML v5 CSS DOM JavaScript IndexedDB Web storage WebAssembly WebGL Protocols HTTP Cookies Encryption OCSP WebRTC WebSocket ActiveBlinkbased Google Chrome Chromium Arc Avast Blisk Brave Citrio Coc Coc Dragon Epic Falkon Maxthon Microsoft Edge Opera Otter Puffin Samsung Internet Silk Sleipnir Sputnik SRWare UC Vivaldi Whale Yandex Geckobased Firefox GNU IceCat PirateBrowser SlimBrowser Tor Browser Gecko forks Basilisk KMeleon LibreWolf Pale Moon SeaMonkey Waterfox WebKitbased Safari Dolphin Dooble GNOME Web iCab Konqueror Midori Roccat surf Other 360 DuckDuckGo eww Flow Links Lunascape Lynx NetFront NetSurf QQ browser qutebrowser w3m DiscontinuedBlinkbased Beaker Flock Redcore Rockmelt SalamWeb Torch Geckobased Beonex Communicator Camino Classilla Conkeror Firefox Lite Galeon Ghostzilla IceDragon Kazehakase Kylo Lotus MicroB Minimo Mozilla suite Pogo Strata Swiftfox Swiftweasel TenFourFox Timberwolf xB MSHTMLbased Internet Explorer AOL Deepnet GreenBrowser MediaBrowser NeoPlanet NetCaptor SpaceTime ZAC WebKitbased Arora BOLT Opera Coast Fluid Google TV Iris Mercury OmniWeb Origyn QtWeb rekonq Shiira Steel Browser for Symbian Uzbl WebPositive xombrero Other abaco Amaya Arachne Arena Avant Blazer Cake Charon CM Browser Deepfish Dillo Edge Legacy ELinks Gazelle HotJava IBM Home Page Reader IBM WebExplorer IBrowse KidZui Line Mode Mosaic MSN TV NetPositive Netscape Skweezer Skyfire ThunderHawk Vision WinWAP WorldWideWeb Category Comparisons List vteStyle sheet languagesModes Desktop publishing Web development User interfaces Standard Cascading CSS DSSSL Extensible XSL Preprocessor JavaScript JSSS FOSI Qt Sass Less Stylus SMIL Timesheets PostCSS List Comparison vteWorld Wide Web Consortium W3CProducts andstandardsRecommendations ActivityPub Activity Streams ARIA Canonical XML CDF CSS Animations Flexbox Grid DOM Geolocation API HTML HTML5 IndexedDB ITS JSONLD Linked Data Notifications MathML Micropub OWL PLS RDF Schema SISR SKOS SMIL SOAP SRGS SRI SSML SVG Filter Effects SCXML SHACL SPARQL Timed text VoiceXML WoT TD Web storage WSDL Webmention WebSub XHTML RDFa XML Base Encryption Events Information Set Namespace Schema Signature XForms XInclude XLink XOP XPath 20 3x XPointer XProc XQuery XSL XSLFO XSLT elements Notes IndieAuth XAdES XBL XHTMLSMIL XUP Working drafts CCXML CURIE EME InkML MSE RIF SMIL Timesheets sXBL WebGPU WebXR XFDL XFrames XMLHttpRequest Guidelines Web Content Accessibility Guidelines Initiative Markup Validation Service Web Accessibility Initiative Web Components Deprecated CHTML HDML JSSS PGML VML WebPlatform Obsoleted P3P XHTMLMathMLSVG Organizations World Wide Web Foundation Working groups TAG CSS SVG WebAssembly WebAuthn WHATWG Community  business groups Web Advertising BG WebAssembly CG Closed groups Device Description DDWG HTML Multimodal Interaction Activity MMI Software CERN httpd Libwww Browsers Line Mode 1990 Arena 199398 Agora 199497 Argo 199497 Amaya browsereditor 19962012 Conferences International World Wide Web Conference IW3C Steering Committee IW3C2 First conference WWW1 1994 Authority control databases National Spain France BnF data Germany Israel United States Czech Republic Portal Computer programming Retrieved from httpsenwikipediaorgwindexphptitleCSSoldid1190479888 Categories Cascading Style SheetsComputerrelated introductions in 1996Stylesheet languagesTypesetting programming languagesWeb designWorld Wide Web Consortium standardsOpen formatsHidden categories CS1 maint numeric names authors listWebarchive template wayback linksArticles with short descriptionShort description is different from WikidataWikipedia articles needing clarification from March 2022Articles containing potentially dated statements from 2014All articles containing potentially dated statementsAll articles with unsourced statementsArticles with unsourced statements from May 2022Articles with excerptsPages using Sister project links with hidden wikidataArticles with BNE identifiersArticles with BNF identifiersArticles with BNFdata identifiersArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with NKC identifiers ,https://en.wikipedia.org/wiki/CSS,Front-End Development,2725,9311
JavaScript Fundamentals, From Wikipedia the free encyclopedia This is the latest accepted revision reviewed on 23 December 2023 Highlevel programming language Not to be confused with Java programming language Javanese script or ECMAScript js redirects here For the Microsoft dialect used in Internet Explorer see JScript For the uses of JavaScript on Wikipedia see WikipediaWikiProject JavaScript JavaScriptScreenshot of JavaScript source codeParadigmMultiparadigm eventdriven functional imperative procedural objectoriented programmingDesigned byBrendan Eich of Netscape initially others have also contributed to the ECMAScript standardFirst appearedDecember 4 1995 28 years ago 199512041Stable releaseECMAScript 20212  June 2021 2 years ago June 2021Preview releaseECMAScript 20223  22 July 2021 2 years ago 22 July 2021 Typing disciplineDynamic weak duckFilename extensions js cjs mjs4 Websiteecmainternationalorgpublicationsandstandardsstandardsecma262Major implementationsV8 JavaScriptCore SpiderMonkey ChakraInfluenced byJava56 Scheme6 Self7 AWK8 HyperTalk9InfluencedActionScript AssemblyScript CoffeeScript Dart Haxe JS Opa TypeScript JavaScript at Wikibooks JavaScript ˈdʒɑːvəskrɪpt often abbreviated as JS is a programming language and core technology of the World Wide Web alongside HTML and CSS As of 2023update 987 of websites use JavaScript on the client side for webpage behavior10 often incorporating thirdparty libraries All major web browsers have a dedicated JavaScript engine to execute the code on users devices JavaScript is a highlevel often justintime compiled language that conforms to the ECMAScript standard11 It has dynamic typing prototypebased objectorientation and firstclass functions It is multiparadigm supporting eventdriven functional and imperative programming styles It has application programming interfaces APIs for working with text dates regular expressions standard data structures and the Document Object Model DOM The ECMAScript standard does not include any inputoutput IO such as networking storage or graphics facilities In practice the web browser or other runtime system provides JavaScript APIs for IO JavaScript engines were originally used only in web browsers but are now core components of some servers and a variety of applications The most popular runtime system for this usage is Nodejs Although Java and JavaScript are similar in name syntax and respective standard libraries the two languages are distinct and differ greatly in design History Creation at Netscape The first popular web browser with a graphical user interface Mosaic was released in 1993 Accessible to nontechnical people it played a prominent role in the rapid growth of the nascent World Wide Web12 The lead developers of Mosaic then founded the Netscape corporation which released a more polished browser Netscape Navigator in 1994 This quickly became the mostused13 During these formative years of the Web web pages could only be static lacking the capability for dynamic behavior after the page was loaded in the browser There was a desire in the flourishing web development scene to remove this limitation so in 1995 Netscape decided to add a scripting language to Navigator They pursued two routes to achieve this collaborating with Sun Microsystems to embed the Java programming language while also hiring Brendan Eich to embed the Scheme language6 Netscape management soon decided that the best option was for Eich to devise a new language with syntax similar to Java and less like Scheme or other extant scripting languages56 Although the new language and its interpreter implementation were called LiveScript when first shipped as part of a Navigator beta in September 1995 the name was changed to JavaScript for the official release in December6114 The choice of the JavaScript name has caused confusion implying that it is directly related to Java At the time the dotcom boom had begun and Java was a popular new language so Eich considered the JavaScript name a marketing ploy by Netscape15 Adoption by Microsoft Microsoft debuted Internet Explorer in 1995 leading to a browser war with Netscape On the JavaScript front Microsoft reverseengineered the Navigator interpreter to create its own called JScript16 JavaScript was first released in 1996 alongside initial support for CSS and extensions to HTML Each of these implementations was noticeably different from their counterparts in Navigator1718 These differences made it difficult for developers to make their websites work well in both browsers leading to widespread use of best viewed in Netscape and best viewed in Internet Explorer logos for several years1719 The rise of JScript In November 1996 Netscape submitted JavaScript to Ecma International as the starting point for a standard specification that all browser vendors could conform to This led to the official release of the first ECMAScript language specification in June 1997 The standards process continued for a few years with the release of ECMAScript 2 in June 1998 and ECMAScript 3 in December 1999 Work on ECMAScript 4 began in 200016 Meanwhile Microsoft gained an increasingly dominant position in the browser market By the early 2000s Internet Explorers market share reached 9520 This meant that JScript became the de facto standard for clientside scripting on the Web Microsoft initially participated in the standards process and implemented some proposals in its JScript language but eventually it stopped collaborating on Ecma work Thus ECMAScript 4 was mothballed Growth and standardization During the period of Internet Explorer dominance in the early 2000s clientside scripting was stagnant This started to change in 2004 when the successor of Netscape Mozilla released the Firefox browser Firefox was well received by many taking significant market share from Internet Explorer21 In 2005 Mozilla joined ECMA International and work started on the ECMAScript for XML E4X standard This led to Mozilla working jointly with Macromedia later acquired by Adobe Systems who were implementing E4X in their ActionScript 3 language which was based on an ECMAScript 4 draft The goal became standardizing ActionScript 3 as the new ECMAScript 4 To this end Adobe Systems released the Tamarin implementation as an open source project However Tamarin and ActionScript 3 were too different from established clientside scripting and without cooperation from Microsoft ECMAScript 4 never reached fruition Meanwhile very important developments were occurring in opensource communities not affiliated with ECMA work In 2005 Jesse James Garrett released a white paper in which he coined the term Ajax and described a set of technologies of which JavaScript was the backbone to create web applications where data can be loaded in the background avoiding the need for full page reloads This sparked a renaissance period of JavaScript spearheaded by opensource libraries and the communities that formed around them Many new libraries were created including jQuery Prototype Dojo Toolkit and MooTools Google debuted its Chrome browser in 2008 with the V8 JavaScript engine that was faster than its competition2223 The key innovation was justintime compilation JIT24 so other browser vendors needed to overhaul their engines for JIT25 In July 2008 these disparate parties came together for a conference in Oslo This led to the eventual agreement in early 2009 to combine all relevant work and drive the language forward The result was the ECMAScript 5 standard released in December 2009 Reaching maturity Ambitious work on the language continued for several years culminating in an extensive collection of additions and refinements being formalized with the publication of ECMAScript 6 in 201526 The creation of Nodejs in 2009 by Ryan Dahl sparked a significant increase in the usage of JavaScript outside of web browsers Node combines the V8 engine an event loop and IO APIs thereby providing a standalone JavaScript runtime system2728 As of 2018 Node had been used by millions of developers29 and npm had the most modules of any package manager in the world30 The ECMAScript draft specification is currentlyas of maintained openly on GitHub and editions are produced via regular annual snapshots31 Potential revisions to the language are vetted through a comprehensive proposal process3233 Now instead of edition numbers developers check the status of upcoming features individually31 The current JavaScript ecosystem has many libraries and frameworks established programming practices and substantial usage of JavaScript outside of web browsers Plus with the rise of singlepage applications and other JavaScriptheavy websites several transpilers have been created to aid the development process34 Trademark JavaScript is a trademark of Oracle Corporation in the United States3536 The trademark was originally issued to Sun Microsystems on 6 May 1997 and was transferred to Oracle when they acquired Sun in 200937 Website clientside usage JavaScript is the dominant clientside scripting language of the Web with 98 of all websites mid2022 using it for this purpose38 Scripts are embedded in or included from HTML documents and interact with the DOM All major web browsers have a builtin JavaScript engine that executes the code on the users device Examples of scripted behavior Loading new web page content without reloading the page via Ajax or a WebSocket For example users of social media can send and receive messages without leaving the current page Web page animations such as fading objects in and out resizing and moving them Playing browser games Controlling the playback of streaming media Generating popup ads or alert boxes Validating input values of a web form before the data is sent to a web server Logging data about the users behavior then sending it to a server The website owner can use this data for analytics ad tracking and personalization Redirecting a user to another page Storing and retrieving data on the users device via the storage or IndexedDB standards Web libraries and frameworks Over 80 of websites use a thirdparty JavaScript library or web framework for their clientside scripting39 jQuery Main article jQuery jQuery is by far the most popular clientside library used by over 75 of websites39 React These paragraphs are an excerpt from React softwareedit React also known as Reactjs or ReactJS is a free and opensource frontend JavaScript library4041 for building user interfaces based on components It is maintained by Meta formerly Facebook and a community of individual developers and companies424344 React can be used to develop singlepage mobile or serverrendered applications with frameworks like Nextjs Because React is only concerned with the user interface and rendering components to the DOM React applications often rely on libraries for routing and other clientside functionality4546 A key advantage of React is that it only rerenders those parts of the page that have changed avoiding unnecessary rerendering of unchanged DOM elements Angular These paragraphs are an excerpt from Angular web frameworkedit Angular also referred to as Angular 247 is a TypeScriptbased free and opensource singlepage web application framework led by the Angular Team at Google and by a community of individuals and corporations Angular is a complete rewrite from the same team that built AngularJS Vanilla JS In contrast the term Vanilla JS has been coined for websites not using any libraries or frameworks instead relying entirely on standard JavaScript functionality48 Other usage The use of JavaScript has expanded beyond its web browser roots JavaScript engines are now embedded in a variety of other software systems both for serverside website deployments and nonbrowser applications Initial attempts at promoting serverside JavaScript usage were Netscape Enterprise Server and Microsofts Internet Information Services4950 but they were small niches51 Serverside usage eventually started to grow in the late 2000s with the creation of Nodejs and other approaches51 Electron Cordova React Native and other application frameworks have been used to create many applications with behavior implemented in JavaScript Other nonbrowser applications include Adobe Acrobat support for scripting PDF documents52 and GNOME Shell extensions written in JavaScript53 JavaScript has recently begun to appear in some embedded systems usually by leveraging Nodejs545556 Execution system Justintime compilation JavaScript engine This section is an excerpt from JavaScript engineedit A JavaScript engine is a software component that executes JavaScript code The first JavaScript engines were mere interpreters but all relevant modern engines use justintime compilation for improved performance57 JavaScript engines are typically developed by web browser vendors and every major browser has one In a browser the JavaScript engine runs in concert with the rendering engine via the Document Object Model The use of JavaScript engines is not limited to browsers For example the V8 engine is a core component of the Nodejs and Deno runtime systems Since ECMAScript is the standardized specification of JavaScript ECMAScript engine is another name for these engines With the advent of WebAssembly some engines can also execute this code in the same sandbox as regular JavaScript code Runtime environment JavaScript typically relies on a runtime environment eg a web browser to provide objects and methods by which scripts can interact with the environment eg a web page DOM These environments are singlethreaded JavaScript also relies on the runtime environment to provide the ability to includeimport scripts eg HTML script elements This is not a language feature per se but it is common in most JavaScript implementations JavaScript processes messages from a queue one at a time JavaScript calls a function associated with each new message creating a call stack frame with the functions arguments and local variables The call stack shrinks and grows based on the functions needs When the call stack is empty upon function completion JavaScript proceeds to the next message in the queue This is called the event loop described as run to completion because each message is fully processed before the next message is considered However the languages concurrency model describes the event loop as nonblocking program inputoutput is performed using events and callback functions This means for instance that JavaScript can process a mouse click while waiting for a database query to return information58 Examples Nodejs These paragraphs are an excerpt from Nodejsedit Nodejs is a crossplatform opensource JavaScript runtime environment that can run on Windows Linux Unix macOS and more Nodejs runs on the V8 JavaScript engine and executes JavaScript code outside a web browser Deno These paragraphs are an excerpt from Deno softwareedit Deno diːnoʊ59 is a runtime for JavaScript TypeScript and WebAssembly that is based on the V8 JavaScript engine and the Rust programming language Deno was cocreated by Ryan Dahl who also created Nodejs60 Features The following features are common to all conforming ECMAScript implementations unless explicitly specified otherwise Imperative and structured Main article Structured programming JavaScript supports much of the structured programming syntax from C eg if statements while loops switch statements do while loops etc One partial exception is scoping originally JavaScript only had function scoping with var block scoping was added in ECMAScript 2015 with the keywords let and const Like C JavaScript makes a distinction between expressions and statements One syntactic difference from C is automatic semicolon insertion which allow semicolons which terminate statements to be omitted61 Weakly typed Main article Weakly typed JavaScript is weakly typed which means certain types are implicitly cast depending on the operation used62 The binary  operator casts both operands to a string unless both operands are numbers This is because the addition operator doubles as a concatenation operator The binary  operator always casts both operands to a number Both unary operators   always cast the operand to a number Values are cast to strings like the following62 Strings are left asis Numbers are converted to their string representation Arrays have their elements cast to strings after which they are joined by commas  Other objects are converted to the string object Object where Object is the name of the constructor of the object Values are cast to numbers by casting to strings and then casting the strings to numbers These processes can be modified by defining toString and valueOf functions on the prototype for string and number casting respectively JavaScript has received criticism for the way it implements these conversions as the complexity of the rules can be mistaken for inconsistency6362 For example when adding a number to a string the number will be cast to a string before performing concatenation but when subtracting a number from a string the string is cast to a number before performing subtraction JavaScript type conversions left operand operator right operand result  empty array   empty array  empty string  empty array   empty object object Object string false boolean   empty array false string 123string  1 number 1231 string 123 string  1 number 122 number 123 string  abc string NaN number Often also mentioned is    resulting in 0 number This is misleading the  is interpreted as an empty code block instead of an empty object and the empty array is cast to a number by the remaining unary  operator If you wrap the expression in parentheses    the curly brackets are interpreted as an empty object and the result of the expression is object Object as expected62 Dynamic Main article Dynamic Programming Typing Main article Dynamic typing JavaScript is dynamically typed like most other scripting languages A type is associated with a value rather than an expression For example a variable initially bound to a number may be reassigned to a string64 JavaScript supports various ways to test the type of objects including duck typing65 Runtime evaluation Main article eval JavaScript includes an eval function that can execute statements provided as strings at runtime Objectorientation prototypebased Prototypal inheritance in JavaScript is described by Douglas Crockford as You make prototype objects and then  make new instances Objects are mutable in JavaScript so we can augment the new instances giving them new fields and methods These can then act as prototypes for even newer objects We dont need classes to make lots of similar objects Objects inherit from objects What could be more object oriented than that66 In JavaScript an object is an associative array augmented with a prototype see below each key provides the name for an object property and there are two syntactical ways to specify such a name dot notation objx  10 and bracket notation objx  10 A property may be added rebound or deleted at runtime Most properties of an object and any property that belongs to an objects prototype inheritance chain can be enumerated using a forin loop Prototypes Main article Prototypebased programming JavaScript uses prototypes where many other objectoriented languages use classes for inheritance67 It is possible to simulate many classbased features with prototypes in JavaScript68 Functions as object constructors Functions double as object constructors along with their typical role Prefixing a function call with new will create an instance of a prototype inheriting properties and methods from the constructor including properties from the Object prototype69 ECMAScript 5 offers the Objectcreate method allowing explicit creation of an instance without automatically inheriting from the Object prototype older environments can assign the prototype to null70 The constructors prototype property determines the object used for the new objects internal prototype New methods can be added by modifying the prototype of the function used as a constructor JavaScripts builtin constructors such as Array or Object also have prototypes that can be modified While it is possible to modify the Object prototype it is generally considered bad practice because most objects in JavaScript will inherit methods and properties from the Object prototype and they may not expect the prototype to be modified71 Functions as methods Main article Method computer science Unlike in many objectoriented languages in JavaScript there is no distinction between a function definition and a method definition Rather the distinction occurs during function calling When a function is called as a method of an object the functions local this keyword is bound to that object for that invocation Functional Main article Functional programming JavaScript functions are firstclass a function is considered to be an object72 As such a function may have properties and methods such as call and bind73 Lexical closure Main article Closure computer programming A nested function is a function defined within another function It is created each time the outer function is invoked In addition each nested function forms a lexical closure the lexical scope of the outer function including any constant local variable or argument value becomes part of the internal state of each inner function object even after execution of the outer function concludes74 Anonymous function Main article Anonymous function JavaScript also supports anonymous functions Delegative Main article Delegation objectoriented programming JavaScript supports implicit and explicit delegation Functions as roles Traits and Mixins Main articles Roleoriented programming Traits computer science and Mixin JavaScript natively supports various functionbased implementations of Role75 patterns like Traits7677 and Mixins78 Such a function defines additional behavior by at least one method bound to the this keyword within its function body A Role then has to be delegated explicitly via call or apply to objects that need to feature additional behavior that is not shared via the prototype chain Object composition and inheritance Whereas explicit functionbased delegation does cover composition in JavaScript implicit delegation already happens every time the prototype chain is walked in order to eg find a method that might be related to but is not directly owned by an object Once the method is found it gets called within this objects context Thus inheritance in JavaScript is covered by a delegation automatism that is bound to the prototype property of constructor functions Miscellaneous Zerobased numbering JavaScript is a zeroindex language Variadic functions Main article Variadic function An indefinite number of parameters can be passed to a function The function can access them through formal parameters and also through the local arguments object Variadic functions can also be created by using the bind method Array and object literals Main articles Associative arrays and Object literal Like in many scripting languages arrays and objects associative arrays in other languages can each be created with a succinct shortcut syntax In fact these literals form the basis of the JSON data format Regular expressions Main article Regular expression In a manner similar to Perl JavaScript also supports regular expressions which provide a concise and powerful syntax for text manipulation that is more sophisticated than the builtin string functions79 Promises and Asyncawait JavaScript supports promises and Asyncawait for handling asynchronous operationscitation needed Promises Main article Futures and promises A builtin Promise object provides functionality for handling promises and associating handlers with an asynchronous actions eventual result Recently the JavaScript specification introduced combinator methods which allow developers to combine multiple JavaScript promises and do operations based on different scenarios The methods introduced are Promiserace Promiseall PromiseallSettled and Promiseany Asyncawait Main article Asyncawait Asyncawait allows an asynchronous nonblocking function to be structured in a way similar to an ordinary synchronous function Asynchronous nonblocking code can be written with minimal overhead structured similarly to traditional synchronous blocking code Vendorspecific extensions Historically some JavaScript engines supported these nonstandard features conditional catch clauses like Java array comprehensions and generator expressions like Python concise function expressions functionargs expr this experimental syntax predated arrow functions ECMAScript for XML E4X an extension that adds native XML support to ECMAScript unsupported in Firefox since version 2180 Syntax Main article JavaScript syntax Simple examples Variables in JavaScript can be defined using either the var81 let82 or const83 keywords Variables defined without keywords will be defined at the global scope  Declares a functionscoped variable named x and implicitly assigns the  special value undefined to it Variables without value are automatically  set to undefined  var is generally considered bad practice and let and const are usually preferred var x  Variables can be manually set to undefined like so let x2  undefined  Declares a blockscoped variable named y and implicitly sets it to  undefined The let keyword was introduced in ECMAScript 2015 let y  Declares a blockscoped unreassignable variable named z and sets it to  a string literal The const keyword was also introduced in ECMAScript 2015  and must be explicitly assigned to  The keyword const means constant hence the variable cannot be reassigned  as the value is constant const z  this value cannot be reassigned  Declares a globalscoped variable and assigns 3 This is generally considered  bad practice and will not work if strict mode is on t  3  Declares a variable named myNumber and assigns a number literal the value  2 to it let myNumber  2  Reassigns myNumber setting it to a string literal the value foo  JavaScript is a dynamicallytyped language so this is legal myNumber  foo Note the comments in the examples above all of which were preceded with two forward slashes There is no builtin Inputoutput functionality in JavaScript instead it is provided by the runtime environment The ECMAScript specification in edition 51 mentions that there are no provisions in this specification for input of external data or output of computed results84 However most runtime environments have a console object that can be used to print output85 Here is a minimalist Hello World program in JavaScript in a runtime environment with a console object consolelogHello World In HTML documents a program like this is required for an output  Text nodes can be made using the write method  This is frowned upon as it can overwrite the document if the document is fully loaded documentwritefoo  Elements can be made too First they have to be created in the DOM const myElem  documentcreateElementspan  Attributes like classes and the id can be set as well myElemclassListaddfoo myElemid  bar  After setting this the tag will look like this span classfoo idbar dataattrbazspan myElemsetAttributedataattr baz  Which could also be written as myElemdatasetattr  baz  Finally append it as a child element to the body in the HTML documentbodyappendChildmyElem  Elements can be imperatively grabbed with querySelector for one element or querySelectorAll for multiple elements that can be looped with forEach documentquerySelectorclass  Selects the first element with the class class documentquerySelectorid  Selects the first element with an id of id documentquerySelectordataother  Selects the first element with the dataother attribute documentquerySelectorAllmultiple  Returns an Arraylike NodeList of all elements with the multiple class A simple recursive function to calculate the factorial of a natural number function factorialn   Checking the argument for legitimacy Factorial is defined for positive integers if isNaNn  consoleerrorNonnumerical argument not allowed return NaN  The special value Not a Number  if n  0 return 1  0  1 if n  0 return undefined  Factorial of negative numbers is not defined if n  1  consolewarnn will be rounded to the closest integer For nonintegers consider using gamma function instead n  Mathroundn   The above checks need not be repeated in the recursion hence defining the actual recursive part separately below  The following line is a function expression to recursively compute the factorial It uses the arrow syntax introduced in ES6 const recursivelyCompute  a  a  1  a  recursivelyComputea  1  1  Note the use of the ternary operator  return recursivelyComputen  factorial3  Returns 6 An anonymous function or lambda const counter  function  let count  0 return function  return count   const x  counter x  Returns 1 x  Returns 2 x  Returns 3 This example shows that in JavaScript function closures capture their nonlocal variables by reference Arrow functions were first introduced in 6th Edition  ECMAScript 2015 They shorten the syntax for writing functions in JavaScript Arrow functions are anonymous so a variable is needed to refer to them in order to invoke them after their creation unless surrounded by parenthesis and executed immediately Example of arrow function  Arrow functions let us omit the function keyword  Here long_example points to an anonymous function value const long_example  input1 input2   consolelogHello World const output  input1  input2 return output   If there are no braces the arrow function simply returns the expression  So here its input1  input2 const short_example  input1 input2  input1  input2 long_example2 3  Prints Hello World and returns 5 short_example2 5  Returns 7  If an arrow function has only one parameter the parentheses can be removed const no_parentheses  input  input  2 no_parentheses3  Returns 5  An arrow function like other function definitions can be executed in the same statement as they are created  This is useful when writing libraries to avoid filling the global scope and for closures let three  a b  a  b 1 2 const generate_multiplier_function  a  b  isNaNb  b  a  ab const five_multiples  generate_multiplier_function5  The supplied argument seeds the expression and is retained by a five_multiples1  Returns 5 five_multiples3  Returns 15 five_multiples4  Returns 60 In JavaScript objects can be created as instances of a class Object class example class Ball  constructorradius  thisradius  radius thisarea  MathPI   radius  2    Classes and thus objects can contain functions known as methods show  consolelogthisradius   const myBall  new Ball5  Creates a new instance of the ball object with radius 5 myBallradius  Object properties can usually be modified from the outside myBallshow  Using the inherited show function logs 6 In JavaScript objects can be instantiated directly from a function Object functional example function Ballradius  const area  MathPI   radius  2  const obj   radius area   Objects are mutable and functions can be added as properties objshow    consolelogobjradius return obj  const myBall  Ball5  Creates a new ball object with radius 5 No new keyword needed myBallradius  The instance property can be modified myBallshow  Using the show function logs 6  the new instance value Variadic function demonstration arguments is a special variable86 function sum  let x  0 for let i  0 i  argumentslength i x  argumentsi return x  sum1 2  Returns 3 sum1 2 3  Returns 6  As of ES6 using the rest operator function sumargs  return argsreducea b  a  b  sum1 2  Returns 3 sum1 2 3  Returns 6 Immediatelyinvoked function expressions are often used to create closures Closures allow gathering properties and methods in a namespace and making some of them private let counter  function  let i  0  Private property return   Public methods get function  alerti  set functionvalue  i  value  increment function  alerti     Module counterget  Returns 0 counterset6 counterincrement  Returns 7 counterincrement  Returns 8 Generator objects in the form of generator functions provide a function which can be called exited and reentered while maintaining internal context statefulness87function rawCounter  yield 1 yield 2  function dynamicCounter  let count  0 while true   It is not recommended to utilize while true loops in most cases yield count    Instances const counter1  rawCounter const counter2  dynamicCounter  Implementation counter1next  value 1 done false counter1next  value 2 done false counter1next  value undefined done true counter2next  value 1 done false counter2next  value 2 done false counter2next  value 3 done false  infinitely JavaScript can export and import from modules88 Export example  mymodulejs   This function remains private as it is not exported let sum  a b   return a  b   Export variables export let name  Alice export let age  23  Export named functions export function addnum1 num2  return num1  num2   Export class export class Multiplication  constructornum1 num2  thisnum1  num1 thisnum2  num2  add  return sumthisnum1 thisnum2   Import example  Import one property import  add  from mymodulejs consolelogadd1 2  3  Import multiple properties import  name age  from mymodulejs consolelogname age  Alice 23  Import all properties from a module import  from modulejs consolelogname age  Alice 23 consolelogadd12  3 More advanced example This sample code displays various JavaScript features  Finds the lowest common multiple LCM of two numbers  function LCMCalculatorx y   constructor function if isNaNxy throw new TypeErrorNonnumeric arguments not allowed const checkInt  functionx   inner function if x  1  0 throw new TypeErrorx  is not an integer return x  thisa  checkIntx  semicolons  are optional a newline is enough thisb  checkInty   The prototype of object instances created by a constructor is  that constructors prototype property LCMCalculatorprototype    object literal constructor LCMCalculator  when reassigning a prototype set the constructor property appropriately gcd function   method that calculates the greatest common divisor  Euclidean algorithm let a  Mathabsthisa b  Mathabsthisb t if a  b   swap variables  t  b b  a a  t a b  b a  swap using destructuring assignment ES6  while b  0  t  b b  a  b a  t   Only need to calculate GCD once so redefine this method  Actually not redefinitionits defined on the instance itself  so that thisgcd refers to this redefinition instead of LCMCalculatorprototypegcd  Note that this leads to a wrong result if the LCMCalculator object members a andor b are altered afterwards  Also gcd  gcd thisgcd  thisgcd thisgcd  function  return a  return a   Object property names can be specified by strings delimited by double  or single  quotes lcm function   Variable names do not collide with object properties eg lcm is not thislcm  not using thisathisb to avoid FP precision issues let lcm  thisa  thisgcd  thisb  Only need to calculate lcm once so redefine this method thislcm  function  return lcm  return lcm   Methods can also be declared using ES6 syntax toString   Using both ES6 template literals and the  operator to concatenate values return LCMCalculator a  thisa b    thisb    Define generic output function this implementation only works for Web browsers function outputx  documentbodyappendChilddocumentcreateTextNodex documentbodyappendChilddocumentcreateElementbr   Note Arrays map and forEach are defined in JavaScript 16  They are used here to demonstrate JavaScripts inherent functional nature  25 55 21 56 22 58 28 56 mapfunctionpair   array literal  mapping function return new LCMCalculatorpair0 pair1 sorta b  alcm  blcm  sort with this comparative function  is a shorthand form of a function called arrow function forEachprintResult function printResultobj  outputobj   gcd    objgcd   lcm    objlcm  The following output should be displayed in the browser window LCMCalculator a  28 b  56 gcd  28 lcm  56 LCMCalculator a  21 b  56 gcd  7 lcm  168 LCMCalculator a  25 b  55 gcd  5 lcm  275 LCMCalculator a  22 b  58 gcd  2 lcm  638 Security See also Browser security JavaScript and the DOM provide the potential for malicious authors to deliver scripts to run on a client computer via the Web Browser authors minimize this risk using two restrictions First scripts run in a sandbox in which they can only perform Webrelated actions not generalpurpose programming tasks like creating files Second scripts are constrained by the sameorigin policy scripts from one Website do not have access to information such as usernames passwords or cookies sent to another site Most JavaScriptrelated security bugs are breaches of either the same origin policy or the sandbox There are subsets of general JavaScriptADsafe Secure ECMAScript SESthat provide greater levels of security especially on code created by third parties such as advertisements8990 Closure Toolkit is another project for safe embedding and isolation of thirdparty JavaScript and HTML91 Content Security Policy is the main intended method of ensuring that only trusted code is executed on a Web page Crosssite vulnerabilities Main articles Crosssite scripting and Crosssite request forgery Crosssite scripting Main article Crosssite scripting A common JavaScriptrelated security problem is crosssite scripting XSS a violation of the sameorigin policy XSS vulnerabilities occur when an attacker can cause a target Website such as an online banking website to include a malicious script in the webpage presented to a victim The script in this example can then access the banking application with the privileges of the victim potentially disclosing secret information or transferring money without the victims authorization A solution to XSS vulnerabilities is to use HTML escaping whenever displaying untrusted data Some browsers include partial protection against reflected XSS attacks in which the attacker provides a URL including malicious script However even users of those browsers are vulnerable to other XSS attacks such as those where the malicious code is stored in a database Only correct design of Web applications on the serverside can fully prevent XSS XSS vulnerabilities can also occur because of implementation mistakes by browser authors92 Crosssite request forgery Main article Crosssite request forgery Another crosssite vulnerability is crosssite request forgery CSRF In CSRF code on an attackers site tricks the victims browser into taking actions the user did not intend at a target site like transferring money at a bank When target sites rely solely on cookies for request authentication requests originating from code on the attackers site can carry the same valid login credentials of the initiating user In general the solution to CSRF is to require an authentication value in a hidden form field and not only in the cookies to authenticate any request that might have lasting effects Checking the HTTP Referrer header can also help JavaScript hijacking is a type of CSRF attack in which a script tag on an attackers site exploits a page on the victims site that returns private information such as JSON or JavaScript Possible solutions include requiring an authentication token in the POST and GET parameters for any response that returns private information Misplaced trust in the client Developers of clientserver applications must recognize that untrusted clients may be under the control of attackers The application author cannot assume that their JavaScript code will run as intended or at all because any secret embedded in the code could be extracted by a determined adversary Some implications are Website authors cannot perfectly conceal how their JavaScript operates because the raw source code must be sent to the client The code can be obfuscated but obfuscation can be reverseengineered JavaScript form validation only provides convenience for users not security If a site verifies that the user agreed to its terms of service or filters invalid characters out of fields that should only contain numbers it must do so on the server not only the client Scripts can be selectively disabled so JavaScript cannot be relied on to prevent operations such as rightclicking on an image to save it93 It is considered very bad practice to embed sensitive information such as passwords in JavaScript because it can be extracted by an attacker94 Misplaced trust in developers Package management systems such as npm and Bower are popular with JavaScript developers Such systems allow a developer to easily manage their programs dependencies upon other developers program libraries Developers trust that the maintainers of the libraries will keep them secure and up to date but that is not always the case A vulnerability has emerged because of this blind trust Reliedupon libraries can have new releases that cause bugs or vulnerabilities to appear in all programs that rely upon the libraries Inversely a library can go unpatched with known vulnerabilities out in the wild In a study done looking over a sample of 133000 websites researchers found 37 of the websites included a library with at least one known vulnerability95 The median lag between the oldest library version used on each website and the newest available version of that library is 1177 days in ALEXA and development of some libraries still in active use ceased years ago95 Another possibility is that the maintainer of a library may remove the library entirely This occurred in March 2016 when Azer Koçulu removed his repository from npm This caused tens of thousands of programs and websites depending upon his libraries to break9697 Browser and plugin coding errors Further information Buffer overflow JavaScript provides an interface to a wide range of browser capabilities some of which may have flaws such as buffer overflows These flaws can allow attackers to write scripts that would run any code they wish on the users system This code is not by any means limited to another JavaScript application For example a buffer overrun exploit can allow an attacker to gain access to the operating systems API with superuser privileges These flaws have affected major browsers including Firefox98 Internet Explorer99 and Safari100 Plugins such as video players Adobe Flash and the wide range of ActiveX controls enabled by default in Microsoft Internet Explorer may also have flaws exploitable via JavaScript such flaws have been exploited in the past101102 In Windows Vista Microsoft has attempted to contain the risks of bugs such as buffer overflows by running the Internet Explorer process with limited privileges103 Google Chrome similarly confines its page renderers to their own sandbox Sandbox implementation errors Web browsers are capable of running JavaScript outside the sandbox with the privileges necessary to for example create or delete files Such privileges are not intended to be granted to code from the Web Incorrectly granting privileges to JavaScript from the Web has played a role in vulnerabilities in both Internet Explorer104 and Firefox105 In Windows XP Service Pack 2 Microsoft demoted JScripts privileges in Internet Explorer106 Microsoft Windows allows JavaScript source files on a computers hard drive to be launched as generalpurpose nonsandboxed programs see Windows Script Host This makes JavaScript like VBScript a theoretically viable vector for a Trojan horse although JavaScript Trojan horses are uncommon in practice107failed verification Hardware vulnerabilities In 2015 a JavaScriptbased proofofconcept implementation of a rowhammer attack was described in a paper by security researchers108109110111 In 2017 a JavaScriptbased attack via browser was demonstrated that could bypass ASLR It is called ASLRCache or AnC112113 In 2018 the paper that announced the Spectre attacks against Speculative Execution in Intel and other processors included a JavaScript implementation114 Development tools Important tools have evolved with the language Every major web browser has builtin web development tools including a JavaScript debugger Static program analysis tools such as ESLint and JSLint scan JavaScript code for conformance to a set of standards and guidelines Some browsers have builtin profilers Standalone profiling libraries have also been created such as benchmarkjs and jsbench115116 Many text editors have syntax highlighting support for JavaScript code Static program analysis ESLint This section is an excerpt from ESLintedit ESLint is a static code analysis tool for identifying problematic patterns found in JavaScript code It was created by Nicholas C Zakas in 2013117118 Rules in ESLint are configurable and customized rules can be defined and loaded ESLint covers both code quality and coding style issues ESLint supports current standards of ECMAScript and experimental syntax from drafts for future standards Code using JSX or TypeScript can also be processed when a plugin or transpiler is used119120 JSLint This section is an excerpt from JSLintedit JSLint is a static code analysis tool used in software development for checking if JavaScript source code complies with coding rules It is provided primarily as a browserbased web application accessible through the domain jslintcom but there are also commandline adaptations121 It was created in 2002 by Douglas Crockford122 Related technologies Java Main article Java A common misconception is that JavaScript is the same as Java Both indeed have a Clike syntax the C language being their most immediate common ancestor language They are also typically sandboxed when used inside a browser and JavaScript was designed with Javas syntax and standard library in mind In particular all Java keywords were reserved in original JavaScript JavaScripts standard library follows Javas naming conventions and JavaScripts Math and Date objects are based on classes from Java 10123 Java and JavaScript both first appeared in 1995 but Java was developed by James Gosling of Sun Microsystems and JavaScript by Brendan Eich of Netscape Communications The differences between the two languages are more prominent than their similarities Java has static typing while JavaScripts typing is dynamic Java is loaded from compiled bytecode while JavaScript is loaded as humanreadable source code Javas objects are classbased while JavaScripts are prototypebased Finally Java did not support functional programming until Java 8 while JavaScript has done so from the beginning being influenced by Scheme JSON This section is an excerpt from JSONedit JSON JavaScript Object Notation pronounced ˈdʒeɪsən also ˈdʒeɪˌsɒn is an open standard file format and data interchange format that uses humanreadable text to store and transmit data objects consisting of attributevalue pairs and arrays or other serializable values It is a common data format with diverse uses in electronic data interchange including that of web applications with servers JSON is a languageindependent data format It was derived from JavaScript but many modern programming languages include code to generate and parse JSONformat data JSON filenames use the extension json Douglas Crockford originally specified the JSON format in the early 2000s124 He and Chip Morningstar sent the first JSON message in April 2001 TypeScript Main article TypeScript TypeScript TS is a strictlytyped variant of JavaScript TS differs by introducing type annotations to variables and functions and introducing a type language to describe the types within JS Otherwise TS shares much the same featureset as JS to allow it to be easily transpiled to JS for running clientside and to interoperate with other JS code125 WebAssembly Main article WebAssembly Since 2017 web browsers have supported WebAssembly a binary format that enables a JavaScript engine to execute performancecritical portions of web page scripts close to native speed126 WebAssembly code runs in the same sandbox as regular JavaScript code asmjs is a subset of JavaScript that served as the forerunner of WebAssembly127 Transpilers Main article Transpiler JavaScript is the dominant clientside language of the Web and many websites are scriptheavy Thus transpilers have been created to convert code written in other languages which can aid the development process34 Ajax This section is an excerpt from Ajax programmingedit Ajax also AJAX ˈeɪdʒæks short for Asynchronous JavaScript and XML or Asynchronous JavaScript transfer xfer128129 is a set of web development techniques that uses various web technologies on the clientside to create asynchronous web applications With Ajax web applications can send and retrieve data from a server asynchronously in the background without interfering with the display and behaviour of the existing page By decoupling the data interchange layer from the presentation layer Ajax allows web pages and by extension web applications to change content dynamically without the need to reload the entire page130 In practice modern implementations commonly utilize JSON instead of XML Ajax is not a technology but rather a programming concept HTML and CSS can be used in combination to mark up and style information The webpage can be modified by JavaScript to dynamically displayand allow the user to interact with the new information The builtin XMLHttpRequest object is used to execute Ajax on webpages allowing websites to load content onto the screen without refreshing the page Ajax is not a new technology nor is it a new language Instead it is existing technologies used in a new way References  a b Netscape and Sun announce JavaScript the Open Crossplatform Object Scripting Language for Enterprise Networks and the Internet Press release December 4 1995 Archived from the original on 20070916  ECMAScript 2021 language specification June 2021 Retrieved 27 July 2021  Error Unable to display the reference properly See the documentation for details  nodejsnodeeps GitHub Archived from the original on 20200829 Retrieved 20180705  a b Seibel Peter September 16 2009 Coders at Work Reflections on the Craft of Programming Apress ISBN 9781430219484 Archived from the original on December 24 2020 Retrieved December 25 2018 Eich The immediate concern at Netscape was it must look like Java  a b c d e Chapter 4 How JavaScript Was Created speakingjscom Archived from the original on 20200227 Retrieved 20171121  Popularity  Brendan Eich  Brendan Eich An Introduction to JavaScript JSConf 2010 YouTube p 22m Archived from the original on August 29 2020 Retrieved November 25 2019 Eich function eight letters I was influenced by AWK  Eich Brendan 1998 Foreword In Goodman Danny ed JavaScript Bible 3rd ed John Wiley  Sons ISBN 0764531883 LCCN 97078208 OCLC 38888873 OL 712205M  Usage Statistics of JavaScript as Clientside Programming Language on Websites July 2023 w3techscom Retrieved 20230702  ECMAScript 2020 Language Specification Archived from the original on 20200508 Retrieved 20200508  Bloomberg Game Changers Marc Andreessen Bloomberg Bloomberg March 17 2011 Archived from the original on May 16 2012 Retrieved December 7 2011  Enzer Larry August 31 2018 The Evolution of the Web Browsers Monmouth Web Developers Archived from the original on August 31 2018 Retrieved August 31 2018  TechVision Innovators of the Net Brendan Eich and JavaScript Archived from the original on February 8 2008  Fin JS June 17 2016 Brendan Eich  CEO of Brave archived from the original on February 10 2019 retrieved February 7 2018  a b Chapter 5 Standardization ECMAScript speakingjscom Archived from the original on 1 November 2021 Retrieved 1 November 2021  a b Champeon Steve April 6 2001 JavaScript How Did We Get Here oreillycom Archived from the original on July 19 2016 Retrieved July 16 2016  Microsoft Internet Explorer 30 Beta Now Available microsoftcom Microsoft May 29 1996 Archived from the original on November 24 2020 Retrieved July 16 2016  McCracken Harry September 16 2010 The Unwelcome Return of Best Viewed with Internet Explorer technologizercom Archived from the original on June 23 2018 Retrieved July 16 2016  Baker Loren November 24 2004 Mozilla Firefox Internet Browser Market Share Gains to 74 Search Engine Journal Archived from the original on May 7 2021 Retrieved May 8 2021  Weber Tim May 9 2005 The assault on software giant Microsoft BBC News Archived from the original on September 25 2017  Big browser comparison test Internet Explorer vs Firefox Opera Safari and Chrome PC Games Hardware Computec Media AG 3 July 2009 Archived from the original on May 2 2012 Retrieved June 28 2010  Purdy Kevin June 11 2009 Lifehacker Speed Tests Safari 4 Chrome 2 Lifehacker Archived from the original on April 14 2021 Retrieved May 8 2021  TraceMonkey JavaScript Lightspeed Brendan Eichs Blog Archived from the original on December 4 2015 Retrieved July 22 2020  Mozilla asks Are we fast yet Wired Archived from the original on June 22 2018 Retrieved January 18 2019  ECMAScript 6 New Features Overview and Comparison es6featuresorg Archived from the original on March 18 2018 Retrieved March 19 2018  Professional Nodejs Building JavaScript Based Scalable Software Archived 20170324 at the Wayback Machine John Wiley  Sons 01Oct2012  Sams Teach Yourself Nodejs in 24 Hours Archived 20170323 at the Wayback Machine Sams Publishing 05Sep2012  Lawton George 19 July 2018 The secret history behind the success of npm and Node TheServerSide Archived from the original on 2 August 2021 Retrieved 2 August 2021  Brown Paul 13 January 2017 State of the Union npm Linuxcom Archived from the original on 2 August 2021 Retrieved 2 August 2021  a b Branscombe Mary 20160504 JavaScript Standard Moves to Yearly Release Schedule Here is Whats New for ES16 The New Stack Archived from the original on 20210116 Retrieved 20210115  The TC39 Process tc39es Ecma International Archived from the original on 20210207 Retrieved 20210115  ECMAScript proposals TC39 Archived from the original on 20201204 Retrieved 20210115  a b Ashkenas Jeremy List of languages that compile to JS GitHub Archived from the original on January 31 2020 Retrieved February 6 2020  US Trademark Serial No 75026640 usptogov United States Patent and Trademark Office 19970506 Archived from the original on 20210713 Retrieved 20210508  Legal Notices oraclecom Oracle Corporation Archived from the original on 20210605 Retrieved 20210508  Oracle to buy Sun in 74bn deal The Economic Times 21 April 2009  Usage statistics of JavaScript as clientside programming language on websites w3techscom 20210409 Archived from the original on 20220213 Retrieved 20210409  a b Usage statistics of JavaScript libraries for websites w3techscom Archived from the original on 20120526 Retrieved 20210409  React  A JavaScript library for building user interfaces reactjsorg Archived from the original on April 8 2018 Retrieved 7 April 2018  Chapter 1 What Is React  What React Is and Why It Matters Book wwworeillycom Archived from the original on May 6 2023 Retrieved 20230506  Krill Paul May 15 2014 React Making faster smoother UIs for datadriven Web apps InfoWorld Retrieved 20210223  Hemel Zef June 3 2013 Facebooks React JavaScript User Interfaces Library Receives Mixed Reviews infoqcom Archived from the original on May 26 2022 Retrieved 20220111  Dawson Chris July 25 2014 JavaScripts History and How it Led To ReactJS The New Stack Archived from the original on Aug 6 2020 Retrieved 20200719  Dere 2017  Panchal 2022  AngularJS and Angular 2 a Detailed Comparison 6 April 2018  Vanilla JS vanillajscom 20200616 Archived from the original on June 16 2020 Retrieved June 17 2020  ServerSide JavaScript Guide oraclecom Oracle Corporation December 11 1998 Archived from the original on March 11 2021 Retrieved May 8 2021  Clinick Andrew July 14 2000 Introducing JScript NET Microsoft Developer Network Microsoft Archived from the original on November 10 2017 Retrieved April 10 2018 Since the 1996 introduction of JScript version 10  weve been seeing a steady increase in the usage of JScript on the serverparticularly in Active Server Pages ASP  a b Mahemoff Michael December 17 2009 ServerSide JavaScript Back with a Vengeance readwritecom Archived from the original on June 17 2016 Retrieved July 16 2016  JavaScript for Acrobat adobecom 20090807 Archived from the original on August 7 2009 Retrieved August 18 2009  treitter 20130202 Answering the question How do I develop an app for GNOME livejournalcom Archived from the original on 20130211 Retrieved 20130207  Tessel 2 Leverage all the libraries of NodeJS to create useful devices in minutes with Tessel tesselio Archived from the original on 20210526 Retrieved 20210508  Nodejs Raspberry Pi GPIO Introduction w3schoolscom Archived from the original on 20210813 Retrieved 20200503  Espruino  JavaScript for Microcontrollers espruinocom Archived from the original on 20200501 Retrieved 20200503  Looper Jen 20150921 A Guide to JavaScript Engines for Idiots Telerik Developer Network Archived from the original on 20181208 Retrieved 20181208  Concurrency model and Event Loop Mozilla Developer Network Archived from the original on September 5 2015 Retrieved August 28 2015  Deno Manual denoland Retrieved 20190517  Schiemann Dylan December 26 2018 Deno Secure V8 TypeScript Runtime from Original Nodejs Creator InfoQ Archived from the original on May 17 2019 Retrieved May 17 2019  Flanagan David August 17 2006 JavaScript The Definitive Guide The Definitive Guide OReilly Media Inc p 16 ISBN 9780596554477 Archived from the original on August 1 2020 Retrieved March 29 2019  a b c d Korolev Mikhail 20190301 JavaScript quirks in one image from the Internet The DEV Community Archived from the original on October 28 2019 Retrieved October 28 2019  Bernhardt Gary 2012 Wat Destroy All Software Archived from the original on October 28 2019 Retrieved October 28 2019  JavaScript data types and data structures MDN February 16 2017 Archived from the original on March 14 2017 Retrieved February 24 2017  Flanagan 2006 pp 176178  Crockford Douglas Prototypal Inheritance in JavaScript Archived from the original on 13 August 2013 Retrieved 20 August 2013  Inheritance and the prototype chain Mozilla Developer Network Archived from the original on April 25 2013 Retrieved April 6 2013  Herman David 2013 Effective JavaScript AddisonWesley p 83 ISBN 9780321812186  Haverbeke Marijn 2011 Eloquent JavaScript No Starch Press pp 9597 ISBN 9781593272821  Katz Yehuda 12 August 2011 Understanding Prototypes in JavaScript Archived from the original on 5 April 2013 Retrieved April 6 2013  Herman David 2013 Effective JavaScript AddisonWesley pp 125127 ISBN 9780321812186  Function  JavaScript MDN Web Docs Retrieved 20211030  Properties of the Function Object Es5githubcom Archived from the original on January 28 2013 Retrieved May 26 2013  Flanagan 2006 p 141  The many talents of JavaScript for generalizing RoleOriented Programming approaches like Traits and Mixins Archived 20171005 at the Wayback Machine Peterseligerblogpsotde April 11 2014  Traits for JavaScript Archived 20140724 at the Wayback Machine 2010  Home  CocktailJS Cocktailjsgithubio Archived from the original on February 4 2017 Retrieved February 24 2017  Croll Angus May 31 2011 A fresh look at JavaScript Mixins JavaScript JavaScript Archived from the original on 20200415  Haverbeke Marijn 2011 Eloquent JavaScript No Starch Press pp 139149 ISBN 9781593272821  E4X  Archive of obsolete content Mozilla Developer Network Mozilla Foundation February 14 2014 Archived from the original on July 24 2014 Retrieved July 13 2014  var  JavaScript The Mozilla Developer Network Archived from the original on December 23 2012 Retrieved December 22 2012  let MDN web docs Mozilla Archived from the original on May 28 2019 Retrieved June 27 2018  const MDN web docs Mozilla Archived from the original on June 28 2018 Retrieved June 27 2018  ECMAScript Language Specification  ECMA262 Edition 51 Ecma International Archived from the original on November 26 2012 Retrieved December 22 2012  console Mozilla Developer Network Mozilla Archived from the original on February 28 2013 Retrieved April 6 2013  arguments Mozilla Developer Network Mozilla Archived from the original on April 13 2013 Retrieved April 6 2013  function  JavaScript  MDN developermozillaorg Retrieved 20220927  JavaScript modules MDN Web Docs Mozilla Archived from the original on 17 July 2022 Retrieved 28 July 2022  Making JavaScript Safe for Advertising ADsafe Archived from the original on 20210706 Retrieved 20210508  Secure ECMA Script SES Archived from the original on May 15 2013 Retrieved May 26 2013  Google Caja Project Google Archived from the original on 20210122 Retrieved 20210709  Mozilla CrossSite Scripting Vulnerability Reported and Fixed  MozillaZine Talkback Mozillazineorg Archived from the original on July 21 2011 Retrieved February 24 2017  Kottelin Thor 17 June 2008 Rightclick protection Forget about it blogantanet Archived from the original on 9 August 2011 Retrieved 28 July 2022  Rehorik Jan 29 November 2016 Why You Should Never Put Sensitive Data in Your JavaScript ServiceObjects Blog ServiceObjects Archived from the original on June 3 2019 Retrieved June 3 2019  a b Lauinger Tobias Chaabane Abdelberi Arshad Sajjad Robertson William Wilson Christo Kirda Engin December 21 2016 Thou Shalt Not Depend on Me Analysing the Use of Outdated JavaScript Libraries on the Web PDF Northeastern University arXiv181100918 doi1014722ndss201723414 ISBN 9781891562464 S2CID 17885720 archived from the original PDF on 29 March 2017 retrieved 28 July 2022  Collins Keith March 27 2016 How one programmer broke the internet by deleting a tiny piece of code Quartz Archived from the original on February 22 2017 Retrieved February 22 2017  SC Magazine UK Developers 11 lines of deleted code breaks the internet Archived February 23 2017 at the Wayback Machine  Mozilla Corporation Buffer overflow in cryptosignText Archived 20140604 at the Wayback Machine  Festa Paul August 19 1998 Bufferoverflow bug in IE CNET Archived from the original on December 25 2002  SecurityTrackercom Apple Safari JavaScript Buffer Overflow Lets Remote Users Execute Arbitrary Code and HTTP Redirect Bug Lets Remote Users Access Files Archived 20100218 at the Wayback Machine  SecurityFocus Microsoft WebViewFolderIcon ActiveX Control Buffer Overflow Vulnerability Archived 20111011 at the Wayback Machine  Fusion Authority Macromedia Flash ActiveX Buffer Overflow Archived August 13 2011 at the Wayback Machine  Protected Mode in Vista IE7  IEBlog Blogsmsdncom February 9 2006 Archived from the original on January 23 2010 Retrieved February 24 2017  US CERT Vulnerability Note VU713878 Microsoft Internet Explorer does not properly validate source of redirected frame Archived 20091030 at the Wayback Machine  Mozilla Foundation Mozilla Foundation Security Advisory 200541 Privilege escalation via DOM property overrides Archived 20140604 at the Wayback Machine  Andersen Starr 20040809 Part 5 Enhanced Browsing Security TechNet Microsoft Docs Changes to Functionality in Windows XP Service Pack 2 Retrieved 20211020  For one example of a rare JavaScript Trojan Horse see Symantec Corporation JSSeekerK Archived 20110913 at the Wayback Machine  Gruss Daniel Maurice Clémentine Mangard Stefan July 24 2015 Rowhammerjs A Remote SoftwareInduced Fault Attack in JavaScript arXiv150706955 csCR  JeanPharuns Alix July 30 2015 Rowhammerjs Is the Most Ingenious Hack Ive Ever Seen Motherboard Vice Archived from the original on January 27 2018 Retrieved January 26 2018  Goodin Dan August 4 2015 DRAM Bitflipping exploit for attacking PCs Just add JavaScript Ars Technica Archived from the original on January 27 2018 Retrieved January 26 2018  Auerbach David July 28 2015 Rowhammer security exploit Why a new security attack is truly terrifying slatecom Archived from the original on July 30 2015 Retrieved July 29 2015  AnC Archived 20170316 at the Wayback Machine VUSec 2017  New ASLRbusting JavaScript is about to make driveby exploits much nastier Archived 20170316 at the Wayback Machine Ars Technica 2017  Spectre Attack Archived 20180103 at the Wayback Machine Spectre Attack  Benchmarkjs benchmarkjscom Archived from the original on 20161219 Retrieved 20161106  JSBENCH JSBENCH Performance Benchmarking Playground for JavaScript jsbench Archived from the original on 20210227 Retrieved 20210813  First commit  eslinteslint GitHub Retrieved 20190705  Zakas Nicholas C 16 July 2013 Introducing ESLint nczonlinenet Retrieved 20180226 JSLint was the state of the art in JavaScript linting technology  The future of TypeScript on ESLint ESLint  Pluggable JavaScript linter Retrieved 20200424  Accessibility auditing with eslintpluginjsxa11y webdev Google Developers 20190429 Retrieved 20200424 The ELint plugin can help pinpoint issues in your JSX  JSLint from the Command Line wwwhacksparrowcom January 2013 Archived from the original on 20180227 Retrieved 20180226  first commit GitHub 20101112 Retrieved 20180225 Copyright 2002 Douglas Crockford All Rights Reserved Wrrrldwide and Beyond  Eich Brendan April 3 2008 Popularity Archived from the original on July 3 2011 Retrieved January 19 2012  Douglas Crockford The JSON Saga YouTube 20110828 Retrieved 20220221  TypeScript JavaScript With Syntax For Types Typescriptlangorg Retrieved 20220812  Edge Browser Switches WebAssembly to On  Visual Studio Magazine Visual Studio Magazine Archived from the original on 20180210 Retrieved 20180209  frequently asked questions asmjs Archived from the original on June 4 2014 Retrieved April 13 2014  Jesse James Garrett 18 February 2005 Ajax A New Approach to Web Applications AdaptivePathcom Archived from the original on 10 September 2015 Retrieved 19 June 2008  Ajax  Web developer guides MDN Web Docs Archived from the original on 28 February 2018 Retrieved 20180227  Ullman Chris March 2007 Beginning Ajax wrox ISBN 9780470106754 Archived from the original on 5 July 2008 Retrieved 24 June 2008 Sources Dere Mohan 20171221 How to integrate createreactapp with all the libraries you need to make a great app freeCodeCamp Retrieved 20180614 Panchal Krunal 20220426 Angular vs React Detailed Comparison Groovy Web Retrieved 20230605 Further reading See also ECMAScript Specification Documents Flanagan David JavaScript The Definitive Guide 7th edition Sebastopol California OReilly 2020 ISBN 9781491952023 Haverbeke Marijn Eloquent JavaScript 3rd edition No Starch Press 2018 472 pages ISBN 9781593279509download Zakas Nicholas Principles of ObjectOriented JavaScript 1st edition No Starch Press 2014 120 pages ISBN 9781593275402 External links JavaScript at Wikipedias sister projects Definitions from WiktionaryMedia from CommonsTextbooks from WikibooksResources from WikiversityDocumentation from MediaWiki Listen to this article 48 minutes This audio file was created from a revision of this article dated 20 August 2013 20130820 and does not reflect subsequent editsAudio help  More spoken articles JavaScript at Curlie JavaScript The First 20 Years Retrieved 20220206 vteJavaScriptCode analysis ESLint JSHint JSLint Supersets JS TypeScript Transpilers AtScript Babel ClojureScript CoffeeScript Dart Elm Emscripten Google Closure Compiler Google Web Toolkit Haxe LiveScript Morfik Nim Opa PureScript Reason WebSharper Concepts JavaScript library JavaScript syntax Debuggers Chrome DevTools Firefox Inspector Komodo IDE Microsoft Edge DevTools Opera DevTools Safari Web Inspector Doc generators JSDoc Editors comparison Ace Cloud9 IDE Atom CodeMirror Brackets Light Table PhpStorm Orion Visual Studio Visual Studio Express Visual Studio Code Visual Studio Team Services Vim Engines List of ECMAScript engines Frameworks Comparison of JavaScript frameworks List of JavaScript libraries Related technologies Ajax AssemblyScript asmjs Cascading Style Sheets Document Object Model HTML HTML5 JSON WebAssembly WebAuthn Package managers npm yarn Module bundlers Webpack Vite esbuild Serverside Active Server Pages Bun CommonJS Deno JSGI Nodejs Wakanda Unit testing frameworks list Jasmine Jest Mocha QUnit People Douglas Crockford Ryan Dahl Brendan Eich John Resig vteProgramming languages Comparison Timeline History Ada ALGOL APL Assembly BASIC C C C Classic Visual Basic COBOL Erlang Forth Fortran Go Haskell Java JavaScript Julia Kotlin Lisp Lua MATLAB ML Object Pascal Pascal Perl PHP Prolog Python R Ruby Rust SQL Scratch Shell Simula Smalltalk Swift Visual Basic more Lists Alphabetical Categorical Generational NonEnglishbased Category vteECMAScriptDialects ActionScript Caja JavaScript engines asmjs JScript JScript NET QtScript TypeScript WMLScript Enginescomparison Carakan Futhark InScript JavaScriptCore JScript KJS Linear B QtScript Rhino SpiderMonkey TraceMonkey JägerMonkey Tamarin V8 ChakraCore Chakra JScript NET Nashorn FrameworksClientside Dojo Echo Ext JS Google Web Toolkit jQuery Lively Kernel midori MochiKit MooTools Prototype Pyjs qooxdoo SproutCore Spry Wakanda Framework Serverside Nodejs Deno Bun Jaxer AppJet WakandaDB Multiple Cappuccino PureMVC Libraries Backbonejs SWFObject Underscorejs People Brendan Eich Douglas Crockford John Resig Scott Isaacs Other DHTML Ecma International JSDoc JSGI JSHint JSLint JSON JSSS Sputnik SunSpider Asynchronous module definition CommonJS Lists JavaScript libraries Ajax frameworks Comparisons JavaScript frameworks serverside JavaScript vteWeb browsers Features standards protocols Features Bookmarks Extensions Privacy mode Web standards HTML v5 CSS DOM JavaScript IndexedDB Web storage WebAssembly WebGL Protocols HTTP Cookies Encryption OCSP WebRTC WebSocket ActiveBlinkbased Google Chrome Chromium Arc Avast Blisk Brave Citrio Coc Coc Dragon Epic Falkon Maxthon Microsoft Edge Opera Otter Puffin Samsung Internet Silk Sleipnir Sputnik SRWare UC Vivaldi Whale Yandex Geckobased Firefox GNU IceCat PirateBrowser SlimBrowser Tor Browser Gecko forks Basilisk KMeleon LibreWolf Pale Moon SeaMonkey Waterfox WebKitbased Safari Dolphin Dooble GNOME Web iCab Konqueror Midori Roccat surf Other 360 DuckDuckGo eww Flow Links Lunascape Lynx NetFront NetSurf QQ browser qutebrowser w3m DiscontinuedBlinkbased Beaker Flock Redcore Rockmelt SalamWeb Torch Geckobased Beonex Communicator Camino Classilla Conkeror Firefox Lite Galeon Ghostzilla IceDragon Kazehakase Kylo Lotus MicroB Minimo Mozilla suite Pogo Strata Swiftfox Swiftweasel TenFourFox Timberwolf xB MSHTMLbased Internet Explorer AOL Deepnet GreenBrowser MediaBrowser NeoPlanet NetCaptor SpaceTime ZAC WebKitbased Arora BOLT Opera Coast Fluid Google TV Iris Mercury OmniWeb Origyn QtWeb rekonq Shiira Steel Browser for Symbian Uzbl WebPositive xombrero Other abaco Amaya Arachne Arena Avant Blazer Cake Charon CM Browser Deepfish Dillo Edge Legacy ELinks Gazelle HotJava IBM Home Page Reader IBM WebExplorer IBrowse KidZui Line Mode Mosaic MSN TV NetPositive Netscape Skweezer Skyfire ThunderHawk Vision WinWAP WorldWideWeb Category Comparisons List vteNodejsPlatform Nodejs npm V8 CommonJS Frameworks MEAN MongoDB Expressjs AngularJSAngular MEEN substituted with Emberjs Backbonejs Meteor Sailsjs uses Expressjs Nextjs Libraries Lodash Underscorejs Reactjs Vuejs Languages JavaScript CoffeeScript TypeScript Portal Computer programming Authority control databases International FAST National Spain France BnF data Germany Israel United States Czech Republic Other IdRef Retrieved from httpsenwikipediaorgwindexphptitleJavaScriptoldid1191491830 Categories JavaScriptAmerican inventionsCrossplatform softwareDynamically typed programming languagesFunctional languagesObjectbased programming languagesHighlevel programming languagesProgramming languages created in 1995Programming languages with an ISO standardPrototypebased programming languagesScripting languagesWeb programmingHidden categories ModuleWd reference errorsWebarchive template wayback linksArticles with short descriptionShort description matches WikidataWikipedia pending changes protected pagesArticles containing potentially dated statements from 2023All articles containing potentially dated statementsAll articles with vague or ambiguous timeVague or ambiguous time from September 2023Articles with excerptsAll articles with unsourced statementsArticles with unsourced statements from August 2023All articles with failed verificationArticles with failed verification from March 2017Pages using Sister project links with wikidata namespace mismatchPages using Sister project links with hidden wikidataPages using Sister project links with default searchArticles with hAudio microformatsSpoken articlesArticles with Curlie linksArticles with FAST identifiersArticles with BNE identifiersArticles with BNF identifiersArticles with BNFdata identifiersArticles with GND identifiersArticles with J9U identifiersArticles with LCCN identifiersArticles with NKC identifiersArticles with SUDOC identifiersArticles with example JavaScript code ,https://en.wikipedia.org/wiki/JavaScript,Front-End Development,3212,10854
Responsive Web Design,Vitaly FriedmanUpdated Aug 11 20180 commentsResponsive Web Design What It Is And How To Use It33 min readCoding CSS Responsive Design Media QueriesShare on Twitter LinkedInAbout The AuthorVitaly Friedman loves beautiful content and doesnt like to give in easily When he is not writing hes most probably running frontend  UX  More about Vitaly Email NewsletterYour smashing email Weekly tips on frontend  UXTrusted by 200000 folks Smart Interface Design Checklists Deep Dive On Accessibility Testing with Manuel Matuzović Cascading Style Systems Resilient  Maintainable CSS with Miriam Suzanne UX Strategy Masterclass with Vitaly Friedman Watch Information Session to Learn More Build layouts 10x fasterGet started with responsive Web design In this article youll find how to respond to the users behavior and environment based on screen size platform and orientationAlmost every new client these days wants a mobile version of their website Its practically essential after all one design for the BlackBerry another for the iPhone the iPad netbook Kindle  and all screen resolutions must be compatible too In the next five years well likely need to design for a number of additional inventions When will the madness stop It wont of courseIn the field of Web design and development were quickly getting to the point of being unable to keep up with the endless new resolutions and devices For many websites creating a website version for each resolution and new device would be impossible or at least impractical Should we just suffer the consequences of losing visitors from one device for the benefit of gaining visitors from another Or is there another optionWhat is Responsive Web DesignResponsive Web design is the approach that suggests that design and development should respond to the users behavior and environment based on screen size platform and orientationThe practice consists of a mix of flexible grids and layouts images and an intelligent use of CSS media queries As the user switches from their laptop to iPad the website should automatically switch to accommodate for resolution image size and scripting abilities One may also have to consider the settings on their devices if they have a VPN for iOS on their iPad for example the website should not block the users access to the page In other words the website should have the technology to automatically respond to the users preferences This would eliminate the need for a different design and development phase for each new gadget on the marketThe Concept Of Responsive Web DesignEthan Marcotte wrote an introductory article about the approach Responsive Web Design for A List Apart It stems from the notion of responsive architectural design whereby a room or space automatically adjusts to the number and flow of people within itRecently an emergent discipline called responsive architecture has begun asking how physical spaces can respond to the presence of people passing through them Through a combination of embedded robotics and tensile materials architects are experimenting with art installations and wall structures that bend flex and expand as crowds approach them Motion sensors can be paired with climate control systems to adjust a rooms temperature and ambient lighting as it fills with people Companies have already produced smart glass technology that can automatically become opaque when a rooms occupants reach a certain density threshold giving them an additional layer of privacyTransplant this discipline onto Web design and we have a similar yet whole new idea Why should we create a custom Web design for each group of users after all architects dont design a building for each group size and type that passes through it Like responsive architecture Web design should automatically adjust It shouldnt require countless custommade solutions for each new category of usersObviously we cant use motion sensors and robotics to accomplish this the way a building would Responsive Web design requires a more abstract way of thinking However some ideas are already being practiced fluid layouts media queries and scripts that can reformat Web pages and markup effortlessly or automaticallyBut responsive Web design is not only about adjustable screen resolutions and automatically resizable images but rather about a whole new way of thinking about design Lets talk about all of these features plus additional ideas in the makingMeet Smashing Workshops on frontend design  UX with practical takeaways live sessions video recordings and a friendly QA With Brad Frost Stéph Walter and so many othersJump to the workshops Adjusting Screen ResolutionWith more devices come varying screen resolutions definitions and orientations New devices with new screen sizes are being developed every day and each of these devices may be able to handle variations in size functionality and even color Some are in landscape others in portrait still others even completely square As we know from the rising popularity of the iPhone iPad and advanced smartphones many new devices are able to switch from portrait to landscape at the users whim How is one to design for these situationsPortrait and landscape modesIn addition to designing for both landscape and portrait and enabling those orientations to possibly switch in an instant upon page load we must consider the hundreds of different screen sizes Yes it is possible to group them into major categories design for each of them and make each design as flexible as necessary But that can be overwhelming and who knows what the usage figures will be in five years Besides many users do not maximize their browsers which itself leaves far too much room for variety among screen sizesMorten Hjerde and a few of his colleagues identified statistics on about 400 devices sold between 2005 and 2008 Below are some of the most commonSome of the most common screen sizes between 2005 and 2008Since then even more devices have come out Its obvious that we cant keep creating custom solutions for each one So how do we deal with the situationPart of the Solution Flexible EverythingA few years ago when flexible layouts were almost a luxury for websites the only things that were flexible in a design were the layout columns structural elements and the text Images could easily break layouts and even flexible structural elements broke a layouts form when pushed enough Flexible designs werent really that flexible they could give or take a few hundred pixels but they often couldnt adjust from a large computer screen to a netbookNow we can make things more flexible Images can be automatically adjusted and we have workarounds so that layouts never break although they may become squished and illegible in the process While its not a complete fix the solution gives us far more options Its perfect for devices that switch from portrait orientation to landscape in an instant or for when users switch from a large computer screen to an iPadIn Ethan Marcottes article he created a sample Web design that features this better flexible layout The entire design is a lovely mix of fluid grids fluid images and smart markup where needed Creating fluid grids is fairly common practice and there are a number of techniques for creating fluid imagesHiding and Revealing Portions of ImagesCreating Sliding Composite ImagesForeground Images That Scale With the LayoutFor more information on creating fluid websites be sure to look at the book Flexible Web Design Creating Liquid and Elastic Layouts with CSS by Zoe Mickley Gillenwater and download the sample chapter Creating Flexible Images In addition Zoe provides the following extensive list of tutorials resources inspiration and best practices on creating flexible grids and layouts Essential Resources for Creating Liquid and Elastic LayoutsWhile from a technical perspective this is all easily possible its not just about plugging these features in and being done Look at the logo in this design for exampleLogo example were the image is divided in two the background set to be cropped and to maintain its size and the other image resized proportionallyIf resized too small the image would appear to be of low quality but keeping the name of the website visible and not cropping it off was important So the image is divided into two one of the illustration set as a background to be cropped and to maintain its size and the other of the name resized proportionallyh1 idlogoa hrefimg srcsitelogopng altThe Baker Street Inquirer ah1Above the h1 element holds the illustration as a background and the image is aligned according to the containers background the headingThis is just one example of the kind of thinking that makes responsive Web design truly effective But even with smart fixes like this a layout can become too narrow or short to look right In the logo example above although it works the ideal situation would be to not crop half of the illustration or to keep the logo from being so small that it becomes illegible and floats upFlexible ImagesOne major problem that needs to be solved with responsive Web design is working with images There are a number of techniques to resize images proportionately and many are easily done The most popular option noted in Ethan Marcottes article on fluid images but first experimented with by Richard Rutter is to use CSSs maxwidth for an easy fiximg  maxwidth 100 As long as no other widthbased image styles override this rule every image will load in its original size unless the viewing area becomes narrower than the images original width The maximum width of the image is set to 100 of the screen or browser width so when that 100 becomes narrower so does the image Essentially as Jason Grigsby noted The idea behind fluid images is that you deliver images at the maximum size they will be used at You dont declare the height and width in your code but instead let the browser resize the images as needed while using CSS to guide their relative size Its a great and simple technique to resize images beautifullyNote that maxwidth is not supported in IE but a good use of width 100 would solve the problem neatly in an IEspecific style sheet One more issue is that when an image is resized too small in some older browsers in Windows the rendering isnt as clear as it ought to be There is a JavaScript to fix this issue though found in Ethan Marcottes articleWhile the above is a great quick fix and good start to responsive images image resolution and download times should be the primary considerations While resizing an image for mobile devices can be very simple if the original image size is meant for large devices it could significantly slow download times and take up space unnecessarilyFilament Groups Responsive ImagesThis technique presented by the Filament Group takes this issue into consideration and not only resizes images proportionately but shrinks image resolution on smaller devices so very large images dont waste space unnecessarily on small screensFilament group image resizingThis technique requires a few files all of which are available on Github First a JavaScript file rwdimagesjs the htaccess file and an image file rwdgif Then we can use just a bit of HTML to reference both the larger and smaller resolution images first the small image with an r prefix to clarify that it should be responsive and then a reference to the bigger image using datafullsrcimg srcsmallResjpg datafullsrclargeResjpgThe datafullsrc is a custom HTML5 attribute defined in the files linked to above For any screen that is wider than 480 pixels the largerresolution image largeResjpg will load smaller screens wouldnt need to load the bigger image and so the smaller image smallResjpg will loadThe JavaScript file inserts a base element that allows the page to separate responsive images from others and redirects them as necessary When the page loads all files are rewritten to their original forms and only the large or small images are loaded as necessary With other techniques all higherresolution images would have had to be downloaded even if the larger versions would never be used Particularly for websites with a lot of images this technique can be a great saver of bandwidth and loading timeThis technique is fully supported in modern browsers such as IE8 Safari Chrome and Opera as well as mobile devices that use these same browsers iPad iPhone etc Older browsers and Firefox degrade nicely and still resize as one would expect of a responsive image except that both resolutions are downloaded together so the end benefit of saving space with this technique is voidStop iPhone Simulator Image ResizingOne nice thing about the iPhone and iPod Touch is that Web designs automatically rescale to fit the tiny screen A fullsized design unless specified otherwise would just shrink proportionally for the tiny browser with no need for scrolling or a mobile version Then the user could easily zoom in and out as necessaryThere was however one issue this simulator created When responsive Web design took off many noticed that images were still changing proportionally with the page even if they were specifically made for or could otherwise fit the tiny screen This in turn scaled down text and other elementsiPhone Scale  Image Think Vitamin  Website referenced 8 FacesBecause this works only with Apples simulator we can use an Applespecific meta tag to fix the problem placing it below the websites head section Thanks to Think Vitamins article on image resizing we have the meta tag belowmeta nameviewport contentwidthdevicewidth initialscale10Setting the initialscale to 1 overrides the default to resize images proportionally while leaving them as is if their width is the same as the devices width in either portrait or lanscape mode Apples documentation has a lot more information on the viewport meta tagCustom Layout StructureFor extreme size changes we may want to change the layout altogether either through a separate style sheet or more efficiently through a CSS media query This does not have to be troublesome most of the styles can remain the same while specific style sheets can inherit these styles and move elements around with floats widths heights and so onFor example we could have one main style sheet which would also be the default that would define all of the main structural elements such as wrapper content sidebar nav along with colors backgrounds and typography Default flexible widths and floats could also be definedIf a style sheet made the layout too narrow short wide or tall we could then detect that and switch to a new style sheet This new child style sheet would adopt everything from the default style sheet and then just redefine the layouts structureHere is the stylecss default content Default styles that will carry to the child style sheet  htmlbody background font color  h1h2h3 p blockquote pre code ol ul  Structural elements  wrapper width 80 margin 0 auto background fff padding 20px  content width 54 float left marginright 3  sidebarleft width 20 float left marginright 3  sidebarright width 20 float left Here is the mobilecss child contentwrapper width 90  content width 100  sidebarleft width 100 clear both  Additional styling for our new layout  bordertop 1px solid ccc margintop 20px  sidebarright width 100 clear both  Additional styling for our new layout  bordertop 1px solid ccc margintop 20px Moving content from wider to narrower screensMedia QueriesCSS3 supports all of the same media types as CSS 21 such as screen print and handheld but has added dozens of new media features including maxwidth devicewidth orientation and color New devices made after the release of CSS3 such as the iPad and Android devices will definitely support media features So calling a media query using CSS3 features to target these devices would work just fine and it will be ignored if accessed by an older computer browser that does not support CSS3In Ethan Marcottes article we see an example of a media query in actionlink relstylesheet typetextcss mediascreen and maxdevicewidth 480px hrefshetlandcss This media query is fairly selfexplanatory if the browser displays this page on a screen rather than print etc and if the width of the screen not necessarily the viewport is 480 pixels or less then load shetlandcssNew CSS3 features also include orientation portrait vs landscape devicewidth mindevicewidth and more Look at The Orientation Media Query for more information on setting and restricting widths based on these media query featuresOne can create multiple style sheets as well as basic layout alterations defined to fit ranges of widths  even for landscape vs portrait orientations Be sure to look at the section of Ethan Marcottes article entitled Meet the media query for more examples and a more thorough explanationMultiple media queries can also be dropped right into a single style sheet which is the most efficient option when used Smartphones portrait and landscape   media only screen and mindevicewidth  320px and maxdevicewidth  480px   Styles    Smartphones landscape   media only screen and minwidth  321px   Styles    Smartphones portrait   media only screen and maxwidth  320px   Styles  The code above is from a free template for multiple media queries between popular devices by Andy Clark See the differences between this approach and including different style sheet files in the markup as described in his book Hardboiled Web DesignCSS3 Media QueriesAbove are a few examples of how media queries both from CSS 21 and CSS3 could work Lets now look at some specific howtos for using CSS3 media queries to create responsive Web designs Many of these uses are relevant today and all will definitely be usable in the near futureThe minwidth and maxwidth properties do exactly what they suggest The minwidth property sets a minimum browser or screen width that a certain set of styles or separate style sheet would apply to If anything is below this limit the style sheet link or styles will be ignored The maxwidth property does just the opposite Anything above the maximum browser or screen width specified would not apply to the respective media queryNote in the examples below that were using the syntax for media queries that could be used all in one style sheet As mentioned above the most efficient way to use media queries is to place them all in one CSS style sheet with the rest of the styles for the website This way multiple requests dont have to be made for multiple style sheetsmedia screen and minwidth 600px  hereIsMyClass  width 30 float right  The class specified in the media query above hereIsMyClass will work only if the browser or screen width is above 600 pixels In other words this media query will run only if the minimum width is 600 pixels therefore 600 pixels or widermedia screen and maxwidth 600px  aClassforSmallScreens  clear both fontsize 13em  Now with the use of maxwidth this media query will apply only to browser or screen widths with a maximum width of 600 pixels or narrowerWhile the above minwidth and maxwidth can apply to either screen size or browser width sometimes wed like a media query that is relevant to device width specifically This means that even if a browser or other viewing area is minimized to something smaller the media query would still apply to the size of the actual device The mindevicewidth and maxdevicewidth media query properties are great for targeting certain devices with set dimensions without applying the same styles to other screen sizes in a browser that mimics the devices sizemedia screen and maxdevicewidth 480px  classForiPhoneDisplay  fontsize 12em  media screen and mindevicewidth 768px  minimumiPadWidth  clear both marginbottom 2px solid ccc  For the iPad specifically there is also a media query property called orientation The value can be either landscape horizontal orientation or portrait vertical orientationmedia screen and orientation landscape  iPadLandscape  width 30 float right  media screen and orientation portrait  iPadPortrait  clear both  Unfortunately this property works only on the iPad When determining the orientation for the iPhone and other devices the use of maxdevicewidth and mindevicewidth should do the trickThere are also many media queries that make sense when combined For example the minwidth and maxwidth media queries are combined all the time to set a style specific to a certain rangemedia screen and minwidth 800px and maxwidth 1200px  classForaMediumScreen  background cc0000 width 30 float right  The above code in this media query applies only to screen and browser widths between 800 and 1200 pixels A good use of this technique is to show certain content or entire sidebars in a layout depending on how much horizontal space is availableSome designers would also prefer to link to a separate style sheet for certain media queries which is perfectly fine if the organizational benefits outweigh the efficiency lost For devices that do not switch orientation or for screens whose browser width cannot be changed manually using a separate style sheet should be fineYou might want for example to place media queries all in one style sheet as above for devices like the iPad Because such a device can switch from portrait to landscape in an instant if these two media queries were placed in separate style sheets the website would have to call each style sheet file every time the user switched orientations Placing a media query for both the horizontal and vertical orientations of the iPad in the same style sheet file would be far more efficientAnother example is a flexible design meant for a standard computer screen with a resizable browser If the browser can be manually resized placing all variable media queries in one style sheet would be bestNevertheless organization can be key and a designer may wish to define media queries in a standard HTML link taglink relstylesheet mediascreen and maxwidth 600px hrefsmallcss  link relstylesheet mediascreen and minwidth 600px hreflargecss  link relstylesheet mediaprint hrefprintcss  JavaScriptAnother method that can be used is JavaScript especially as a backup to devices that dont support all of the CSS3 media query options Fortunately there is already a premade JavaScript library that makes older browsers IE 5 Firefox 1 Safari 2 support CSS3 media queries If youre already using these queries just grab a copy of the library and include it in the markup css3mediaqueriesjsIn addition below is a sample jQuery snippet that detects browser width and changes the style sheet accordingly  if one prefers a more handson approachscript typetextjavascript srchttpsajaxgoogleapiscomajaxlibsjquery144jqueryminjsscript script typetextjavascript documentreadyfunction windowbindresize resizeWindow function resizeWindowe var newWindowWidth  windowwidth  If width width is below 600px switch to the mobile stylesheet ifnewWindowWidth  600 linkrelstylesheetattrhref  mobilecss   Else if width is above 600px switch to the large stylesheet else ifnewWindowWidth  600 linkrelstylesheetattrhref  stylecss    script There are many solutions for pairing up JavaScript with CSS media queries Remember that media queries are not an absolute answer but rather are fantastic options for responsive Web design when it comes to pure CSSbased solutions With the addition of JavaScript we can accomodate far more variations For detailed information on using JavaScript to mimic or work with media queries look at Combining Media Queries and JavaScriptShowing or Hiding ContentIt is possible to shrink things proportionally and rearrange elements as necessary to make everything fit reasonably well as a screen gets smaller Its great that thats possible but making every piece of content from a large screen available on a smaller screen or mobile device isnt always the best answer We have best practices for mobile environments simpler navigation more focused content lists or rows instead of multiple columnsShow or hide content on different screen sizesResponsive Web design shouldnt be just about how to create a flexible layout on a wide range of platforms and screen sizes It should also be about the user being able to pick and choose content Fortunately CSS has been allowing us to show and hide content with ease for yearsdisplay noneEither declare display none for the HTML block element that needs to be hidden in a specific style sheet or detect the browser width and do it through JavaScript In addition to hiding content on smaller screens we can also hide content in our default style sheet for bigger screens that should be available only in mobile versions or on smaller devices For example as we hide major pieces of content we could replace them with navigation to that content or with a different navigation structure altogetherNote that we havent used visibility hidden here this just hides the content although it is still there whereas the display property gets rid of it altogether For smaller devices there is no need to keep the markup on the page  it just takes up resources and might even cause unnecessary scrolling or break the layoutHide content and replace it with links on smaller devicesHere is our markupp classsidebarnava hrefLeft Sidebar Contenta  a hrefRight Sidebar Contentap div idcontent h2Main Contenth2 div div idsidebarleft h2A Left Sidebarh2 div div idsidebarright h2A Right Sidebarh2 div In our default style sheet below we have hidden the links to the sidebar content Because our screen is large enough we can display this content on page loadHere is the stylecss default contentcontent width 54 float left marginright 3  sidebarleft width 20 float left marginright 3  sidebarright width 20 float left  sidebarnavdisplay noneNow we hide the two sidebars below and show the links to these pieces of content As an alternative the links could call to JavaScript to just cancel out the display none when clicked and the sidebars could be realigned in the CSS to float below the content or in another reasonable wayHere is the mobilecss simpler contentcontent width 100  sidebarleft display none  sidebarright display none  sidebarnavdisplay inlineWith the ability to easily show and hide content rearrange layout elements and automatically resize images form elements and more a design can be transformed to fit a huge variety of screen sizes and device types As the screen gets smaller rearrange elements to fit mobile guidelines for example use a script or alternate style sheet to increase white space or to replace image navigation sources on mobile devices for better usability icons would be more beneficial on smaller screensTouchscreens vs CursorsTouchscreens are becoming increasingly popular Assuming that smaller devices are more likely to be given touchscreen functionality is easy but dont be so quick Right now touchscreens are mainly on smaller devices but many laptops and desktops on the market also have touchscreen capability For example the HP Touchsmart tm2t is a basic touchscreen laptop with traditional keyboard and mouse that can transform into a tabletTouchscreen on laptops and desktopsTouchscreens obviously come with different design guidelines than purely cursorbased interaction and the two have different capabilities as well Fortunately making a design work for both doesnt take a lot of effort Touchscreens have no capability to display CSS hovers because there is no cursor once the user touches the screen they click So dont rely on CSS hovers for link definition they should be considered an additional feature only for cursorbased devicesLook at the article Designing for Touchscreen for more ideas Many of the design suggestions in it are best for touchscreens but they would not necessarily impair cursorbased usability either For example subnavigation on the right side of the page would be more userfriendly for touchscreen users because most people are righthanded they would therefore not bump or brush the navigation accidentally when holding the device in their left hand This would make no difference to cursor users so we might as well follow the touchscreen design guideline in this instance Many more guidelines of this kind can be drawn from touchscreenbased usabilityA Showcase Of Responsive Web DesignBelow we have a few examples of responsive Web design in practice today For many of these websites there is more variation in structure and style than is shown in the pairs of screenshots provided Many have several solutions for a variety of browsers and some even adjust elements dynamically in size without the need for specific browser dimensions Visit each of these and adjust your browser size or change devices to see them in actionArt Equals Work is a simple yet great example of responsive Web design The first screenshot below is the view from a standard computer screen dimension The website is flexible with browser widths by traditional standars but once the browser gets too narrow or is otherwise switched to a device with a smaller screen then the layout switches to a more readable and userfriendly format The sidebar disappears navigation goes to the top and text is enlarged for easy and simple vertical readingArt Equals Work website view from a standard computer screen dimensionArt Equals Work website layout switches for simple vertical reading once the browser gets too narrowWith Think Vitamin we see a similar approach When on a smaller screen or browser the sidebar and top bar are removed the navigation simplifies and moves directly above the content as does the logo The logo keeps its general look yet is modified for a more vertical orientation with the tagline below the main icon The white space around the content on larger screens is also more spacious and interesting whereas it is simplified for practical purposes on smaller screensThink Vitamin navigation simplifies when on smaller screen or browser8 Faces website design is flexible right down to a standard netbook or tablet device and expands in content quantity and layout width when viewed on wider screens or expanded browsers When viewed on narrower screens the featured issue on the right is cut out and the content below is shortened and rearranged in layout leaving only the essential information8 Faces website expands in content quantity on wider screens8 Faces website view on narrower screens hides and rearranges contentThe Hicksdesign website has three columns when viewed on a conventional computer screen with a maximized browser When minimized in width the design takes on a new layout the third column to the right is rearranged above the second and the logo moves next to the introductory text Thus no content needs to be removed for the smaller size For even narrower screens and browser widths the side content is removed completely and a simplified version is moved up top Finally the font size changes with the screen and browser width as the browser gets narrower the font size throughout gets smaller and remains proportionalHicksdesign website view on a conventional computer screenHicksdesigns website design takes on a new layout on narrower screensHere is a great example of a flexible image The image in this design automatically resizes after certain break points but in between those width changes only the side margins and excess white space are altered On smaller screens and minimized browsers the navigation simplifies and the columns of navigation at the top fall off At the designs smallest version the navigation simplifies to just a dropdown menu perfect for saving space without sacrificing critical navigation linksExample of a flexible image on smaller screens and minimized browsersThe website for Garret Keizer is fully flexible in wider browsers and on larger screens the photo logo and other images resize proportionally as do the headings and block areas for text At a few points some pieces of text change in font size and get smaller as the screen or browser gets narrower After a certain break point the layout transforms into what we see in the second screenshot below with a simple logo introductory text and a simple vertical structure for the remaining contentThe Garret Keizer website layout transforms from wider to narrower browsersWith four relatively contentheavy columns its easy to see how the content here could easily be squished when viewed on smaller devices Because of the easy organized columns though we can also collapse them quite simply when needed and we can stack them vertically when the space doesnt allow for a reasonable horizontal span When the browser is minimized or the user is on a smaller device the columns first collapse into two and then into one Likewise the horizontal lines for break points also change in width without changing the size or style of each lines title textCollapsing columnsOn the CSS Tricks website like many other collapsible Web designs the sidebars with excess content are the first to fall off when the screen or browser gets too narrow On this particular website the middle column or first sidebar to the left was the first to disappear and the sidebar with the ads and website extras did the same when the browser got even narrower Eventually the design leaves the posts uses less white space around the navigation and logo and moves the search bar to below the navigation The remaining layout and design is as flexible as can be because of its simplicityCollapsible Web design exampleAs one can see the main navigation here is the simple layout of tshirt designs spanning both vertically and horizontally across the screen As the browser or screen gets smaller the columns collapse and move below This happens at each break point when the layout is stressed but in between the break points the images just change proportionally in size This maintains balance in the design while ensuring that any images which are essential to the website dont get so small that they become unusableCollapsing columns and resizing images proportionallyTen by Twenty is another design that does not resort to changing layout structure at all after certain break points but rather simplifies responsive Web design by making everything fully flexible and automatically resizing no matter what the screen or browser width After a while the design does stress a bit and could benefit from some rearrangement of content But overall the image resizing and flexible content spaces allow for a fairly simple solution that accommodates a wide range of screen sizesTen by Twenty website image resizing and flexible content exampleOn wide screens and browsers all of the content on this simply designed website is well organized into columns sidebar and simple navigation up top Its a fairly standard and efficient layout On smaller screens the sidebar is the first to drop off and its content is moved below the book previews and essential information Being limited in space this design preserves its important hierarchy Whereas on a wider screen wed look left to right on a narrower screen wed tend to look from top to bottom Content on the right is moved below content that would appear on the left on a wider screen Eventually when the horizontal space is fully limited the navigation is simplified and stacked vertically and some repeated or inessential elements are removedWhen the horizontal space is fully limited the navigation is simplified and stacked verticallyThis design features a complex layout that looks inspired by a print style When viewed on a standard wide computer screen more portfolio pieces are featured and spanned horizontally across the page As one moves down the page more graphics and imagery span the space On a smaller screen the portfolio piece is cut down to one and then eventually left out altogether for very small screens and narrow browsers The visualizations below collapse into fewer columns and more rows and again some drop off entirely for very small screens This design shows a creative and intelligent way to make a notsocommon layout work responsivelyExample of how the imagery and graphics can collapse into fewer columns and more rowsThis design has three main stages at which the design and layout collapse into a more userfriendly form depending on how wide the screen or browser is The main image featuring type is scaled proportionally via a flexible image method Each layout structure is fully flexible until it reaches a breaking point at which point the layout switches to something more usable with less horizontal space The bottom four columns eventually collapse into two the logo moves above the navigation and the columns of navigation below are moved on top or below each other At the designs narrowest stage the navigation is supersimplified and some inessential content is cut out altogetherThe design and layout collapse into a more userfriendly form depending on how wide the screen or browser isThis layout does not change at all no content is dropped or rearranged and the text size does not change either Instead this design keeps its original form no matter what the change in horizontal and vertical space Instead it automatically resizes the header image and the images for the navigation The white space margins and padding are also flexible giving more room as the design expands and shrinksThe design keeps its original form and automatically resizes the header image and the images for the navigationThis is perhaps the simplest example of a responsive Web design in this showcase but also one of the most versatile The only piece in the layout that changes with the browser width is the blog posts date which moves above the posts title or to the side depending on how much horizontal space is available Beyond this the only thing that changes is the width of the content area and the margin space on the left and right Everything is centered so a sense of balance is maintained whatever the screen or browser width Because of this designs simplicity switching between browser and screen widths is quick and easyIn this example the only piece in the layout that changes with the browser width is the blog posts dateHarry Roberts shows that responsive design can also have quite humble uses If the user has a large viewport the website displays three columns with a navigation menu floating on the left For users with a viewport between 481px and 800px a narrow version is displayed the navigation jumps to the top of the site leaving the area for the content column and the sidebar Finally the iPhone view displays the sidebar under the content area Harry also wrote a detailed article about the CSS styles he added to the stylesheet in his article Media queries handier than you think A nice example of how a couple of simple CSS adjustments can improve the websites appearance across various devicesUsing simple CSS adjustments can improve the websites appearance across various devicesThis last design by Bryan James shows that responsive Web design need not apply only to static HTML and CSS websites Done in Flash this one features a fullsized background image and is flexible up to a certain width and height As a result of the design style on screens that are too small the background image gets mostly hidden and the content can become illegible and squished Instead of just letting it be though a message pops up informing the user that the screen is too small to adequately view the website It then prompts the user to switch to a bigger screen One can discuss if the design solution is good or bad in terms of usability but the example shows that Flash websites can respond to users viewport tooResponsive Web design on Flash websites can also respond to users viewportConclusionWe are indeed entering a new age of Web design and development Far too many options are available now and there will be far too many in the future to continue adjusting and creating custom solutions for each screen size device and advancement in technology We should rather start a new era today creating websites that are futureready right now Understanding how to make a design responsive to the user doesnt require too much learning and it can definitely be a lot less stressful and more productive than learning how to design and code properly for every single device availableResponsive Web design and the techniques discussed above are not the final answer to the everchanging mobile world Responsive Web design is a mere concept that when implemented correctly can improve the user experience but not completely solve it for every user device and platform We will need to constantly work with new devices resolutions and technologies to continually improve the user experience as technology evolves in the coming yearsBesides saving us from frustration responsive Web design is also best for the user Every custom solution makes for a better user experience With responsive Web design we can create custom solutions for a wider range of users on a wider range of devices A website can be tailored as well for someone on an old laptop or device as it can for the vast majority of people on the trendiest gadgets around and likewise as much for the few users who own the most advanced gadgets now and in the years to come Responsive Web design creates a great custom experience for everyone As Web designers we all strive for that every day on every project anyway rightFurther Resources for Responsive Web DesignDesigning for a Responsive Web with Heuristic Methods Design ReviverExamples Of Flexible Layouts With CSS3 Media Queries Zoe Mickley GillenwaterThe Big Web Show 9 Responsive Web Design 5by5 StudiosHow to Use CSS3 Media Queries to Create a Mobile Version of Your Website Smashing MagazineApplication Rapid Prototyping of Adaptive CSS and Responsive Design ProtoFluidHandcrafted CSS More Bulletproof Web Design Dan Cederholm printed bookFlexible Web Book Zoe Mickley Gillenwater printed bookFurther ReadingResponsive Web Design Techniques Tools and StrategiesThe State Of Responsive Web DesignDesign Process In The Responsive AgeTechniques For Gracefully Degrading Media QueriesAussie Hostings List of Responsive Web Hosts al vf mrnExplore more onCodingCSSResponsive DesignMedia Queries,https://www.smashingmagazine.com/2011/01/guidelines-for-responsive-web-design/,Front-End Development,1667,6841
React, The world cant live without mobile and web applications in this day and age Everything is digitized from booking cabs to ordering food to make bank transactions Thanks to the efficient frameworks that provide a seamless user experience One such robust frontend library is React This tutorial on what is React will help you understand the librarys fundamentals and work with a simple demo What Is React React is a framework that employs Webpack to automatically compile React JSX and ES6 code while handling CSS file prefixes React is a JavaScriptbased UI development library Although React is a library rather than a language it is widely used in web development The library first appeared in May 2013 and is now one of the most commonly used frontend libraries for web development React offers various extensions for entire application architectural support such as Flux and React Native beyond mere UI ReactJS History When compared to other technologies on the market React is a new technology Jordan Walke a software engineer at Facebook founded the library in 2011 giving it life The likes of XHP a straightforward HTML component framework for PHP have an influence on React Reacts newsfeed was its debut application in 2011 Later Instagram picks it up and incorporates it into their platform Why React Reacts popularity today has eclipsed that of all other frontend development frameworks Here is why Easy creation of dynamic applications React makes it easier to create dynamic web applications because it requires less coding and offers more functionality as opposed to JavaScript where coding often gets complex very quickly Improved performance React uses Virtual DOM thereby creating web applications faster Virtual DOM compares the components previous states and updates only the items in the Real DOM that were changed instead of updating all of the components again as conventional web applications do Reusable components Components are the building blocks of any React application and a single app usually consists of multiple components These components have their logic and controls and they can be reused throughout the application which in turn dramatically reduces the applications development time Unidirectional data flow React follows a unidirectional data flow This means that when designing a React app developers often nest child components within parent components Since the data flows in a single direction it becomes easier to debug errors and know where a problem occurs in an application at the moment in question Small learning curve React is easy to learn as it mostly combines basic HTML and JavaScript concepts with some beneficial additions Still as is the case with other tools and frameworks you have to spend some time to get a proper understanding of Reacts library It can be used for the development of both web and mobile apps We already know that React is used for the development of web applications but thats not all it can do There is a framework called React Native derived from React itself that is hugely popular and is used for creating beautiful mobile applications So in reality React can be used for making both web and mobile applications Dedicated tools for easy debugging Facebook has released a Chrome extension that can be used to debug React applications This makes the process of debugging React web applications faster and easier The above reasons more than justify the popularity of the React library and why it is being adopted by a large number of organizations and businesses Now lets familiarize ourselves with Reacts features Want a Top Software Development Job Start HereFull Stack DevelopmentMEANExplore ProgramReactJS Keys After answering what is ReactJs let us know what are keys While dealing with components that are produced periodically in React keys are essential Your component will continue to be uniquely identifiable after the modification if the key value is set They aid React in determining which elements have changed been eliminated or been added When making lists of components in React you must use a special string personality factor key React uses keys to indicate which list items have been modified destroyed or altered Or to put it another way we may say that keys are utilized to identify the components in lists ReactJS Advantages Reactjs builds a customized virtual DOM Because the JavaScript virtual DOM is quicker than the conventional DOM this will enhance the performance of apps ReactJS makes an amazing UI possible Search  engine friendly ReactJS Modules and valid data make larger apps easier to manage by increasing readability React integrates various architectures React makes the entire scripting environment process simpler It makes advanced maintenance easier and boosts output Guarantees quicker rendering The availability of a script for developing mobile apps is the best feature of React ReactJS is supported by a large community Advantages and Limitations Pros and Cons Advantages Makes use of the JavaScript structure known as virtual DOM Since JavaScripts virtual DOM is quicker than the conventional DOM this will boost the speed of programs Can be used with various systems and on both client and server sides is commendable Components and identify trends make larger apps easier to manage by increasing clarity Limitations Only addresses the apps angle and distance as a result additional techniques must be selected if you want a full collection of development tools Employs inline scripting and JSX which some programmers might find uncomfortable Features of React React offers some outstanding features that make it the most widely adopted library for frontend app development Here is the list of those salient features JSX JSX is a JavaScript syntactic extension Its a term used in React to describe how the user interface should seem You can write HTML structures in the same file as JavaScript code by utilizing JSX const name  Simplilearn const greet  h1Hello nameh1 The above code shows how JSX is implemented in React It is neither a string nor HTML Instead it embeds HTML into JavaScript code Virtual Document Object Model DOM The Virtual DOM is Reacts lightweight version of the Real DOM Real DOM manipulation is substantially slower than virtual DOM manipulation When an objects state changes Virtual DOM updates only that object in the real DOM rather than all of them What is the Document Object Model DOM Fig DOM of a Webpage DOM Document Object Model treats an XML or HTML document as a tree structure in which each node is an object representing a part of the document How do Virtual DOM and React DOM interact with each other When the state of an object changes in a React application VDOM gets updated It then compares its previous state and then updates only those objects in the real DOM instead of updating all of the objects This makes things move fast especially when compared to other frontend technologies that have to update each object even if only a single object changes in the web application Learn From The Best Mentors in the IndustryAutomation Testing Masters ProgramExplore ProgramArchitecture In a Model View ControllerMVC architecture React is the View responsible for how the app looks and feels MVC is an architectural pattern that splits the application layer into Model View and Controller The model relates to all datarelated logic the view is used for the UI logic of the application and the controller is an interface between the Model and View Extensions React goes beyond just being a UI framework it contains many extensions that cover the entire application architecture It helps the building of mobile apps and provides serverside rendering Flux and Redux among other things can extend React Data Binding Since React employs oneway data binding all activities stay modular and quick Moreover the unidirectional data flow means that its common to nest child components within parent components when developing a React project Fig Oneway data binding Debugging Since a broad developer community exists React applications are straightforward and easy to test Facebook provides a browser extension that simplifies and expedites React debugging Fig React Extension This extension for example adds a React tab in the developer tools option within the Chrome web browser The tab makes it easy to inspect React components directly Now that you know the key features of React lets move on to understanding the pillars of React Components in React Components are the building blocks that comprise a React application representing a part of the user interface React separates the user interface into numerous components making debugging more accessible and each component has its own set of properties and functions Here are some of the features of Components  Reusability  A component used in one area of the application can be reused in another area This helps speed up the development process Nested Components  A component can contain several other components Render method  In its minimal form a component must define a render method that specifies how the component renders to the DOM Passing properties  A component can also receive props These are properties passed by its parent to specify values Have a look at the demo for a better understanding Consider two components a Functional component and a Class Component with the following code import React from react function FunctionalComp  return pThis is a Functional componentp  export default FunctionalComp import React from react export class ClassComp extends ReactComponent  render  return pThis is the Class Component p   export default ClassComp A class component comes with a render method that renders onto the screen Export default is used to export only one object function variable class from the file Only one default export per file is allowed Evidently these components are imported into the main component which is Appjs in our case import React from react import FunctionalComp from ComponentsFunctionalComp import ClassComp from ComponentsClassComp function App  return  div h1Hello Welcome to Simplilearnh1 FunctionalComp  ClassComp  div   export default App Once run the browser will look like this A named export or just export can also be used to export multiple objects from a file Now that you have an understanding of React Components move on to React Props Dont miss out on the opportunity to become a Certified Professional with Simplilearns Post Graduate Program in Full Stack Web Development Enroll Today Props in React Props short for Properties in React Props short for properties allow the user to pass arguments or data to components These props help make the components more dynamic Props in a component are readonly and cannot be changed Consider the class Classpropsjs with the following code import React  Component  from react class Classprops extends Component  render  return  div h1 Hello thispropsname from thispropsplace Welcome to Simplilearn h1 div    export default Classprops Here you use the properties called name and place whose values can be passed when importing the component into the parent component In the main component Appjs consider the following code import React from react import Classprops from Classprops class App extends ReactComponent  render  return  div Classprops nameLearner 1 placePlaceX Classprops nameLearner 2 placePlaceY Classprops nameLearner 3 placePlaceZ  div    export default App Here the component is called thrice and it passes three different values for the same property The following is the output of the code Now that you know how props work lets understand how a state in React works Prepare Yourself to Answer All QuestionsAutomation Testing Masters ProgramExplore Program State in React A state is an object that stores properties values for those attributed to a component that could change over some time A state can be changed as a result of a users action or changes in the network React rerenders the component to the browser whenever the state of an object changes The function Object  native code  is where the state object is created Multiple properties can be stored in the state object this setState is used to alter the state objects value The setState function merges the new and prior states shallowly Consider the following component Statejs import React  Component  from react class State extends Component  constructorprops  superprops thisstate   message Subscribe to Simplilearn   render  return  div classNameApp h3thisstatemessageh3 div    export default State Here the h3 tag displays the value of message a state object In your main component Appjs consider the following code import React from react import Appcss import State from ComponentsState class App extends ReactComponent  styles   fontStyle bold color teal  render  return  div classNameApp h1 stylethisstyles Welcome h1 State  div    export default App The output will look like this setState Method A state can be updated to event handlers server responses or prop changes This is done using setState method thissetState quantity value   setState method enqueues all the updates made to the component state and instructs React to rerender the component and its children with the updated state Consider the scenario where the subscribe button is clicked On clicking the button the display message must change To implement this you make use of the setState method import React  Component  from react class State extends Component  constructorprops  superprops thisstate   message Subscribe to Simplilearn sub Subscribe   ChangeMessage thissetState message Thank you for Subscribing sub Subscribed   render  return  div classNameApp h3thisstatemessageh3 button onClickthisChangeMessagethisstatesubbutton div    export default State You first create an additional state object called sub for the button When a button click event occurs the method ChangeMessage is called This method in turn uses the setState method to update the values of message and sub and rerender the output After clicking the button the output will look like this Although the above can be achieved using just props using state makes it extremely efficient The following section covers the differences between props and State in React Want a Top Software Development Job Start HereFull Stack DevelopmentMEANExplore ProgramProps vs State in React Props State Props are used to send data and event handlers to a components children The data of the components that must be presented to it store the view in the state Props are immutable  they cant be modified after theyve been set The data is stored in the state which might change over time Both functional and class components can benefit from the use of props Only class components can use the state The parent component sets props for the children components Event handlers are typically responsible for updating the state ReactJS Prerequisites Here are some of the concepts that you should be familiar with to one degree or another Programming concepts like functions objects arrays and to a lesser extent classes Basic knowledge of JavaScript Some familiarity with HTML Now that you know what concepts you should already be familiar with before working on React lets take a look at the industry trends Related reading Best Programming Languages to Learn  Is React Worth Learning Around the years React has emerged as the most popular web framework among developers all over the world Due to the ease it provides React is preferred by the majority of enterprises In comparison to other IT specialists react developers make a lot of money Brilliant individuals are in a growing market worldwide because of the increasing need for React among businesses According to Indeed the US average salary for React developers is between 55k and 110k USD The Google Trends figure demonstrates the rate at which Reacts reputation has been steadily increasing as a result of the addition of additional features throughout time Industry Trends React is more popularly adopted by developers across the globe as compared to other frameworks and libraries The average salary for an entrylevel React developer in the USA is about 87000USD per annum The average salary for an entrylevel React developer in India is about 650000INR per annum FAQs 1 What is React JS used for ReactJSs primary goal is to create User Interfaces UI which enhance the speed of programs It makes use of virtual DOM JavaScript object which enhances the apps efficiency Quicker than the standard DOM is the JavaScript virtual DOM 2 Is React JS a framework Yes  A programme that provides prebuilt or fully prepared Associated traits to accelerate up the design process is called a React UI component framework 3 Is React JS frontend or backend ReactJS is a free element frontend toolkit that is exclusively in charge of the softwares layered architecture 4 What is the difference between React and React JS Although Reactjs is essentially a Software framework and React Native is the whole framework the two work in harmony because the former forms the core of the latter React Native is perfect for giving your mobile apps a native feel just as Reactjs is ideal for building apps with higher efficacy and complications  5 Which is better React or Angular If your application needs to integrate complicated functionality like dynamic solitary and native web applications Angular is preferable over React React on the other hand can be utilized in any app even standard apps and focuses on developing UI components Earn upto 25 CEUs from Caltech CTME and score a new job with an average annual package of 910 L after completing the PGP in Full Stack Web Development Enroll Today Next Steps We hope that this tutorial on What is React has helped you better grasp how React works A fullstack development course would be useful if you want to study React and become a frontend developer It will teach you the fundamentals of React including JSX props state and events a popular online framework for creating user interfaces Reducers actions and the state tree are all covered in this Redux training course Are there any questions youd want to ask us In case youve got any recommendations or questions for us please leave them in the comments section Our professionals will respond as soon as possible ,https://www.simplilearn.com/tutorials/reactjs-tutorial/what-is-reactjs,Front-End Development,946,2945
Back-End Development,How to Become a Backend Developer  A Complete GuideBy SimplilearnLast updated on Jun 12 202339560Table of ContentsView More Web development as a career is experiencing strong growth And as the demand for web developers begins to outpace the supply of qualified professionals those with an interest in the field and a desire to learn new technologies have an advantage when it comes to landing a wellpaying career with exceptional potential Web developers play different roles Some focus strictly on backend or frontend development while others choose to expand their skill set to include both as a full stack developer Specialization is critical when pursuing a career in web development with backend engineers benefiting from a more excellent command for their skills and experience Read more What is Backend Development Skills Salary Roles  More Backend development can be a fulfilling career choice for those with web development experience or who have a keen interest in development technologies What is it exactly that a backend developer does and how can you begin working towards earning the qualifications for this exciting career Lets take a look Discover other backend development courses Want a Top Software Development Job Start HereFull Stack DevelopmentMEANExplore Program What Is a Backend Developer There are essentially two components to web developmentbackend and frontend When a visitor lands on a website what they initially see and experience are the efforts of frontend development The average internet user gives little thought to what goes on behind the scenes of web development but that doesnt mean that a backend web developers role is any less critical The quality of user experience a website provides is dependent upon backend programming Read more How to Become a Front End Developer A backend developers role is to focus on details like building an effective website architecture scripting and writing code that serves as a means of communication between the websites database and the browser the site visitor is using For those who choose backend development as their career daily core responsibilities include Forming an understanding of the performance needs and goals of the website to develop effective successful solutions Development and management of APIs Developing systems for websites to accept and securely store data such as those required for payment processing systems Writing code testing and development solutions for coderelated issues maintenance Development of site architecture using proper methodologies of the product life cycle such as Agile Scrum and framework Organization of system logic Providing solutions to system problems Are Backend Developers in Demand Backend developers are a kind of task force who are entirely responsible for everything that happens behind a website or software According to a survey conducted by HackerEarth a developer hiring platform backend developers have topped the list of indemand jobs So it is visibly apparent that a skilled backend developer is always in demand How to Become a Backend Developer One needs handson training in many facets to emerge as a successful backend developer Here lets have a stepbystep idea about how to become a backend developer Step 1 Learn a Programming Language Programming language is the language through which the developer can command the computer A backend developer needs to have knowledge of the programming languages There are plenty of programming languages like C C Java etc Choose one and start learning it Understand every single step and technique Focus on one language at a time develop the skill and practice It is a bonus if a backend developer knows more than one programming language Recently Python has led the list of programming languages Step 2 Get a Clear Idea About the Data Structure and Algorithm Basics Data structures and algorithms are the absolute phenomena behind any application or software running So it is quintessential for a backend developer to have a clear picture of the basics of data structures and algorithms Step 3 Learn Frameworks Frameworks are a template where the developer can add edit and alter the coding according to their needs Although learning a programming language helps the developer to write any code learning and using a framework is a timesaving way where you can use the same framework for multiple purposes It cuts off rewriting the code every time Want a Top Software Development Job Start HereFull Stack DevelopmentMEANExplore ProgramStep 4 Learn the Database Concept A database is a kind of storage zone and a structured data storage that can be accessed electronically Learning about the database is vital for backend developers because it is the vault where they store the data through their programming language Step 5 Handson Training Theoretical knowledge will never suffice in any field The developer can not understand the techniques and formats behind any programming language until they practice it Write your code and run it in the coder Analyze the errors Following its start developing small apps like notes app etc Step 6 Ideate and Develop With enough practice create unique ideas and develop them into any software It is always better to start by modifying the existing softwares algorithm and understanding the modifications output Once done start developing your idea and add it to your portfolio Step 7 Launch Your Idea Now it is time for the developer to make their product available online like any cloud service that provides www access Pitch your product to multiple companies and bag your backend developer job What Skills are Required in Backend Development A backend developer is a person who makes the users experience with the efforts of frontend developers possible One might think of a backend developer as the person who builds and supports the components that work as the glue holding the website together and enabling it to function One of the most critical skills of a backend developer is a depth of knowledge in backend programming languages This includes proficiency in PHP Java Python Perl Ruby and Node JS Proficiency is essential not only for performing daily tasks but also for working alongside frontend developers for developing solutions Because backend and frontend developers work so closely together its also helpful to have a foundational understanding of frontend web technologies HTML and CSS for example Additionally knowledge and practical use experience with Mongo DBs and Express help maximize your frontend capabilities Of course there are nontechnical skills that are required of backend developers Those who choose this as a profession should be comfortable with analytical processes have welldeveloped problemsolving capabilities be interested in emerging technologies have decent communication skills and be able to work independently as well as being comfortable working with others sometimes as part of a collaborative team Areas of Work for Backend Engineers and Developers Backend developers can find career opportunities in a variety of industries and locations Some backend developers work exclusively with one company while others work for agencies that specialize in web development for their clients Beginning a career in this field requires learning the various aspects of serverside language and gaining an understanding of the other tools used daily Its also recommended that you seek an entrylevel position to gain practical handson experience Employers who hire backend developers tend to value a mixture of relevant education updated skills training and practical experience in the industry A passion for learning new technologies is a significant plus in the web development industry Those who move up the ranks toward senior backend developer positions often possess a strong knowledge of frontend development If youre interested in a fruitful career in this field starting with backend development training is the first step Moving on to frontend or fullstack development certification is an important future step for optimizing your career opportunities Learn 15 InDemand Tools and SkillsAutomation Testing Masters ProgramExplore ProgramSalaries and Career Prospects for Backend Developers According to the Bureau of Labor Statistics the career outlook for web development is favorable as the industry expected to grow much faster than average As with most web development careers location can make a big difference in terms of average salary According to Glassdoor the average salary for a web developer in the United States is 75487 per year with specializations leading to a higher average salary Top cities where web developers earn more than the national average include San Francisco Seattle New York City Los Angeles and Chicago Those who pursue additional training and education to become fullstack developers are typically able to command higher salaries To give you a sense of how fast the field of web developmentincluding backend developersis growing consider the fact that there were approximately 148500 positions for developers five years ago Looking ahead five years into the future that number is expected to grow to an estimated 188000 This is substantial growth which indicates a promising future for those who are just now getting their foot in the door of web development FAQs 1 How long does it take to become a backend developer It usually takes three months to four years to become a backend developer depending on the skill set needed to be acquired A coding boot camp can be an immediate option to become a backend developer But fouryear degree courses will land the developer in a better position 2 Is it hard to become a backend developer No if the person is interested in programming and its skills they can become a backend developer It might take time but it is not more challenging 3 Do I need a degree to become a backend developer No it is not necessary Anyone with the knowledge and skills related to programming can become a backend developer 4 Which language is used in backend development Multiple programming languages are being used in backend development The most common use programming languages include Java Python SQL Ruby PHP etc 5 How much does a backend developer make The salary range of a backend developer is from 2 lakhs to 20 lakhs The average annual salary of a backend developer is around 7 lakhs Becoming Skilled in Backend Web Development Those who are interested in becoming backend developers should have some degree of experience or education in web development technologies With a beginning background and a basic understanding of web development technologies leaping backend programming and development is as simple as taking a comprehensive certification course Simplilearn offers such a course with their Full Stack Web DeveloperMEAN Stack Masters Program This course is designed to help you advance your career as a web developer When taking this course youll master the elements of becoming a backend developer as well as those involved in frontend technologies Taking a course like the one offered by Simplilearn is a surefire way to set yourself on the fast track to career success This comprehensive course will help you understand precisely what backend developers do Youll gain a practical handson skillset in thorough Node JS certification training Angular training MongoDB developer training and the fundamentals of JavaScript among other tools This course is perfect for anyone interested in becoming a backend engineer or expanding their knowledge of fullstack development to enhance their income earning potential The MEAN Stack Developer Masters Course is ideal for any professional or student with an interest in learning MEAN Stack web developers IT project managers and entrepreneurs who want to develop a skill set to effectively handle their web development Choose The Right Software Development Program This table compares various courses offered by Simplilearn based on several key features and details The table provides an overview of the courses duration skills you will learn additional benefits among other important factors to help learners make an informed decision about which course best suits their needs Program Name Automation Testing Masters Program Full Stack Developer  MEAN Stack Caltech Coding Bootcamp Geo All All US University Simplilearn Simplilearn Caltech Course Duration 11 Months 11 Months 6 Months Coding Experience Required Basic Knowledge Basic Knowledge Basic Knowledge Skills You Will Learn Java AWS API Testing TDD etc HTML CSS Expressjs API Testing etc Java JavaScript Angular MongoDB etc Additional Benefits Structured GuidanceLearn From ExpertsHandson Training Blended Learning ProgramLearn 20 Tools and SkillsIndustry Aligned Projects Caltech Campus ConnectCareer Services17 CEU Credits Cost    Explore Program Explore Program Explore Program Begin Your Learning Path with Simplilearn Today Are you ready to take your web development career to the next level Get your foot in the backend development door by learning the skills you need to fuel fast growth along your career path We encourage you to contact Simplilearn to learn more about our Caltech Coding Bootcamp today If you have any questions or queries feel free to post them in the comments section below Our team will get back to you at the earliest Find our Caltech Coding Bootcamp Online Bootcamp in top citiesNameDatePlace Caltech Coding Bootcamp Cohort starts on 30th Jan 2024 Weekdays batchYour CityView DetailsAbout the AuthorSimplilearnSimplilearn is one of the worlds leading providers of online training for Digital Marketing Cloud Computing Project Management Data Science IT Software Development and many other emerging technologiesView MoreRecommended ProgramsCaltech Coding Bootcamp 767 LearnersLifetime AccessAutomation Testing Masters Program 1235 LearnersLifetime AccessPost Graduate Program in Full Stack Web Development 2340 LearnersLifetime AccessLifetime access to highquality selfpaced elearning contentExplore Category Next ArticleFull Stack Developer vs Front End Developer vs Back End DeveloperBy Nikita Duggal105336Jul 19 2023Recommended ResourcesThe Ultimate Guide to Top Front End and Back End Programming Languages for 2021EbookHow to Use Node Js for Backend Web DevelopmentArticleWhat is Backend Development The Ultimate Guide for BeginnersTutorialBlockchain Career Guide A Comprehensive Playbook To Becoming A Blockchain DeveloperEbookHow to Become a Front End DeveloperArticleYour Guide to the Best Backend Languages for 2023TutorialprevNext,https://www.simplilearn.com/how-to-become-a-backend-developer-article,Back-End Development,858,2265
"Server-Side Scripting (e.g., Node.js, Python, PHP)", From Wikipedia the free encyclopedia Technique used in web development For broader coverage of this topic see Dynamic web page This article has multiple issues Please help improve it or discuss these issues on the talk page Learn how and when to remove these template messages This article needs attention from an expert in technology The specific problem is unfocused scattered unnecessary details WikiProject Technology may be able to help recruit an expert April 2012 This article needs additional citations for verification Please help improve this article by adding citations to reliable sources Unsourced material may be challenged and removedFind sources Serverside scripting  news  newspapers  books  scholar  JSTOR October 2008 Learn how and when to remove this template message Learn how and when to remove this template message Serverside scripting is a technique used in web development which involves employing scripts on a web server which produces a response customized for each users clients request to the website Scripts can be written in any of a number of serverside scripting languages that are available see below Serverside scripting is distinguished from clientside scripting where embedded scripts such as JavaScript are run clientside in a web browser but both techniques are often used together The alternative to either or both types of scripting is for the web server itself to deliver a static web page Serverside scripting is often used to provide a customized interface for the user These scripts may assemble client characteristics for use in customizing the response based on those characteristics the users requirements access rights etc Serverside scripting also enables the website owner to hide the source code that generates the interface whereas with clientside scripting the user has access to all the code received by the client A downside to the use of serverside scripting is that the client needs to make further requests over the network to the server in order to show new information to the user via the web browser These requests can slow down the experience for the user place more load on the server and prevent the use of the application when the user is disconnected from the server When the server serves data in a commonly used manner for example according to the HTTP or FTP protocols users may have their choice of a number of client programs most modern web browsers can request and receive data using both of those protocols In the case of more specialized applications programmers may write their own server client and communications protocol that can only be used with one another Programs that run on a users local computer without ever sending or receiving data over a network are not considered clients and so the operations of such programs would not be considered clientside operations Historyedit Netscape introduced an implementation of JavaScript for serverside scripting with Netscape Enterprise Server first released in December 1994 soon after releasing JavaScript for browsers12 Serverside scripting was later used in early 1995 by Fred Dufresne while developing the first website for Boston MA television station WCVB The technology is described in US patent 5835712 The patent was issued in 1998 and is now owned by Open Invention Network OIN In 2010 OIN named Fred DuFresne a Distinguished Inventor for his work on serverside scripting Explanationedit In the earlier days of the web serverside scripting was almost exclusively performed by using a combination of C programs Perl scripts and shell scripts using the Common Gateway Interface CGI Those scripts were executed by the operating system and the results were served back by the webserver Many modern web servers can directly execute online scripting languages such as ASP JSP Perl PHP and Ruby either by the web server itself or via extension modules eg mod_perl or mod_php to the webserver For example WebDNA includes its own embedded database system Either form of scripting ie CGI or direct execution can be used to build up complex multipage sites but direct execution usually results in less overhead because of the lower number of calls to external interpreters Dynamic websites sometimes use custom web application servers such as Glassfish Plack and Pythons Base HTTP Server library although some may not consider this to be serverside scripting When using dynamic webbased scripting techniques developers must have a keen understanding of the logical temporal and physical separation between the client and the server For a users action to trigger the execution of serverside code for example a developer working with classic ASP must explicitly cause the users browser to make a request back to the webserver Serverside scripts are completely processed by the servers instead of clients When clients request a page containing serverside scripts the application server processes the scripts and returns an HTML page to the client Serverside renderingedit In the beginning of the web content was generated purely on the back end After the big adoption of front end singlepage applications a new approach was introduced to generate the HTML using the client application but on the back end Examples of frameworks that use SSR are Nextjs Nuxtjs and Nestjs They use Reactjs Vuejs and Angular respectively to generate the content of the server Serverside generationedit Another similar to SSR technique of generating content for a website is using Serverside generation This technique use application that create static html pages and then those files are send to the server File generation can happen on completely different computer for example using continuous delivery Example of SSG tools are Jekyll Gatsby or Eleventy Those sites are often hosted on Netlify or GitHub pages GitHub also supports Jekyll projects where it automatically build the site when changes are added to git Languagesedit There are a number of serverside scripting languages available including ActiveVFP avfp ASP asp ASPNET Web Forms aspx ASPNET Web Pages cshtml vbhtml ColdFusion Markup Language cfm Go go Google Apps Script gs Hack php Haskell hs example Yesod Java jsp do via JavaServer Pages JavaScript using Serverside JavaScript ssjs js example Nodejs Lasso lasso Lua lp op lua Parser p Perl via the CGIpm module cgi ipl pl PHP php php3 php4 phtml Python py examples Pyramid Flask Django R rhtml Ruby rb rbw example Ruby on Rails Tcl tcl WebDNA dnatpl Progress WebSpeed rw See alsoedit Clientside scripting Content management system CMS Edge Side Includes JSP Nodejs Nextjs Outline of web design and web development PerlPlack PHP Server Side Includes SSI Web development Referencesedit  ServerSide JavaScript Guide Netscape Communications Corporation 1998 Retrieved 20120425  Mike Morgan 1996 Using Netscape LiveWire Special Edition Que External linksedit Wikiversity has learning resources about ServerSide Scripting Serverside scripting at Curlie vteWeb interfacesServersideProtocols HTTP v2 v3 Encryption WebDAV CGI SCGI FCGI AJP WSRP WebSocket Server APIs C NSAPI C ASAPI C ISAPI COM ASP Jakarta Servlet container CLI OWIN ASPNET Handler Python WSGI Python ASGI Ruby Rack JavaScript JSGI Perl PSGI Portlet container Apache modules mod_include mod_jk mod_lisp mod_mono mod_parrot mod_perl mod_php mod_proxy mod_python mod_wsgi mod_ruby Phusion Passenger Topics Web resource vs Web service Open API Webhook Application server comparison Scripting ClientsideBrowser APIs C NPAPI LiveConnect XPConnect C NPRuntime C PPAPI NaCl ActiveX BHO XBAP Web APIsW3C Audio Canvas CORS DOM DOM events EME File Geolocation IndexedDB MSE SSE SVG Video WebAssembly WebAuthn WebGPU WebRTC WebSocket WebXR Web messaging Web storage Web worker XMLHttpRequest Khronos WebCL WebGL Others Gears Web SQL Database formerly W3C WebUSB Topics Ajax and Remote scripting vs DHTML Browser extension Mashup Web IDL Scripting Topics Web page Static Dynamic Web standards Web API security Web application Rich Singlepage Progressive Web framework Retrieved from httpsenwikipediaorgwindexphptitleServerside_scriptingoldid1178630647 Category Scripting languagesHidden categories Articles with short descriptionShort description matches WikidataArticles needing expert attention from April 2012All articles needing expert attentionTechnology articles needing expert attentionArticles needing additional references from October 2008All articles needing additional referencesArticles with multiple maintenance issuesArticles with Curlie links ,https://en.wikipedia.org/wiki/Server-side_scripting,Back-End Development,647,1303
"Database Management (e.g., SQL, MongoDB)", What is a database management system A database management system DBMS is system software for creating and managing databases A DBMS makes it possible for end users to create protect read update and delete data in a database The most prevalent type of data management platform the DBMS essentially serves as an interface between databases and users or application programs ensuring that data is consistently organized and remains easily accessible What does a DBMS do The DBMS manages the data the database engine allows data to be accessed locked and modified and the database schema defines the databases logical structure These three foundational elements help provide concurrency security data integrity and uniform data administration procedures The DBMS supports many typical database administration tasks including change management performance monitoring and tuning security and backup and recovery Most database management systems are also responsible for automated rollbacks and restarts as well as logging and auditing of activity in databases and the applications that access them The DBMS provides a centralized view of data that can be accessed by multiple users from multiple locations in a controlled manner A DBMS can limit what data end users see and how they view the data providing many views of a single database schema End users and software programs are free from having to understand where the data is physically located or on what type of storage medium it resides because the DBMS handles all requests The DBMS can offer both logical and physical data independence to protect users and applications from having to know where data is stored or from being concerned about changes to the physical structure of data So long as programs use the application programming interface API for the database that the DBMS provides developers wont have to modify programs just because changes have been made to the database This article is part of What is data management and why is it important Which also includes 8 data integration challenges and how to overcome them Data lake vs data warehouse Key differences explained What key roles should a data management team include Download1 Download this entire guide for FREE now In a relational database management system RDBMS  the most widely used type of DBMS  the API is SQL a standard programming language for defining protecting and accessing data What are the components of a DBMS A DBMS is a sophisticated piece of system software consisting of multiple integrated components that deliver a consistent managed environment for creating accessing and modifying data in databases These components include the following Structure of database management system Storage engine This basic element of a DBMS is used to store data The DBMS must interface with a file system at the operating system OS level to store data It can use additional components to store data or interface with the actual data at the file system level Metadata catalog Sometimes called a system catalog or database dictionary a metadata catalog functions as a repository for all the database objects that have been created When databases and other objects are created the DBMS automatically registers information about them in the metadata catalog The DBMS uses this catalog to verify user requests for data and users can query the catalog for information about the database structures that exist in the DBMS The metadata catalog can include information about database objects schemas programs security performance communication and other environmental details about the databases it manages Database access language The DBMS also must provide an API to access the data typically in the form of a database access language to access and modify data but may also be used to create database objects and secure and authorize access to the data SQL is an example of a database access language and encompasses several sets of commands including Data Control Language for authorizing data access Data Definition Language for defining database structures and Data Manipulation Language for reading and modifying data Optimization engine A DBMS may also provide an optimization engine which is used to parse database access language requests and turn them into actionable commands for accessing and modifying data Query processor After a query is optimized the DBMS must provide a means for running the query and returning the results Lock manager This crucial component of the DBMS manages concurrent access to the same data Locks are required to ensure multiple users arent trying to modify the same data simultaneously Log manager The DBMS records all changes made to data managed by the DBMS The record of changes is known as the log and the log manager component of the DBMS is used to ensure that log records are made efficiently and accurately The DBMS uses the log manager during shutdown and startup to ensure data integrity and it interfaces with database utilities to create backups and run recoveries Data utilities A DBMS also provides a set of utilities for managing and controlling database activities Examples of database utilities include reorganization runstats backup and copy recover integrity check load data unload data and repair database Popular types and examples of DBMS technologies Popular database models and management systems include RDBMS NoSQL DBMS NewSQL DBMS inmemory DBMS columnar DBMS multimodel DBMS and cloud DBMS RDBMS Sometimes referred to as a SQL DBMS and adaptable to most use cases RDBMS presents data as rows in tables with a fixed schema and relationships defined by values in key columns RDBMS Tier1 products can be quite expensive but there are high quality open source options such as PostgreSQL that can be costeffective Other examples of popular RDBMS products include Oracle MySQL Microsoft SQL Server and IBM Db2 NoSQL DBMS Wellsuited for loosely defined data structures that may evolve over time NoSQL DBMS may require more application involvement for schema management There are four types of NoSQL database systems document databases graph databases keyvalue stores and widecolumn stores Each uses a different type of data model resulting in significant differences between each NoSQL type Document databases store semistructured data and descriptions of that data in document format usually JavaScript Object Notation JSON Theyre useful for flexible schema requirements such as those common with content management and mobile applications Popular document databases include MongoDB and Couchbase Graph databases organize data as nodes and relationships instead of tables or documents Because it stores the relationship between nodes the graph system can support richer representations of data relationships The graph data model doesnt rely on a strict schema and it can evolve over time Graph databases are useful for applications that map relationships such as social media platforms reservation systems or customer relationship management Examples of popular graph databases include Neo4j and GraphDB Keyvalue stores are based on a simple data model that pairs a unique key with an associated value Due to this simplicity keyvalue stores can be used to develop highly scalable and performant applications such as those for session management and caching in web applications or for managing shopping cart details for online buyers Examples of popular keyvalue databases include Redis and Memcached Widecolumn stores use the familiar tables columns and rows of relational database systems but column names and formatting can differ from row to row in a single table Each column is also stored separately on disk As opposed to traditional roworientated storage a widecolumn store is optimal when querying data by columns such as in recommendation engines catalogs fraud detection and event logging Cassandra and HBase are examples of widecolumn stores NewSQL DBMS Modern relational systems that use SQL NewSQL database systems offer the same scalable performance as NoSQL systems But NewSQL systems also provide ACID atomicity consistency isolation and durability support for data consistency A NewSQL DBMS is engineered as a relational SQL database system with a distributed faulttolerant architecture Other typical features of NewSQL system offerings include inmemory capability and clustered database services with the ability to be deployed in the cloud Many NewSQL DBMS packages have fewer features and components and a smaller footprint than legacy relational offerings making them easier to support and understand Some vendors now eschew the NewSQL label and describe their technologies as distributed SQL databases CockroachDB Google Cloud Spanner NuoDB Volt Active Data and YugabyteDB are examples of database systems in this category IMDBMS An inmemory database management system predominantly relies on main memory for data storage management and manipulation By reducing the latency associated with reading from disk an IMDBMS can provide faster response times and better performance but can consume more resources Therefore an inmemory database is ideal for applications that require high performance and rapid access to data such as data stores that support realtime HTAP hybrid transactional and analytical process Any type of DBMS relational NoSQL etc can also support inmemory processing SAP HANA and Redis are examples of inmemory database systems CDBMS A columnar database management system stores data in tables focused on columns instead of rows resulting in more efficient data access when only a subset of columns is required Its wellsuited for data warehouses that have a large number of similar data items Popular columnar database products include Snowflake and Amazon Redshift Multimodel DBMS This system supports more than one database model Users can choose the model most appropriate for their application requirements without having to switch to a different DBMS For example IBM Db2 is a relational DBMS but it also offers a columnar option Many of the most popular database systems similarly qualify as multimodel through addons including Oracle PostgreSQL and MongoDB Other products such as Azure Cosmos DB and MarkLogic were developed specifically as multimodel databases Cloud DBMS Built in and accessed through the cloud the DBMS may be any type relational NoSQL etc and a conventional system thats deployed and managed by a user organization or a managed service provided by the database vendor Popular cloud services that enable cloud database implementation include Microsoft Azure Google Cloud and AWS Benefits of using a DBMS One of the biggest advantages of using a DBMS is that it lets users and application programmers access and use the same data concurrently while managing data integrity Data is better protected and maintained when it can be shared using a DBMS instead of creating new iterations of the same data stored in new files for every new application The DBMS provides a central store of data that multiple users can access in a controlled manner Central storage and management of data within the DBMS provide the following data abstraction and independence data security a locking mechanism for concurrent access an efficient handler to balance the needs of multiple applications using the same data the ability to swiftly recover from crashes and errors strong data integrity capabilities logging and auditing of activity simple access using a standard API and uniform administration procedures for data Another advantage of a DBMS is that database administrators DBAs can use it to impose a logical structured organization on the data A DBMS delivers economy of scale for processing large amounts of data because its optimized for such operations A DBMS can also provide many views of a single database schema A view defines what data the user sees and how that user sees the data The DBMS provides a level of abstraction between the conceptual schema that defines the logical structure of the database and the physical schema that describes the files indexes and other physical mechanisms the database uses A DBMS enables users to modify systems much more easily when business requirements change A DBA can add new categories of data to the database without disrupting the existing system thereby insulating applications from how data is structured and stored However a DBMS must perform additional work to provide these advantages thereby incurring overhead A DBMS will use more memory and CPU than a simple file storage system and different types of DBMSes will require different types and levels of system resources Drawbacks of DBMSes Perhaps the single biggest drawback is the cost of the hardware software and personnel required to run an enterprise DBMS such as SQL Server Oracle or IBM Db2 The hardware is usually a highend server with a significant amount of memory configured coupled with large disk arrays to store the data The software includes the DBMS itself which is pricey as well as tools for programming and testing and for DBAs to enable management tuning and administration From a personnel perspective using a DBMS requires hiring a DBA staff training developers in the proper usage of the DBMS and possibly hiring additional systems programmers for managing installation and integrating the DBMS into the IT infrastructure Dealing with additional complexity is also a concern when implementing a DBMS The DBMS software is complex and requires indepth knowledge to properly implement and manage But the DBMS interfaces with many other IT components such as the OS transaction processing systems programming languages and networking software Ensuring the proper configuration and efficiency of such a complicated setup can be difficult and cause performance slowdowns or even system outages Some of the cost and administrative overhead of running enterprise database systems can be alleviated by the cloud computing model For example the cloud service provider CSP installs and manages the hardware which can be shared across cloud users Furthermore storage memory and other resources can be scaled up and down as required based on usage needs And basic DBA tasks like patching and simple backups become the responsibility of the CSP Therefore it can be easier and more costeffective for some databases to be deployed in the cloud instead of onpremises DBMS use cases Enterprises that need to store data and access it later to conduct business have a viable use case for deploying a DBMS Any application requiring a large amount of data that needs to be accessed by multiple users or customers is a candidate for using a DBMS Most medium to large organizations can benefit from using a DBMS because they have more datasharing and concurrency needs and are able to more readily overcome cost and complexity issues Sample customer use cases for DBMS technology include the following Applications can include storing customer and account information tracking account transactions such as withdrawals and deposits and tracking loan payments ATMs are a good example of a banking system that relies on a DBMS to track and manage that activity DBMSes manage sales for any type of business including storing product customer and salesperson information and recording the sale tracking fulfillment and maintaining sales history information Most commercial airlines rely on a DBMS for dataintensive applications such as scheduling flight plans and managing customer flight reservations Manufacturing companies depend on a DBMS to track and manage inventory in warehouses A DBMS can also be used to manage data for supply chain management applications that track the flow of goods and services including the movement and storage of raw materials workinprocess inventory and finished goods from the point of origin to the point of consumption A DBMS also makes it easier for a company to track and manage employee information in a human resources management application including managing employee data such as addresses phone numbers salary details payroll and paycheck generation Changes in how DBMSes are built sold and serviced By 2019 open source DBMS technologies were rapidly gaining traction In fact Gartner projected that open source databases would account for 10 of total spending on database software for that year due to increased enterprise adoption By 2022 three of the top five databases ranked by DBEngines were open source Most mainstream IT organizations use open source software in some of their missioncritical operations This trend complements two others acquisitions of open source database vendors by bigger rivals and the expansion of the cloudbased database service market In 2019 Gartner also said that cloud databases were driving most of the growth in the DBMS market describing the cloud as the default platform for managing data In 2021 Gartner concluded that by 2022 cloud database management system revenue will account for 50 of the total DBMS market revenue In connection with the increasing shift toward the cloud numerous DBMS vendors have introduced managed cloud database services that offer to free IT and data management teams from many of the tasks required to deploy configure and administer database systems Another growing trend is what Gartner refers to as HTAP  using a single DBMS to deliver both transaction processing and analytics without requiring a separate DBMS for each operation To support this trend more DBMS vendors are creating hybrid database systems that deliver multiple database engines within a single DBMS Most hybrid DBMSes provide a combination of relational and multiple NoSQL engines and APIs Examples include Altibase Microsofts Azure Cosmos DB and DataStax Enterprise History of database management systems The first DBMS was developed in the early 1960s when Charles Bachman created a navigational DBMS known as the Integrated Data Store Shortly after IBM developed Information Management System IMS a hierarchical DBMS designed for IBM mainframes thats still used by many large organizations today The next major advancement came in 1971 when the ConferenceCommittee on Data Systems Languages CODASYL standard was delivered Integrated Database Management System is a commercial implementation of the network model database approach advanced by CODASYL But the DBMS market changed forever as the relational model for data gained popularity Introduced by Edgar Codd of IBM in 1970 in his seminal paper A Relational Model of Data for Large Shared Data Banks the RDBMS soon became the industry standard The first RDBMS was Ingres developed at the University of California Berkeley by a team led by Michael Stonebraker in the mid1970s At about the same time IBM was working on its System R project to develop an RDBMS In 1979 the first successful commercial RDBMS Oracle was released followed a few years later by IBMs Db2 Sybase SQL Server and many others In the 1990s as objectoriented OO programming became popular several OO database systems came to market but they never gained significant market share Later in the 1990s the term NoSQL was coined Over the next decade several types of new nonrelational DBMS products including keyvalue graph document and widecolumn store were grouped into the NoSQL category Today the DBMS market is dominated by RDBMS but NewSQL and NoSQL database systems continue to grow in popularity ,https://www.techtarget.com/searchdatamanagement/definition/database-management-system,Back-End Development,956,3064
RESTful APIs, What is RESTful API RESTful API is an interface that two computer systems use to exchange information securely over the internet Most business applications have to communicate with other internal and thirdparty applications to perform various tasks For example to generate monthly payslips your internal accounts system has to share data with your customers banking system to automate invoicing and communicate with an internal timesheet application RESTful APIs support this information exchange because they follow secure reliable and efficient software communication standards What is an API An application programming interface API defines the rules that you must follow to communicate with other software systems Developers expose or create APIs so that other applications can communicate with their applications programmatically For example the timesheet application exposes an API that asks for an employees full name and a range of dates When it receives this information it internally processes the employees timesheet and returns the number of hours worked in that date range You can think of a web API as a gateway between clients and resources on the web Clients Clients are users who want to access information from the web The client can be a person or a software system that uses the API For example developers can write programs that access weather data from a weather system Or you can access the same data from your browser when you visit the weather website directly Resources Resources are the information that different applications provide to their clients Resources can be images videos text numbers or any type of data The machine that gives the resource to the client is also called the server Organizations use APIs to share resources and provide web services while maintaining security control and authentication In addition APIs help them to determine which clients get access to specific internal resources What is REST Representational State Transfer REST is a software architecture that imposes conditions on how an API should work REST was initially created as a guideline to manage communication on a complex network like the internet You can use RESTbased architecture to support highperforming and reliable communication at scale You can easily implement and modify it bringing visibility and crossplatform portability to any API system API developers can design APIs using several different architectures APIs that follow the REST architectural style are called REST APIs Web services that implement REST architecture are called RESTful web services The term RESTful API generally refers to RESTful web APIs However you can use the terms REST API and RESTful API interchangeably The following are some of the principles of the REST architectural style Uniform interface The uniform interface is fundamental to the design of any RESTful webservice It indicates that the server transfers information in a standard format The formatted resource is called a representation in REST This format can be different from the internal representation of the resource on the server application For example the server can store data as text but send it in an HTML representation format Uniform interface imposes four architectural constraints Requests should identify resources They do so by using a uniform resource identifier Clients have enough information in the resource representation to modify or delete the resource if they want to The server meets this condition by sending metadata that describes the resource further Clients receive information about how to process the representation further The server achieves this by sending selfdescriptive messages that contain metadata about how the client can best use them Clients receive information about all other related resources they need to complete a task The server achieves this by sending hyperlinks in the representation so that clients can dynamically discover more resources Statelessness In REST architecture statelessness refers to a communication method in which the server completes every client request independently of all previous requests Clients can request resources in any order and every request is stateless or isolated from other requests This REST API design constraint implies that the server can completely understand and fulfill the request every time Layered system In a layered system architecture the client can connect to other authorized intermediaries between the client and server and it will still receive responses from the server Servers can also pass on requests to other servers You can design your RESTful web service to run on several servers with multiple layers such as security application and business logic working together to fulfill client requests These layers remain invisible to the client Cacheability RESTful web services support caching which is the process of storing some responses on the client or on an intermediary to improve server response time For example suppose that you visit a website that has common header and footer images on every page Every time you visit a new website page the server must resend the same images To avoid this the client caches or stores these images after the first response and then uses the images directly from the cache RESTful web services control caching by using API responses that define themselves as cacheable or noncacheable Code on demand In REST architectural style servers can temporarily extend or customize client functionality by transferring software programming code to the client For example when you fill a registration form on any website your browser immediately highlights any mistakes you make such as incorrect phone numbers It can do this because of the code sent by the server What are the benefits of RESTful APIs RESTful APIs include the following benefits Scalability Systems that implement REST APIs can scale efficiently because REST optimizes clientserver interactions Statelessness removes server load because the server does not have to retain past client request information Wellmanaged caching partially or completely eliminates some clientserver interactions All these features support scalability without causing communication bottlenecks that reduce performance Flexibility RESTful web services support total clientserver separation They simplify and decouple various server components so that each part can evolve independently Platform or technology changes at the server application do not affect the client application The ability to layer application functions increases flexibility even further For example developers can make changes to the database layer without rewriting the application logic Independence REST APIs are independent of the technology used You can write both client and server applications in various programming languages without affecting the API design You can also change the underlying technology on either side without affecting the communication How do RESTful APIs work The basic function of a RESTful API is the same as browsing the internet The client contacts the server by using the API when it requires a resource API developers explain how the client should use the REST API in the server application API documentation These are the general steps for any REST API call The client sends a request to the server The client follows the API documentation to format the request in a way that the server understands The server authenticates the client and confirms that the client has the right to make that request The server receives the request and processes it internally The server returns a response to the client The response contains information that tells the client whether the request was successful The response also includes any information that the client requested The REST API request and response details vary slightly depending on how the API developers design the API What does the RESTful API client request contain RESTful APIs require requests to contain the following main components Unique resource identifier The server identifies each resource with unique resource identifiers For REST services the server typically performs resource identification by using a Uniform Resource Locator URL The URL specifies the path to the resource A URL is similar to the website address that you enter into your browser to visit any webpage The URL is also called the request endpoint and clearly specifies to the server what the client requires Method Developers often implement RESTful APIs by using the Hypertext Transfer Protocol HTTP An HTTP method tells the server what it needs to do to the resource The following are four common HTTP methods GET Clients use GET to access resources that are located at the specified URL on the server They can cache GET requests and send parameters in the RESTful API request to instruct the server to filter data before sending POST Clients use POST to send data to the server They include the data representation with the request Sending the same POST request multiple times has the side effect of creating the same resource multiple times PUT Clients use PUT to update existing resources on the server Unlike POST sending the same PUT request multiple times in a RESTful web service gives the same result DELETE Clients use the DELETE request to remove the resource A DELETE request can change the server state However if the user does not have appropriate authentication the request fails HTTP headers Request headers are the metadata exchanged between the client and server For instance the request header indicates the format of the request and response provides information about request status and so on Data REST API requests might include data for the POST PUT and other HTTP methods to work successfully Parameters RESTful API requests can include parameters that give the server more details about what needs to be done The following are some different types of parameters Path parameters that specify URL details Query parameters that request more information about the resource Cookie parameters that authenticate clients quickly What are RESTful API authentication methods A RESTful web service must authenticate requests before it can send a response Authentication is the process of verifying an identity For example you can prove your identity by showing an ID card or drivers license Similarly RESTful service clients must prove their identity to the server to establish trust RESTful API has four common authentication methods HTTP authentication HTTP defines some authentication schemes that you can use directly when you are implementing REST API The following are two of these schemes Basic authentication In basic authentication the client sends the user name and password in the request header It encodes them with base64 which is an encoding technique that converts the pair into a set of 64 characters for safe transmission Bearer authentication The term bearer authentication refers to the process of giving access control to the token bearer The bearer token is typically an encrypted string of characters that the server generates in response to a login request The client sends the token in the request headers to access resources API keys API keys are another option for REST API authentication In this approach the server assigns a unique generated value to a firsttime client Whenever the client tries to access resources it uses the unique API key to verify itself API keys are less secure because the client has to transmit the key which makes it vulnerable to network theft OAuth OAuth combines passwords and tokens for highly secure login access to any system The server first requests a password and then asks for an additional token to complete the authorization process It can check the token at any time and also over time with a specific scope and longevity What does the RESTful API server response contain REST principles require the server response to contain the following main components Status line The status line contains a threedigit status code that communicates request success or failure For instance 2XX codes indicate success but 4XX and 5XX codes indicate errors 3XX codes indicate URL redirection The following are some common status codes 200 Generic success response 201 POST method success response 400 Incorrect request that the server cannot process 404 Resource not found Message body The response body contains the resource representation The server selects an appropriate representation format based on what the request headers contain Clients can request information in XML or JSON formats which define how the data is written in plain text For example if the client requests the name and age of a person named John the server returns a JSON representation as follows nameJohn age30 Headers The response also contains headers or metadata about the response They give more context about the response and include information such as the server encoding date and content type How can AWS help you with RESTful API management Amazon API Gateway is a fully managed service that makes it easy for developers to create publish maintain monitor and secure APIs at any scale Using API Gateway you can create RESTful APIs for realtime twoway communication applications Using API Gateway you can Provide users with highspeed performance for both API requests and responses Authorize access to your APIs with AWS Identity and Access Management IAM and Amazon Cognito both of which provide native OAuth support Run multiple versions of the same API simultaneously with API Gateway to quickly iterate test and release new versions Monitor performance metrics and information about API calls data latency and error rates from the API Gateway Get started with API Gateway by using our stepbystep guidance and creating an AWS account today ,"https://aws.amazon.com/what-is/restful-api/#:~:text=RESTful%20API%20is%20an%20interface,applications%20to%20perform%20various%20tasks.",Back-End Development,636,2189
JSON and XML," What is Cloud Computing Cloud Computing Concepts Hub Developer Tools Whats the Difference Between JSON and XML Create an AWS Account , JavaScript TutorialJSON Vs XML  Key DifferencesJSON Vs XML  Key DifferencesJSON Vs XML  Key DifferencesLearn via video courseJavaScript Course With Certification Unlocking the Power of JavaScriptBy Mrinal Bhattacharya Free48Enrolled 1000Start Learning View all courses JavaScript Course With Certification Unlocking the Power of JavaScriptMrinal BhattacharyaFree48Enrolled 1000Start Learning OverviewJSONJavaScript Object Notation is a data interchange format and XMLeXtensible Markup Language is a custom markup language that is used to interchange data and can do many other things like data validation Both JSON and XML are used to store and interchange data in an easily understandable format Almost all programming languages like Python JavaScript and Ruby along with various APIs Application Programming Interfaces have parsers for JSON and XML through which data can be interchanged Even though the purpose of using XML and JSON is the same they have their ways of operations and can be used in different scenarios What is JSON JavaScript Object NotationJavaScript Object Notation JSON serves as a datainterchange format designed to store and transmit data objects in a manner that is easily readable by humans Unlike many formats that are tied to a specific programming language JSON stands out for its lightweight and languageindependent nature Although its syntax finds its roots in the JavaScript programming language its crucial to understand that JSON is entirely independent of any language This independence means that while JSON data can be read and generated using JavaScript the same can be accomplished using numerous other programming languages All data stored in this format is saved with the json extension and can include a range of data types including strings numbers booleans and nulls The structure of JSON data often involves JSON Objects and JSON Arrays which are essential components in the storage and transfer of data across the web These elements will be delved into in greater detail later in this article1 JSON ObjectsJSON objects are used to store and transfer data across the web Objects in JSON store data in keyvalue pairs Keyvalue pairs are related elements where a Key is a constant that defines the data set while a value is a variable of that data set For eg color can be a key and colors like blue red etc can be the valuesKeys in JSON objects should be strings and values can be of any valid JSON data type JSON objects are enclosed in curly braces ie  while the keys  values are separated by a colon ie  and each keyvalue pair is separated by a commaExampleAbove is the keyvalue pair that stores data related to a book Here book_name author and genre are the keys and their related values are there in the values part2 JSON ArraysArrays in JSON are just like arrays in any other programming language JSON arrays are a list of objects enclosed in square brackets ie  Values stored in JSON array can be of data types string number object boolean or null JSON arrays can be a list of JSON objects which means multiple keyvalue pairs can be stored in a single arrayExampleThe above array shows the availability of cars in a car showroom Each element of the array is a JSON object that stores data in the form of keyvalue pairs Here the objects have information about distinct cars like their id names and if they are present in the showroom or not History of JSON JSON format was specified by Douglas Crockford in the early 2000s Official website of JSON was launched in 2003 JSON was created to hold the structured data that could be used in javascript But it became so popular that it is used to transfer data for all kinds of applications Yahoo was the first company to start offering its web services in JSON in 2005 JSON became ECMA international standard in 2013 In 2017 the most updated format standard of JSON was published What is XML Extensible markup languageXML or eXtensible Markup Language is a system designed primarily for data storage and has become a popular medium for distributing data across the internet and various application programming interfaces APIs At its core XML is a markup language characterized by a set of symbols rendered in a way that both humans and computers can interpret seamlessly Unlike some languages which are meant for both storing and displaying data XMLs main function is to store and transfer data it doesnt possess the inherent tools to present data aesthetically One of the reasons for XMLs widespread adoption is its compatibility with numerous programming languages Virtually every programming language today is equipped with a parser for XML making it easy to fetch and validate data stored in this formatA distinguishing feature of XML is its provision to store namespaces In essence a namespace acts as a unique container or group wherein specific elements and attribute names are housed This mechanism facilitates differentiation especially when elements originate from different sources Another important aspect of XML is its ability to store metadataessentially data about data This could range from information regarding the source of files to more nuanced details Interestingly XML tags themselves can be viewed as a form of metadata since they provide context to the type of data or attribute they encapsulateWith the rapid digitization of various sectors such as ebanking and online shopping XMLs role has become increasingly pivotal Its structure mandates case sensitivity and primarily uses tags for data storage These tags in XML bear a resemblance to those found in HTML They are demarcated with  to signify the beginning and  for closure and its imperative that the names of the starting and ending tags are identical Furthermore in XML data can be handled in two primary ways either through tags or attributes ExampleThe above example gives us an idea about XML file format and how tags are used in XML Here rainbow is the main tag that has other subtags like violet red which display numeric values History of XML XML is derived from SGMLStandard Generalized Markup Language which is an international standard for the definition of markup languages SGMLGML was invented by Charles Goldfarb Ed Mosher and Ray Lorie in 1970 The development of XML started in the year 1996 at Sun Microsystem First version of XML XML 10 was released in February 1998 Key Difference Between JSON and XMLThe main difference between JSON and XML is their structure and purpose JSON or JavaScript Object Notation is a lightweight datainterchange format that uses humanreadable text to represent data structures Originating from JavaScript JSON has become languageindependent and is primarily used for asynchronous browserserver communication On the other hand XML or eXtensible Markup Language is a markup language designed for storing and transporting data without any focus on how the data looks While both can be parsed by most programming languages XML uses tags is more verbose and is extensible whereas JSON utilizes a more compact keyvalue pair structure JSON Vs XML Detailed Comparison JSONXMLJSON stands for JavaScript Object NotationXML stands for eXtensible Markup LanguageJSON files are stored with json extensionXML files are stored with xml extensionIt is extended from JavascriptIt is extended from SGML Standard Generalized Markup LanguageIt is a way of representing objects using keyvalue pairsIt is a markup language and uses tag structures to represent data itemsJSON is objectorientedXML is documentorientedData stored in JSON in the form of arrays and keyvalue pairsXML stores data in the form of tags and attributesJSON files are easy to understand as compared to XML because of their simple syntaxXML files are difficult to read and interpret as compared to JSON because of the complex tag structureIt doesnt support commentsIt supports commentsIt doesnt support namespaces and metadataIt supports namespaces and metadataJSON files occupy less size due to the absence of tagsXML documents can be bulkier due to their tag structureJSON is preferred in BrowserSide technologies because its files can be transmitted in less timeXML is preferred in ServerSide technologies as it gives the provision to validate the dataJSON is less verbose and fasterXML can be slower to parse and is more verboseJSON format is akin to a map data structureXML format resembles a tree data structureJSON is dataoriented and is suitable for data serializationXML is both data and documentoriented making it suitable for complex document structuresJSON is native to JavaScript and can be parsed natively by web browsersXML requires an XML parser to be parsedNo official support for displaying JSON in a browserXML can be displayed in a browser with the help of XSLT Structure of JSON vs XML1 Structure of JSON JSON handles data in two ways JSON arrays and JSON objects Data structural hierarchy of JSON is in map format As it handles data in keyvalue pairs It supports data types like string number boolean array and null JSON arrays are a list of objects enclosed in square brackets ie  Object in JSON are dictionaries that store data in keyvalue pairs Keys in JSON objects should be string and values can be of any valid JSON data type JSON objects are enclosed in curly braces ie  while the keys  values are separated by a colon ie  and each keyvalue pair is separated by a comma Structure Here the student is the array that stores the students information in the form of keyvalue pairs2 Structure of XML XML handles data in two ways tags and attributes These tags are casesensitive Tags in XML are similar to that of HTML Tags start with  and end with  Names of the start and end tags must match The names of tags must only be letters numbers and underscore and the tag name must start with a letter only Structure Above is the structure of XML tags And it shows the hierarchy of XML tags XML follows a tree data structure The tree starts at the root and branches to the lower level of trees root tag is at the root of the tree Similarities Between JSON and XML Both JSON and XML serve the same purpose of storing and transferring data across the web These are humanreadable easy to understand and selfdescribing Both have parsers in most programming languages and APIs The code in JSON and XML is converted into the code that is understandable by the compiler of the programming language in which it is used The data in both JSON and XML can be fetched from web servers using HTTP requests HttpRequests is used to request data from servers The methods used for fetching the data are GET PUT and POST JSON and XML support hierarchical structure ie they store values within values Both JSON and XML are open source software and the software code is publicly accessible anyone can see modify and distribute the code Advantages of Using JSON Easy to read and write due to simple syntax Supported by all browsers and is recognized by JavaScript Can be used with almost all programming languages and provides support for all browsers Transmission of JSON files over browsers is much faster Due to the increasing popularity of javascript the use of JSON has been increasing JSON supports different data types and keyvalue pairs which makes it easy to understand Disadvantages of Using JSON JSON does not support namespace and cannot be extended It lacks formatting validation meaning incorrect data structures can be passed into your APIs JSON is less secure compared to XML Advantages of Using XML XML separates data from normal HTML documents It simplifies the platform exchange process Support for different APIs and almost every programming language has XML parser Userdefined tags can be created in XML XML does something that JSON cannot do  it can dress it up and allow languages like Java and C to create interfaces for applications that may not be webbased Disadvantages of Using XML The syntax used in XML is complex and using tags makes it similar to other webbased programming languages which makes it confusing There is no datatype support in XML XML files are bulky and require more size Conclusion When deciding between JSON and XML its essential to align with the specific needs of your application or project JSON is lightweight easily readable and offers faster parsing Its compatibility with JavaScript makes it a favorite for webbased applications and APIs XML boasts a robust structure allowing custom tags This makes it apt for applications needing more complex configurations and those requiring extensive metainformation While JSON is streamlined it does not support features like namespaces or a standard for comments areas where XML has an edge The demand for efficient data interchange has seen a rise in JSONs adoption especially with the growth of modern web technologies Neither format is universally superior Their value comes from how they fit within a particular application context Assessing requirements future scalability and user experience are all essential before settling on one Read More XML Formatter JSON XML 0 JSON stands for JavaScript Object Notation XML stands for eXtensible Markup Language 1 JSON files are stored with json extension XML files are stored with xml extension 2 It is extended from Javascript It is extended from SGML Standard Generalized Markup Language 3 It is a way of representing objects using keyvalue pairs It is a markup language and uses tag structures to represent data items 4 JSON is objectoriented XML is documentoriented 5 Data stored in JSON in the form of arrays and keyvalue pairs XML stores data in the form of tags and attributes 6 JSON files are easy to understand as compared to XML because of their simple syntax XML files are difficult to read and interpret as compared to JSON because of the complex tag structure 7 It doesnt support comments It supports comments 8 It doesnt support namespaces and metadata It supports namespaces and metadata 9 JSON files occupy less size due to the absence of tags XML documents can be bulkier due to their tag structure 10 JSON is preferred in BrowserSide technologies because its files can be transmitted in less time XML is preferred in ServerSide technologies as it gives the provision to validate the data 11 JSON is less verbose and faster XML can be slower to parse and is more verbose 12 JSON format is akin to a map data structure XML format resembles a tree data structure 13 JSON is dataoriented and is suitable for data serialization XML is both data and documentoriented making it suitable for complex document structures 14 JSON is native to JavaScript and can be parsed natively by web browsers XML requires an XML parser to be parsed 15 No official support for displaying JSON in a browser XML can be displayed in a browser with the help of XSLT ","https://aws.amazon.com/compare/the-difference-between-json-xml/, https://www.scaler.com/topics/javascript/xml-vs-json/",Data Handling,751,2467
Web Hosting and Deployment, Everything You Need To Know About Web Hosting 10192021 13 minutes By Codecademy Team Share article on Twitter Share article on Facebook Share article on LinkedIn Until you started exploring web development you may have never heard of the term web hosting Or if you did you probably had no clue whats involved in hosting a website or app Its an underappreciated part of how the internet works Everything you access on the internet  from your favorite podcast to that funny meme you saw last week  lives on a server or multiple servers that either a company or private individual pays for so that you can access this content Once you get past this simple description web hosting can get complicated There are many types of web hosting and ways to host web applications In this article well explore What is web hosting Types of web hosting Suggested hosting solutions for beginners Learning more about web development Setting the scene To get an idea of why web hosting is important imagine that youve just developed a web application Its what Web Developers do after all Lets say that its an app that allows users to save snippets of code along with related data to make flashcards that other users can use to teach themselves to write code Everything in your app is running fine locally You have a great user interface using React or some other modern frontend framework You also have a backend service that works like a charm But theres one problem with your app It currently lives on your computer so youre the only one who can access it and you want to share it with the rest of the world You cant let the public access your computer to check out your shiny new application Well you could but that would be reckless and unsafe Learn something new for free Intro to DevOps Learn JavaScript What is web hosting This brings us to web hosting Instead of hosting your application on your own computer and server its much safer to deploy it to another server owned by a company that specializes in these things called a web hosting provider If youre like most people you probably dont want to go out and buy a bunch of servers hook them up yourself and deal with network setup and everything else related Wouldnt it be easier to rent a server from someone whos done all the hard work for you A web host or hosting provider is a business that provides all the services needed by Web Developers to run their apps on the internet When someone wants to view your website all they have to do is type its domain name in a browser and the servers provided by your web host will serve it up Some hosting companies will require that you have a domain that you own to host your site Others will provide you with a subdomain they own If you need a domain most web hosting providers will help you purchase one An important part of web hosting is making sure that you choose the right type of web hosting for your project If you create a web application with a front end a back end and a database youll need a different type of web hosting than you would for a static website When you find the right host its also important to allocate the right amount of resources to your application so it doesnt time out when traffic hits it For hobby applications you rarely have to worry about this But if your app will be getting thousands of visitors every hour youll have to plan on having more resources available when you need them Types of web hosting A couple of decades ago there were only a few types of web hosting providers to choose from But technology changed and now there are a lot more choices The type of web host you choose depends on what you want to do and your technological skills Some types of hosting require you to know a lot about the technology involved in serving your web application up to users Other web hosts require little knowledge other than how to navigate around a user interface Website builders Website builders are online platforms that allow you to build a website quickly in the browser They usually have a draganddrop type of interface you can use to arrange the elements on your pages and a selection of prebuilt themes you can apply to your whole site with one click Some website builders you may have heard of include Wix and Squarespace Hosted content management systems like WordPresscom could also be considered website builders because you dont have to deal with all the technical details of deploying or installing WordPress You can choose from hundreds of themes and thousands of plugins to install from your browser to customize your site You can also add new blog posts and pages that get stored in a database somewhere that you never have to worry about Many small businesses use website builders like Wix to build a presence for their company online Its simple and easy to build a basic site with no technical knowledge and is a great choice when you dont have to update your website that often But for the most part your content is static You can add effects and other features but each change requires logging in again and arranging things manually Website builders backed by content management systems like WordPresscom have one advantage over other website builders because you can add new content much quicker You dont have to create a whole new page on your website for every new piece of content you add All you have to do is create a new post or page which gets stored in a database and that post will be dynamically rendered using the theme and plugins youve installed Another type of website builder is a static site generator This type of website builder generates complete static HTML pages based on markdown files you edit Static site generators support custom themes that you create yourself or find online When you run the build command a static site generator will use the markdown files and your theme to generate your site While static site generators arent hosting some web hosting options like GitHub Pages only support static hosting and use a static site generator to build your site Website builders arent suitable for deploying custom code Some will allow you to use JavaScript or CSS but thats about all Theyre designed mainly to put your content in a nicelooking theme you can modify using their interface Theyre a good choice for your blog or portfolio site but not for showing off your custom code Some popular website builders include GitHub Pages GitHub Pages provides you with the static website generator Jekyll to publish your site and will host it on one of their subdomains or using your own domain Wix You can build your website using Wixs online interface with draganddrop elements and an extensive selection of themes WordPresscom Here you have all the power of WordPresss themes and plugins to build your site and you dont have to worry about configuring a server or installing WordPress Shared web hosting Shared hosting is a step up from a website builder With this type of hosting your application shares the same server with multiple other users and the hosting provider takes care of all the server configurations Shared hosting providers have other services like email and databases that are also hosted on servers shared by other users Usually you can purchase a package with a monthly subscription that provides you with these services for one price If youve ever had roommates you already have an idea of what this type of web hosting is Just replace roommates with apps that other people have built When you use the shared hosting plan you share a server with other people So essentially youre getting a portion of the resources the machine has to offer Much like having roommates this makes rent cheaper but you have to share evenly If someone elses app starts consuming lots of resources your apps performance will suffer There can be many disadvantages to using shared web hosting Your web applications performance will depend on the type of applications also hosted on the same server Sometimes you get lucky and all of your shared hosting neighbors get very little traffic Other times you arent as lucky and one of the other users sharing your server hogs all the resources and your site will take a while to load Other disadvantages of shared hosting include Vulnerable to security issues If one website on the server gets hacked then your application is at risk If the server itself gets hacked then every website on the application goes down There are limits on what you can install If youre building an application using PHP and MySQL then shared hosting will work for you But if you want to use Python Nodejs C Java or another programming language for your app then your options could be limited You dont have root access so youre stuck with how the hosting provider configured the server and cannot customize it You get what you pay for so the support you receive when you run into issues will be limited Most shared hosting providers also provide dedicated hosting Dedicated web hosting Dedicated web hosting has a lot of advantages over shared hosting Dedicated web hosting is a hosting option where you rent a whole physical server from a hosting provider No one will share your resources Youll get full control over your server and can install any software that it supports Youll also have root access so you can configure the server in any way you want When you order a dedicated server youll choose between having an unmanaged server where you handle all the changes needed on the server or a managed server where the hosting providers staff will manage the server When you order a dedicated host its important to know what type of server you need first since youre ordering an actual physical machine You can usually choose the operating system the server will use the amount of physical RAM the type of CPU the amount of physical storage and other options In the past many companies started with shared hosting and moved up to dedicated hosting when their traffic picked up If the traffic load increased so much that one dedicated server wasnt enough theyd have to configure a load balancer and add more servers to handle the load While this is still an option many companies have opted to go with cloud hosting which gives you this type of scaling capabilities without all the manual setup Some popular shared and dedicated web hosting providers include HostGator HostGator provides multiple types of shared and dedicated hosting packages GoDaddy GoDaddy will sell you the domain and offer both shared and dedicated hosting InMotion InMotion offers shared dedicated and WordPressspecific hosting Note that there are also virtual private servers VPS A VPS functionality lies somewhere between shared and dedicated web hosting Theyre generally more affordable than the latter and theyre more reliable and secure than the former They also provide users with root access and theyre commonly used for game development Cloud hosting Cloud hosting providers have data centers across the globe All the services they provide are virtual which means even the hardware you rent is software that can be configured scaled and backed up on the fly The worldwide servers allow you to spread your applications and data across multiple interconnected servers This allows your users to access them from a server thats closer to them with lower latency Because cloud servers can scale dynamically you always have just enough resources at hand Infrastructure as a Service IaaS With IaaS the cloud provider delivers your infrastructure over the internet So all the networking storage servers memory and CPU youll use will be virtualized and highly scalable Youll still have to configure and maintain these resources but you wont have to worry about the underlying physical infrastructure Because everything is virtual you can do all this maintenance and configuration through the browser or via the command line and make almost realtime changes to your infrastructure Popular IaaS providers include Digital Ocean A IaaS cloud provider thats simpler to use than the big three cloud providers also in this list Amazon Web Services The first and most popular of all cloud providers Google Cloud Platform Googles answer to IaaS Microsoft Azure Microsofts IaaS solution Platform as a Service PaaS With PaaS the cloud host delivers a framework for developers to build their applications on top of Instead of worrying about setting up your servers and configuring your virtual machines properly you only have to create your application and the cloud provider takes care of the rest But since youre using a specialized framework when you go with PaaS youll have to code your application according to the rules of the framework Popular PaaS providers include Render Render is a cloud hosting provider that can run a wide range of applications including static websites dynamic web apps scheduled cron jobs and more It natively supports many popular programming languages like Nodejs Python and Ruby In our course Deploying with Render youll learn how to build deploy and monitor a web app with Render Heroku Heroku makes it easy to deploy Nodejs Ruby Java PHP Python Go Scala and Clojure applications with a few commands Google App Engine Google App Engine lets you build highly scalable applications on a fully managed serverless platform Function as a Service FaaS With FaaS you dont deploy services to the cloud hosting provider just functions That means you dont have to worry about configuring a server or configuring resources You just choose the runtime youll be writing your code in and write functions to return the data you need When you use FaaS the physical hardware virtual machine operating systems and web server software are all handled by your cloud service provider Popular FaaS providers include Amazon Lambda Amazon Lambda is the most popular FaaS provider Azure Functions Azure also provides FaaS Cloud Functions This is Google Cloud Platforms FaaS offering Suggested hosting solutions for beginners We just covered a lot and you may feel a little overwhelmed but we have a few suggestions if youre just beginning with web development The following web hosting providers should give you what you need to get started When choosing a web hosting provider experiment with simple demo projects and see what works for you and what doesnt Always make sure you evaluate your options against what youre trying to build Remember that at the end of the day all of these are just tools you can use Theres no onesizefitsall solution so you might use some of these you might use none or you might use a mixture of all three  or even other solutions GitHub Pages static site generator GitHub Pages uses the Git version control system and a static website generator called Jekyll to publish websites for its users and its free Because you can only publish static pages you wont be able to deploy your web applications here but its good for blogs your portfolio site or possibly a compiled version of a React application that doesnt require backend code Our How to Deploy a Website course will teach you how to deploy a website to GitHub Pages Render PaaS Render is a popular cloudbased software that handles building and deploying code and provides the necessary resources to host applications and services Learn to build deploy and monitor an app in our course Deploying with Render Digital Ocean IaaS If you want to scale your application and Render doesnt fit your needs Digital Ocean is a good option Especially if you want to use an IaaS cloud provider but dont want to deal with all the complexity that comes with some of the bigger providers Its easy to build your applications on Digital Ocean and they have a lot of resources to help beginners get started Learning more about web development If you want to show your shiny new app to the rest of the world you need web hosting There are plenty of options from website builders to cloud hosting It all depends on what type of website or application you want to deploy For blogs and sites that are mainly content a website builder may be enough If you want to deploy an actual web application thatll execute serverside code youll need to go with either a shared host a dedicated host or a cloud hosting provider If you dont have a web application to deploy yet we can show you how to build one with our courses Our FrontEnd Engineer Career Path will teach you how to use JavaScript HTML CSS and React to build the part of the application that runs in the browser Our BackEnd Engineer Career Path will show you how to write serverside code using Nodejs To learn how to work on both frontend and backend code check out our FullStack Engineer Career Path And if you just want to jump right into building a website from scratch try Build a Website with HTML CSS and GitHub Pages Related courses 4 courses Deploying with Render Intermediate Learn how to build deploy and monitor a web app with Render Build a Website with HTML CSS and GitHub Pages Beginner Learn the basics of web development to build your own website How to Deploy a Website Beginner Learn how to publish a website to the Internet with Jekyll Amazon Web Services AWS and GitHub Pages FullStack Engineer Beginner Learn to build web applications from start to finish This path will start with the frontend move to the backend then connect the two Subscribe for news tips and more Subscribe ,https://www.codecademy.com/resources/blog/what-is-web-hosting/,Deployment,782,3018
"Version Control Systems (e.g., Git)", What is a version control system Version control systems are a category of software tools that helps in recording changes made to files by keeping a track of modifications done in the code Why Version Control system is so Important As we know that a software product is developed in collaboration by a group of developers they might be located at different locations and each one of them contributes to some specific kind of functionalityfeatures So in order to contribute to the product they made modifications to the source codeeither by adding or removing A version control system is a kind of software that helps the developer team to efficiently communicate and managetrack all the changes that have been made to the source code along with the information like who made and what changes have been made A separate branch is created for every contributor who made the changes and the changes arent merged into the original source code unless all are analyzed as soon as the changes are green signaled they merged to the main source code It not only keeps source code organized but also improves productivity by making the development process smooth Basically Version control system keeps track on changes made on a particular software and take a snapshot of every modification Lets suppose if a team of developer add some new functionalities in an application and the updated version is not working properly so as the version control system keeps track of our work so with the help of version control system we can omit the new changes and continue with the previous version Benefits of the version control system Enhances the project development speed by providing efficient collaboration Leverages the productivity expedites product delivery and skills of the employees through better communication and assistance Reduce possibilities of errors and conflicts meanwhile project development through traceability to every small change Employees or contributors of the project can contribute from anywhere irrespective of the different geographical locations through this VCS For each different contributor to the project a different working copy is maintained and not merged to the main file unless the working copy is validated The most popular example is Git Helix core Microsoft TFS Helps in recovery in case of any disaster or contingent situation Informs us about Who What When Why changes have been made Use of Version Control System A repository It can be thought of as a database of changes It contains all the edits and historical versions snapshots of the project Copy of Work sometimes called as checkout It is the personal copy of all the files in a project You can edit to this copy without affecting the work of others and you can finally commit your changes to a repository when you are done making your changes Working in a group Consider yourself working in a company where you are asked to work on some live project You cant change the main code as it is in production and any change may cause inconvenience to the user also you are working in a team so you need to collaborate with your team to and adapt their changes Version control helps you with the merging different requests to main repository without making any undesirable changes You may test the functionalities without putting it live and you dont need to download and set up each time just pull the changes and do the changes test it and merge it back It may be visualized as Types of Version Control Systems Local Version Control Systems Centralized Version Control Systems Distributed Version Control Systems Local Version Control Systems It is one of the simplest forms and has a database that kept all the changes to files under revision control RCS is one of the most common VCS tools It keeps patch sets differences between files in a special format on disk By adding up all the patches it can then recreate what any file looked like at any point in time Centralized Version Control Systems Centralized version control systems contain just one repository globally and every user need to commit for reflecting ones changes in the repository It is possible for others to see your changes by updating Two things are required to make your changes visible to others which are You commit They update The benefit of CVCS Centralized Version Control Systems makes collaboration amongst developers along with providing an insight to a certain extent on what everyone else is doing on the project It allows administrators to finegrained control over who can do what It has some downsides as well which led to the development of DVS The most obvious is the single point of failure that the centralized repository represents if it goes down during that period collaboration and saving versioned changes is not possible What if the hard disk of the central database becomes corrupted and proper backups havent been kept You lose absolutely everything Distributed Version Control Systems Distributed version control systems contain multiple repositories Each user has their own repository and working copy Just committing your changes will not give others access to your changes This is because commit will reflect those changes in your local repository and you need to push them in order to make them visible on the central repository Similarly When you update you do not get others changes unless you have first pulled those changes into your repository To make your changes visible to others 4 things are required You commit You push They pull They update The most popular distributed version control systems are Git and Mercurial They help us overcome the problem of single point of failure Purpose of Version Control Multiple people can work simultaneously on a single project Everyone works on and edits their own copy of the files and it is up to them when they wish to share the changes made by them with the rest of the team It also enables one person to use multiple computers to work on a project so it is valuable even if you are working by yourself It integrates the work that is done simultaneously by different members of the team In some rare cases when conflicting edits are made by two people to the same line of a file then human assistance is requested by the version control system in deciding what should be done Version control provides access to the historical versions of a project This is insurance against computer crashes or data loss If any mistake is made you can easily roll back to a previous version It is also possible to undo specific edits that too without losing the work done in the meanwhile It can be easily known when why and by whom any part of a file was edited Last Updated  29 Jun 2022 Like Article Save Article Previous Git Tutorial Next Introduction and Installation of Git ,https://www.geeksforgeeks.org/version-control-systems/,Development Tools,416,1154
"Content Management Systems (e.g., WordPress, Drupal)", What is a content management system CMS A content management system CMS is an application that is used to manage content allowing multiple contributors to create edit and publish Content in a CMS is typically stored in a database and displayed in a presentation layer based on a set of templates like a website The following are common functions of a CMS Content creation allows users to easily create and format content Content storage stores content in one place in a consistent fashion Workflows assigns permissions for managing content based on roles such as authors editors and admins Publishing tells the software when and where the content should go live Optimization helps you improve digital experience and learn from your content Benefits of a content management system One major advantage of a CMS is its collaborative nature Multiple editors can contribute schedule or manage content to be published Because the user interface is usually browserbased a CMS can be accessed from anywhere by any number of users The second major advantage of a CMS is that it allows nontechnical people who dont know programming languages to easily create and manage their own content The draganddrop editors of a typical content management platform allows users to enter text and upload images without needing to know any HTML or CSS programming languages When a company uses a CMS to publish its web pages it reduces its reliance on frontend developers to make changes to the website making it quicker and easier to publish new web pages improving the digital experience for users and visitors When a company uses a CMS to publish content to other channels  like social mobile apps and ecommerce it can drastically reduce the amount of development a company needs to do and make it easier to distribute content to different channels simultaniously What is the difference between a website and a CMS TLDR a website is a collection of web pages you can browse and a CMS is the software that the website runs on Wikipedia probably describes it besta website is a collection of web pages and related content that is identified by a common domain name and published on at least one web server In contrast a CMS or Content Management System is a piece of software that allows you to store manage and publish said web pages Most websites use a content management system but you could make one without a CMS writing directly in a programming language like HTML and CSS More often though its easier to use a CMS to manage content for the editor instead of building a website from code What are some examples of a CMS While there are hundreds of CMS platforms each with their own unique functionality some of the best and most popular CMS providers are Wordpress Drupal Optimizely CMS Contentful Squarespace Wix Specifically for online stores although Optimizely Monetize Adobe Magento and Shopify also manage content similar to a CMS they are typically not considered a true CMS as much as an ecommerce platform with some added functionality What to look for in a CMS Before choosing a content management system it is a good idea to start with thinking about how your website and content will be consumed You will need to begin by making a list of the goals you are trying to achieve as well as any specific requirements you may have This will help you choose the right content management system  the one that supports your business requirements  rather than the most popular or wellliked Common goals for CMS are getting more readers on a blog increasing purchases in a shop or optimizing your content for search engines SEO CMSs come in all shapes and sizes each with its own set of features and benefits Some are ideally suited for bloggers others may be tailored to ecommerce sites with features for pricing and online store functionality Specifics will vary based on your companys size needs and resources Media CMS video Here are some questions to consider when picking the best CMS for your situation What is your budget If you have infinite resources to spend there are some very complex content management systems with features designed to make content creators and editors lives easier With a limited budget however your choices will be more limited Your web content management system will need hosting so its good to take costs for a domain and web hosting into account when deciding Common components that make up a CMSs costs are The hosting  where your website lives The domain name  examplecom The content management system itself  the piece of software that stores and manages all the content Any development work required  for example templates custom functionality Maintenance fees  often required for larger sites to keep them up to date and secure What kinds of content and processes does the CMS need to support Next think about what kinds of digital content will be managed in the CMS If youre just publishing blog articles a simpler CMS might suffice however in most cases sites and apps have different kinds of content Does your company need to publish hundreds of new videos a day Change prices on thousands of products per day Host images for blog posts Publishing a lot of changes and authoring new content can be a lot of work to manage with your team members Consider using a Conent Marketing Platform to make managing and collaborating on content easier What technologies does the CMS need to support or integrate with If your company already uses a CRM or web analytics program like Google Analytics youll need to consider a CMS that has integrations with existing online marketing software If you have developers inhouse a solid API and documentation might also be needed Most companies have multiple pieces of marketing software and you could consider using a CMS plugin with Email marketing software like Mailchimp or Marketo if youre looking to collect newsletter signups andor leads A CRM like Salesforce often used for personalization and targeting content to subsets of visitors audiences Web analytics like Google Analytics for tracking visitor behavior and demographics APIs for apps or existing software that could ingest some of the CMS content Ecommerce if you want to sell products andor services online How easy is it to create and edit content Most modern CMS have a draganddrop editor out of the box allowing you to drag and drop hence the name content onto a page and publish it with a visual preview of your page However in some cases your digital content might not just be simple pages to be published to a website So its good to evaluate how easy it would be to publish what youre looking to write and create Typically in larger companies the team that implements the website is not the same set of end users writing and publishing content When these large companies have developers designers and content writers on different teams specific userfriendly functionality for each role is key You dont want anyone to be able to edit everything on your shiny new website Some editor features beginners and advanced users should look out for A WYSIWYG editor  What You See Is What You Getstyle editors show you what content looks like while its being edited drastically improving the ease of use Role and rights management  So youre in control of who gets to edit and publish each type of content Updates and upgrades  Cloudbased software is typically easier to update than selfinstalled ones as the operating system running the software is managed for you Readymade integrations and modules  see the integrations section for some examples of software you might already own A digital asset manager  otherwise known as a DAM stores your images videos and does document management in the same way a CMS does for pagebased but more tailored to digital assets Advanced users who might want to build more than templates or needs a CMS for mobile apps a headless CMS might also be a good option A headless CMS does not come with a visitable website out of the box which is more work initially but also allows for greater control over the final experience How many people will work on the CMS Depending on the size of your website or company you will have different requirements Larger companies typically have more strict requirements for content management applications and may even require features only found in enterprise content management systems Some examples of features enterprise companies might look for are Single signon SSO scalability and what cloudbased services the backend is built on and integrations with Small business however should focus on picking an easy user interfaces and maintenance as the teams who manage the website are typically smaller and roles are shared between team members How will you measure success Depending on the goal of your CMS like a blog or a commerce site you should strongly consider using a web analytics platform like Google Analytics or Mixpanel to measure conversions A CMS allows editors to make rapid changes to your content without requiring a frontend developer You can measure how these changes are impacting your website by running an AB test Great CMS software allows you to do this optimization in an easy way without building complex addons and integrations yourself Is the platform SEOfriendly In most cases visitors will have traveled to your website through organic search engines like Google Even if youre very active on other channels like social you will want to make sure your website can be found when potential customers look for it If being listed well on search engines SEO is important to your company a CMS that has automation for basic onpage optimization tasks such as title tags urls alt tags on images and a sound internal linking structure is very valuable CMS software lacking these features on installation often have free or paid plugins to help manage search engine friendliness Practicing search engine optimization typically also has the added benefit of helping your websites appearance on other platforms like social media and when visitors share links to your website in messages What technology is it built on Most CMS platforms use custom templates and integrate with your existing marketing systems This may require work from a developer or implementation agency if you dont have developers inhouse and not all developers and agencies can work with every CMS Therefore its important to pick software that your developers and agency know how to work with Developers often know a set of programming languages and most content management systems are built on php NET or serverside Javascript How well is it supported Some checks often overlooked are Is the CMS updated frequently Does the CMS use the latest technology How fast are bugs and security problems solved How large and globally built out is the support team If youre an international company this is even more important Is the developer community behind the software sizable and happy Most opensource CMS have large developer communities but as some systems are more targeted at those developers it can be hard to parse all the information for less technical users Its good practice to look out for a mix of developer and practitioner editor designer writer content and standard templates The advantage to a sizable community is the amount of online help and documentation you will find on most aspects of customization Optimizelys own CMS also has a large and active forum for developers that might be able to help with your website or app ,https://www.optimizely.com/optimization-glossary/content-management-system/,Back-End Development,640,1940
Search Engine Optimization (SEO),What Is SEOSEO search engine optimization is a set of processes aimed at improving a websites visibility in search engines like Google with the goal of getting more organic traffic SEO is about fulfilling users search needs by creating relevant highquality content and providing the best possible user experienceSEO activities can take place both onsite and offsite Thats why you may often see SEO divided into onpage and offpage categories In practice SEO typically involves Keyword research Content creation and optimization Technical optimization Link buildingWhy Is SEO ImportantEvery day Google users conduct billions of searches for information and products Its no surprise that search engines are usually one of the biggest traffic sources to websitesTo harness this traffic sources potential you need to appear in the top search results for your target keywords The correlation is very simplethe higher you rank the more people will visit your pageThe No 1 organic result is 10x more likely to receive a click than a page ranking in position No 10And the top three organic results get more than 50 of all the clicksThis is where SEO enters the picture Search engine optimization plays a key role in improving your ranking positions Better rankings mean more traffic And more traffic means new customers and more brand awarenessIn other words neglecting SEO would mean neglecting one of the most important traffic channelsleaving that space completely to your competitorsSEO vs PPCMost search engine results pages SERPs contain two main types of results Paid results You have to pay to be here through payperclick PPC advertising Organic results You must earn your rankings here through SEOYou may ask Why not just pay to appear in the ads sectionThe answer is simple The vast majority of people just ignore ads and click on the organic results insteadYes SEO takes more time effort andalthough it focuses on free organic trafficresources But once you rank for your target keywords you can reach more people and generate passive traffic that doesnt disappear the moment you stop payingNote Need to set up a Google Ads campaign Our PPC Keyword Tool offers a quick and easy way to set up a campaign organize keywords set negative keywords and export everything into the Google Ads editor How Do Search Engines WorkThe ultimate goal of any search engine is to make searchers happy with the results they findTo achieve this search engines need to find the best pages And serve them as the top search resultsNote Google is not the only search engine But it is by far the most popular one Thats why we refer to Google most times we talk about search engines Besides SEO fundamentals are fairly similar across most search enginesGoogle uses the following stages to find and rank content Crawling Google uses bots or computer programs to crawl the web and look for new or updated pages In order for Google to find a page the page should have at least one link pointing to it Indexing Next Google analyzes each page and tries to make sense of what the page is about Then it may store this information in the Google Indexa huge database of webpages Serving results When a user enters a query Google determines which pages are the best in terms of both quality and relevance and ranks them in the SERPYour job as a website owner is to help search engines crawl and index all the pages on your site that you want them to And none of them that you dontYou can ensure the crawlability and indexability of your pages through a number of actions and best practices commonly referred to as technical SEO Now that you understand how Google finds and categorizes pages its time to take a closer look at how the top results are selected And the role of SEO in this processFurther reading What Is Technical SEO Basics and Best PracticesHow Does SEO WorkGoogle uses relatively complex processes known as algorithms to rank pages These algorithms take into account a huge number of ranking factors to decide where a specific page should rankYou dont need to know how search algorithms work Actually nobody does with 100 certainty However knowing the basics can help you better understand how SEO works and what it takes to optimize your pages to rank in GoogleEnsuring RelevanceYour No 1 job in SEO is to ensure that youre offering relevant contentWhy Because Googles No 1 job is to show users relevant results Relevance is much more than just showing pages about dogs not cats when someone searches for dogs It is also about satisfying the users search intentthe reason why they used a particular search queryThere are four main types of search intent Navigational eg spotify login Informational eg what is spotify Commercial eg spotify review Transactional eg spotify premiumHeres an exampleIf you search for best dog food you dont want to see articles about different types of dog diets or recipes for homemade dog food Both would be topically relevant but they do not fulfill your search intent Google knows based on the behavior of millions of other users that if you search for best dog food you almost certainly want to buy dog food Thats why Google ranks either product pages or reviews of the best dog food products ie the search intent is either transactional or commercialSo how do you make sure your page fulfills the intent behind a search queryLuckily Google does all the hard work All you need to do is look at the search results and analyze what you seeThings you need to consider to create relevant content Topical relevance One of the ways Google determines a pages topic is by looking at the keywords that appear on the page Optimize your pages for keywords but avoid overdoing it Type of content Make sure your page provides the right type of content for the query by looking at what types of results rank for the keyword eg landing pages product pages informational posts reviews etc Content freshness Some types of topics such as news updates or product reviews require fresh frequently updated information If the search query is timesensitive you need to ensure your content will also stay up to date Location Google may serve different results based on a searchers location If this is the case you need to adjust your strategy accordingly eg if you run a local business follow local SEO best practices Where to StartTo quickly identify a keywords intent use a tool like Keyword Overview Enter your keyword and click SearchYoull see the intent in the widget labeled Intent And if youre doing keyword research the Keyword Magic Tool also displays intent Like thisFurther reading How to Do Keyword Research for SEOCreating Quality ContentFinding the right keywords is just the first stepYou also need to create content that will rank for those keywords Content creation and optimization are two irreplaceable parts of SEOWhen asked about the most important factor to rank in the top search results John Mueller of Google answered with a single word methode JohnMu Whats the main important factor for rank a website in top search results on a particular phrase Saroj Kumar sarojnishad September 6 2017To rank well in Google you need to create content that is literally among the top 10 pieces on a given topic There are 10 organic results on the first page of each SERP and thats where you want to beHere are a few key things that separate highquality content from mediocre content Comprehensiveness Cover the topic thoroughly and answer all the questions a visitor might have Its not about word count Ensure that each page gives searchers a complete resource Uniqueness Your content should not be a compilation of the top results It should always provide some added valuewhether it is a unique angle useful data helpful examples or original visuals EEAT signals Google pays a lot of attention to Experience Expertise Authoritativeness and Trustworthiness EEAT You should provide accurate and reliable information be an expert on what you write about and demonstrate it both onsite and offsite Readability Your text should be easy to read This includes structuring your content logically writing short sentences avoiding passive voice having a consistent tone of voice etc Where to StartOnce youve conducted keyword research its time to start creating contentIts difficult to measure the quality of content exactly but a tool like SEO Writing Assistant can helpTo start open the tool and start writing Or if you already have the text copy and paste it inThe tool will evaluate your content in four categoriesReadability SEO Originality and Tone of Voiceand suggest improvementsLike soProviding Great UsabilityGoogle prefers userfriendly websitesTechnical SEO plays an important role here again Besides ensuring the crawlability and indexability of your website SEO also makes sure your website meets usability standards This includes factors like Site security Your website should meet standard security criteria like having an SSL certificate using HTTPS protocol instead of HTTP Page speed Google ranks faster pages higher in the search results because they provide a better user experience Mobile friendliness Google evaluates your content based on its performance on a mobile devicethis is called mobilefirst indexing Mobile SEO ensures that mobile users are able to consume your content easily Ease of use You should have an easytofollow website structure that allows visitors to find everything quickly And navigate through your site without any problems or obstructions Where to StartThe best way to get a general overview of your websites usability is to run a complete site auditIn Semrushs Site Audit youll find several reports that focus on different aspects of your websites performance Start by entering your domain and clicking Start Audit In the basic settings select the number of pages per audit and the crawl source as Website Then click Start Site AuditOnce the tool is done crawling your site youll see a dashboard with your sites overall health And different thematic reports Besides checking for over 140 issues the tool also provides recommendations on how to fix themLike thisHead to the Issues tab and youll see all of your sites errors warnings and notices To learn more about the issue and how to fix it click Why and how to fix it and youll see a popup Further reading How to Perform a Complete SEO Audit Building AuthoritySearch engines use several offpage signals to determine whether your site can be trusted One of the strongest signals and one of the strongest ranking factors in general is backlinkslinks from other websites pointing to your siteEssentially backlinks function as votes of confidence to search engines In general the more highquality links your page receives the more authority your page has in the eyes of Google Which can lead to higher rankingsThats why link buildingthe practice of getting backlinks to your siteis an important part of SEOThere are plenty of link building strategies For example Creating linkable assets creating content that provides great value and naturally attracts links eg original studies interactive pages free tools Guest blogging writing posts for other websites in order to link back to your website Broken link building finding links that no longer work on other websites and suggesting links to your pages as replacementsTip Learn more about the best ways to get backlinks in our link building guide for beginners Focus on quality not quantity when building links A single backlink from a highauthority page will pass more authority than 100 backlinks from irrelevant lowquality pages Yes you do want as many links as possible But those links need to be from relevant quality pages related to your sites topicLast thing to remember Although Google ranks pages not websites meaning they evaluate most authority signals at a page level the overall number of backlinks to your website can still influence a particular pages rankings How Through internal linking linking from one page of your website to another you can pass authority between your pages the same way it passes from external pages to your siteKeep this in mind when creating internal links And make sure your most important pages have enough internal links pointing at them As Googles John Mueller said about internal linking It is one of the biggest things that you can do on a website to kind of guide Google and guide visitors to the pages that you think are importantWhere to StartThe easiest way to find backlink opportunities is to run a backlink gap analysisWhyItll help you see the sites linking to your competitors but not to you After all if a site is happy to link to a competitor theyll probably be happy to link to you too Especially if you create higherquality content To start head to the Backlink Gap tool Then enter your domain and up to four competitor domains And click Find prospectsYoull get a table with all the websites that have backlinks to your competitors And you have different filters Best Weak Strong Shared Unique or All opportunitiesHeres what each filter means Best Websites that link to all of your competitors but not to you Weak Websites that link to you less than to competitors Strong Websites that link only to you Shared Websites that link to all of your competitors Unique Websites that link to only one competitor domain All All prospective websitesStart with the Best filter Hit the Export button on the top rightAnd you now have a long list of sites you can reach out to for backlinks 7 Truths About SEOSo thats what SEO means in practice But here are seven truths you should take to heart before embarking on your SEO journey SEO is not about cheating Google Instead think of it as convincing Google to rank your page by showing the value you provide for users SEO is not about hacks Dont get caught in a loop of looking for cool new SEO tricks or hacks Usually all you need is to do the SEO basics really well really consistently SEO is a longterm game SEO results usually dont appear immediately although there are exceptionsfor example when you fix some serious issue In general think in months instead of days SEO is more than just installing an SEO plugin SEO plugins are useful tools But the mere fact that you set one up does not mean your website is suddenly SEOfriendly Youre never done with SEO Search engine optimization is a continuous process Even if you rank No 1 for all your keywords you always need to keep improving The competition never sleeps Knowing your audience is key The more you understand your target audience customers readers subscribers the easier it is to create an effective SEO strategy SEO is just one part of the puzzle No amount of optimization will help you if you neglect to work on the core of your businessyour product or serviceGet Started With SEONow that you know what SEO is its time to take action Execute on the tips we mentioned earlier and youll be on your way to higher rankings And one step ahead of your competitors Start by signing up for a free Semrush account no credit card needed Youll be able to Do keyword research up to 10 searches per day Analyze competitors up to 10 domains per day Track your keyword rankings up to 10 keywords Run a free site audit crawl up to 100 URLs Get ideas to improve your onpage SEO up to one campaignAnd tons more SEO FAQsFinally here are the answers to some common questions about SEOWhat Is the Role of SEO in Digital Marketing The prime objective of SEO is improving the visibility of a website in search engines As such it is a crucial part of every digital marketing strategy SEO creates great synergy with PPC advertising and overlaps with other areas of marketing such as content marketing and social media marketingCan I Do SEO MyselfIf youve ever wondered whether you can DIY SEO without the help of a professional or an agency the answer is definitely yes All you need is a willingness to learn new things and a website where you can apply your knowledgeHow Do I Start Learning SEOThis guide is a good stepping stone for your SEO learning journey But if you want to dive deeper andor prefer video content youll love Semrush Academy Find dozens of 100 free online courses taught by top industry experts such as Eric Enge Brian Dean and Nathan GotchDo I Need an SEO ToolYour SEO actions must be based on accurate data If you run a website that makes you money having a complete SEO toolset that will cover all your SEO needs is a necessity And it will pay for itself quickly,https://www.semrush.com/blog/what-is-seo/,SEO and Marketing,974,2799
Web Security Practices, LRS Web Solutions is a website design and development company based in Springfield Illinois We offer web design services including custom website development applications hosting content marketing SEO analytics photography videography services and more Lets get in touch Fill out the form below What are the strategies to secure Web applications Traditionally when we talk about IT security we tend to think of network security or operating system security However with the trend toward using webbased applications for  well basically everything more attention is being placed on cybersecurity a term weve come to know since the very early 1990s and the advent of the web Today web applications are a critical aspect of business and everyday life By using web applications both businesses and individuals can simplify and get more things done with fewer resources achieving objectives much faster than they could before They no longer need a warehouse full of meticulously organized paperwork There is little or no need to rely on actual physical mail now for communication Most marketing efforts are now highly webfocused Even customer service is now pointing you to websites instead of 1800 phone numbers Web applications can help target a proliferating amount of clientele and customers in ways that were never available to before Web apps can interact with your customers to communicate offer product support and keep their business Because we are using web applications for so many things and passing so much sensitive information around via so many different types of online channels we should next be obliged to also take a hard stance at protecting and securing that information To date no web technology has proven itself invulnerable beyond all doubt New threats pop up every single day that require at least some change or improvement in implementing countermeasures and general webfocused security To improve the overall quality of web applications developers should abide by these rules Here are 11 tips developers should remember to protect and secure information 1 Maintain Security During Web App Development Before you run out and hire a team of security consultants realize that you can maintain security in your web applications during the actual development of those tools 2 Be Paranoid Require Injection  Input Validation User Input Is Not Your Friend A good rule of thumb is to consider all input to be hostile until proven otherwise Input validation is done so that only properlyformed data passes through the workflow in a web application This prevents bad or possibly corrupted data from being processed and possibly triggering the malfunction of downstream components Some types of input validation are as follows Data type validation ensures that parameters are of the correct type numeric text et cetera Data format validation ensures data meets the proper format guidelines for schemas such as JSON or XML Data value validation ensures parameters meet expectations for accepted value ranges or lengths There is a whole lot more to input validation and injection prevention however the basic thing to keep in mind is that you want to validate inputs with both a syntactical as well as a semantic approach Syntactic validation should enforce correct syntax of information SSN birth date currency or whole numbers while semantic validation should enforce the correctness of their values within a very specific business context end date is greater than the start date low price is less than high price 3 Encrypt your data Encryption is the basic process of encoding information to protect it from anyone who is not authorized to access it Encryption itself does not prevent interference in transmit of the data but obfuscates the intelligible content to those who are not authorized to access it Not only is encryption the most common form of protecting sensitive information across transit but it can also be used to secure data at rest such as information that is stored in databases or other storage devices When using Web Services and APIs you should not only implement an authentication plan for entities accessing them but the data across those services should be encrypted in some fashion An open unsecured web service is a hackers best friend and they have shown increasingly smarter algorithms that can find these services rather painlessly 4 Use Exception Management Another developmentfocused security measure is proper exception management You would never want to display anything more than just a generic error message in case of a failure Including the actual system messages verbatim does not do the enduser any good and instead works as valuable clues for potentially threatening entities When developing consider that there are generally only three possible outcomes from a security standpoint Allow the operation Reject the operation Handle an exception Usually in the case of an exception or error you will revert to rejecting the operation An application that fails securely will prevent operations from unintentionally being allowed For example if an ATM failed you would prefer it to display a simple friendly message to the user not spill money out onto the ground 5 Apply Authentication Role Management  Access Control Implementing effective account management practices such as strong password enforcement secure password recovery mechanisms and multifactor authentication are some strong steps to take when building a web application You can even force reauthentication for users when accessing more sensitive features When designing a web application one very basic goal should be to give each and every user as little privileges as possible for them to get what they need from the system Using this principle of minimal privilege you will vastly reduce the chance of an intruder performing operations that could crash the application or even the entire platform in some cases thus adversely affecting other applications running on that same platform or system Other considerations for authentication and access control include things such as password expiration account lockouts where applicable and of course SSL to prevent passwords and other accountrelated information being sent in plain view 6 Dont Forget HostingServiceFocused Measures Equally important as developmentfocused security mechanisms proper configuration management at the service level is necessary to keep your web applications safe Is your site vulnerable Read how the LRS web solutions team recovered and secured the Macon County Circuit Clerks website after hackers attacked it 7 Avoid Security Misconfigurations Given the endless amount of options that contemporary web server management software provides this also means that there are endless ways to really muck things up Not protecting filesdirectories from being served Not removing default temporary or guest accounts from the webserver Unnecessarily having ports open on the webserver Using olddefunct software libraries Using outdated security level protocols Allowing digital certificates to expire Have a welldocumented process for not only setting up new websites but also for setting up the web servers and the software used to serve those websites The modular nature of web server features allows for more granular control over resources and security Although this can make your applications less secure if you are not careful when using them Be extremely cautious and careful when managing more highrisk security options and features 8 Implement HTTPS and Redirect All HTTP Traffic to HTTPS We had discussed encryption previously with developmentfocused approaches Encryption at the service level is also extremely helpful and sometimes necessary preventative measure that can be taken to safeguard information This is typically done by using HTTPS SSL or Secure Sockets Layer SSL is a technology used to establish an encrypted link between a web server and a browser This ensures that the information passed between the browser and the webserver remains private SSL is used by millions of websites and is the industry standard for protecting online transactions In addition blanket use of SSL is advised not only because it simply will then protect your entire website but also because many issues can crop up with resources like stylesheets JavaScript or other files if they arent referenced via HTTPS over an SSL 9 Include Auditing  Logging We are also concerned with auditing and logging at the server level Thankfully much of this is built into the content serving software applications such as IIS Internet Information Services and is readily accessible should you need to review various activityrelated information Not only are logs often the only record that suspicious activity is taking place but they also provide individual accountability by tracking a users actions Different from Error Logging Activity or Audit Logging should not require really much setup at all since it is generally built into the webserver software Be sure to leverage it to spot unwanted activities track end users actions and to review application errors not caught at codelevel In extremely rare cases logs may be needed in legal proceedings As I am sure you well know in these cases the handling of the log data is critical 10 Use Rigorous Quality Assurance and Testing If your situation at all allows you to utilizing a thirdparty service that specializes in penetration testing or vulnerability scanning as an addition to your own testing efforts is a great idea Many of these specialized services are very affordable It is better to be overly cautious when possible and not rely on only your own inhouse quality assurance process to uncover every little hole in every little web application you are using Adding another layer of testing to catch a few holes here and there that were perhaps not identified by other means of testing is never a bad thing To make security upgrades and routine testing efforts go more smoothly have a welldefined and easily replicable process in place as well as a thorough inventory of all web applications and where they exist Nothing is more frustrating than trying to fix security bugs with a specific code library but to only then have no idea which web applications are even using it Your web applications should also be free of any vulnerabilities or breaches that would fail any PCI or HIPAA guidelines To be certain of this you should be diligent in all these areas with your approach and design Whenever possible you should consult with a party that specializes in adherence to these guidelines so that you can be fully confident that you have everything in place to not only thwart attacks but to simply follow the rules put forth by governing agencies as well 11 Be Proactive to Keep Up With the Bad Guys When I talk to people about cybersecurity I often use military analogies and phraseology since cybersecurity seems to me like an arms race Threats are constantly evolving and developing new attacks and tactics are constantly being developed Businesses with an online presence must counter these threats to keep up with the bad guys out there Like a good military strategy the key to cybersecurity is proactivity You should have a welldefined blueprint for a security plan for all your sensitive web applications This means prioritizing your more highrisk applications It can be easier to identify if you have an inventory or repository of all the web applications that your business uses or provides to its end users As security threats evolve so should your approach and plan for handling them Increasingly sophisticated adversaries and everexpanding soft spots as we turn to web applications to solve more and more of even our most tenable business needs is a concern that requires a fulltime effort The current reality is that while you cannot exactly expect to avert all attacks you should certainly aim to meet the challenge by building your own intel as a force multiplier Get your leadership fully engaged and make sure you have ample resources applied to build an active defense to detect and respond to emerging security risks and hazards The web security landscape is changing constantly and so must your strategy to traverse it Contact LRS Web Solutions to keep your web applications secure ,https://www.lrswebsolutions.com/Blog/Posts/32/Website-Security/11-Best-Practices-for-Developing-Secure-Web-Applications/blog-post/,Security,845,1979
Cross-Browser Compatibility, October 5 2023  Browsers CrossBrowser Compatibility Testing  Best Practices for Web Developers Casmir Onyekani Imagine putting in a ton of work to build a web application And then it works in the Chrome browser but misbehaves in Mozilla Safari or any other browserAs a web developer youre likely eager to create amazing web applications that reach users across the globe But one major challenge youll face is ensuring that your web app works seamlessly on various web browsers This is where crossbrowser compatibility testing comes into playIn this article well dive into the challenges of crossbrowser compatibility and Ill give you some best practices to overcome themWhat is CrossBrowser compatibility testingCrossbrowser compatibility testing is a critical quality assurance process in web development It involves testing and ensuring that a website or web application functions and appears consistently and correctly across different web browsers and their various versions Since web browsers are developed by different companies and have distinct rendering engines they may interpret HTML CSS and JavaScript code differently This can lead to discrepancies in how a website looks and behaves causing issues for users who access the site using different browsersCommon CrossBrowser Compatibility IssuesOne fundamental crossbrowser compatibility concern relates to the rendering of web pages CSS styles add another layer of complexity Inconsistencies in how browsers interpret and apply these styles can lead to visual disparities such as variations in font sizes colors spacing and layout These discrepancies can undermine the websites design integrity and user experiencePlugins like Flash or Java pose compatibility challenges as not all browsers support them and some browsers have disabled them entirely This can result in certain features of a website not working as intended or being inaccessible to users on specific browsersWeb developers often rely on thirdparty libraries and frameworks to streamline development But these dependencies may not be universally compatible with all browsers Compatibility issues with these external tools can lead to malfunctions or performance bottlenecks affecting the websites overall stability and functionalityBrowserspecific bugs related to form submission caching and other critical functions can create headaches for developers These bugs may manifest differently on each browser requiring meticulous testing and workarounds to ensure consistent performance and functionality across the boardDifferences Between CrossBrowser and Compatibility TestingThere are some key differences between crossbrowser testing and compatibility testing Here are the main onesScopeCrossbrowser testing focuses on ensuring that a website or web application functions consistently and correctly across different web browsers It primarily addresses variations in rendering and behavior caused by different browsers rendering engines Compatibility testing is a broader testing approach that encompasses not only different browsers but also various operating systems devices screen sizes and network conditions It assesses how well a website or application functions across a range of diverse environmentsObjectiveThe main objective of crossbrowser testing is to verify that the website or web app looks works and behaves the same or very similarly across various browsers such as Google Chrome Mozilla Firefox Apple Safari Microsoft Edge and others It aims to eliminate visual discrepancies functional issues and inconsistencies in user experience The primary goal of compatibility testing is to ensure that the website or application is compatible with a wide array of user environments such as browsers operating systems Windows macOS Android iOS devices desktops laptops tablets smartphones and network conditions internet speeds and connectivity typesChallengesChallenges in crossbrowser testing arise from variations in how browsers interpret HTML CSS and JavaScript code as well as differences in supported features and standards compliance Challenges in compatibility testing include addressing issues related to devicespecific features operating system dependencies and networkrelated performance problems in addition to crossbrowser challengesIn summary crossbrowser testing is a subset of compatibility testing While crossbrowser testing specifically focuses on ensuring consistent performance across different web browsers and versions compatibility testing encompasses a wider range of factors including browsers operating systems devices and network conditions This helps guarantee a seamless user experience across diverse user environments Both types of testing are crucial for delivering highquality web applications that meet the needs of a broad user baseImportance of CrossBrowser Compatibility TestingNeglecting this crucial aspect of web development can result in missed opportunities and potential damage to your brands reputationUser ExperienceUsers access websites and web applications through a variety of browsers and devices Ensuring compatibility across these platforms guarantees a consistent and seamless experience for all users Frustration resulting from a poorly rendered website on a specific browser can lead to a high bounce rate and loss of potential customers or visitorsMarket ReachDifferent users prefer different web browsers Ignoring compatibility testing means potentially alienating a significant portion of your audience By ensuring your website works well on popular browsers like Chrome Firefox Safari and Edge you maximize your market reach and accessibilityMaintaining Credibility A website that functions well across browsers reflects professionalism and attention to detail On the contrary a website with compatibility issues can harm your brands credibility and reputation Users might perceive your site as unreliable or poorly developedMobile DevicesMobile browsers come with their own set of quirks and challenges Given the rise in mobile internet usage ensuring compatibility with mobile browsers is crucial A website that adapts well to varying screen sizes and touch interfaces is essential for catering to the mobile audienceSEO ImpactSearch engines like Google consider user experience as a ranking factor If your website performs poorly on specific browsers it might affect your search engine rankings A lower search ranking can significantly reduce organic traffic to your siteSupport and MaintenanceA website that works smoothly across different browsers reduces the burden of ongoing support and maintenance Fewer compatibilityrelated issues mean fewer updates and patches needed saving time and resources in the long runAccessibility ComplianceAccessibility is not only a legal requirement in many regions but also a moral imperative Ensuring compatibility with screen readers and other assistive technologies allow people with disabilities to access and use your website Failure to meet accessibility standards can lead to legal consequences and damage to your brands reputationGlobal AudienceThe internet connects people worldwide International users will access your website using various browsers Crossbrowser compatibility ensures that language characters fonts and other regional aspects display correctly enabling you to cater to a global audience effectivelyCompetitive AdvantageWebsites that prioritize crossbrowser compatibility gain a competitive edge They can attract and retain users more effectively than those with compatibility issues A welloptimized site provides a better user experience leading to higher user engagement and potentially higher conversion ratesTypes of CrossBrowser Compatibility TestingHere are some of the main types of crossbrowser and compatibility testingFunctional TestingThis type of testing checks if all the interactive features and functionalities of a website work as expected across different browsers Examples are ensuring that forms can be submitted buttons are clickable navigation menus function correctly and scripting interactions behave consistentlyVisual TestingThis type of testing focuses on the visual appearance of a website or application across different browsers and devices Examples are verifying that fonts colors layouts and images are displayed consistently and that there are no visual glitches or misalignmentsPerformance TestingThis type of testing assesses how a website performs in terms of loading speed and responsiveness across various browsers and devices Examples are measuring page load times checking the sites responsiveness on different screen sizes and ensuring that resourceintensive features videos or animations do not cause performance issuesCrossDevice TestingThis type of testing ensures that a website functions properly on a range of devices including desktops laptops tablets and mobile phones Examples are testing touch interactions on mobile devices verifying responsiveness on different screen resolutions and confirming compatibility with various device orientations landscape and portraitCrossPlatform TestingThis type of testing involves checking compatibility across different operating systems and browsers Example is to verify that the website functions consistently on both Windows and macOS computers as well as Android and iOS devicesBrowser Version TestingThis type of testing involves testing a website on different versions of a particular browser to ensure compatibility across various iterations An example is to test on older versions of popular browsers like Internet Explorer 11 or older versions of Firefox or Chrome to support users who have not updated their browsersAccessibility TestingThis type of testing helps ensure that a website is usable by people with disabilities and complies with accessibility standards such as WCAG Web Content Accessibility Guidelines Examples are testing keyboard navigation screen reader compatibility and the use of ARIA Accessible Rich Internet Applications attributes to make the site more accessible to users with disabilitiesSecurity TestingSecurity testing verifies that a websites security features and protocols work consistently across different browsers and platforms Examples are to ensure that SSL Secure Sockets Layer certificates are correctly implemented that login forms are secure and that security headers like Content Security Policy CSP are effectiveThis comprehensive testing approach helps ensure a seamless and consistent user experience across diverse user environmentsRoles and Collaboration in CrossBrowser Compatibility TestingCrossbrowser compatibility testing involves web developers designers and quality testers working together Developers write clean code designers ensure visual consistency and testers find and document issuesCollaboration is key Developers and designers create flexible designs and testers rely on their expertise Communication is vital for resolving issues promptly and meeting compatibility standardsExternal collaboration with users and clients is also crucial User feedback helps identify realworld issues and managing client expectations aligns with browser capabilities Successful testing relies on technical knowhow and a collaborative culture within the team and with external stakeholdersBest Practices for CrossBrowser Compatibility TestingBy adhering to these best practices web developers and testers can effectively tackle crossbrowser compatibility challenges and deliver web experiences that are reliable and userfriendly across a wide range of browsers and devicesIdentify Target Browsers Determine which browsers are most commonly used by your target audience Focus your testing efforts on these browsers to ensure the best user experience for the majority of your visitorsPrioritize Popular Browsers Give higher priority to testing on the most popular web browsers such as Google Chrome Mozilla Firefox Apple Safari and Microsoft Edge These browsers have larger user bases and are more likely to be used by your visitorsTest on Mobile Devices Dont forget to test on mobile browsers including iOS Safari and Android Chrome as mobile users make up a significant portion of internet traffic Ensure that your website is responsive and mobilefriendlyUse Browser Developer Tools Familiarize yourself with the developer tools available in modern browsers These tools allow you to inspect elementsdebug JavaScript and simulate different browser environments making it easier to identify and fix issuesLeverage CrossBrowser Testing Tools Consider using crossbrowser testing tools and services like BrowserStack CrossBrowserTesting or Sauce LabsThese platforms provide access to a wide range of browser and OS combinations allowing you to test efficiently without setting up multiple physical environmentsRegularly Update Your Browser List Keep your list of target browsers up to date Browsers release new versions regularly and older versions may become less relevant Test on the latest browser versions to address potential issues before they become widespreadValidate HTML and CSS Use validation tools such as the W3C Markup Validation Service and CSS Validator to check your code for compliance with web standards Valid code is more likely to render consistently across browsersImplement Graceful Degradation and Progressive Enhancement Design your website with a baseline experience that works on all browsers and devices Then enhance the experience for modern browsers with additional featuresThis approach ensures that all users have a functional experiencePerform Automated Testing Consider setting up automated testing using tools like Selenium Puppeteer or TestCafe These tools allow you to create and run test scripts across various browsers automatically saving time and ensuring consistencyRegularly Review and Update Stay informed about the latest developments in web standards browser updates and best practices Periodically review and update your testing procedures to remain effective in ensuring crossbrowser compatibilityTest Accessibility Ensure that your website complies with web accessibility standards such as WCAG Test with screen readers and other assistive technologies to make your site accessible to users with disabilitiesDocument and Track Issues Maintain a detailed log of crossbrowser compatibility issues and their resolutions This documentation will help your team address similar issues in the future and maintain a high level of consistencyTools for CrossBrowser TestingYou have access to various tools that can help you test your web projects efficiently Lets look at a few popular ones nowBrowserStackThis is a popular cloudbased crossbrowser testing platform that allows you to test your website or web app on a wide range of browsers and operating systems It provides access to real browser instances for manual testing and supports automated testing with Selenium and AppiumCrossBrowserTestingThis is a cloudbased testing platform that offers a vast array of browsers and devices for crossbrowser testing It provides live interactive testing as well as automated testing capabilities and integrates with various testing frameworksSauce LabsThis is another cloudbased testing platform that offers a comprehensive range of browser and device combinations for testing web and mobile applications It supports both manual and automated testing and integrates with popular testing frameworks like Selenium and AppiumLambdaTestThis is a cloudbased crossbrowser testing platform that provides access to a large selection of browsers and operating systems It offers live interactive testing and supports automated testing with popular testing frameworksBrowserlingThis is a webbased tool that allows you to quickly test your website on a variety of browsers without the need for downloads or installations It offers realtime browser access and is suitable for quick checks and debuggingBrowsershotsThis is an opensource tool that provides screenshots of your website or web app as it appears in different browsers and versions While it doesnt offer live testing or interaction its useful for visual comparisonsBliskThis is a browser specifically designed for web development and testing It provides a sidebyside view of your website in multiple devices and browsers making it easier to spot compatibility issues during developmentGhostlabThis is a paid tool for synchronized testing and debugging across multiple devices and browsers It helps you inspect and debug issues in real time while maintaining synchronization between devicesBrowser DevToolsMost modern browsers including Chrome Firefox Safari and Edge come with builtin developer tools These tools are essential for inspecting debugging and testing websites directly in the browser environment They offer features for emulating different browsers devices and network conditionsThese tools vary in terms of features pricing and ease of use so its essential to choose the one that best fits your specific crossbrowser testing needs and budgetConclusionCrossbrowser compatibility testing is an essential aspect of web development By following these best practices you can ensure that your web applications provide a consistent and delightful user experience across different browsersA combination of cloudbased testing platforms and browser developer tools can provide comprehensive coverage for testing your web projects on different browsers and ensuring a consistent user experienceRemember that the web development field is constantly changing so continuous learning and adaptation are key to your successIf you found this guide helpful and enjoyable please give it a like For more insightful tutorials follow me on X for updates Happy coding and may your web apps thrive in every corner of the internetKudos to ValueCoders for the cover image image ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT Casmir Onyekani Frontend Developer and Technical Writer If you read this far thank the author to show them you care Say Thanks Learn to code for free freeCodeCamps open source curriculum has helped more than 40000 people get jobs as developers Get started ADVERTISEMENT ,https://www.freecodecamp.org/news/cross-browser-compatibility-testing-best-practices-for-web-developers/,Front-End Development,885,2563
UI/UX Design Principles, Gone are the days of Geocities sites with their hardcoded neverchanging HTML Sites and apps today are dynamic and interactive Our job as designers is to make it so that the interface through which they interact with our web UI design is as close to ideal as possible Luckily there are some nearly universal rules of that can help We have put together what we think are the best design principles so that you can enhance all your future web design projects Table Of Contents 1 10 Rules of Good UI Design to Follow On Every Web Design Project 11 1 Make Everything the User Needs Readily Accessible 12 2 Be Consistent 13 3 Be Clear 14 4 Give Feedback 15 5 Use Recognition Not Recall 16 6 Choose How People Will Interact First 17 7 Follow Design Standards 2 8 Elemental Hierarchy Matters 21 9 Keep Things Simple 22 10 Keep Your Users Free  In Control 3 Are UI Ready 10 Rules of Good UI Design to Follow On Every Web Design Project Subscribe To Our Youtube Channel 1 Make Everything the User Needs Readily Accessible Whether its a series of design tools for web design apps the inventory for a character in a video game a spreadsheet or anything else if the user cant find what they want they bounce off your software Tabs make things accessible Shortcuts and hover tooltips too We chose to use tabs to organize Divi for instance All the tools you need are right there in the builder separated by category Toolbars are similarly accessible If you use WordPress the admin toolbar gives you the ability to quickly get to the post editor the theme customizer plugin settings and so on The options are clearly labeled and you dont have to search them out Another example is the HelpSupportContact options When designing a UI whether its for a mobile app web apps WordPress websites or anything else your users will always need to find the Help button or the Contact Support button They will absolutely need to contact you at some point Thats why you must always be sure to put the help buttons frontandcenter Look at Divi In every module we have the support button ready for you at your fingertips whenever you need it On top of that the help window pops up with a video tutorial on whatever feature youre working with By including this inmodule Divi becomes far more accessible and less frustrating Plus as a part of the UI the location for help is consistent across the entire product Which brings us to the next point 2 Be Consistent Like we said just a moment ago being consistent in feature placement within your UI is important But you should also be concerned that your UI works and looks consistent across the entire product too Dont have the menu on top of one page and at the bottom of another Dont rearrange menu items every time it loads Make sure that your users know where things are on your site If you keep a contact form underneath your blog posts dont decide to leave it off Users will notice and be baffled Consistency also includes your fonts and design should work from page to page to page Dont go swapping headerbody fonts from page to page Theres an interesting idea called the principle of least surprise that says if you make your user surprised at how something worksrework it so its more intuitive Additionally you should make sure that your UI is proper for your platform  iOS apps work differently in some cases than Android Desktop sites have different needs than mobile sites for menus galleries and even product checkout Consistency means that you dont frustrate your users by making them have to figure out what to do on your site 3 Be Clear This may seem like a repeat of above but clarity and consistency are different Clarity means that you want your users to know what to do at all times In some ways this also bleeds into UX design because it reduces frustration on your users and increases retention and reduces bounce rate Clarity is the reason minimalist and to an extent brutalist web design has been so popular People are not confused about the purpose of any site or page because there is no or little clutter You want to provide the opposite experience that Lings Cars does One way to achieve clarity is to move from one step to another on different pages Instead of having a checkout process scroll down the page  or be contained within a single section or box  have your users navigate from a Product Page to a Shopping Cart page to a Checkout Page to a Choose Your Payment page to a Place Order page to a Confirmation page Amazon does this as you can see in the image below They will know exactly where they stand in the process eliminating any ambiguity This is especially important for mobile users as screen real estate is at a premium 4 Give Feedback The last thing that users want is to not understand what is going on If they press a button provide an indication that the button was pressed You can do it in multiple ways You can animate the button making it appear to sink into the page Loading icons like the MacOS Rainbow Wheel provide feedback We are working on your request without having to say it If you allow users to upload files such as with Dropbox or Google Drive give an indication of time remaining Provide a popup or modal that tells them their action was a success reduces frustration and confusion Really whenever the user takes any action within your interface just a small acknowledgment can be the difference in a good experience and a lackluster one 5 Use Recognition Not Recall The opposite of good testtaking skills you want your users to recognize everything about your site when they see it They shouldnt have to think about it and recall the information More than anything you are streamlining your interface so that every part is intuitive and moves from one point to another This can be done by using recognizable icons as we mentioned above People recognize certain icons for certain things It can also be done by using virtual tours to guide a user through a process even when its not their first time They will recognize the process once the first modal appears and they wont have to expend the energy recalling exactly how to perform those actions You may also be able to accomplish this through wellplaced messaging that reminds your users of what on your site does what We accomplish this in Divi with simple hover tooltips  even if someone doesnt recall what the icon does we lead them to its function After that they should recognize the icon Or at least the tooltip if they hover again Or even the process of hovering to get the information 6 Choose How People Will Interact First photo credit John Picklap courtesy of MarieClairecom You know whats the worst Pushing on a pull door Especially when you just pushed on a previous to get to that one That buildings designer made the user interface inconsistent so you had no clue how to do what you needed to do What about pressing something that looks like a button that isnt but waiting for a response anyway Well thats because those designers didnt take into consideration how their users were going to interact with their product So when youre designing your UI pick one movement maybe two and stick with it On mobile devices that tends to be swiping Look at Snapchat Pretty much every single action is performed by swiping including reaching your settings and profile You can swipe down on Snapchat to see yourself swipe left to get to the conversations right to stories and up to get to your memories or whatever theyre being called this week They chose how they wanted their users to interact with their product and designed their UI to accommodate that Not the other way around When youre designing your UI choose if youre going to use menus and taps iconography swipes and gestures or something else entirely Alexa and Siri use voice input as their primary UI interaction The way they provide information and perform their tasks is designed around that particular input And as a user you know what to do intuitively because that information was set out for you at the beginning The designers told you what to do and you did it Your users will appreciate you doing the same for them 7 Follow Design Standards The old saying if it aint broke dont fix it applies here There really is no need to try to revitalize something if the standard works That goes from icon usage to standard placement of elements You dont want to go against what your users expect things to do People know that question marks  indicate help So dont use an exclamation point  If you want users to find your mobile menu use the hamburger icon the three stacked lines not a grid Think about search bars They tend to be in similar places on most sites the top of the sidebar or the end of the header menu If not there the center of the top section of the page If you decide to include the only search field at the bottom of your sidebar page footers or beneath the text of your blog posts folks wont know where to look Even if you identify it with the standard magnifying glass icon Theres nothing wrong with thinking outside the box and going for a new and innovative design but that shouldnt mean the design is hard to use 8 Elemental Hierarchy Matters No we dont mean that either Earth Wind Water or Fire is the boss of the others We mean that the elements on your page need to have a clear hierarchy for both utility and the way the user sees the page Basically you want to make sure that the most important functions are at the top of their respective pages Additionally this kind of hierarchy can lead the user down the page organically leading the user through your service Large elements that decrease in size as you move through the process are indicative of importance and order So does color and contrast Making use of whitespace is also important as clutter can stall user progress and draw the eye away from the purpose of the page Clean lines lots of space and welldefined elements can visually indicate to your users how to move through your UI without any documentation or annotation A decent rule of thumb is that you want to keep things flowing from left to right top to bottom 9 Keep Things Simple Look at this contact form Now look at this one Both are contact forms to make a request One of these is no problem to fill out while the other is a bit more of a headache Outside of being a government form the design of the bottom form is not made for the user but for the administrator Thats not your job Your job is to make things as frictionless for the user as possible And one of the best ways to do that is to cut out anything thats not absolutely necessary 10 Keep Your Users Free  In Control The very last thing we want to touch on  and the very last thing you want to do with your UI  is taking control from the user Or to make them feel confined or restricted by your design You want to empower them and your UI should allow them to perform the actions they want There are two parts to this rule context and permission First whatever action the user needs to take should be located near what they want to act on If they need to edit a post the edit button should be near the save publishsubmit preview buttons In fact the better option is for contextual menus for all of the actions the user can take on any particular item or page If youre consistent in your UI as we talked about above your users will understand that these context menus or toolbars will always have the entire list of actions for any given element Additionally your UI should always make the user feel as though they can get out of or revert any action they take While you design the UI they are going to be using it So they need permission or maybe even freedom to do what they need to get the job done Doing this can be as simple as adding a cancel button to every page of your ecommerce checkout because pressing the browsers back button may cause things to go haywire Maybe its an undo feature so they feel that experimentation is okay Or a revision history for largescale projects such as in Google Drive or WordPress or Git When your users feel free and unconstrained youve obviously followed some good UI design principles Are UI Ready Bad pun I know sorry But with these UI rules you are absolutely going to be ready to knock your next web design project out of the park While some of these may apply more to some projects than others good UI is good UI and good UI leads to good UX But thats a topic for a whole different post Do you have any rules for good UI design that you always follow Article featured image by emojoez  shutterstockcom ,https://www.elegantthemes.com/blog/resources/10-rules-of-good-ui-design-to-follow-on-every-web-design-project?utm_source=Blog&utm_medium=Manual%20Divi%20Targets&utm_campaign=Google%20Search&retargeting=off&gad_source=1&gclid=Cj0KCQiAkKqsBhC3ARIsAEEjuJhwozI4JAzwxhdnCw_BdcKdiQj3YlgBHbChPpUW5PFH5MZCtnvjKmEaAmfeEALw_wcB,UI/UX Design,787,2299
Graphic Design for Web, 14 Essential Graphic Design Tips For Every Website by Henna Ray Tweet  February 5 2020 in Graphic Design Copy httpswwwdesignhillcomdesignblogessentialgraphicdesigntipsforeverywebsite Copied Facebook Twitter LinkedIn WhatsAppLast updated on January 31st 2023As humans we get easily attracted to appealing visual content Whether youre passing a mall full of billboards surfing the web or flipping through a magazine you get attracted to graphics everywhere Graphics play a vital role even in the online industry If youre having a website you need a power of graphic design to attract visitors and take your brand to the next level In this article we have shared what is a graphic design why is it important for websites and what are the essential design tips one should follow while creating a websiteA great website strikes the right balance between being visually appealing and successfully converting visitors to take the desired action Ex subscribe to an email list fill out a form buy something etc The graphic design elements utilized throughout the page can have a big influence Before sharing tips let us discuss what is a graphic design and why is it important for every websiteWhat Is A Graphic DesignGraphic design is a technique of creating visual content to communicate the message among the audience Interactive designs such as magazines brochures logos advertisements web banners etc are created by using various fonts typography and images to optimize the user experience By using various software graphic designers create visual concepts to communicate ideas that inform inspire and captivate people to make an effective decisionWhy Is Graphic Design Important For WebsitesVisual appeal is important for websites success An appealing graphic design promotes the communication of ideas to your audience It gives a huge boost to any website by increasing its appeal brand value usability and professionalismVisuals help to stimulate the aesthetic senses in human which helps to increase a feeling of connection with the brand website Therefore its necessary to have a great graphic design for your websiteNow the questions arise  What should you keep in mind while creating appealing graphic designed website What are the tips one should remember while creating website designsIn this post we have shared 14 design tips to help you create a stunning and effective websiteHere Are The 14 Essential Graphic Design Tips For Every Website 01 Choose Contrasting ColorsColors inherently communicate emotion Think  bright reds for urgency blues for calmness or tranquility and purple for royalty These colors can have a strong influence on a visitors reaction to your design  when they can see themOne of the largest web design faux pas is choosing colors with no contrast such as white and light gray or peach and light pink Not only will these color combinations fail to pop on screen but they will also likely be washed out and illegible Instead consider choosing highcontrast color palettes or colors that are located directly across from each other on the color wheel like orange and blue 02 Create A Cohesive Look And FeelWhile highcontrasting color palettes can create graphics and text boxes that jump off the screen that doesnt mean every color within your palette should be battling for the spotlightCreate a color palette with 1 to 3 primary colors and 1 to 3 secondary colors Your primary colors will fill most of the design while your secondary colors serve as a contrast to complement the paletteConsider using different tones of the same color for cohesiveness in your primary palette adjusting the brightness to create your ideal shades Next choose one highcontrast secondary color and play with its brightness to create accompanying secondary shades or choose colors of similar brightness and color family 03 Choose Simple EasyToRead FontsWhen it comes to web design readability is paramount While fancy script fonts and youthful bubble letters both can have their moments to shine that moment is not on your landing page Overly stylized or condensed fonts will leave readers struggling to grasp the overall meaning of your message and more than likely will run them off the pageInstead choose a simpler typeface that allows your content to shine Fonts do reflect tone and personality so aim for a typeface that represents the theme of your site Opt for serifs for an elegant look sans for a modern nofuss look and more roundededge sans for a friendly feel 04 Keep Multiple Fonts To A MinimumOne of the dos of good design is incorporating at least two different fonts to indicate headings within page structure and make certain elements pop However one of the donts of good design is incorporating numerous typefaces and font styles on one page Once you begin utilizing upwards of five fonts on one page it becomes difficult for the eye to scan and absorb informationYou can create a difference in fontweight and style by applying one font family or typeface to text and manipulating its variants such as bold condensed or italics This creates visual uniformity by having all text elements share an overarching look but allows you to indicate structure and importance by adjusting the variantsLooking For a Graphic DesignWe have helped thousands of business owners from all around the world with their graphic design needs such as logo design website design social media posts banner design and much more Get Your Graphic Design Get a Free Quote 05 Embrace White SpaceIts a common misconception dating back to the early days of the Internet that to create a stunning design all areas of the page must be populated with text imagery or filler In reality web visitors much prefer simplicity as opposed to a Geocitiestype website This is where white space or negative space left unmarked becomes so valuableIn a 2012 study completed by Google researchers learned that more complex designs are less likely to be perceived as beautiful Low visual complexity or sites blanketed in white or negative space are perceived as highly appealingUtilize white space in your design by focusing on a single element such as a text box or video and placing nothing around it to distract from it This is more likely to grab attention and be viewed as attractive than a highlycluttered graphic designPro Tip If youre unsure how to begin adding white space or how to create balance among your elements lines are a fantastic place to start For example when aligning a heading text box and graphic element consider inserting a vertical line to the left or right This anchors the text and acts as a mockmargin line to create a vertical structureLikewise combine multiple lines to create squares rectangles or triangles that border your text A strong border creates a visual contrast between text and the background that acts as a minimalist touch to create order within the design 06 Be Aware Of Alignment And StructureKeeping elements aligned will create structure across the page that will naturally lead a readers eyes to where youd like them to go Items that are designed without alignment can create a haphazard feel across the page that can confuse readers and ultimately cause them to exit the pageHeadings bodies of text and images should all be alignedi HeadingManipulate letter space or kerning to fill dead space condense headings that take up too much and overall align text Be sure not to reduce letter spacing to the point that individuals letters cannot be read or increase it such that letters become detachedii Body Of TextEdit each line to consist of 3040 characters each including spaces This makes content easytoread and will keep all paragraphs inline with one anotheriii ImageAlign images with a frame or utilize a grid to make images flush with bodies of text or headings 07 Use Color And Scale To Signal ImportanceEvery good graphic design leverages visual hierarchy or the arrangement contrast color and scale of elements to imply importance Web designers harness hierarchy to draw attention to the most visually dominant element in a design which is usually the most important aspect of the message This element is typically noted by its position such as being highest on the page or in a larger or darker fontFrom the most visually dominant element comes a series of subsequent elements that are manipulated in size weight or color These elements of visual hierarchy encourage a reader to follow a specific path down the page towards what is ultimately a call to action or form Try a free Form Builder like JotForm to create custom online forms for your websiteConsider applying contrasting colors or multiple font variants to create a visual hierarchy within your elements Adjust various settings until you feel each element plays its role in guiding a reader to either the end of the page or to a call to action 08 Emphasize Your CallToAction CTAOn the coattails of visual hierarchy comes the importance of emphasizing a call to action A call to action CTA is designed to prompt an immediate response or encourage a conversion Common calls to action include completing contact forms signing up for an email list or completing a purchaseEssentially your call to action should reflect why youve published the page in the first placeWhen designing your CTA button aim for contrasting colors between the button color and the button text Similarly you can choose to contrast the button color with the color of the background or leave plenty of white space around itLikewise consider the above graphic design tips about forming a cohesive color palette When designing your CTA button or other action items choose a secondary color that contrasts with your other brand colors Its optional to have a secondary color used solely for action items like links and buttons that can be used throughout the design 09 Respect The FoldFrom smartphone models to tablets laptops and desktops many believe the variety in how we view websites has eliminated the fold If youre not familiar with the fold its a graphic design term involving the top part of a page visible when a screen loads At the bottom of the screen is the fold and anything beneath this line must be scrolled to in order to be seenAs the viewable area per screen does vary it goes without saying that the fold is nowhere near as consistent as it was in the early 2000s However this doesnt mean the fold simply doesnt existFor each viewer that loads a webpage there will only be a certain segment of the screen that they will be able to see without scrolling Tools like Hotjar can even calculate the average fold line for your websiteTherefore respect the fold in your design According to the Nielsen Norman Group visitors spend 80 of their time above the fold Ensure that you fit your key messaging and a CTA above the fold so that its easily accessible 10 Use Images Of Real People in Your Graphic DesignAs chic as a minimalistic website can be one devoid of human touch can come across cold and impersonal People dont want to be sold to by robots they crave human interaction This is why incorporating imagery of real people can be so useful in web design This is one of the web design trends followed by major brands in their graphic design strategyConsider the case study by Basecamp who experienced a massive lift in results when a cluttered design devoid of humans was replaced by faces and testimonials on a sales pageWhen the sales page featured an image of a real person in the background conversions skyrocketed by 1025 Faces help build trust and drive conversions  when you avoid stock photos that isMost stock photos are staged and feature models with stiff overexasperated expressions This can have the opposite effect that you are going for Instead opt for more relaxed photos of real people preferably real employees or customers that understand your audiences needs 11 Stay ConsistentDeveloping a consistent style all depends on your choices of font colors quality lighting and proportion For example a headline of 120 px should not be paired with a subhead of 40 px From the scale of your elements to how custom or stylized they are create a cohesive feel by remaining consistentSimilarly this graphic design tip also refers to the images used across the page While all images should be highquality and welllit if youre using more cooltoned imagery all images should be cooltonedIf you choose a variety of portraits taken from the shoulders up retake or recrop the photo of an employee who was posed from the waist up These tiny details all create an overall consistent look to your designPro Tip Creating a brand book or style guidelines can go a long way to creating a cohesive design on your website 12 Add Icons To Add Layers Of InterestSometimes we want to embellish on an area of text or call to action but a fullsize image would be much too distracting This is where icons can come into play From arrows and lightning bolts to social media icons they can be placed to accent a section to direct trafficFor instance say you want to highlight the benefits of your service or product Youve created three separate text boxes to detail each benefit The easiest and leastoverwhelming way to add interest to these sections would be to place an icon above the top of eachJust like photos icons can be stylized to fit your unique tone they can be made heavier or thinner and their coloring can be manipulated Likewise icons like arrows can be used as a directional cue to guide visitors towards CTAs 13 Keep It SimpleIn the previously mentioned Google study it was found that visitors viewed less complex graphic designs as more beautiful That same study also discovered that high prototypicality also correlates with perceived beauty meaning that a website that follows a standard template has a higher likelihood of being found appealingIn other words your audience likely prefers simple and easy to navigate websites This doesnt mean boring  feel free to utilize vibrant colors various fonts and highquality imagery to create a highimpact website However do consider using ample white space clean lines and aligned elements to create a clean simple structure 14 Make Every Graphic Design Element PurposefulA large part of embracing simplicity is removing extraneous design elements that serve no purpose For instance consider you added a thick vertical line to act as a margin for your heading and text box and stylized the section by adding various other linesWhile the original line serves a purpose the elements added to stylize the section have actually made the text harder to read and less impactful By removing the extraneous elements and simplifying the original margin line the design looks cleaner and is easier to followBefore finalizing your graphic design take a step to admire the page as a whole Elements that dont highlight or add structure to a section can likely be removed If youre on the fence simply delete the item review and undo the deletion if you dislike it The beauty of most design programs is the ease with which you can add and delete elements until youve struck a balance of beauty and purposeAre You Looking for a New Graphic DesignerIf Yes Call Us on 18556992851 times for calling 9 am to 6 pm EST US or Register for a Free Design ConsultationEnd NoteWhether in the form of a new conversion or an increase in the average time spent on a page good design has the power to improve your business ultimately When you utilize these 14 tips you can be confident youre optimizing your site for success Get Your Graphic Design Henna Ray aka hennaray Hi I am professional Logo designer and an aspiring blogger An expert on various tools Like Adobe Photoshop Illustrator and Coral Draw I have successfully designed several application interfaces android apps logo designs business card designs letterhead designs envelop designs flyer designs brochure designs and web banners TwitterContact Posts 235 More in Graphic Design More by Henna Ray Designhill Review Choosing The Right Design Platform I  1 month ago Designhill vs Canva Which One to Choose 2 months ago 2024 NFT Marketplace AI And The Metaverse Redefining  2 months ago 20 Fonts to Bring the Nostalgia of the 90s 6 months ago 10 Best AI Art Generators All Designers Can Use 6 months ago How To Gather Graphic Design Requests Online 7 months ago How To Use AI Images to Ignite Creative Sparks 7 months ago How To Find The Perfect Creative Agency 7 months ago From Sketch to Screen 21 MustWatch Documentaries For  8 months ago How ChatGPT Can Help Graphic Designers Supercharge Thei  8 months ago The 30 Best Marketplaces To Sell Art Online A Guide Fo  9 months ago The 10 Best YouTube Fonts In 2024 10 months ago What is Emotional Design Discover How It Helps Engage  10 months ago Unleashing The Potential Of OpenAIs ChatGPT For Produc  10 months ago 10 Best Graphic Design Tools You Must Know As A Beginne  11 months ago See all Graphic Design 20 Customizable Christmas Products from PrintShop by De  3 weeks ago 51 Iconic Logos  Their Secret Significance 8 months ago Design Unique Preakness Outfits Bespoke Tips For Perso  8 months ago Top 21 Amazing Telecom Logos Of Famous Companies 9 months ago 21 Community  NonProfit Logos You Can Draw Inspiratio  10 months ago Branding Color Guide How To Choose Brand Colors 11 months ago The Repetition Principle Of Graphic Design  A Brief Gu  11 months ago Top 15 Valentines Day Gift Ideas For Him  Her 11 months ago 15 Incredible Valentines Day Gift Ideas You Should Exp  1 year ago Top 5 Wedding Card Makers In 2023 1 year ago Top 15 Freelance Flyer Designers For Hire In 2024 1 year ago 5 Best Free Form Builder Tools For 2023 1 year ago Top 15 Inspiring Instagram Accounts Every Entrepreneur  1 year ago 5 Best Free Twitter Header Maker Tools In 2024 1 year ago 10 Best Freelance Business Card Designers For Hire In 2  1 year ago See all stories by Henna Ray,https://www.designhill.com/design-blog/essential-graphic-design-tips-for-every-website/,UI/UX Design,1145,3019
"CSS Preprocessors (e.g., SASS, LESS)", Popular CSS preprocessors with examples Sass Less Stylus and more By Anna Monus  Posted Jun 8 2023  22 min 4635 words As a stylesheet language CSS has limited capabilities when it comes to writing logic organizing code and performing other computational tasks CSS preprocessors provide a solution to this problem While CSS has improved a lot in recent years with the introduction of custom and logical properties math and color functions new pseudoclasses and other enhancements there are still many good reasons to use CSS preprocessors They can help with speeding up your workflow optimizing your code base improving performance preparing for scaling and more In this article well look into the state of CSS preprocessors in 2023 and review the seven best options in the market including Sass LESS Stylus and more Quicklinks What is a CSS preprocessor CSS preprocessors vs PostCSS Sass Syntactically Awesome Style Sheets LESS Leaner Style Sheets Stylus Expressive dynamic and robust CSS Stylable For componentbased JavaScript applications Stylis Lightweight with basic functionality Clay Functional CSS implemented in Haskell CSS Crush CSS implemented in PHP Which is the best CSS preprocessor for you What is a CSS preprocessor CSS preprocessors are scripting languages that extend the default capabilities of CSS They enable us to use logic in our CSS code such as variables nesting inheritance mixins functions and mathematical operations CSS preprocessors make it easy to automate repetitive tasks reduce the number of errors and code bloat create reusable code snippets and ensure backward compatibility Each CSS preprocessor has its own syntax that they compile into regular CSS so that browsers can render it on the client side CSS preprocessors do similar things but in more or less different ways and each has its own syntax and ecosystem tools frameworks libraries too CSS preprocessors vs PostCSS CSS preprocessors are sometimes equated with PostCSS but theyre not the same thing PostCSS is a popular JavaScript library that allows us to automate CSSrelated tasks once CSS code is ready to be published Its a CSS postprocessor that we can use for things such as autoprefixing linting support experimental features and many others The confusion comes from the fact that some CSS preprocessors eg Sass LESS and Stylus have dedicated PostCSS plugins However the main functionality of these plugins is to apply PostCSS transformations back to the SassLESSStylusetc source code Instead of being a substitute for CSS preprocessors PostCSS is more of a DevOps tool that helps with ensuring a smooth Software Development Life Cycle SDLC process and a consistent code base On the other hand CSS preprocessors focus on the actual development phase of the SDLC As they serve different purposes you can use SassLESSStylusetc and PostCSS together or just a preprocessor with no PostCSS or just PostCSS with no preprocessor  these are all valid options and the best choice between them will depend on your workflow code structure and goals While a preprocessor can help prevent errors and enhance frontend performance its no replacement for proper monitoring To get full visibility over errors and performance issues and know exactly how your CSS code performs in production check out Rayguns realuser monitoring and crash reporting platform to get detailed insight into the frontend performance of your application with advanced features like filtering full waterfall breakdown issue prioritization performance trend tracking and alerting and loads more Grab your 14day nocreditcard free trial today The 7 best CSS preprocessors in 2023 Currently the three most popular CSS preprocessors are Sass LESS and Stylus  theyre also stable tools that have been in active development for more than a decade In the early to mid2010s many smaller CSS preprocessors appeared on the market but many of these are not in active development anymore some examples of outdated CSS preprocessors include Myth DtCSS Rework and Switch To give you a more comprehensive overview of CSS preprocessors in addition to the market leader SassLESSStylus trio well also look into four lesserknown CSS preprocessors that are still in active development and have their own niches and particular advantages 1 Sass Syntactically Awesome Style Sheets Sass is the most popular and oldest CSS preprocessor initially released in 2006 Its creators Natalie Weizenbaum and Hampton Catlin were inspired by the Haml templating language which adds dynamic features to HTML Their goal was to implement similar dynamic functionality in CSS as well So they came up with a CSS preprocessor and named it Syntactically Awesome Style Sheets The Sass preprocessor allows us to use variables ifelse statements forwhileeach loops inheritance operators interpolation mixins and other dynamic features then compile the code to plain CSS that web browsers can interpret Sass was originally written in the Ruby programming language but the Sass team decided to deprecate the Ruby implementation in 2019 as it made the workflow overly complicated compared to newer CSS preprocessors like LESS and Stylus which are JavaScript libraries available as npm packages In 2023 the Dart Sass library is the primary implementation of the Sass preprocessor Dart is a programming language that has been specifically created for developing user interfaces its most wellknown use case is the Flutter mobile development framework Sass is also available as an npm package so you can easily add Sass to your frontend build system Plus it has a public JavaScript API built from the main Dart Sass implementation you can use to compile Sass code within JavaScript applications Features Sass variables have scope so you can use them both locally and globally It follows the DRY Dont Repeat Yourself programming principle to avoid duplication It has two main features that help with implementing DRY mixins and the extend rule Mixins make it possible to create a group of related CSS rules and apply them to any property well see an example below The extend rule brings inheritance to the Sass language Its useful when you have different design elements that share some characteristics With the extend rule you can add the properties of any class to another one Sass allows nesting as well which improves code readability and maintainability It can be used when working with CSS selectors that share the same parent Loops and conditionals are probably the most loved part of Sass as they enable us to write CSS rules just like in any scripting language Sass has builtin if and else rules that enable us to test for different conditions and for each and while loops too Sass supports modularity as well via partial Sass files that contain smaller code blocks you can use multiple times for instance a _resetscss stylesheet Partials can be added to any other Sass file with the import rule The Sass preprocessor also has builtin functions for things like converting and mixing colors manipulating strings performing mathematical calculations and applying other dynamic functionalities to your design In addition you can define your own custom Sass functions as well Benefits wellestablished stable CSS preprocessor compilation has become easier with the introduction of Dart Sass has a large ecosystem advanced dynamic functionalities you can choose between two syntaxes Sass and SCSS  see examples below extensive documentation Tools and Usage Sass has an active developer community and its used in many popular tools and libraries The two most widelyused frontend frameworks Bootstrap and Zurb Foundation are both written in Sass which gives extra traction to the language Moreover Sass has powerful mixin libraries and authoring frameworks that further enhance the functionality of the language such as Bourbon and Sassmagic by W3C There are several notable companies that use Sass in their production sites for instance Airbnb Trustpilot Hubspot Asana Skyscanner and many others Examples Sass has two syntaxes The sass file extension uses the older syntax which is indentationbased and omits semicolons and curly brackets from the code The newer and more widely used syntax belongs to the scss file extension It uses a CSSlike syntax with braces and semicolons Below you can see a basic example of the SassSCSS syntax The code declares two variables primarycolor and primarybg and applies them to the body HTML element   SCSS  primarycolor seashell primarybg darkslategrey body  color primarycolor background primarybg   The same code with the Sass syntax   Sass  primarycolor seashell primarybg darkslategrey body color primarycolor background primarybg  Both compiles to the same CSS   Compiled CSS  body  color seashell background darkslategrey   While the older Sass syntax is quicker to write and harder to get wrong the newer SCSS syntax is fully compliant with the regular CSS syntax Heres another example which shows how Sass mixins work The following mixin creates a simple card layout with width height background and border as parameters   SCSS  mixin cardwidth height bg border  width width height height background bg border border   Whenever you want to create a new card you can call the card mixin using the include rule and pass four arguments to it   SCSS  card1  include card300px 200px yellow red 2px solid  card2  include card400px 300px lightblue black 1px dotted   These two calls produce a smaller card with yellow background and red border and a larger one with light blue background and black dotted border   Compiled CSS  card1  width 300px height 200px background yellow border red 2px solid padding 20px  card2  width 400px height 300px background lightblue border black 1px dotted padding 20px   2 LESS Leaner Style Sheets LESS was released three years after Sass in 2009 by Alexis Sellier It was influenced by Sass and so implements many of its features such as mixins variables and nesting Funny enough later on LESS also influenced Sass as the newer SCSS syntax was inspired by the syntax of LESS The LESS CSS preprocessor is a JavaScript library that extends the default functionalities of CSS As its written in JavaScript you can either run it as an npm package or compile LESS right in the browser by adding less files and the LESS converter to the section of your HTML page Features Just like Sass variables LESS variables also have scope which lets you decide where to call them You can use LESS variables in CSS rules selector and property names URLs and import statements LESS mixins work similarly to Sass mixins you can define a set of related style rules and reuse them throughout the code The LESS preprocessor also comes with specific guarded mixins that implement a basic conditional logic in LESS This is an important feature because LESS doesnt have as advanced conditional logic as Sass eg it doesnt have an ifelse statement but you can still achieve a lot with mixin guards Similar to Sass LESS also gives you access to builtin functions with which you can manipulate colors images gradients dimensions units and more The DRY principle and inheritance are integral parts of the LESS syntax as well You can use the extend pseudoclass to extend selectors and the merge feature to aggregate values from multiple properties LESS also supports nesting so that you can achieve a readable and clear code base Benefits it can be added directly to an HTML page flat learning curve as LESS uses the standard CSS syntax see examples below several dynamic features including scoped variables import options mixins nested selectors and others extensible via plugins detailed documentation Tools and Usage Bootstraps decision to move from LESS to Sass was a huge hit to the popularity of LESS There are still some LESS frameworks available such as Metro UI and Semantic UIs LESSonly distribution However be careful with the tools list on the LESS website as it doesnt seem to be regularly updated and includes some outdated tools as well eg LESS Hat CSSowl and others LESS also has some mixin libraries such as LESS Elements and EFE Styling Toolkit by Baidu but not as many as Sass We can also encounter LESS on production sites such as Patreon Deloitte Transferwise Indiegogo and many others Examples Heres the code example we saw in the Sass section above in LESS syntax   LESS  primarycolor seashell primarybg darkslategrey body  color primarycolor background primarybg   It compiles to the same CSS   Compiled CSS  body  color seashell background darkslategrey   Lets see what a mixin guard looks like in LESS too For instance the following code example defines two distinct font colors black and white and applies them based on the lightness of the background the example also makes use of the lightness LESS function   LESS  textcolor bgcolor when lightnessbgcolor  50  color black  textcolor bgcolor when lightnessbgcolor  50  color white  textcolor bgcolor  backgroundcolor bgcolor  card1  textcolor yellow  card2  textcolor darkblue   In the compiled CSS the guarded mixin called textcolor assigns black fonts to the first card with the yellow light background and white fonts to the second card with the dark blue dark background   Compiled CSS  card1  color black backgroundcolor yellow  card2  color white backgroundcolor darkblue   3 Stylus Expressive dynamic and robust CSS The first version of Stylus was launched one year after LESS in 2010 by TJ Holowaychuk a former Nodejs developer Like LESS Stylus is written in JavaScript so that developers can easily integrate it into their Nodejs projects Holowaychuk was influenced by both Sass and LESS so Stylus combines the powerful logical abilities of Sass with the easy and straightforward setup of LESS Developers frequently praise Stylus for its terse and flexible syntax Stylus uses the styl file extension and allows developers to write code in many different ways You can use the standard CSS syntax but you can also omit brackets colons andor semicolons or leave out all punctuation Features Stylus has the same basic features as Sass and LESS Its variables have a very clear syntax you only need to pay attention to the equals sign and you dont even need to prepend them   Stylus  primarycolor  seashell  Stylus mixins work similarly to Sass and LESS mixins you can use them to store and reuse custom style rule sets However transparent mixins are a unique feature in Stylus They allow you to automatically add vendor prefixes to newer CSS properties that still have insufficient browser support Stylus also automatically adds vendor prefixes to keyframes so it can be your ideal CSS preprocessor if you often build keyframes animations Stylus has several builtin functions to manipulate and convert colors and units calculate average minimum and maximum values match patterns and perform other actions Similar to Sass you can create powerful custom functions with Stylus too Stylus also provides powerful conditional logic It has both ifelseelse if and unlesselse conditional statements The unless statement is the logical opposite of if  you can think of it as an if not statement With Stylus you can also make use of postfix conditionals and looping that uses the forinhttpstyluslangcomdocsiterationhtml construct Stylus has many other advanced features that are popular with users like property lookup which makes it possible to reference previous properties without assigning them to variables and partial reference which makes it possible to access only a certain number of levels of nested selectors Benefits flexible easytolearn syntax similar to Python automatic vendor prefixes feature set is on par with Sass advanced support for keyframe animations powerful conditional control flow advanced selectors detailed documentation Tools and Usage Stylus doesnt have any thirdparty mixin libraries that are still actively maintained but it has the official Nib library that includes multiple readymade crossbrowser Stylus mixins  probably everything youll need The most comprehensive Stylusbased CSS framework is Kouto Swiss which includes mixins functions and utilities to help you write Stylus code faster Some notable corporate users of Stylus are Coursera Discord Accenture HackerEarth and a few others Examples Our previous code example looks like this using the different syntaxes of Stylus   Stylus standard CSS syntax  primarycolor  seashell primarybg  darkslategrey body  color primarycolor background primarybg   However we can remove the brackets   Stylus syntax without brackets  primarycolor  seashell primarybg  darkslategrey body color primarycolor background primarybg  Or we can remove the brackets and the semicolons too   Stylus syntax without brackets and semicolons  primarycolor  seashell primarybg  darkslategrey body color primarycolor background primarybg  Or we can remove all punctuation brackets semicolons colons   Stylus syntax without punctuation  primarycolor  seashell primarybg  darkslategrey body color primarycolor background primarybg  The only thing you cant remove is the assignment operator  as it indicates the declaration of a new variable As Stylus is a pythonic indentationbased language you always need to pay attention to proper indentation otherwise the code wont compile 4 Stylable CSS preprocessor for componentbased JavaScript applications Stylable is an opensource CSS preprocessor developed by Wix the creator of the popular website builder tool It has been made with componentbased applications larger teams and scalability in mind Stylable gives CSS a type system  on its landing page its marketed as a tool that does for CSS what TypeScript does for JavaScript Staying true to this statement Stylable is written in the TypeScript language As Stylable uses static typing you can see errors at build time which prevents runtime errors Stylable files use the filestcss notation for the root Stylable stylesheets meaning that these are regular CSS files You can use the stcss files to style individual components in your application Then Stylable compiles them into plain cascading CSS that you can add to your page You can add Stylable to your app by either integrating it manually or using one of the preconfigured Stylable boilerplates available as npm and Yarn packages The boilerplates also include a starter React application with either Webpack or Rollup bundling and builtin optimizations Features Stylable scopes style rules to components so different styles that apply to the same element dont clash It gives you access to dynamic features provided by other popular CSS preprocessors as well including mixins formatters extend and import rules and others Stylable also allows the use of custom pseudoclasses and pseudoelements that enables you to style components externally when needed As Stylable has been created for JavaScript applications each component exposes a Style API as well that makes it possible to reuse components across teams and projects  which can significantly improve productivity in larger organizations Benefits static typing modular scoped styles uses the default CSS syntax results in more performant and cleaner CSS code supports serverside rendering SSR readytouse online Stylable playground Tools Stylable provides a powerful extension for the Visual Studio Code editor called Stylable Intelligence for VS Code which includes syntax highlighting hinting code completion and other developer features It also gives you access to readytouse integrations with NextJS Rollup Storybook TypeScript and Webpack Stylable has a handbook too that includes some code examples and a useful list of best practices that can help with writing performant Stylable code Examples The following example shows a Stylable project file that includes five variables a component variant cancelButton and a shared class emphasisBox   projectstcss  vars  color1 f012be color2 ff4136 fontbig 2rem fontsmall 1rem spacing 6px  stimport Button from buttonbuttonstcss cancelButton  stextends Button  emphasisBox  background pink color white   The emphasisBox shared class can be reused in the individual component stylesheets using the stextends property in the following way   compstcss  stimport emphasisBox from projectstcss root emphasisBox  messageBox  stextends emphasisBox   5 Stylis Lightweight CSS preprocessor with basic functionality Stylis is a lightweight CSS preprocessor created by Sultan Tarimo Its a small JavaScript library that gives you access to basic preprocessing functionality You can add it either locally as a js file load it from CDN or add it as an npm package to your project It uses the default CSSSCSS syntax so if you already know Sass but dont need its more complex features it can be a good idea to give Stylis a try Stylis is also the choice of CSS preprocessor for some popular CSSinJS libraries such as Styled Components and Emotion as it makes it possible to use SCSS syntax right in JavaScript see an example below So if you use one of these libraries you already have access to Stylis functionality Features Stylis is compatible with EcmaScript modules and comes with features such as nesting using Sass ampersand syntax vendorprefixing to support older browsers selector namespacing minification dead code elimination and some other utilities Unlike Sass LESS and Stylus it doesnt have variables and mixins However it supports custom CSS properties aka CSS variables  but note that the readme page warns against the exotic usage of CSS variables Stylis also provides an optional middleware function if you want to implement your own logic Benefits lightweight clean code structure uses the standard SCSS syntax can be directly used in JavaScript applications advanced selector patterns extensible via plugins Tools Emotion created its own version of Stylis that comes with preset defaults so its even more lightweight than the original library As its available as a standalone npm package you can also use it in your JavaScript application without Emotion There are also a handful of thirdparty Stylis plugins you can add to your projects such as the Stylis RTL plugin by Styled Components Examples The following code example is from Styled Components documentation As you can see below you can use the Stylis syntax inside a template literal in JavaScript heres Styled Components brief explanation and the compiled CSS  const Thing  styleddivattrs props    tabIndex 0  color blue hover  color red      background tomato      background lime  something  background orange   somethingelse   border 1px solid    render ReactFragment ThingHello worldThing ThingHow ya doingThing Thing classNamesomethingThe sun is shiningThing divPretty nice day todaydiv ThingDont you thinkThing div classNamesomethingelse ThingSplendidThing div ReactFragment   6 Clay Functional CSS preprocessor implemented in Haskell Clay is a Haskellbased CSS preprocessor created by Sebastiaan Visser It has a different setup than other popular CSS preprocessors as its an embedded domainspecific language ESDL in Haskell Haskell itself is a statically typed functional programming language As opposed to objectoriented languages functional languages dont use objects but pure functions to create maintainable software applications In Clay all CSS selectors and rules are first class Haskell functions which facilitates reusability While Clay is probably not the most obvious choice for most frontend developers the syntax is clean and easy to read uses a CSSlike monadic syntax so it can be a great way to get started with functional programming It can also be a good choice if you want to take leverage of static typing but dont want to use a componentbased architecture provided by Stylable or if you want to use a CSS preprocessor right in a Haskellbased web application Features Clay provides you with a wide array of features that let you manipulate your CSS code including flexible nesting rules modules functions mixins size and color calculations importing automatic vendorprefixing for experimental CSS properties custom selector combinators pseudoclasses and pseudoelements Benefits statically typed logical structure focused on reusability first class selectors and properties neartotal CSS coverage including support for media queries extensible with new features Tools To use Clay you need the Glasgow Haskell Compiler GHC and the Cabal package manager The Clay API is available in the Hackage Haskell Package Repository In addition to giving you programmatic access to the CSS preprocessing functionality it also allows you to define your own Clay properties Examples The following code example shows the monadic syntax used by Clay It defines some basic color rules and also takes leverage of Clays nesting functionality   stylehs import Clay main  putCss  do p  color red li  color yellow article  do strong  background black abbr  fontVariant smallCaps  Heres what the compiled CSS looks like   Compiled CSS  p  color  rgb25500  li  color  rgb2552550  article strong  background  rgb000  article  abbr  fontvariant  smallcaps   7 CSS Crush CSS preprocessor implemented in PHP CSS Crush is a PHPbased CSS preprocessor created by Pete Boere As its implemented in PHP you can use it directly in PHP applications and websites Its available as a standalone PHP library that you can either manually copy into your project or add as a Composer or npm package With CSS Crush you write your root style file as a css file but with the CSS Crush syntax which is inspired by Sass SCSS syntax CSS Crush automatically compiles your root file and uses the crushcss notation for the processed CSS for example if your root file is called stylecss the compiled file will be called stylecrushcss Features CSS Crush gives you access to a wide array of dynamic features such as automaticallygenerated vendor prefixes nesting parent referencing variables interpolation inheritance loops several functions mixins fragments and many others Featurewise CSS Crush is on par with LESS and close to Sass and Stylus so it can be a smart addition to your PHP projects Benefits SCSSlike syntax can be directly used in PHP applications many easytouse custom directives eg set ifset import extend name abstract etc available as both a PHP and npm package extensible via plugins fairly good documentation Tools CSS Crush has a small API that gives you programmatic access to the CSS preprocessing functionality It also has a couple of plugins you can add to your projects for tasks such as adding ARIA syntax enhancing easing transitions embedding SVG and more  but you can create your own plugin too Examples The following code example shows how nesting works in CSS Crush As you can see its similar to the SCSS syntax   stylecss  container  color darkmagenta background white content  p  fontsize 110 textdecoration underline     Heres the compiled CSS code CSS Crush automatically minifies the code   stylecrushcss  containercolordarkmagentabackgroundwhitecontainer content pfontsize110textdecorationunderline  You can find many other easytounderstand code examples in the docs Summary  Which is the best CSS preprocessor for you The CSS landscape has improved considerably in recent years Web browsers have adopted many new features that previously had only been available via CSS preprocessors such as variables mathematical and color functions advanced selectors and others PostCSS has also appeared in the market making it possible to automate many CSSrelated tasks such as vendor prefixing However that doesnt mean we dont need CSS preprocessors anymore They still provide much more dynamic functionalities than CSS and can help with organizing your code improving frontend performance and speeding up your development workflow Some features are available with most preprocessors such as nesting importing vendor prefixing and others However there are also toolspecific features that can help you decide which CSS preprocessor to use The best CSS preprocessor for you will depend on your stack the current skill set of your team the architecture of your project and your needs While a preprocessor can help prevent errors and enhance frontend performance its no replacement for proper monitoring To get full visibility over errors and performance issues and know exactly how your CSS code performs in production check out our realuser monitoring and crash reporting platform that gives you detailed insight into the frontend performance of your application with advanced features like filtering full waterfall breakdown issue prioritization performance trend tracking and alerting and loads more Grab your 14day nocreditcard free trial today ,"https://raygun.com/blog/css-preprocessors-examples/#:~:text=preprocessor%20for%20you%3F-,What%20is%20a%20CSS%20preprocessor%3F,%2C%20functions%2C%20and%20mathematical%20operations.",Front-End Development,1171,4454
"JavaScript Libraries (e.g., jQuery)"," 4246 readsCool JavaScript Libraries To Consider Using in 2023April 6th 20235m by catherine 4246 readsToo Long Didnt ReadJavaScript libraries are incredibly useful tools for any web app developer Theyre designed for boosting the development process and adding extra functionality to your projects with just a few lines of code Theres almost a neverending collection of JS libraries and frameworks to try so we picked 20 cool toolsprogramming javascript webdevelopment css jscatherineCatherine SkorobogatayaReceive Stories from catherineSUBSCRIBE SUBSCRIBE TO RECEIVE THIS WRITERS CONTENT STRAIGHT TO YOUR INBOXby Catherine Skorobogataya catherine2021  HackerNoon Contributor of the Year  PROJECTMANAGEMENT RELATED STORIES5 JavaScript Project Management Libraries to Boost Web DevelopmentPublished at Mar 23 2021 by catherine javascript Coding Interview Prep Lets Test Your CSSPublished at Dec 26 2023 by melnik909 css Resolving the 10 Common Javascript ErrorsPublished at Dec 25 2023 by freefullstack webdevelopment Redesigning Apps Using Ruby On Rails The Risks and The RiskFree ApproachesPublished at Dec 22 2023 by ka8725 rubyonrails The Most Popular Cypress Packages of 2023Published at Dec 22 2023 by elaichenkov cypress Building a Point Map in JavaScriptPublished at Dec 20 2023 by awanshrestha datascience L O A D I N G   comments  more,  4246 readsCool JavaScript Libraries To Consider Using in 2023April 6th 20235m by catherine 4246 readsToo Long Didnt ReadJavaScript libraries are incredibly useful tools for any web app developer Theyre designed for boosting the development process and adding extra functionality to your projects with just a few lines of code Theres almost a neverending collection of JS libraries and frameworks to try so we picked 20 cool toolsprogramming javascript webdevelopment css jscatherineCatherine SkorobogatayaReceive Stories from catherineSUBSCRIBE SUBSCRIBE TO RECEIVE THIS WRITERS CONTENT STRAIGHT TO YOUR INBOXby Catherine Skorobogataya catherine2021  HackerNoon Contributor of the Year  PROJECTMANAGEMENT RELATED STORIES5 JavaScript Project Management Libraries to Boost Web DevelopmentPublished at Mar 23 2021 by catherine javascript Coding Interview Prep Lets Test Your CSSPublished at Dec 26 2023 by melnik909 css Resolving the 10 Common Javascript ErrorsPublished at Dec 25 2023 by freefullstack webdevelopment Redesigning Apps Using Ruby On Rails The Risks and The RiskFree ApproachesPublished at Dec 22 2023 by ka8725 rubyonrails The Most Popular Cypress Packages of 2023Published at Dec 22 2023 by elaichenkov cypress Building a Point Map in JavaScriptPublished at Dec 20 2023 by awanshrestha datascience L O A D I N G   comments  more io HACKERNoOon ,  Home Resource Center Blog JavaScript Frameworks The 40 Best JavaScript Libraries and Frameworks The 40 Best JavaScript Libraries and Frameworks Durga Prasad Acharya October 20 2023 JavaScript libraries and frameworks make website and application development easier with wideranging features and functionalities  all thanks to JavaScripts dynamic flexible and engaging features According to a StackOverflow survey JavaScript continues to be the most commonly used programming language for the 8th year with 677 of the respondents using it Its versatility favors both backend and frontend development in addition to testing them As a result you can find many JavaScript libraries and frameworks that serve various purposes Hence it can be confusing to developers when choosing the right fit for their project But dont you worry Weve compiled a total of 40 JavaScript libraries and frameworks in this article along with their features benefits and use cases Stay tuned to find out about them and decide which one is suitable for your project What Are JavaScript Libraries JavaScript libraries contain various functions methods or objects to perform practical tasks on a webpage or JSbased application You can even build a WordPress site with them Think of them as a book library where you revisit to read your favorite books You may be an author and enjoy other authors books get a new perspective or idea and utilize the same in your life Similarly a JavaScript library has codes or functions that developers can reuse and repurpose A developer writes these codes and other developers reuse the same code to perform a certain task like preparing a slideshow instead of writing it from scratch It saves them significant time and effort They are precisely the motive behind creating JavaScript libraries which is why you can find dozens of them for multiple use cases They not only save you time but also bring simplicity to the entire development process How to Use JavaScript Libraries To use a JavaScript library in your app add script to the head element using the src attribute that references the library source path or the URL Read the JavaScript librarys documentation you intend to use for more information and follow the steps provided there What Are JavaScript Libraries Used For As weve said JavaScript libraries are used to perform specific functions There are around 83 of them each created to serve some purpose and we are going to cover some of their usability in this section You can use JavaScript libraries for Data Visualization in Maps and Charts Data visualization in applications is crucial for users to view the statistics clearly in the admin panel dashboards performance metrics and more Presenting these data in charts and maps helps you analyze that data easily and make informed business decisions Examples Chartjs Apexcharts Algolia Places DOM Manipulation Document Object Model DOM represents a web page a document as objects and nodes that you can modify using JavaScript You can change its content style and structure Examples jQuery Umbrella JS Data Handling With the enormous amounts of data that businesses now deal with daily handling and managing them properly is essential Using a JavaScript library makes it easier to handle a document following its content while adding more interactivity Examples D3js Database Effective database management is necessary to read create delete edit and sort data You can also use sophisticated queries autocreate tables synchronize and validate data and much more Examples TaffyDB ActiveRecordjs Forms Use JS libraries to simplify form functions including form validation synchronization handling conditional capabilities field controls transforming layouts and more Examples wForms LiveValidation Validanguage qForms Animations People love animations and you can leverage them to make your web page interactive and more engaging Adding microinteractions and animations is easy by using JavaScript libraries Examples Animejs JSTweener Image Effects Users can add effects to images and make them stand out using JS libraries Effects include blurring lightening embossing sharpening grayscale saturation hue adjusting contrast flipping inverting reflection and so on Examples ImageFX Reflectionjs Fonts Users can incorporate any font they wish to make their web page more compelling based on the content type Examples typefacejs Math and String Functions Adding mathematical expressions date time and strings can be tricky For example a date consists of many formats slashes and dots to make things complex for you The same holds when it comes to matrices and vectors Use JavaScript libraries to simplify these complexities in addition to manipulating and handling URLs effortlessly Examples Datejs Sylvester JavaScript URL Library User Interface and Its Components You can provide a better user experience via web pages by making them more responsive and dynamic decreasing the number of DOM operations boosting page speed and so forth Examples ReactJS Glimmerjs And those are just the most common use cases Other uses of JavaScript libraries include Creating a custom dialog box Creating keyboard shortcuts Switching platforms Creating rounded corners Affecting data retrievalAJAX Aligning page layouts Creating navigation and routing Logging and debugging And many more The Most Popular JavaScript Libraries Below weve rounded up the most popular JavaScript libraries available today jQuery jQuery is a classic JavaScript library thats fast lightweight and featurerich It was built in 2006 by John Resig at BarCamp NYC jQuery is free and opensource software with a license from MIT It makes things simpler for HTML document manipulation and traversal animation event handling and Ajax According to W3Techs 776 of all sites use jQuery as of 23rd February 2021 jQuery library FeaturesBenefits It has an easytouse minimalistic API It uses CSS3 selectors in manipulating style properties and finding elements jQuery is lightweight taking just 30 kb to gzip and minify and supports an AMD module As its syntax is quite similar to that of CSS it is easy for beginners to learn Extendable with plugins Versatility with an API that supports multiple browsers including Chrome and Firefox Use cases DOM manipulation with CSS selectors that use certain criteria to select a node in the DOM These criteria include element names and their attributes like class and id Element selection in DOM using Sizzle an opensource multibrowser selector engine Creating effects events and animations JSON parsing Ajax application development Feature detection Control of asynchronous processing with Promise and Deferred objects Reactjs Reactjs also known as ReactJS or React is an opensource frontend JavaScript library It was created in 2013 by Jordan Walke who works at Facebook as a software engineer Now it has the MIT license but was initially released under the Apache License 20 React was designed to make interactive UI creations painless Just design a simple view for individual states in your app Next it will render and update the right component efficiently upon data changes React library FeaturesBenefits The React code comprises components or entities that need rendering to a specific element in DOM with the help of a React DOM library It uses a virtual DOM by creating an inmemory cache in a data structure computing the difference and updating the display DOM in the browser efficiently Due to this selective rendering the app performance boosts while saving the developers efforts in recalculating the page layout CSS styles and fullpage rendering It uses lifecycle methods like render and componentDidMount to allow code execution at specific points during an entitys lifetime It supports JavaScript XML JSX that combines both JS and HTML It helps in component rendering with nested elements attributes JS expressions and conditional statements Use cases Serving as the base while developing mobile or singlepage applications Rendering a state to the DOM and manages it Building efficient user interfaces while developing web applications and interactive sites Debugging and testing more easily A bonus point Facebook Instagram and Whatsapp all use React D3js DataDriven Documents D3 or D3js is another famous JS library that developers use to document manipulation based on data It was released in 2011 under the BSD license D3js library FeaturesBenefits It emphasizes web standards and provides you with modern browser capabilities without being limited to a single framework D3js enables powerful data visualizations It supports HTML CSS and SVG Takes a datadriven approach and applies it to manipulate the DOM D3js is fast and supports a wide number of dynamic behavior and datasets for animations and interaction It reduces overhead allowing wider graphical complexity within high framerates Use cases To produce interactive and dynamic data visualization To bind data to a DOM and perform a datadriven transformation on them For example you can generate HTML tables out of a numbers array and then create an SVG barchart or a 3D surface plot using D3js Its functional code makes it reusable with a vast collection of modules D3 provides various modes to mutate nodes like changing styles or attributes by taking a declarative approach adding sorting or removing nodes changing text or HTML content etc To create animated transitions sequencing complex transitions through events performing CSS3 transitions etc Underscorejs Underscore is a JavaScript utility library that provides various functions for typical programming tasks It was created in 2009 by Jeremy Askenas and release with an MIT license Now Lodash has overtaken it Underscore library FeaturesBenefits Its features are similar to Prototypejs another popular utility library but Underscore has a functional programming design rather than object prototype extensions It has 100 functions of 4 different types based on the datatypes they manipulate These are functions to manipulate Objects Arrays Both objects and arrays Other functions Underscore is compatible with Chrome Firefox Edge and more Use cases It supports functional helpers such as filters maps etc along with specialized functions such as binding quick indexing JavaScript templating quality testing etc Lodash Lodash is also a JS utility library that makes it easier to work with numbers arrays strings objects etc It was released in 2013 and also uses functional programming design like Underscorejs Lodash library FeaturesBenefits It helps you write maintainable and concise JavaScript codes Simplifies common tasks such as math operations binding throttling decorating constraining debouncing etc String functions like trimming camel case and upper case are made simpler Creating modifying compressing and sorting arrays Other operations on the collection object and sequence Use cases Its modular methods help you in Iterating arrays strings and objects Crafting composite functions Manipulating and testing values Algolia Places Algolia Places is a JavaScript library that provides an easy and distributed way of using address autocompletion on your site Its a blazingly fast and wonderfully accurate tool that can help increase your site user experience Algolia Places leverages the impressive opensource database of OpenStreetMap to cover worldwide places For example you can use it to boost your product page conversions Algolia Places library FeaturesBenefits It simplifies checkouts by filling up multiple inputs simultaneously You can use the country or city selector effortlessly You can view results quickly by displaying link suggestions on a map in realtime Algolia Places can handle typing mistakes and displays results accordingly It delivers results within milliseconds by routing all queries automatically to their closest server Use cases Allows you to incorporate a map to display a specific location that is quite useful It enables you to use forms efficiently Animejs If you want to add animations to your site or application Animejs is one of the best JavaScript libraries you can find It was released in 2019 and is lightweight with a powerful yet simple API Animejs library FeaturesBenefits Animejs runs with DOM attributes CSS properties SVG CSS transforms and JS objects Works with a wide range of browsers such as Chrome Safari Firefox Opera etc Its source code is effortless to decipher and use Complex animation methods such as overlapping and staggering followthrough become easier Use cases You can use Animejs staggering system on properties and timings Create layered CSS transformations with multiple timings simultaneously over one HTML element Play pause trigger reverse and control events in synchronizing manner using Animejs callbacks and controls functions Animate On Scroll AOS Animate On Scroll works great for singlepage parallax websites This JS library is fully opensource and helps you add decent animations on your pages that look sweet as you scroll down or up It makes your site design a joyful ride by helping you add fade effects static anchor positions and more to delight your users Animate On Scroll library FeaturesBenefits The library can detect element positions and add suitable classes while they show up in the viewport Apart from adding animations easily it helps you change them on the viewport It works seamlessly on different devices be it a cell phone tablet or computer As it is written in pure JavaScript it has no dependencies Use cases Animate an element according to the position of another Animate elements based on their screen positions Disable element animations on mobiles Create different animations such as fade flip slide zoom anchor placements etc Bideojs Do you want to incorporate fullscreen videos into your sites background Try Bideojs Bideojs library FeaturesBenefits Adding a video background is easy with this JavaScript library This feature looks cool on screens of different scales and sizes and works smoothly Videos added can resize based on the browser used Easy to implement using CSSHTML Use cases To add responsive fullscreen background videos on a site Chartjs Is your website or project related to the data analysis field Do you need to present lots of statistics Chartjs is an excellent JavaScript library to use Chartjs is a flexible and simple library for designers and developers who can add beautiful charts and graphs to their projects in no time It is opensource and has an MIT license Chartjs library FeaturesBenefits Elegant and simple to add basic charts and graphs Results in responsive web pages Lightweight to load and easy to learn and implement 8 different types of charts Great for beginners Animation capabilities to make pages more interactive Use cases Provide clear visual representations when different datasets are used with the help of mixed chart types Plot sparse and complex datasets on logarithmic date time or custom scales Cleavejs Cleavejs offers an interesting solution if you want to format your text content Its creation aims to provide an easier way to increase the input fields readability by formatting the typed data This way you no longer need to mask patterns or write regular expressions to format text Cleavejs library FeaturesBenefits Increases user experience with consistent data for form submissions You can perform different formatting types for credit card numbers phone numbers date time and numerals Format custom blocks prefix and delimiter Supports ReactJS components and more Use cases Implement cleavejs to multiple DOM elements with CSS selectors To update a specific raw value To get the reference of the text field It is used with a Redux Form in Vuejs jQuery and Playground Choreographerjs Use Chreographerjs to animate complex CSS effectively It can even add more custom functions that you can use for nonCSS animations To use this JavaScript library install its package through npm or add its script file Choreographerjs library FeaturesBenefits Its Animation class manages individual animation data The animationConfig object configures each animation instance Includes 2 builtin animation functions change and scale Scale is used to map progressively measured values to the style property of a node Change removes or adds style properties Use cases Perform instant scroll animations Create animations according to mouse movements Glimmer Released in 2017 Glimmer features lightweight and fast UI components It uses the powerful Ember CLI and can work with EmberJS as a component Glimmer library FeaturesBenefits Glimmer is a fast DOM rendering engine that can deliver incredible performance for renders and updates It is versatile that can work alongside your current technology stack without requiring you to rewrite codes Use cases You can use it as a standalone component or add it as a web component in existing applications DOM rendering It helps you distinguish between static and dynamic content Use Glimmer when you want the features of Ember but in a lighter package Granimjs Granimjs is a JS library that helps you create fluid and interactive gradient animations This way you can make your site stand out with colorful backgrounds Granimjs library FeaturesBenefits Gradients can cover images work standalone slide under image masks and so on You can customize gradient directions with percentage or pixel values Set gradient orientation as diagonal topbottom leftright radial or custom Set animation duration in milliseconds ms with changing states Customize gradient color and positions Image customization based on its canvas position source scaling etc Other options included are setting callbacks emitting events methods for gradient control etc Use cases Creating a basic gradient animation using 3 gradients with 2 colors Complex gradient animation using 2 gradients with 3 colors Animating gradients with one background image 2 colors and one blending mode Create gradient animations under a specific shape using one image mask Creating gradient animations that are responsive to events fullPagejs The opensource JS library fullPagejs helps you create fullscreen scrolling sites or onepage websites easily It is simple to use and can also add a landscape slider inside your site sections fullpagejs library FeaturesBenefits Offers a wide range of customization and configuration options Supports JavaScript frameworks like reactfullpage angularfullpage and vuefullpage Enables both vertical and horizontal scrolling Responsive design that fits the screens of different sizes as well as multiple browsers Autoscrolling on page loads Videoimage lazy load Use cases To improve the default features using lots of extensions To create fullscreen scrolling sites Building a singlepage website Leaflet Leaflet is one of the best JavaScript libraries that you can use to include interactive maps into your site It is opensource and mobilefriendly weighing around 39kb The MapPress Maps for WordPress plugin uses Leaflet to power its interactive maps Leaflet library FeaturesBenefits Offers performance features such as mobile hardware acceleration and CSS features Unique layers including tile layers popups markers vector layers GeoJSON and image overlays Interaction features including drag panning pinchzoom keyboard navigation events etc Map controls such as layer switcher attribution scale and zoom buttons Supports browsers like Chrome Safari Firefox Edge etc Customization including OOP facilities HTML and imagebased markers CSS3 controls and popups Use cases Add a map into your site with better zooming and panning smart polygonpolyline rendering modular build and tapdelay mobile animation Multiplejs Multiplejs enables background image sharing across various elements by using CSS or HTML with no JavaScript coordinate processing As a result it creates a stunning visual effect to increase more user interaction Multiplejs library FeaturesBenefits Supports multiple backgrounds Gradient opacity support Supports many mobile and web browsers Use cases To share background images Momentjs Momentjs helps you manage time and date effectively when working with different time zones API calls local languages etc You can streamline dates and times by validating parsing formatting or manipulating them Momentjs library FeaturesBenefits It supports a lot of international languages Object mutability Multiple internal properties like epoch shifting retrieving native Date objects etc To use its parser correctly there are some guidelines such as strict mode date formats forgiving mode etc Use cases To display the time in a published article Communicating with people from across the world in their local language Masonry Masonry is an awesome JS grid layout library This library helps you place your grid elements in suitable positions based on how much vertical space is available Its even used by some of the popular photo gallery WordPress plugins Compare this with how a mason fits stones while building a wall Masonry library FeaturesBenefits Masonrys grid layout is based on columns and does not have a fixed row height Optimizes space on a web page by eliminating unnecessary gaps Sorting and filtering elements without compromising the layout structure Animation effects Dynamic elements to autoadjust the layout for optimal structure Use cases To create image galleries with varying image dimensions List the latest blog posts in multiple columns while maintaining consistency even if they have varying summary lengths To represent portfolio items like images designs projects etc Omniscient Omniscientjs is a JS library that provides React component abstraction for prompt topdown rendering that embraces immutable data This library can help you build your project seamlessly as it is optimized and offers interesting features Omniscient library FeaturesBenefits Memorizes stateless React components Functional programming for the user interfaces Topdown component rendering Supports immutable data using Immutablejs Enables small and composable components with shared functionality using mixins Use cases To provide component keys Talkback to parent codes using helper functions or constructions Overriding components Filtering and debugging Parsley Do you want to add forms to your projects If yes Parsley can be useful to you It is an easy yet powerful JS library that you can use to validate forms Parsley library FeaturesBenefits Its intuitive DOM API takes inputs directly from HTML tags without requiring you to write a JS line Dynamic form validation by detecting form modifications dynamically 12 builtin validators Ajax validator and other extensions You can override Parsley default behavior and offer UI and UX focussed experience Free opensource and super reliable that works with many browsers Use cases Creating a simple form Making complex validations Creating multistep forms Validating multiple inputs Handling promises and Ajax requests Styling inputs to create exquisite floating error labels Popperjs Popperjs was created to make it easier to position popovers dropdowns tooltips and other contextual elements that appear close to a button or other similar elements Popper provides an excellent way to arrange them stick them to other site elements and enable them to perform seamlessly on any screen size Popperjs library FeaturesBenefits Lightweight library of about 3kb in size Ensures the tooltip continues to stay with the reference element when you scroll inside the scrolling containers Advanced configurability Uses robust library like Angular or React to write UIs making integrations seamless Use cases To build a tooltip from scratch To position these elements smoothly Threejs Threejs can make your 3D designing delightful It uses WebGL for rendering scenes on modern browsers Use other CSS3 CSS2 and SVH renderers if you use IE 10 and below Threejs library FeaturesBenefits Supports Chrome 9 Opera 15 Firefox 4 IE 11 Edge and Safari 51 Support JS features like typed arrays Blob Promise URL API Fetch and more You can create different geometrics objects lights shadows loaders materials math elements textures etc Use cases To create a geometric cube sphere etc Creating a camera or scene Screenfulljs Use Screenfulljs to add a fullscreen element to your project Due to its impressive crossbrowser efficiency you wont be in trouble while using this JavaScript library Screenfulljs library FeaturesBenefits Fullscreen a page or element Hide navigation UI on mobile phones Add fullscreen elements using jQuery and Angular Detects fullscreen modifications errors etc Use cases Adding fullscreen element on a web page Importing Screenfulljs in a doc Exiting and toggling the fullscreen mode Handling events Polymer The opensource JavaScript library by Google  Polymer is used to build web apps using components Polymer library FeaturesBenefits A simple way to create custom elements Computed properties Support both databinding oneway and twoway Gesture events Use cases To create interactive web apps with custom web components using JS CSS and HTTP It is used by leading sites and services like YouTube Google Earth and Play etc Voca The idea behind creating Voca is to ease out the pain while working with JavaScript strings It comes with useful functions that make it easy to manipulate strings like changing case pad trim truncate and more Voca library FeaturesBenefits Due to its modular structure the whole library or its individual functions load quickly while reducing the app build Offers functions to chop format manipulate query and escape strings No dependencies Use cases You can use Voca in multiple environments like Nodejs Webpack Rollup Browserify etc To convert a subject to the title case camel case kebab case snake case upper case and lowercase To convert the first character to uppercase and lowercase To create chain objects to wrap a subject enabling an implicitexplicit chain sequence To perform other manipulations like counting the characters formatting a string etc What Are JavaScript Frameworks JavaScript frameworks are application frameworks that allow developers to manipulate code to meet their unique requirements Web application development is analogous to building a house You have the option to create everything from scratch with construction materials But it will consume time and may incur high costs But if you use readymade materials such as bricks and assemble them based on the architecture then construction becomes faster saving you money and time Application development works similarly Instead of writing every code from scratch you can use prewritten codes working as building blocks based on the application architecture Frameworks can adapt to website design more quickly and make it easy to work with JavaScript How to Use JavaScript Frameworks To use a JavaScript framework read the JS frameworks documentation you intend to use and follow the steps What Are JavaScript Frameworks Used For To build websites Frontend app development Backend app development Hybrid app development Ecommerce applications Build modular scripts for example Nodejs Update DOM manually Automate repetitive tasks using templating and 2way binding Develop video games Create image carousels Testing codes and debugging To bundle modules The Most Popular JavaScript Frameworks AngularJS AngularJS by Google is an opensource JavaScript framework released in 2010 This is a frontend JS framework you can use to create web apps It was created to simplify the development and testing of web applications with a framework for MVC and MVVM clientside architectures AngularJS framework FeaturesBenefits Supports 2way data binding Uses directive to insert into an HTML code and provide the app with better functionality Quick and easy to declare static documents Its environment is readable expressive and fast to develop Impressive extensibility and customizability to work with Builtin testability and support for dependency injection Use cases To develop ecommerce applications Developing realtime data apps for weather updates Example YouTube app for Sony PlayStation 3 Note Google has ceased active development of AngularJS but theyve promised to keep it on an extended Long Term Support until December 31 2021 mainly to fix security issues Google will no longer support it after that Bootstrap Design fast and mobile responsive sites quickly using Bootstrap one of the most popular opensource toolkits for frontend development It was released in 2011 and provides developers with great flexibility in customizing various elements tailored to the clients needs Bootstrap framework FeaturesBenefits Responsive grid system Powerful JS plugins Extensive builtin components Sass variables and mixins Includes opensource SVG icons that work perfectly with their components and styled using CSS Offers beautiful and premium themes They ensure you dont have to deal with lots of bugs when updating a new Bootstrap version Use cases To create CSS or HTMLbased design templates for forms buttons typography navigation dropdowns tables modals etc For images image carousels and icons Aurelia Released in 2016 Aurelia is a simple unobtrusive and powerful opensource frontend JS framework to build responsive mobile desktop and browser applications It aims to focus on aligning web specifications with convention instead of configuration and requires fewer framework intrusion Aurelia framework FeaturesBenefits Aurelia is designed to execute high performance and perform batch DOM updates efficiently Delivers consistent and scalable performance even with a complex UI An extensive ecosystem with state management validation and internationalization Enables reactive binding and syncs your state automatically with high performance Simpler unit testing Unparalleled extensibility to create custom elements add attributes manage template generation etc Leverages advanced clientside routing UI composition and progressive enhancements Use cases To develop applications Use serverside rendering Perform twoway data binding Vuejs Vuejs was created in 2014 by Evan You while he worked for Google It is a progressive JavaScript framework to build user interfaces Vuejs is incrementally adoptable from its core and can scale between a framework and library easily based on various use cases Vuejs framework FeaturesBenefits Supports ES5compliant browsers It has a core library that is approachable and focuses only on the view layer It also supports other useful libraries that can help you manage complexities associated with onepage applications Blazingfast virtual DOM 20 kb mingzip runtime and needs fewer optimization Use cases Perfect to use in small projects that need lesser reactivity display a modal include a form using Ajax etc You can also use it on large singlepage applications using its Vuex and Router components To create events binding classes update element content etc Emberjs The opensource JS framework Emberjs is battletested and productive to build web applications with rich UIs capable of working across devices It was released in 2011 and was named SproutCore 20 back then Emberjs framework FeaturesBenefits Scalable user interface architecture Batteries included perspective helps you find everything you need to start building your app right away Features the Ember CLI working as the backbone for Ember apps and offering code generators for creating new entities Comes with an inbuilt development environment with quick autoreload rebuilds and test runners A bestinclass router using data loading with query parameters and URL segments Ember Data is a data access library that works with multiple sources simultaneously and keeps model updates Use cases To build modern interactive web apps Used by DigitalOcean Square Accenture etc Nodejs Nodejs is a serverside opensource JavaScript framework built on Chromes JS V8 Engine created in 2009 It is a runtime environment that executes JS codes outside a browser Nodejs is designed to help you develop scalable fast and reliable networkbased serverside applications Nodejs framework FeaturesBenefits Faster code execution It can drive asynchronous IO using its eventdriven architecture Shows similar Java properties such as forming packaging threading or forming loops Singlethreaded model No hassles of video or audio buffering by cutting down significant processing time Use cases To develop serverside applications Create realtime web apps Communication programs Develop browser games Its corporate usage includes GoDaddy LinkedIn Netflix PayPal AWS IBM and more Backbonejs The lightweight JS framework Backbonejs was created in 2010 and based on the Model View Presenter MVP architecture It has a RESTful JSON interface and helps you build clientside web applications It structures web apps with models for custom events and keyvalue binding collections with an efficient API and views using declarative event handling Backbonejs framework FeaturesBenefits Free and opensource with 100 available extensions Impressive design with fewer codes Offers structured and organized app development Code is simple and easy to learn and maintain Softer dependency over jQuery while stronger on Underscorejs Use cases To develop simplepage applications Smooth frontend JS functions To create organized and welldefined clientside mobile or web applications Nextjs The Open source platform of Nextjs offers a React frontend JavaScript framework Released in 2016 it allows you to enable functionalities like creating static sites and serverside rendering Nextjs framework FeaturesBenefits Automatic image optimization using instant builds Builtin domain and subdomain routing and language detection automatically Realtime analytics score that shows visitor data and per page insights Automatic bundling and compilation You can prerender a page at request time SSR or build time SSG Supports TypeScript filesystem routing API routes CSS codesplitting and bundling and more Use cases This productionready framework allows you to create both static and dynamic JAMstack sites Serverside rendering Mocha Every application needs to be tested before you deploy it This is what Mocha or Mochajs does for you It is a featurerich opensource JS test framework that runs on Nodejs as well as in a browser Mocha framework FeaturesBenefits It makes asynchronous testing fun and effortless Enables running Nodejs test simultaneously Autodetects and turnsoff coloring for a nonTTY stream Reports test duration Displays slow tests Metagenerate suites and test cases Support for multiple browsers configuration files node debugger sourcemap Growl and more Use cases To perform application audits To execute functions in a certain order using functions and log the test results Cleaning the tested softwares state to ensure each test case runs separately Ionic Released in 2013 Ionic is an opensource JavaScript framework to build highquality hybrid mobile apps Its latest release allows you to choose any UI framework like Vuejs Angular or React It uses CSS Sass and HTML5 to build applications Ionic framework FeaturesBenefits Leverages Cordova and Capacitor plugins to access host OS features like GPS camera flashlight etc Includes typography mobile components interactive paradigms beautiful themes and custom components Offers a CLI for object creation Enables push notifications creates app icons native binaries and Splash screens Use cases To build hybrid mobile apps Build frontend UI framework Create engaging interactions Webix The easytouse framework of Webix helps you develop rich UIs by using lighter codes It offers 102 user interface widgets like DataTable Tree Spreadsheets etc along with featurerich HTML5CSS JS controls Webix framework FeaturesBenefits Userfriendly JS file management Saves time by using builtin widgets and UI controls Easy to understand code Crossplatform and browser support Seamless integration with other JavaScript libraries and frameworks Fast performance for rendering widgets and even for large datasets like Trees Lists etc GDPR and HIPAA compliant along with unlimited extensibility and web accessibility Use cases To develop UIs Crossplatform web application development Gatsby Gatsby helps you develop fastperforming websites and apps with React This is a frontend JS framework that is opensource and free Check this out on GitHub Gatsby framework FeaturesBenefits High performance with automated codesplitting inlining styles image optimization lazyloading etc to optimize sites Its serverless rendering creates attic HTML during build time Hence no server and DDoS attacks or malicious requests Higher web accessibility 2000 plugins themes and recipes Use cases Frontend app and website development Static site generation Serverside rendering Used by sites like Airbnb and Nike the latter for their Just Do It project Meteorjs Meteor is an opensource JS framework released in 2012 It allows you to build fullstack apps seamlessly for mobile desktop and web Meteorjs framework FeaturesBenefits Integrate tools and frameworks for more functionality such as MongoDB React Cordova etc Build applications on any device APM to view app performance Livebrowser reloading Opensource Isomorphic Development ecosystem IDevE to facilitate development from scratch Use cases Rapid prototyping Crossplatform apps Sites built with Meteor Pathable Maestro Chatra etc MithrilJS Although not as popular as some of the other items in this list Mithril is an advanced clientside JS framework to develop clientside applications It is lightweight  less than 10kb gzip  but fast and offers XHR and routing utilities MithrilJS framework FeaturesBenefits Pure JS framework Support for all the major browsers without polyfills Creates Vnode data structures Offers declarative APIs to manage UI complexities Use cases Singlepage apps Used by sites like Vimeo Nike etc ExpressJS Expressjs is a backend JS framework for developing web applications It was released in 2010 under MIT incense as free opensource software It is a fast and minimalist Nodejs web framework that comes with an array of useful features ExpressJS framework FeaturesBenefits Scalable and lightweight Enables receiving HTTP responses by allowing you to set up middleware Features a routing table to take actions based on URL and HTTP method Includes dynamic HTML page rendering Use cases Rapid nodebased application development Creation of REST APIs Some Useful MustKnow JavaScript Tools Slick Slick is a useful JS tool that takes care of your carousel requirements It is responsive and scalable with its container Its features include CSS3 support swipes mouse dragging full accessibility infinite looping autoplay lazy loading and many more Babel Babel is an opensource and free JS compiler that you can use to convert new JS features to run an old JS standard The plugin is also used for syntax transformation that isnt supported in an old version It provides polyfills to support features missing from certain JS environments iziModal iziModal is an elegant lightweight flexible and responsive modal plugin that works with jQuery It is useful to notify something to your users or ask for information using a popup modal It is easy to use and comes with many customizations ESLint Finding bugs and fixing them in your JS code is easy by using ESLint It analyses codes statistically to quickly catch syntax errors command lines style issues etc and fix them automatically Shave Shave is a zerodependency JS plugin that you can use to truncate text inside HTML elements by setting a maximum height to perfectly fit inside the element It also stores some extra original texts inside a hidden element span ensuring you dont lose those texts Webpack Webpack is a tool to bundle JS modules for modern applications You can write the code and use it to bundle your assets reasonably while keeping the code clean How JavaScript Libraries and Frameworks Work Together The difference between JavaScript libraries and frameworks lies in its flow of controls They are just opposite in the flow or inverted In JS libraries the parent code calls the function that a library offers In JS frameworks the framework itself calls the code and uses it in a specific way It defines the overall application design Simply put you can think of JavaScript libraries as a particular app function In contrast the framework acts like its skeleton while an API acts as the connector to bring them together Commonly developers start the development process with a JS framework and then complete the app functions with JS libraries and an APIs help Summary JavaScript libraries and frameworks are efficient to accelerate your website or app development process And as a web developer using the right one for your project is crucial If you are a Kinsta customer you can also take advantage of the code minification feature that is built into the MyKinsta dashboard This allows customers to easily enable automatic CSS and JavaScript minification with a simple click Different libraries and frameworks serve different purposes and have their own sets of pros and cons Hence you need to choose them based on your unique requirements and future goals associated with a website or application I hope this extensive list of JavaScript libraries and frameworks helps you choose the right one for your next project Get all your applications databases and WordPress sites online and under one roof Our featurepacked highperformance cloud platform includes Easy setup and management in the MyKinsta dashboard 247 expert support The best Google Cloud Platform hardware and network powered by Kubernetes for maximum scalability An enterpriselevel Cloudflare integration for speed and security Global audience reach with up to 35 data centers and 260 PoPs worldwide Get started with a free trial of our Application Hosting or Database Hosting Explore our plans or talk to sales to find your best fit Durga Prasad Acharya Is your WordPress site slow Uncover your websites performance bottlenecks to deliver a better user experience Free Audit ty Lightweight Footprint CSS3 Compliant CrossBrowser View Source on GitHub  Only 30kB minified and gzipped Can Supports CSS3 selectors to find Chrome Edge Firefox IE Safari How jQuery Works  also be included as an AMD module elements as well as in style property Android 10S and more manipulation React A JavaScript library for building user interfaces Take the Tutorial  3 Data Driven USGUNEMIS UNDERSCORES  O Lodash A modern JavaScript utility library delivering modularity performance  extras sl Algolia Places aaa Turn any Qfiiaiisd into an address autocomplete Animejs eenemer is a lightweight JavaScript animation library with a simple yet powerful API It works with CSS properties SVG DOM attributes and JavaScript Objects Getting started AOS Animate On Scroll Library BIDEOJS A JS library that makes it super easy to add fullscreen background videos Hold on The video might take a while to load VIEW ON GITHUB HOW IT WORKS Chartjs Simple yet flexible JavaScript charting for designers  developers Cleaves Format your input content when you are typing star 16431  Fork CHOREOGRAPHERJS A simple library to take care of complex CSS animations  npm install save choreographerjs yw glimmer Fast and lightweight UI components for the web Available for use within Emberjs and standalone apps Granimj Create fluid and interactive gradient animations with this small javascript library EXAMPLES API DOWNLOAD fullPagejs  Leaflet fp an opensource JavaScript library for mobilefriendly interactive maps Moments 2291 Considering using Moment in your project Parse validate manipulate There may be better modern alternatives and display dates and times in JavaScript For more details and recommendations please see Project Status in the docs Black Lives Matter It is not our differences that divide us It is our inability to recognize accept and celebrate those differences  Audre Lorde Donate  Wikipedia  Read  Watch  Get Involved Cascading grid layout library What is Masonry Masonry is a JavaScript grid layout library It works by placing elements in optimal position based on available vertical space sort of like a mason fitting stones in a wall Youve probably seen it in use all over the Internet Q Star  1198  Fork  57 Parsley the ultimate JavaScript form validation library Validating forms frontend have never been so powerful and easy Get started today 292 SAMMI TOOLTIP  POPOVER POSITIONING ENGINE Weighs just 3 kB VOICE OF RACISM screenfulljs Simple wrapper for crossbrowser usage of the JavaScript Fullscreen API which lets you bring the page or any element into fullscreen Smoothens out the browser implementation differences so you dont have to Polymer Library The Polymer library is our original web components library For new projects we recommend starting with our nextgeneration web components library LitElement LitElement is a smaller lighter successor to the Polymer library For existing Polymer apps we recommend upgrading to version 30 of the Polymer library LitElement Polymer Library 30 OG The ultimate JavaScript string library Wncuraris Oy  TRY THE NEW ANGULAR B cownc Build fast responsive sites with Bootstrap Quickly design and customize responsive mobilefirst sites with Bootstrap the worlds most popular frontend open source toolkit featuring Sass variables and mixins responsive grid system extensive prebuilt components and powerful JavaScript plugins Get started  Download Currently v500beta2  v46x docs  All releases Simple Powerful Unobtrusive Why Aurelia Join thousands creating nextgeneration apps The Progressive JavaScript Framework CED cet started   cithus A framework for ambitious web developers Emberjs is a productive battletested JavaScript framework for building modern web applications It includes everything you need to build rich Uls that work on any device Nodejs is a JavaScript runtime built on Chromes V8 JavaScript engine BlackLivesMatter New security releases to be made available February 23 2021 Download for Windows x64 14155 LTS 1590 Current Recommended For Most Users Latest Features Other Downloads  Changelog  APIDocs Other Downloads  Changelog  AP Docs Or have a look at the Long Term Support LTS schedule Bg BACKBONES The React Framework for Production Nextjs gives you the best developer experience with all the features you need for production hybrid static  server rendering TypeScript support smart bundling route prefetching and more No config needed eck simple flexible fun One codebase Any platform Now in React An open source mobile UI toolkit for building high quality crossplatform native and web app experiences Move faster with a single code base running everywhere with JavaScript and the Web TUE LET Emm Talk to an expert  One frontend to rule them all Create blazing fast websites and apps AND harness the power of 2000 plugins Build FullStack Javascript Apps with Meteor Meteor is an open source framework for seamlessly building and deploying Web Mobile and Desktop applications in Javascript  Mithril 204 Guide API Chat GitHub EXpress Fast unopinionated minimalist web framework for Nodejs  npm install express save ","https://hackernoon.com/cool-javascript-libraries-to-consider-using-in-2023, https://hackernoon.com/cool-javascript-libraries-to-consider-using-in-2023, https://kinsta.com/blog/javascript-libraries/",Front-End Development,2412,7608
AJAX for Asynchronous Requests,"nan, AJAX Promises Async  AwaitA quick tour of how JavaScript Asynchronous programming patterns have evolved and how to implement themBrian MuteaFollow5 min readMay 31 2022ListenShareImage by Rocco Stoppoloni from PixabayIn my previous article on how Asynchronous JavaScript code works behind the scenes I thought it would be great to talk about how this asynchronous programming has evolved over time to date and what I have understood on the topicsWe know that JavaScript is a synchronous language which means that by default JavaScript code can only be executed one statement at a time This behavior can cause blocking in the call stack since it runs on a single threadDue to this nature an asynchronous way of executing JavaScript code had to be implemented to do away with the blocking behavior and enable asynchronous code to run in the background and at the same time execute other functionalities These implementations have evolved over timeAJAX and CallbacksAJAXAsynchronous JavaScript and XML It allows the web page to be updated asynchronously by exchanging data with the webserver behind the scenes It allows updating a page without reloading the pageThese days the JSON data format is mostly preferred over the XML format as it is lighterBefore developers used AJAX to implement asynchronous JavaScript The AJAX model makes use of the XMLHttpRequestobject that can be used to exchange data with a web server behind the scenes Before its introduction developers had a tough time pulling data from the web servers without full page refreshing They used techniques like scriptinjection or thirdparty pluginsFor example let us say we wanted to query data from an online API this is what the AJAX way of doing it would look likeIn the code we first have to initialize the XMLHttpRequestobject as newXMLHttpRequestthen we initialize the request usingrequestDataopen where we pass in the method for getting the data and the urlendpoint from where we are requesting the datarequestDatasendsends the request This happens asynchronously in the background which allows the rest of the code to runCallbacksCallback function  This is a function that can be passed to another function as an argumentFrom the code above we have to use a callback function that contains the code that will be executed when the response is finally ready function if   The callback is attached to a load event Here are some of the other events you can useThe problem with CallbacksLet us say now in our application using the code above we want to get the neighbor of this countryKenya in this case In order to get this neighbor we will require data returned from the ajax call for Kenya So basically we will require data from the first ajax call to make another ajax call that will determine the neighborSample AJAX CallbacksFrom the code we see that we have an ajax callback function inside another ajax callback function Simply we can state that we have nested callbacksNow that is a small piece of code suppose that in that application we want to send more requests sequentially like request the neighbor of the neighbor of the neighbor of the neighbor of the countries etc Imagine how many callbacks would be nested It would be like a callback inside a callback inside another callback and the process goes on This would result in a term used in JavaScript for asynchronous requests handled by callbacks called Callback hell where we have many callbacks nested togetherToo many nested callbacks make it harder to read and maintain code To visualize this is what the code would look likecallbackHell structureThe Fetch API and PromisesThe fetch API is the modern alternative for AJAX call with the XMLHttpRequest object It is essentially an interface for fetching resources available in the network It is a more flexible feature and provides request and responseobjectsIt makes a request and fetches data using the fetchmethod This method will always return a promise which will resolve to the response of that requestPromises work with asynchronous operations they are timesensitive This means that a promise will be in either of three states at a particular time These states arePending  This is a state before any value is available and the task is still loading in the backgroundFulfilled  This is when the promise has successfully resulted in a value as we expectedRejected  This means that the asynchronous task has run into an error and was not able to avail a value to us as expected This problem can feature loss of Internet connection etcSince this is a better way than the callback one we will convert our code from the nested ajax callbacks and use the Fetch API You will be able to see how much easier the task has been madefetchAPI_promiseWe can see that by using promises the code also becomes less bulk and easier to read and understand whatever is happening at every chain of the promise So instead of having a chain of callbacks we have a clear flat chain of promisesWe can also build a PromisePromiseresolveResolve Immediatelythenres  consolelogresolvedthis creates an immediately resolved promisePromiserejectnew ErrorRejected Immediatelycatchres  consolelogRejectedthis creates an immediately rejected promisePromisifying the callback hell of the setTimeout abovesetTimeout promisifiedAsync  WaitThis technique came to simplify our tasks more From promises we have seen that we chained promises to get data which we called a flat chain of promises With the Async function we avoid this explicit chaining of the promises This makes the code cleaner However in order to understand nicely how this async function works you will have to have a basic knowledge of how the promises work since it leverages the conceptSo what is an Async function An Async function is a function that has been declared with the asynckeyword When the function is declared this way it always returns a promiseThe awaitkeyword when used will make the function wait for the promise to settle that is resolve or reject and then returns the results Basically it will stop the execution of the code until the promise is settled However by stopping the code execution does not mean blocking will happen Since resides inside the async function it will be asynchronously running in the background and hence no blocking occursA combination of the async and await keywords enable the asynchronous and promisebased codeDoes this not feel like real asynchronous operations going on and much cleanerHere we just assign values to a variable after the promise is settled It is much cleaner without the callbacks and the thenmethods of the promisesFinal thoughtsWe have seen that the coding patterns have changed over time From AJAXs XMLHttpRequest object to Fetch APIs promises and eventually the simple Async  Wait we can now right more beautiful asynchronous requests to servers and that our code can be easier to understand handle bugs and maintainAsync Await is simply syntactic sugar for promisesAJAX is still in use today However it may change based on what libraries or frameworks are in the projectAlso if you grasped something new by reading this kindly follow me on medium and also on LinkedIn I will greatly enlighten you with more exciting topics in the future Thanks for reading through","https://medium.com/@brianmuteak/ajax-promises-now-we-just-async-wait-fba74d57cda3, https://medium.com/@brianmuteak/ajax-promises-now-we-just-async-wait-fba74d57cda3",Front-End Development,449,1181
Web Accessibility Standards, Web Accessibility The Ultimate Guide Learn about what web accessibility is why its an important investment to make and how it can help you boost brand loyalty Written by Kristen Baker WEBSITE ACCESSIBILITY CHECKLIST A checklist to help you make your website more accessible and usable  available as a PDF or on Google Sheets Get the Checklist Updated 022123 Published 022123 Web accessibility ensures that all visitors regardless of ability have a seamless experience on your website Unfortunately many sites dont comply with web accessibility best practices and guidelines which makes the experience for users with disabilities difficult The solution to this issue is making your website  including the format structure navigation visuals and written content  inclusive for everyone In other words you need to prioritize web accessibility Chapters prev next What Is Web Accessibility Web Accessibility Standards How to Make Your Website Accessible Web Accessibility Tools Web Accessibility Examples What is web accessibility Web accessibility is the practice of making websites usable for all visitors including those with disabilities impairments and limitations Web accessibility involves following certain design principles which ensure that people who experience difficulties or limitations have the same or a similar experience as those who do not This ensures your content is accessible for every user Who manages web accessibility on the internet So whos in charge of the web accessibility initiative and works to enforce it across the internet The answer is the members of the Web Accessibility Initiative WIP of The World Wide Web Consortium W3C These organizations are responsible for publishing the Web Content Accessibility Guidelines WCAG which well review below and related content Were committed to your privacy HubSpot uses the information you provide to us to contact you about our relevant content products and services You may unsubscribe from these communications at any time For more information check out our Privacy Policy Why is web accessibility important As mentioned web accessibility makes your website  and its content  more userfriendly and easy to understand for all visitors This includes those with disabilities and limitations such as Blindness Low vision Learning disabilities Cognitive disabilities Deafness Hearing loss Speech disabilities Physical disabilities Web accessibility isnt optional its a musthave which is why web accessibility is important By prioritizing your sites level of accessibility you will enhance the user experience for all of your visitors  including those with disabilities or limitations who land on your site Youll also demonstrate your companys commitment to inclusivity By doing this you show your visitors leads and customers that you value and care about them as individuals  and in return this investment will boost your brand loyalty and advocacy Meeting web accessibility standards may sound like the right thing to do at this point and it is  but is it required of you by law Were committed to your privacy HubSpot uses the information you provide to us to contact you about our relevant content products and services You may unsubscribe from these communications at any time For more information check out our Privacy Policy Website Accessibility Checklist This checklist will help you make the following more accessible on your website Web Pages Navigation Video  Media And More Download for Free Loading your download form Youre all set Click this link to access this resource at any time Access now Learn more How is web accessibility enforced Long story short there arent any enforceable laws related to website accessibility unless you run a government website In that case you must abide by Section 508 of the Rehabilitation Act guidelines However just because web accessibility isnt a formal law doesnt mean your business will automatically avoid a lawsuit There are multiple cases in which major companies have been sued for lacking an accessible website In fact between the years of 2017 and 2018 there was an increase of 181 in the number of filed federal court lawsuits For example in the Gil v WinnDixie decision a court ruled that websites may constitute public accommodations under the Americans with Disabilities Act ADA In other words for businesses with physical stores and websites their sites can be considered heavily integrated with their physical store locations So their websites could be considered gateways to their physical store locations For this reason websites constitute a service of public accommodation covered by the ADA In other words websites are expected to meet accessibility standards And in Dominos Pizza v Guillermo Robles a court ruled in favor of Robles a blind man who could not order food through Dominos website and app despite using screenreading software In this case the 9th US Circuit Court of Appeals panel said  alleged inaccessibility of Dominos website and app impedes access to the goods and services of its physical pizza franchises which are places of public accommodation To avoid legal trouble  or simply pushing visitors away  make sure your website doesnt prevent anyone from consuming navigating or obtaining any of the information you share The best way to do this is by abiding by WCAG  so lets review those guidelines and standards next Web Accessibility Standards The most recent WCAG states four main principles when creating an accessible website Within these four principles are web accessibility guidelines you can reference and work to apply whenever and wherever possible on your site 1 Perceivable Visitors must be able to perceive or understand and be aware of the content and information presented on your website Remember that perceive doesnt necessarily mean see with ones eyes  users who are blind or have low vision often use screen reader software which converts printed text into synthesized speech or braille characters Consider these users when you are creating and updating your site 2 Operable Operable websites can be used without disrupting the user in any way All visitors can utilize every part of the sites functionality from navigating a page to selecting a link from a menu to playing and pausing video and audio Generally speaking the most operable websites are simple Additionally many have ditched any excess functionality that could impede users with disabilities and limitations 3 Understandable All content on your website  including your written and graphic design content  should be easily understood by visitors Not only is jumbled verbose language difficult for your typical visitor to interpret  it also limits access to those with cognitive difficulties and impairments and people who do not speak your sites predominant language Keep it digestible This principle applies to your sites structure too Your pages need to be organized intuitively and your navigation readily available to visitors on most if not all pages 4 Robust The content on your site should be easily interpreted and consumable by all visitors including those using assistive technology like screen readers To achieve this write your HTML that allows assistive technologies can parse your code without a visual reference How to Make Your Website Accessible After reviewing the above principles you may realize that your website doesnt quite meet these standards Or perhaps you ran your site through an accessibility testing tool and didnt get the best score Either way the WCAG provides several specific guidelines for each of the four principles above that you can implement immediately Lets unpack these guidelines further Or for an even more comprehensive review of these guidelines see our complete web accessibility checklist Were committed to your privacy HubSpot uses the information you provide to us to contact you about our relevant content products and services You may unsubscribe from these communications at any time For more information check out our Privacy Policy Website Accessibility Checklist This checklist will help you make the following more accessible on your website Web Pages Navigation Video  Media And More Download for Free Loading your download form Youre all set Click this link to access this resource at any time Access now Learn more Perceivable Web Accessibility Guidelines Offer text alternatives All nontext items on your page  including images videos and audio content  must have a text alternative so that nonsighted individuals can understand them Image alt text is the most common approach to meet this guideline and its recommended that you include alt text for every nondecorative image on your website For decorative images include the alt attribute but leave it blank ie img srcdecorativepng alt  This tells the screen reader that an image exists but it can ignore the graphic And while image alt text is essential remember to provide alt text for other elements of your site such as graphs or tables that are difficult for assistive technologies to interpret Furthermore ensure you follow alt text best practices when writing yours Offer alternative ways to consume timebased media Timebased media comprises audio and video content For audio content provide a full transcript of the recording For video ensure captions are in sync with the audio Both of these help users with limited hearing capabilities Structure content in an adaptable way This guideline means writing your HTML files so that you wouldnt lose the intended information and structure if the page styling were to be removed For example proper headings ordered and unordered list elements and bold and italic text convey information Make your content easy to see and hear For individuals with sight its essential to utilize color contrast so that everyone including those with color blindness can read your content and understand any visual information you want to convey Additionally users should be able to adjust any background audio on your site or halt audio playback altogether Some websites such as HubSpots feature a toggle option so visitors can choose their color contrast Operable Web Accessibility Guidelines Ensure complete functionality via the keyboard Some users who navigate your site will not use a mouse or a touchpad Therefore all functionality on your website should be accessible with the keyboard alone For example the tab key should let users jump between selectable elements on the page and the enterreturn key should click the element in focus Provide ample time to engage with your website Allow users to read watch and use the various content types on your site within a reasonable time constraint If any action on your site includes a time limit users should be allowed to extend or cancel it This guideline also applies to accessible dropdown menus If a user disengages with the menu from the mouse setting a time delay before the menu disappears is a good practice Avoid blinkingflashing content According to W3C content that blinks or flashes more than three times in a second can trigger seizures Its best to avoid this If for some reason you cannot its imperative you provide a warning Provide navigation to help users know where they are and where they can go A clear page title meaningful links a keyboard focus indicator and proper headings all signal to users where they are on your site and which elements are clickable links Understandable Web Accessibility Guidelines Make text content readable Consider the full scope of your potential audience when drafting your content Your writing should be comprehendible by many readers including those learning your sites native language Avoid using highly technical jargon and regional slang Structure your pages logically When planning your sites structure and navigation place your navigational links and pages in a way that feels intuitive to visitors This includes putting navigation above the fold most commonly in the pages header and footer Write useful error messages No one likes receiving an error message so provide a clear description of the error and instructions to help visitors correct their mistakes Robust Web Accessibility Guidelines Write HTML that can be parsed Assistive technologies often use a web pages HTML file to translate its contents into a different format For this reason your pages HTML code should be wellwritten For accessibility this means using start and end tags when required and avoiding duplicate IDs across elements and duplicate attributes within the same HTML tag Now that you understand what web accessibility is why its essential and the guidelines lets look at some tools you can lean on for assistance when making your site more accessible Web Accessibility Tools There are various web accessibility testing tools available today W3C has compiled and shared a list of them on their website for you to learn more about and compare to one another We have our list of tool recommendations too And if youre seeking website accessibility solutions weve got you covered there too For the sake of this guide weve highlighted a few options below to provide insight into the capabilities these accessibility tools have Were committed to your privacy HubSpot uses the information you provide to us to contact you about our relevant content products and services You may unsubscribe from these communications at any time For more information check out our Privacy Policy Website Accessibility Checklist This checklist will help you make the following more accessible on your website Web Pages Navigation Video  Media And More Download for Free Loading your download form Youre all set Click this link to access this resource at any time Access now Learn more WAVE WAVE by WebAIM offers multiple tools to help you evaluate the accessibility of your website They provide a visual representation of the areas on your website that could use improvement to be more accessible To begin enter your site URL and Wave will highlight which areas of your site dont meet WCAG standards Youll also get a human audit and review of your websites content Image Source DYNO Mapper DYNO Mapper by Indigo Design Company LLC is a sitemap generator  meaning it uses sitemaps to display the accessibility of your website after conducting content inventories and audits as well as keyword tracking The tool also integrates with Google Analytics to allow indepth analyses with identifiable areas for accessibility improvement Dyno Mapper will test all types of sites for you including public private and online apps so it scores points for its thoroughness Image Source SortSite Next we have SortSite by PowerMapper evaluates the accessibility of your website as a whole or specific web pages in just one click The tool uses 1200 guidelines and standards to determine a sites accessibility Some of the main categories of accessibility SortSite reviews on your site include broken links compatibility SEO privacy web standards and usability Image Source A11Y Color Contrast Accessibility Validator To make your websites colors accessible use the A11Y Color Contrast Accessibility Validator by A11Y Company It displays the color contrast issues on your website or web pages In the tool you can test by URL or a specific set of colors by using their hex codes or locations on the color wheel Wherever the tool detects errors in color combinations or contrast there will be ideas and recommendations for fixing them to meet WCAG standards Image Source Web Accessibility Examples Now that youre set with your web accessibility tools you might need some inspiration to help you brainstorm how to bring your site to life with these best practices Here are eight WCAGcompliant websites you can reference for inspiration while making your website accessible 1 W3C It seems obvious but what better example than the organization that writes these accessibility standards themselves W3C has everything an accessible website should including wellstructured HTML with clear tags to denote structure color contrast simple language and a focus indicator for the currently selected page element Image Source 2 The Cram Foundation The Cram Foundation focuses on supporting those with disabilities so having a WCAGcompliant site is necessary Its website balances web accessibility with an aesthetically pleasing and branded design The bright and branded website meets all WCAG color and contrast standards and its navigation is accessible in terms of structure and color Image Source 3 US Center for Disease Control CDC and Prevention The US Center for Disease Control CDC and Prevention is a government website that must be accessible The site includes a page that explains how the Center works to meet and exceed the accessibility standards outlined in Section 508 Additionally the page describes how visitors with any comments related to their web accessibility can get in touch The sites standard site navigation is easy to understand for all It also offers visitors a couple of different navigation options so they can maneuver around the site in the way that best suits their needs There are several different content types available on the site too so visitors can get the information they need in a format that works for them eg written audio video Image Source 4 Healthmonix Healthmonix leverages cloudbased technology payment solutions for health systems and medical groups Its website shows an impressive adherence to accessibility standards The navigational layout is intuitive the content is structured in a clear hierarchy and clear color contrast ensures readable text Image Source 5 Unilever Unilever owns 400 brands and sells consumer goods to over 2 billion people globally For this reason it has committed to ensuring its website is accessible to all visitors  and it shares information about this investment on a dedicated site page The websites accessible features include accommodation for assistive technologies and code eg screen readers software for texttospeech or speechtospeech keyboard emulator screen magnifier enhanced UI and visual styling Unilevers website also meets or exceeds the WCAG regarding color and contrast layout and navigation browser support text alternatives audio and video content and more Image Source 6 The Financial Gym The Financial Gym is a personal finance coaching service with an accessible website It uses text and image colors to provide ample contrast while sticking to the companys branding Layout and navigation are intuitive enough to navigate with a screen reader and a keyboard Also videos on the homepage do not autoplay so users completely control the media playback Image Source 7 The White House Like some other websites mentioned The White House is a government site so it must offer an accessible experience for all users When you arrive on the homepage you are greeted with a section where you can toggle high contrast and alter the text size As you can see there is alt text too Then at the bottom of the page you can learn more about accessibility by checking out the accessibility statement page Image Source 8 Sandy Liang Fashion brand Sandy Liang shows us how its done with accessible website design This site excels at catering to all visitors regardless of ability When you arrive on Sandy Liangs site you can click the accessibility icon in the bottom right corner Once there you can make selections to update the site to your preferences including seizure safety settings visual impairment accessibility ADHDfriendly cognitive disabilityassistive and beyond You can also alter the font make color adjustments and more Image Source Designing Websites for Everyone Although not legally required its wise to make as much of your website accessible and WCAGcompliant as possible Now that you know why web accessibility is essential you can prioritize it in your site design This will create a memorable and positive UX and help you boost customer loyalty By ensuring your site is accessible youre doing the right thing for the people who matter most to your business  your visitors and customers Be sure to use the tools listed above and review the examples we listed for inspiration when making your site accessible Editors note This post was originally published in February 2021 and has been updated for comprehensiveness Topics Web Accessibility Dont forget to share this post Related Articles prev next Designing for Accessibility The Complete Guide Oct 09 2023 ARIA Accessibility The Beginners Guide to Understanding How it Works Aug 02 2023 How to Run a Web Accessibility Audit Jul 18 2023 Understanding the Web Accessibility Initiative WAI A Comprehensive Guide Jul 13 2023 Website Accessibility Mistakes Novice Designers Make Jul 12 2023 12 Web Accessibility Resources Every Developer Needs May 04 2023 Website Accessibility 25 Statistics that Prove It Matters Mar 21 2023 What is an ADACompliant Website The Complete Guide Mar 06 2023 Best Fonts for Accessibility and Visually Impaired Users ADACompliant Fonts Mar 01 2023 10 Most Common Website Accessibility Issues Examples Mar 01 2023 4 Download Now Free Website Accessibility Checklist FEATURED RESOURCE Website Accessibility Checklist Available as an interactive PDF and on Google Sheets 4 Download on the  App Store P Googe Play img srcdecorativepng alt ,https://blog.hubspot.com/website/web-accessibility,UI/UX Design,1061,3401
Performance Optimization, 6Performance Optimization Designing for peak efficiency ensures that your TopLink application is fast smooth and accurate This chapter discusses how to optimize TopLinkenabled applications It discusses Basic performance optimization TopLink writing optimization features Schema optimization Basic performance optimization Performance consideration should be factored into every part of the development cycle This means that you should be aware of performance issues in your design and implementation This does not mean however that you should try to optimize performance in the first iteration Optimizations that complicate the design or implementation should be left until the final iteration of your application However you should plan for these performance optimizations from your first iteration to make it easier to integrate them later The single most important aspect of performance optimization is knowing what to optimize To improve the performance of your application you must fully understand exactly what areas of your application have performance problems You must also fully understand the causes of performance problems TopLink provides a diverse set of features to optimize performance Most of these features can be turned on or off in the descriptors andor database session and result in a global system performance improvement without any changes to application code When optimizing the performance of your application you should first check to see if a TopLink feature can solve the optimization problem If no such feature is present then you should consider more complex optimizations such as those provided in the later sections of this chapter TopLink reading optimization features Certain read and write operations can be optimized through TopLink The following two key concepts are used to optimize reading changing how much data is read from the database changing the way the data is queried from the database Table 61 lists the read optimization features provided with TopLink Table 61 Read optimization features Feature Effect on performance Unit of Work Tracks object changes within the unit of work Only register objects that will change to minimize the amount of tracking required Object indirection Value holders are used to stand in for real domain objects to avoid reading them until they are accessed The usage of value holders is strongly recommended as they provide a major performance benefit Weak identity map Clientside caching of objects read from database The clientside cache holds only objects referenced by the application Avoids database calls by reading objects from cache Efficient use of memory The benefit of caching with the weak identity map may not be as great as the soft cache weak identity map but it uses less memory Soft cache weak identity map Clientside caching of objects read from database The clientside cache holds only objects referenced by the application and releases objects not referenced by the application when memory becomes low Avoids database calls by reading objects from cache Efficient use of memory Gives the benefit of caching but does not cause memory problems Full identity map Client side caching of objects read from the database This permits database calls to be avoided if the object has already been read in Caution Ensure that the cache size does not grow too large as this may cause severe performance problems Cache identity map Client side cache that will always use only a fixed amount of memory Gives the benefit of caching but does not cause memory problems No identity map Cache lookup can be avoided completely for objects that do not need to be cached Batch reading and joining Both of these features can be used to dramatically reduce the number of database accesses that are required to perform a read query Reduces database access by batching many queries into a single query that reads more data Partial object reading Allows reading of a subset of a result set of the objects attributes Reduces the amount of data that needs to be read from the database to improve performance Report query Similar to partial object reading but returns only the data instead of the objects Gives the same performance benefit as partial object reading The report query also supports complex reporting functions such as aggregation functions and group by Complex results can be computed on the database instead of reading the objects into the application and computing the result in memory Reading Case 1 Displaying names in a list  optimized through partial object reading and report query An application often asks the user to choose a particular element from a list The list displays only a subset of the information contained in the objects and therefore it is wasteful to query all of the information for all of the objects from the database It is possible to query only the information required to display in the list and then when the user chooses one read only that object from the database TopLink has two features partial object reading and report query that allow the performance of these types of operations to be optimized Partial object reading Partial object reading is a query designed to extract only the required information from a selected record in a database rather than all of the information the record contains When using partial object reading the object is not fully populated so it cannot be cached Consequently the object cannot be edited Because the primary key is required to requery the object so it can be edited for example and because TopLink does not automatically include the primary key information in a partially populated object the primary key must be explicitly specified as a partial attribute Example 61 No optimization  Read all the employees from the database ask the user to choose one and return it This must read in all the information for all of the employees List list  Fetch data from database and add to list box Vector employees  Vector sessionreadAllObjectsEmployeeclass listaddAllemployees  Display list box   Get selected employee from list Employee selectedEmployee  Employee listgetSelectedItem return selectedEmployee Example 62 Optimization through partial object reading  Read all the employees from the database ask the user to choose one and return it This uses partial object reading to read just the last name of the employees Note that TopLink does not automatically include the primary key of the object If this is needed to select the object for a query it must be specified as a partial attribute so that it can be included In this way the object can easily be read for editing  List list  Fetch data from database and add to list box ReadAllQuery query  new ReadAllQueryEmployeeclass queryaddPartialAttributelastName  add this if the primary key is required for requerying the object queryaddPartialAttributeid  TopLink does not automatically include the primary key of the object If this is needed to select the object for a query it must be specified as a partial attribute so that it can be included queryaddPartialAttributeid querydontMaintainCache Vector employees  Vector sessionexecuteQueryquery listaddAllemployees  Display list box   Get selected employee from list Employee selectedEmployee  EmployeesessionreadObjectlistgetSelectedItem return selectedEmployee Note If querydontMaintainCache is not included in this example a query exception is thrown Example 63 Optimization through report query  Read all the employees from the database ask the user to choose one and return it This uses the report query to read just the last name of the employees It then uses the primary key stored in the report query result to read the real object List list  Fetch data from database and add to list box ExpressionBuilder builder  new ExpressionBuilder ReportQuery query  new ReportQuery Employeeclass builder queryaddAttributelastName queryretrievePrimaryKeys Vector reportRows  Vector sessionexecuteQueryquery listaddAllreportRows  Display list box   Get selected employee from list Employee selectedEmployee  Employee ReportResultlistgetSelectedItemreadObject return selectedEmployee Conclusion Although the differences between the two examples are slight there is a substantial performance improvement by using partial objects and report query In the example called No optimization  all of the full employee objects are created even though only the employees last name is displayed in the list All of the data that makes up an employee object must be read In the example called Optimization through partial object reading  partial object reading is used to read only the last name and the primary key if specified of the employees Read employee objects are still created but only the last name and primary key is set The other employee attributes are left as null or as their constructor defaults This reduces the amount of data read from the database In this example the report query is used to read only the last name of the employees This reduces the amount of data read from the database and avoids instantiating any employee instances Specifying fewer partial attributes and querying larger objects improves the overall performance gain of these optimizations Reading Case 2 Batch reading objects The amount of data read by your application affects performance but how that data is read also affects performance Reading a collection of rows from the database is significantly faster than reading each row individually The most common performance problem is reading a collection of objects that have a onetoone reference to another object If this is done without optimizing how the objects are read N  1 database calls are required That is one read operation is required to read in all of the source rows and one call for each target row is required in the onetoone relationship The next three examples show a twophase query that reads the addresses of a set of employees individually and then reads them using TopLinks query optimization features The optimized read accesses the database only twice so it is significantly faster Example 64 No optimization Read all the employees and collect their address cities This takes N  1 queries if not optimized   Read all of the employees from the database This requires 1 SQL call Vector employees  sessionreadAllObjectsEmployeeclassnew ExpressionBuildergetlastNameequalSmith SQL Select  from Employee where l_name  Smith  Iterate over employees and get their addresses  This requires N SQL calls Enumeration enum  employeeselements Vector cities  new Vector whileenumhasMoreElements Employee employee  Employee enumnextElement citiesaddElementemployeegetAddressgetCity SQL Select  from Address where address_id  123 etc  Example 65 Optimization through joining  Read all the employees and collect their address cities Although the code is almost identical because joining optimization is used it only takes 1 query   Read all of the employees from the database using joining This requires 1 SQL call ReadAllQuery query  new ReadAllQuery querysetReferenceClassEmployeeclass querysetSelectionCriterianew ExpressionBuildergetlastNameequalSmith queryaddJoinedAttributeaddress Vector employees  sessionexecuteQueryquery  SQL Select E A from Employee E Address A where El_name  Smith and Eaddress_id  Aaddress_id Iterate over employees and get their addresses The previous SQL already read all of the addresses so no SQL is required Enumeration enum  employeeselements Vector cities  new Vector while enumhasMoreElements  Employee employee  Employee enumnextElement citiesaddElementemployeegetAddressgetCity Example 66 Optimization through batch reading  Read all the employees and collect their address cities Although the code is almost identical because batch reading optimization is used it only takes 2 queries   Read all of the employees from the database using batch reading This requires 1 SQL call note that only the employees are read ReadAllQuery query  new ReadAllQuery querysetReferenceClassEmployeeclass querysetSelectionCriterianew ExpressionBuildergetlastNameequalSmith queryaddBatchReadAttributeaddress Vector employees  VectorsessionexecuteQueryquery  SQL Select  from Employee where l_name  Smith  Iterate over employees and get their addresses  The first address accessed will cause all of the addresses to be read in a single SQL call Enumeration enum  employeeselements Vector cities  new Vector while enumhasMoreElements  Employee employee  Employee enumnextElement citiesaddElementemployeegetAddress getCity  SQL Select distinct A from Employee E Address A where El_name  Smith and Eaddress_id  Aaddress_i  Conclusion By using TopLink query optimization a number of queries are reduced to a single query This leads to much greater performance It may seem that because joining requires only a single query that batch reading would never be required The advantage of batch reading is that it allows for delayed loading through value holders and has much better performance where the target objects are shared For example if all of the employees lived at the same address batch reading would read much less data than joining because batch reading uses a SQL DISTINCT to filter duplicate data Batch reading is also supported for onetomany relationships where joining is supported only for onetoone relationships Although this technique is very efficient it should only be used when all of the desired objects such as addresses are required Otherwise the resources spent reading all of the objects could hurt performance Reading Case 3 Using complex custom SQL queries TopLink provides a highlevel query mechanism This query mechanism is powerful but currently does not support everything possible through raw SQL If you have a complex query required by your application and the query must be done optimally the best solution in many cases is to use raw SQL Reading Case 4 Viewing objects Some parts of an application may require information from a variety of objects rather than from just one object This can be very difficult to implement and very performance intensive In such situations it may be advantageous to define a new readonly object to encapsulate this information and map it to a view on the database Set the object to be readonly by using the addDefaultReadOnlyClass API in the oracletoplinksessionsProject class Example 67 No optimization  Gather the information to report on an employee and return the summary of the information In this situation a hashtable is used to hold the report information Notice that this reads a lot of objects from the database but uses very little of the information contained in the objects This may take 5 queries and read in a large number of objects public Hashtable reportOnEmployeeString employeeName  Vector projects associations Hashtable report  new Hashtable  Retrieve employee from database Employee employee  sessionreadObjectEmployeeclass new ExpressionBuildergetlastNameequalemployeeName  Get all of the projects affiliated with the employee projects  sessionreadAllObjectsProjectclass SELECT P FROM PROJECT P EMPLOYEE E WHERE PMEMBER_ID  EEMP_ID AND EL_NAME    employeeName  Get all of the associations affiliated with the employeeassociations sessionreadAllObjectsAssociationclass SELECT A FROM ASSOC A EMPLOYEE E WHERE AMEMBER_ID  EEMP_ID AND EL_NAME    employeeName  reportputfirstName employeegetFirstName reportputlastName employeegetLastName reportputmanager employeegetManager reportputcity employeegetAddressgetCity reportputprojects projects reportputassociations associations return report Example 68 Optimization through view object CREATE VIEW NAMED EMPLOYEE_VIEW AS SELECT F_NAME  EF_NAME L_NAME  EL_ NAMEEMP_ID  EEMP_ID MANAGER_NAME  ENAME CITY  ACITY NAME  ENAME FROM EMPLOYEE E EMPLOYEE M ADDRESS A WHERE EMANAGER_ID  MEMP_ID AND EADDRESS_ID  AADDRESS_ID Then define a descriptor for the EmployeeReport class Define the descriptor as normal however set tableName to be EMPLOYEE_VIEW Map only the attributes required for the report in the case of numberOfProjects and associations a transformation mapping can be used to get the required data Now the report can be queried from the database like any other TopLinkenabled object Example 69 With optimization  Return the report for the employee public EmployeeReport reportOnEmployeeString employeeName  EmployeeReport report report  EmployeeReport sessionreadObjectEmployeeReportclass new ExpressionBuildergetlastNameequal employeeName return report TopLink writing optimization features Table 62 lists the write optimization features provided with TopLink Table 62 Write optimization features Feature Effect on performance Unit of Work Minimal update of object changes on commit of the unit of work Improves performance by updating only the changed fields and objects Tracks object changes within the unit of work Minimizes the amount of tracking required which can be expensive by registering only those objects that will change Note The unit of work supports marking classes as readonly which allows the unit of work to avoid tracking changes of objects that will not be changed Parameterized SQL The session or an individual query can be configured to use a prepared statement and cache the statement thus avoiding the SQL prepare call on subsequent executions of the query Performance improves in situations when the same SQL statement is executed many times Batch writing Supported in both JDK 11 and JDK 12 Allows for all of the insert update and delete commands from a transaction to be grouped into a single database call Performance improves dramatically because the number of calls to the database is reduced Sequence number preallocation Sequence numbers are cached preallocated on the client side to dramatically improve insert performance Does exist alternatives Does exist call on write object can be avoided in certain situations by checking the cache for does exist or assuming existence Writing Case 1 Batch writes TopLink also provides several write optimization features The most common write performance problem is a batch job that inserts a large volume of data into the database Consider a batch job that requires to load a large amount of data from one database and migrate the data into another Assume that the objects are simple employee objects that use generated sequence numbers as their primary key and have an address that also uses a sequence number The batch job requires to load 10000 employees from the first database and insert them into the target database First lets approach the problem naively and have the batch job read all of the employees from the source database and then acquire a unit of work from the target database register all of the objects and commit the unit of work Example 610 No optimization  Read all the employees acquire a unit of work and register them   Read all of the employees from the database This requires 1 SQL call but will be very memory intensive as 10000 objects will be read Vector employees  sourceSessionreadAllObjectsEmployeeclass SQL Select  from Employee  Acquire a unit of work and register the employees UnitOfWork uow  targetSessionacquireUnitOfWork uowregisterAllObjectsemployees uowcommit SQL Begin transaction SQL Update Sequence set count  count  1 where name  EMP SQL Select count from Sequence SQL  repeat this 10000 times  10000 times for the addresses  SQL Commit transaction SQL Begin transaction SQL Insert into Adresss  values  SQL  repeat this 10000 times SQL Insert into Employee  values  SQL  repeat this 10000 times SQL Commit transaction This batch job would have extremely poor performance and would cause 60000 SQL executions It also reads huge amounts of data into memory that can cause memory performance issues There are a number of TopLink optimization that can be used to optimize this batch job Batching and cursoring The first performance problem is that loading from the source database may cause memory problems To optimize the problem a cursored stream should be used to read the employees from the source database Also a cache identity map should be used in both the source and target databases not a full identity map a weak identity map could be used in JDK 12 The cursor should be streamed in groups of 100 using the releasePrevious method after each read Each batch of 100 employees should be registered in a new unit of work and committed Although this does not change the amount of SQL executed it does fix the memory problems You should be able to notice a memory problem in a batch job through noticing the performance degrading over time and possible disk swapping occurring Sequence number preallocation SQL select calls are more expensive than SQL modify calls so the biggest performance gain is in reducing any select being issued In this example selects are used for the sequence numbers Using sequence number preallocation dramatically improves the performance In TopLink the sequence preallocation size can be configured on the login it defaults to 50 In the nonoptimized example we used a preallocation size of 1 to demonstrate this point Because batches of 100 are used a sequence preallocation size of 100 should also be used Because both employees and address use sequence number we can get even better preallocation by having them share the same sequence In this case we set the preallocation size to 200 This optimization reduces the number of SQL execution from 60000 to 20200 Batch writing TopLink supports batch writing on batch compliant databases in JDK 11 and through batch compliant JDBC 20 drivers in JDK 12 Batch writing allows for a group of SQL statements to be batched together into a single statement and sent to the database as a single database execution This reduces the communication time between the application and the server and can lead to huge performance increases Batch writing can be enabled on the login through the useBatchWriting method In our example each batch of 100 employees can be batched into a single SQL execution This reduces the number of SQL execution from 20200 to 300 Parameterized SQL TopLink supports parameterized SQL and prepared statement caching Using parameterized SQL can improve write performance by avoiding the prepare cost of a SQL execution through reusing the same prepared statement for multiple executions Batch writing and parameterized SQL cannot be used together because batch writing does not use individual statements The performance benefits of batch writing are much greater than parameterized SQL therefore if batch writing is supported by your database it is strongly suggested that you use batch writing and not use parameterized SQL Parameterized SQL avoids only the prepare part of the SQL execution not the execute therefore it normally does not give a huge performance gain However if your database does not support batch writing parameterized SQL can improve performance In this example the number of SQL executions is still 20200 but the number of SQL prepares is reduced to 4 Multiprocessing Multiple processes and even multiple machines can be used to split the batch job into several smaller jobs Splitting the batch job across ten threads leads to performance increases In this case the read from the cursored stream could be synchronized and parallel units of work could be used on a single machine Even if the machine has only a single processor this can lead to a performance increase During any SQL execution the thread must wait for a response from the server but in this waiting time the other threads can be processing The final optimized example does not show multiprocessing as normally the other features are enough to improve the performance Example 611 Fully optimized  Read each batch of employees acquire a unit of work and register them  targetSessiongetLoginuseBatchWriting targetSessiongetLoginsetSequencePreallocationSize200  Read all of the employees from the database into a stream This requires 1 SQL call but none of the rows will be fetched ReadAllQuery query  new ReadAllQuery querysetReferenceClassEmployeeclass queryuseCursoredStream CursoredStream stream stream  CursoredStream sourceSessionexecuteQueryquery SQL Select  from Employee Process each batch while  streamatEnd  Vector employees  streamread100  Acquire a unit of work to register the employees UnitOfWork uow  targetSessionacquireUnitOfWork uowregisterAllObjectsemployees uowcommit  SQL Begin transaction SQL Update Sequence set count  count  200 where name  SEQ SQL Select count from Sequence where name  SEQ SQL Commit transaction SQL Begin transaction BEGIN BATCH SQL Insert into Address  values   repeat this 100 times Insert into Employee  values   repeat this 100 times END BATCH SQL SQL Commit transactionJava optimization In most clientserver database applications most of the performance problems come from the communications between the client and the server This means that optimizing Java code is normally not as important as optimizing database interactions However you should still try to write clean optimized Java code since very poorly optimized Java code does affect the performance of your application Optimization check list The following is a general checklist to keep in mind when developing Java applications Do not make code more complicated than necessary Write encapsulated code so that complex behavior can be easily optimized within the encapsulation Use instance or static variables to cache the results of expensive computations Use hash tables for large collections that are looked up by key Always provide default sizes to vectors and hash tables if only a few elements will be added to them Postpone executing expensive tasks until absolutely necessary Make use of multitasking to perform background jobs When performing a lot of String manipulations use a StringBuffer instead of the  operator for appending Strings Consider lazy initialization in cases where the values initialization in the constructor is normally not required If using RMI or CORBA avoid finegrain remote message sends Schema optimization When designing your database schema and object model optimization is very important The key element to remember in the design of your object model and database schema is to avoid complexity The most common objectrelational performance problem is when the database schema is derived directly from a complex object model This normally produces an overnormalized database schema that can be slow and difficult to query Although it is best to design the object model and database schema together there should not be a direct onetoone mapping between the two Schema Case 1 Aggregation of two tables into one A common schema optimization technique is to de normalize two tables into one This can improve read and write performance by requiring only one database operation instead of two This technique is demonstrated through analyzing the ACME Member Location Tracking System Table 63 Original schema Elements Details Title ACME Member Location Tracking System Classes Member Address Tables MEMBER ADDRESS Relationships Source Instance Variable Mapping Target Member address onetoone Address Table 64 Optimized schema Elements Details Classes Member Address Tables MEMBER Relationships Source Instance Variable Mapping Target Member address aggregate Address Domain In the ACME Member Location Tracking System employees and addresses are always looked up together Problem Querying a member based on address information requires an expensive database join Reading a member and its address requires two read statements Writing a member requires two write statements This unnecessarily adds complexity to the system and results in poor performance Solution Since members are always read and written with their address information considerable performance can be gained through combining the MEMBER and ADDRESS tables into a single table and changing the onetoone relationship to an aggregate relationship This allows all of the information to be read in a single operation and doubles the speed of updates and inserts as only one row from one table is modified Schema Case 2 Splitting one table into many This example demonstrates how a table schema can be further normalized to provide performance optimization Frequently relational schemas can stuff too much data into a particular table The table may contain a large number of columns but only a small subset of those may be frequently used By splitting the large table into two or even several smaller tables the amount of data traffic can be significantly reduced improving the overall performance of the system Table 65 Original schema Elements Details Title ACME Employee Workflow System Classes Employee Address PhoneNumber EmailAddress JobClassification Project Tables EMPLOYEE PROJECT PROJ_EMP Relationships Source Instance Variable Mapping Target Employee address aggregate Address Employee phoneNumber aggregate EmailAddress Employee emailAddress aggregate EmailAddress Employee job aggregate JobClassification Employee projects manytomany Project Table 66 Optimized schema Elements Details Classes Employee Address PhoneNumber EmailAddress JobClassification Project Tables EMPLOYEE ADDRESS PHONE EMAIL JOB PROJECT PROJ_EMP Relationships Source Instance Variable Mapping Target Employee address onetoone Address Employee phoneNumber onetoone EmailAddress Employee emailAddress onetoone EmailAddress Employee job onetoone JobClassification Employee projects manytomany Project Domain This system is responsible for assigning employees to projects within an organization The mostcommon operation is to read a set of employees and projects assign some employees to different projects and update the employees Occasionally the employees address or job classification is used to determine which project would be the best placement for the employee Problem When a large volume of employees is read from the database at one time their aggregate parts must also be read Because of this the system suffers from a general read performance problem The only solution is to reduce the amount of data traffic to and from the server Solution In this system normalize the EMPLOYEE table into the EMPLOYEE ADDRESS PHONE EMAIL and JOB tables Since normally only the employee information is read the amount of data transferred from the database to the client is reduced by splitting the table This improves your read performance by reducing the amount of data traffic by 25 Schema Case 3 Collapsed hierarchy When models are designed in an objectoriented design and then transformed into a relational model a common mistake is to make a large hierarchy of tables on the database This makes it necessary to perform a large number of joins and makes querying difficult Normally it is a good idea to collapse some of the levels in your inheritance hierarchy into a single table Table 67 Original schema Elements Details Title ACME Sales Force System Classes Tables Person PERSON Employee PERSON EMPLOYEE SalesRep PERSON EMPLOYEE REP Staff PERSON EMPLOYEE STAFF Client PERSON CLIENT Contact PERSON CONTACT Table 68 Optimized schema Elements Details Classes Tables Person none Employee EMPLOYEE SalesRep EMPLOYEE Staff EMPLOYEE Client CLIENT Contact CLIENT Domain In this system the clients of the company are assigned to its sales force representatives The managers track which sales representatives are under them Problem The system suffers from overcomplexity which hinders the development and performance of the system Large expensive joins are required to do almost anything making every database operation expensive Solution By collapsing the threelevel table hierarchy into one the complexity of the system is reduced All of the expensive joins in the system are eliminated and simplified queries allow read performance to be further optimized leading to greatly improved system performance Schema Case 4 Choosing one out of many A common situation is for an object to have a collection of other objects where only one of the other objects in the collection is commonly used In this situation it is desirable to add an instance variable just for this special object This way the important object can be accessed and used without requiring the instantiation of all of the other objects in the collection Table 69 Original schema Elements Details Title ACME Shipping Package Location Tracking System Classes Package Location Tables PACKAGE LOCATION Relationships Source Instance Variable Mapping Target Package locations onetomany Location Table 610 Optimized schema Elements Details Classes Package Location Tables PACKAGE LOCATION Relationships Source Instance Variable Mapping Target Package locations onetomany Location Package currentLocation onetoone Location Domain This system is used by an international shipping company which wants to be able to track the location of its packages as they travel from their source to their destination When a package is moved from one location to another a location is created in realtime on the database The application normally receives a request for the current location of a particular package and displays this for the user Problem A package could accumulate many locations as it travels to its destination so reading all of these locations from the database is expensive Solution By adding a specific instance variable for just the current location and a onetoone mapping for the instance variable the current location can be accessed without reading in all of the other locations This drastically improves the performance of the system Oracle9iAS TopLink Foundation Library GuideRelease 2 903Part Number B1006401 HomennSolution AreannContentsnnIndex Home Solution Area Contents Index 0 Oracle9iAS TopLink Foundation Library GuideRelease 2 903Part Number B1006401 HomennSolution AreannContentsnnIndex Home Solution Area Contents Index Home Solution Area Contents Index 0 Home Solution Area Contents Index Feature Effect on performance 0 Feature Effect on performance 1 Unit of Work Tracks object changes within the unit of work Only register objects that will change to minimize the amount of tracking required 2 Object indirection Value holders are used to stand in for real domain objects to avoid reading them until they are accessedrnnrnThe usage of value holders is strongly recommended as they provide a major performance benefit 3 Weak identity map Clientside caching of objects read from database The clientside cache holds only objects referenced by the application Avoids database calls by reading objects from cache Efficient use of memoryrnnrnThe benefit of caching with the weak identity map may not be as great as the soft cache weak identity map but it uses less memory 4 Soft cache weak identity map Clientside caching of objects read from database The clientside cache holds only objects referenced by the application and releases objects not referenced by the application when memory becomes low Avoids database calls by reading objects from cache Efficient use of memoryrnnrnGives the benefit of caching but does not cause memory problems 5 Full identity map Client side caching of objects read from the database This permits database calls to be avoided if the object has already been read inrnnnCaution Ensure that the cache size does not grow too large as this may cause severe performance problems 6 Cache identity map Client side cache that will always use only a fixed amount of memory rnnrnGives the benefit of caching but does not cause memory problems 7 No identity map Cache lookup can be avoided completely for objects that do not need to be cached 8 Batch reading and joining Both of these features can be used to dramatically reduce the number of database accesses that are required to perform a read query Reduces database access by batching many queries into a single query that reads more data 9 Partial object reading Allows reading of a subset of a result set of the objects attributes Reduces the amount of data that needs to be read from the database to improve performance 10 Report query Similar to partial object reading but returns only the data instead of the objects Gives the same performance benefit as partial object readingrnnrnThe report query also supports complex reporting functions such as aggregation functions and group by Complex results can be computed on the database instead of reading the objects into the application and computing the result in memory NotennrnIf querydontMaintainCache is not included in this example a query exception is thrown 0 NotennrnIf querydontMaintainCache is not included in this example a query exception is thrown Feature Effect on performance 0 Feature Effect on performance 1 Unit of Work Minimal update of object changes on commit of the unit of work Improves performance by updating only the changed fields and objectsrnnrnTracks object changes within the unit of work Minimizes the amount of tracking required which can be expensive by registering only those objects that will changernnnNote The unit of work supports marking classes as readonly which allows the unit of work to avoid tracking changes of objects that will not be changed 2 Parameterized SQL The session or an individual query can be configured to use a prepared statement and cache the statement thus avoiding the SQL prepare call on subsequent executions of the queryrnnrnPerformance improves in situations when the same SQL statement is executed many times 3 Batch writing Supported in both JDK 11 and JDK 12 Allows for all of the insert update and delete commands from a transaction to be grouped into a single database call Performance improves dramatically because the number of calls to the database is reduced 4 Sequence number preallocation Sequence numbers are cached preallocated on the client side to dramatically improve insert performance 5 Does exist alternatives Does exist call on write object can be avoided in certain situations by checking the cache for does exist or assuming existence Elements Details 0 Elements Details 1 Title ACME Member Location Tracking System 2 Classes Member Address 3 Tables MEMBER ADDRESS Elements Details 0 Elements Details 1 Relationships Source Instance Variable Mapping Target 2 Member address aggregate Address Elements Details 0 Elements Details 1 Relationships Source Instance Variable Mapping Target 2 Employee address aggregate Address 3 Employee phoneNumber aggregate EmailAddress 4 Employee emailAddress aggregate EmailAddress 5 Employee job aggregate JobClassification 6 Employee projects manytomany Project Elements Details 0 Elements Details 1 Relationships Source Instance Variable Mapping Target 2 Employee address onetoone Address 3 Employee phoneNumber onetoone EmailAddress 4 Employee emailAddress onetoone EmailAddress 5 Employee job onetoone JobClassification 6 Employee projects manytomany Project Elements Details 0 Elements Details 1 Title ACME Sales Force System 2 Classes Tables 3 Person PERSON 4 Employee PERSON EMPLOYEE 5 SalesRep PERSON EMPLOYEE REP 6 Staff PERSON EMPLOYEE STAFF 7 Client PERSON CLIENT 8 Contact PERSON CONTACT Elements Details 0 Elements Details 1 Classes Tables 2 Person none 3 Employee EMPLOYEE 4 SalesRep EMPLOYEE 5 Staff EMPLOYEE 6 Client CLIENT 7 Contact CLIENT Elements Details 0 Elements Details 1 Relationships Source Instance Variable Mapping Target 2 Package locations onetomany Location Elements Details 0 Elements Details 1 Relationships Source Instance Variable Mapping Target 2 Package locations onetomany Location 3 Package currentLocation onetoone Location Copyright  2002 Oracle CorporationnnAll Rights Reserved HomennSolution AreannContentsnnIndex Home Solution Area Contents Index 0 Copyright  2002 Oracle CorporationnnAll Rights Reserved HomennSolution AreannContentsnnIndex Home Solution Area Contents Index 0 Home Solution Area Contents Index 0 Home Solution Area Contents Index  Read all the employees from the database ask the user to choose one and return it This uses partial object reading to read just the last name of the employees Note that TopLink does not automatically include the primary key of the object If this is needed to select the object for a query it must be specified as a partial attribute so that it can be included In this way the object can easily be read for editing   TopLink does not automatically include the primary key of the object If this is needed to select the object for a query it must be specified as a partial attribute so that it can be included  Read all the employees from the database ask the user to choose one and return it This uses the report query to read just the last name of the employees It then uses the primary key stored in the report query result to read the real object  Fetch data from database and add to list box  Display list box  Get selected employee from list  Read all of the employees from the database This requires 1 SQL call SQL Select  from Employee where l_name  Smith  Iterate over employees and get their addresses  This requires N SQL calls  Read all the employees and collect their address cities Although the code is almost identical because joining optimization is used it only takes 1 query   SQL Select E A from Employee E Address A where El_name  Smith and Eaddress_id  Aaddress_id Iterate over employees and get their addresses The previous SQL already read all of the addresses so no SQL is required  Read all the employees and collect their address cities Although the code is almost identical because batch reading optimization is used it only takes 2 queries   Read all of the employees from the database using batch reading This requires 1 SQL call note that only the employees are read  SQL Select  from Employee where l_name  Smith  Iterate over employees and get their addresses  The first address accessed will cause all of the addresses to be read in a single SQL call  SQL Select distinct A from Employee E Address A where El_name  Smith and Eaddress_id  Aaddress_i  Retrieve employee from database  Get all of the associations affiliated with the employeeassociations sessionreadAllObjectsAssociationclass SELECT A FROM ASSOC A EMPLOYEE E WHERE AMEMBER_ID  EEMP_ID AND EL_NAME    employeeName Vector employees  sourceSessionreadAllObjectsEmployeeclass UnitOfWork uow  targetSessionacquireUnitOfWork uowregisterAllObjectsemployees uowcommit ,https://docs.oracle.com/cd/A97329_03/toplink.903/b10064/performa.htm,Optimization,1116,6455
Progressive Web Apps (PWAs)," June 27 2023  Progressive Web App What is a PWA Progressive Web Apps for Beginners Hillary Nyakundi These days everything is made possible with the help of mobile phones and applicationsLets say you need to order food  you can do so instantly via the companys app Maybe you need government services  the same thing applies You can even get medical emergency dial services via an appTheres an app for everything  from banking to studying and from trading to shopping Every business has an app and even our governments have simplified their services into app formHold on building and maintaining an app is cumbersome and its quite expensive for small businesses so how do they manageWell its simple with the help of advancements in technology there is an option that helps small businesses out This option combines the features of an app with the technology used in web development to build affordable services for businesses  Im talking about Progressive Web AppsLets dive in and get a better understanding of what PWAs are all aboutWhat is a Progressive Web AppProgressive Web Applications PWAs are apps built with web technologies that we probably all know and love like HTML CSS and JavaScript But they have the feel and functionality of an actual native app Wait a minute Native Apps what do we mean by thisA Native App is a software application built in a specific programming language for a specific device platform either IOS or AndroidPWAs are built with the capabilities like push notifications and the ability to work offline They are also built on and enhanced with modern APIs which makes it easy to deliver improved capabilities along with reliability and the ability to install them on any devicePWAs takes advantage of the huge web ecosystem this is inclusive of the plugins and community and the relative ease of deploying and keeping a website contrary to a native application which is pretty difficult to develop This means you can build a PWA quickly and easilyWith its popularity many companies have shifted into the product I tend to believe that this is because of its ability to run on an android and iOS without much difference Some good examples of top companies who have their products as PWAs include Twitter Pintrest Uber Tiktok Spotify Jumia a leading ecommerce site in Africa etcA common feature about this products is that they are all installable on your home screen able to work offline from where you last left and offer a comparable experience and features to their native appsJust like when building a native mobile app there are some expectations that should be met to make a good product for consumer use the same thing applies to PWAs Lets discuss what makes a good PWACharacteristics of PWAsBelow is what should be considered when developing a PWAResponsivenessDifferent companies produce gadgets with different screen sizes and as a developer its your responsibility to ensure all the different users enjoy the product regardless the device they are using So its a good idea to make sure your app can be used on any screen size and its content is available at any viewport sizeInstallableResearch has shown that users tend to engage more with installed apps compared to visiting the official sites Having a PWA as your product gives the users the look feel and engagement of a normal appIndependent ConnectivityBy keeping a user engaged to your app even while they are offline provides a more consistent experience than dropping them back to a default offline pageA good example to illustrate this will be that of a music app your users should be able to access offline playback and listen to saved music even without internet connection Another good example is twitter app a user is able to go back a read through tweets which they might have missedDiscoverabilitySince most PWAs are converted websites it is fair to make them discoverable on the search engines this will help generate extra traffic to your app This also acts as an advantage over native apps which cant be discovered over the search enginesAppearanceThe appearance of the app should feel and look like that of a normal app so be sure to include things like an app icon this will help make it easily recognizable also things like splash screen will add the touch and feel of an appCross PlatformPWAs are developed as web app first which means that they need to work on all browserssystems and not just a selected few Users should be able to use them in any browser before they decide to install themSo folks there you have it the general info about PWAs Along the way you might have noticed occasionally a comparison between PWAs and Native App and this might have confused you a bit Well lets clear the airwaves by checking the comparison between the two to get a clear understandingDifferences Between PWAs and Native AppsDevelopment CostPWAs are cheaper to develop compared to Native AppsWhen youre developing a native app youll have to learn a certain programming language and then build a version of the app for each type of device Android and iOS On the other hand you can choose to hire a experienced professional to do the work for you which will even turn out to be more costlyDown the road you will also need resources to maintain and update the app which means lots of money and time is requiredIn the case of a PWA you can have a single codebase for the different platforms Its also timesaving since you will not need to develop it from scratch you can configure your current web site to fitAnd if you choose to hire developer it will only be one compared to native where you can hire upto two depending on where you need your appDiscoverabilityNative apps cannot be indexed by the search engines they can just be found through the AppPlay stores website You can make your app more discoverable on the AppPlay store by using App Store OptimizationASO but thats another storyUnlike native apps PWAs work like websites so they can be indexed by search engines This helps them rank better in search resultsSafetyNowadays in order to run a website it should be encrypted with a SSL certificate this adds an extra layer of security Now as we already know PWAs are site converted into app which means they are more secure because they run on HTTPS These are security protocols that allow safe exchange of data between client and server so that is doesnt get tampered withTo secure your native apps you need to implement various security measures like multifactor authentication and so onInstallation and DownloadNative apps need to be downloaded and installed from an app store This requires some commitment from the user to do it from start to finish Users have to pass and check multiple permissions before installing an appOn the other hand PWAs dont require any of those steps From the browser you can bookmark it and add the app to your home screen with just a few tapsBenefits of PWAsA lot of organizations both private and public are switching to PWAs not only because they are cheap to develop but also because they offer greater engagementNow lets look at a quick summary of the benefits of a PWAThey are responsive and work with many different screen sizesThey can run on multiple platforms and any device with a modern web browserThey function just like normal Native AppsThe updates are independent you dont need to visit the play store for an updateTheyre built with common web technologiesTheyre fast and lightweightThey work offline unlike other sitesThey are discoverable via search engineThey are easily installableLow maintenance costRequirements to Get Started with PWA DevelopmentIt does not take much to get started building a PWA You just need a few things and you are good to goToolsThe best known technology stack to develop PWAs is AngularJS Speaking of Angular here is a resourceful guide on how you can convert your already existing Angular app into PWA Others stacks include ReactJS and PolymerHTTPSYou will need a server with a HTTPS connection This makes sure your users data is secure It adds an extra layer of security to you siteApplication ShellIt provides a good first impression when your app loads In simpler words this is what the user sees when they interact with your app for the first timeService workersThis is one of the key technologies behind PWAs They help support your app work offline and they perform advanced caching and run background tasks Service workers can complete tasks even when your PWA is not runningSome other functions associated with Service Worker includeSending push notificationBadging iconsRunning background fetch tasks etcManifest fileThis is a JSON file that is created with a Web App Manifest Generator This file contains the information that tells how your PWA should appear and function It allows you to determine the name description icon colors and other features of your PWA Heres an example of a manifest file short_name DevBlogger name DevBlogger description All dev stories under one roof theme_color eb5252 background_color 000000 display fullscreen Scope  orientation portrait icons   src imagesandroidandroidlaunchericon4848png type imagepng sizes 48x48   src imagesandroidandroidlaunchericon9696png type imagepng sizes 96x96   src imagesandroidandroidlaunchericon192192png type imagepng sizes 192x192   start_url indexhtmlutm_sourcehomescreen  Audit your AppThis is possible using the Google Lighthouse tool Google Lighthouse is a opensource software that anyone can use on any webpage Google is a big champion of PWAs and pushes them as the future of the web You can use Lighthouse to help you see how fast accessible and SEO readiness your PWA isHow to Build a PWABy following the steps below you can easily create a fully functional PWA that offers an mazing user experience across all devicesStep 1  Plan your appBefore diving into development you should consider the goals of your PWA what features you want to include priorities and user experience You can create first design concepts and wireframes for the app to visualize the structure and layoutIn most scenarios this is often referred to as a discovery phase You get the opportunity to ideate and gather user and stakeholder feedback as well as considering the functionalities of your to be productStep 2  Designing the User InterfaceAfter getting everything right from planning you can now proceed to designing the UI of your app During this stage consider things like responsiveness compatibility with different platforms etc Be sure to capture all details that are crucial to the user including their interaction and engagement during usageStep 3  Developing the FrontEndUsing the web technologies that is HTML CSS JavaScript and frameworks like Angular React or Vuejs develop a visually appealing interface for the users And always remember they key principle in development using this stack implement a mobile first approach while ensuring responsiveness for larger screens tooStep 4  Implementing Service WorkersAs mentioned previously service workers are a key component of PWAs They are JavaScript files that run in the background enabling offline functionality push notifications and caching To make sure your PWA works to its fullest potential youll need to register and implement a service worker The way on how you can do this massively depends on which framework you are usingStep 5  Adding Push NotificationsLeverage the Push API and service workers to implement push notifications Obtain the necessary user consent and use a push notification service to send notifications to usersStep 6  Optimizing PerformanceOptimization is a very important step in development in general This is how you provide a seamless experience to your users by ensuring you reduce loading times by leveraging techniques such as code splitting and caching we should be able to achieve a fast and efficient operation for our PWAStep 7  Testing and DebuggingTest your PWA on different devices browsers and network condition to be sure that it meets the objective Also be sure to gather user feedback and make necessary improvements when necessaryResources to Get Started with PWA DevelopmentIf you want to learn and move with the trend finding resources to help you might be a bit tedious to help you get started here are some of the best resources listed for youOnline Tutorials and GuidesGoogle Developers  Progressive Web AppsMDN Web Docs  Progressive Web AppsfreeCodeCamp  Frontend TechnologiesLearn PWADocumentation and Reference MaterialsService Workers API DocumentationProgressive Web Apps PWAsPWA Development ToolsWorkbox  Offline Caching and Service Worker LibraryPWA Builder  PWA Generation PlatformConclusionKeeping in mind that PWAs are new to the industry and havent yet been fully utilized they can be a great addition to add to your toolkitWith the latest technologies and the right tools getting started with PWAs can ultimately increase sales and monetary gain for your product either as an individual or organization With its many features including they are fast able to work offline and also they perform like normal native apps This offers your users a great experience and keeps them satisfiedIf you have read this far I really appreciate itEnjoy Coding  ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT Hillary Nyakundi Technical Writer   OpenSource Enthusiast   Empowering Developers to Learn  Grow  Committed to Making a Meaningful Contribution to the Tech Community and Beyond If you read this far thank the author to show them you care Say Thanks Learn to code for free freeCodeCamps open source curriculum has helped more than 40000 people get jobs as developers Get started ADVERTISEMENT What is a PWA Progressive Web Apps for Beginners Slarymaki freeCodeCamp A  short_name DevBlogger name DevBlogger description All dev stories under one roof theme_color eb5252 background_color 000000 display fullscreen Scope  orientation portrait icons   src imagesandroidandroidlaunchericon4848png type imagepng sizes 48x48   src imagesandroidandroidlaunchericon9696png type imagepng sizes 96x96   src imagesandroidandroidlaunchericon192192png type imagepng sizes 192x192   start_url indexhtmlutm_sourcehomescreen  , TABLE OF CONTENTSOptions for Building an Ecommerce WebsiteFunctionality To Consider When Developing An Ecommerce Website6 Steps For Developing a Custom Ecommerce WebsiteThe Final WordFAQs About Ecommerce Website DevelopmentWith an estimated 12 million to 24 million active ecommerce sites around the world its easy for an online store to get lost in the crowd The key to standing out Topnotch website development that gives customers the experience they need Ecommerce website development is the process of developing the technical aspects of your ecommerce website  how it functions accepts payments behaves in response to user action and appears aesthetically Valued at 11 billion in 2022 the web development services industry opens the door for business owners to launch userfriendly websites and solve their most pressing ecommerce challenges which could include Determining the right features and functionality for your ecommerce project Understanding which ecommerce framework might work best for you Integrating ecommerce into a current website site or website template In this article well talk about what ecommerce web development is how you can find a developer or team of developers to help you realize your vision and the steps to take before launch Lets dive in Options for Building an Ecommerce WebsiteWhen it comes to building out your ecommerce store youll likely come across three options Build your website from scratch aka open source Customize a SaaS softwareasaservice solution Harness the power of MACH architecture Build it from scratch If you already have a web development or IT team in place going the opensource route may be your best bet Opensource ecommerce platforms are solutions in which you can modify all aspects of the code meaning you can build your website from scratch with few to no customization limits However keep in mind that using an opensource solution often means your business is responsible for things like PCI compliance web hosting security issues manual patches and updates For this reason some brands may view open source as too cumbersome expensive and techheavy especially as your business grows and complexity increases Customize a SaaS solution Dont have the coding expertise or budget to build a solution from scratch Enter SaaS ecommerce SaaS is a subscriptionbased solution that is built and maintained by a thirdparty vendor and may be hosted in the cloud Instead of building and developing a custom solution yourself SaaS allows you to essentially rent the platform while the platform provider takes care of tasks such as product updates security hosting PCI compliance and everything else that comes with managing your own software For this reason SaaS solutions enable businesses to gotomarket quickly and affordably Some ecommerce solutions referred to as open SaaS even offer benefits from both opensource and SaaS platforms BigCommerce for example is one of the leading open SaaS ecommerce platforms for midmarket and enterprise brands With our open API merchants receive all the benefits of a SaaS platform  being hosted on behalf of BigCommerce a lower total cost of ownership and faster gotomarket time  as well as the flexibility to create custom integrations and functionality faster similar to using an opensource platform MACH Microservices APIFirst CloudNative and Headless For decades the traditional ecommerce model has tied together the frontend storefront and backend serverside into an allinone monolith setup While a monolith solution might be a smart choice for small and midsized SMB businesses with limited requirements it can present some challenges as your business scales and requires greater complexity such as launching multiple websites or expanding into new regions The solution MACH architecture MACH microservices APIfirst cloudnative SaaS and headless is a set of guiding principles using a bestofbreed approach to build enterprise software tech stacks Unlike monolithic architecture MACH allows you to choose the technology that best meets your business needs and future roadmap Microservices Microservices are small services that perform a very specific task and are brought together to build an application They are independently developed updated deployed and managed and each use different code APIfirst APIs application programming interface are what make it possible to connect and communicate to deliver content between two or more applications or services  which means the application needs to be built with APIs at the forefront Cloudnative A cloudnative application leverages the full capabilities of the cloud and SaaS technology to manage monitor and maintain the technology and license it through subscription services Headless Headless commerce architecture is the decoupling of the frontend presentation layer of a website from the backend ecommerce functionality This allows for greater design flexibility when creating the user interface and integrating various channels Monolith vs MACH A MACH Commerce Guide learn more about MACH and see if its right for you Download Your Guide How Do I Choose the Right Ecommerce Website Developer Next well look at what an ecommerce developer does and why its important that their skills align with your ecommerce web design needs According to research from PWC 73 of US consumers say customer experience is an important factor when purchasing online yet only 49 believe brands provide a good experience The best way to ensure your ecommerce web development team provides a better user experience on your site is by hiring one with experience designing andor developing for ecommerce With any luck or if like BigCommerce your platform has a strong partner program you can find ecommerce website development services that are familiar with the latest in ecommerce best practices and can produce a site that will delight your customers and boost your conversion rate Understand different developers strengths Some developers are great at bringing your brand to life through a beautifully designed frontend while others excel in backend customization and technical implementation When you evaluate developers for your online store make sure you know what their strengths are While some developers will be capable of both backend development and frontend design they more typically pick one as their primary focus Make sure that the developer you choose has skills aligned with your needs Here are some of the top elements to consider when developing your ecommerce website PCI compliance and web security SEO search engine optimization Multiple payment options and gateways CMS content management system integration Mobileresponsiveness Shopping cart design Product filtering Base your choice off your needs Dont choose a developer or development company until you deeply understand what you want from your ecommerce storefront and what skills will be necessary to make it happen For example if your ecommerce solution uses an opensource framework then a backend developer may be more essential than someone focusing on design though youll likely need both If youre using a SaaS platform you may need more frontend work than anything else  though you may also want someone wellversed in building APIs While most SaaS platforms have a relatively robust set of apps with prebuilt integrations further complexity is best handled by an expertFunctionality To Consider When Developing An Ecommerce WebsiteDifferent features and functionality you may want in your ecommerce site will vary based on your business model and unique needs Based on your set goals create a list of features your ecommerce website needs These should be closely aligned with your customer lifecycle For example a startup or small business may not need to support multiple currencies but this could be a crucial feature for a crossborder retailer An easy way to determine what shopping cart features you need is to work from general to specific List all the general musthaves such as preferred payment gateways or marketplace integrations Add extras that your business needs like automatic sales taxshipping rate calculation Prioritize all the nicetohaves from 1 to 5 with 1 being a crucial feature for driving revenues and 5 as a handy addon that could make your daytoday operations more efficient Responsive design By 2025 Statista forecasts that mobile commerce sales will make up over 10 of all US retail sales which would be a growth of 7 percent points since 2018 As more customers use mobile phones to shop online youll need a website that supports responsive mobilefriendly web design Or you could even have your web developer create a mobile app Either way the goal is to make sure you can deliver a consistent shopping experience whether your site is accessed on a desktop or mobile device Luckily the BigCommerce theme marketplace offers both free and premium fully responsive themes Professionally designed and developed using our Stencil theme platform our themes are optimized for multiple product catalogs and industries SEO capabilities SEO is a great distribution strategy for your content and an essential aspect of your website design Ranking highly on Google search engine for relevant keywords can help drive traffic to your site from interested users who are searching online SEO can organically deliver you potential clients with high intent who are more likely to convert which can make SEO traffic more costeffective Site speed According to a study by Google the probability of bounce increases dramatically with every couple seconds added to page load time Fastloading sites are also a plus for SEO since Google uses site speed as a ranking factor This is why you need to hire ecommerce website developers who know how to optimize your ecommerce store so that its not only functional and attractive but also fastloading CMS Content Management System A CMS content management system is crucial for an ecommerce site as it houses any dynamic content  such as blog posts visuals and any other blocks of content in a design  all in one place With a CMS youll be able to make changes to or add new content and the changes will be automatically reflected on your ecommerce website This way you can consistently keep your site updated with new content that supports your products Product Management Picture your favorite online retailer Chances are they consistently have the products in stock that you want they provide multiple versions of products and they offer promotions and discounts when needed As youre developing your ecommerce site make sure it has the functionality necessary to add edit and keep track of inventory so that you can consistently give customers the products they want Payments and Checkout In the age of Apple Pay PayPal and mobile wallets its no longer acceptable for ecommerce businesses to offer only one payment option In fact research shows that flexible and seamless payment options speed up the decisionmaking process for nine in 10 shoppers and even prompts them to spend more  which is why its crucial that your ecommerce platform can integrate with multiple payment gateways Luckily as a BigCommerce merchant you can build a custom checkout for your online shop and even offer oneclick checkout with apps like BoltSecurity Developing an online store means dealing with sensitive data such as customer phone numbers credit card numbers and other payment information  which means its your responsibility to handle it with care PCI Compliance standards must be met to accept payments or you may risk being charged fines termination of ability to accept payments loss of customer confidence and other fraudrelated financial consequences But the bare minimum provided by some platforms may not be enough Some platforms come with an SSL certificate but proper protection may mean thirdparty software or an additional investment in inhouse infrastructure Luckily BigCommerce stores come standard with Level 1 PCI compliance to make your site safe and secure This way you can spend your time building your business instead of worrying about security Integrations No ecommerce platform will come with every single feature you want natively Youll need to make sure your platform enables you to customize your site by offering plugins and integrations with solutions that you need How do you want your back office to run Many businesses prioritize connecting their ecommerce solution to existing ERP OMS PIM or CRM systems so make sure the integration you need is available with the platform you choose What kinds of digital marketing do you rely on If you want to deliver a personalized experience you may want to use a customer data platform Dig into what you can do with your data so you know whats possible with each ecommerce software Can you integrate your data with your email marketing system You may also want to consider things like onsite chat or SMS marketing and if you need to integrate with marketplaces like Amazon or with social media channels Marketing strategy As youre developing your online store begin building your ecommerce marketing strategy early on in the process This will help you to define the structure of your site and determine what features you may need For example if part of your marketing strategy is to advertise on social media channels you may want to incorporate social sharing options on your website Or if mobile commerce is a large part of your strategy then you may want to add push notifications or build a mobile app 6 Steps For Developing a Custom Ecommerce WebsiteIts not necessary  or even recommended  to build your ecommerce website from scratch There are many platforms that can help you create an ecommerce store with minimal coding or technical skill required on your part But determining your platform isnt the only thing you need to do before starting the development process Here are some things to consider before diving in 1 Understand your business goals The decision to sell online is a big one And you cant proceed with action until you figure out the operational bells and whistles To do that start with the why Why do you want to sell online To attract more business  thats easy But how exactly do you plan to make that happen Will you use your ecommerce business as an avenue for directtoconsumer sales Do you want to drive online traffic to supplement brickandmortar operations Do you want to expand a B2C business to B2B or vice versa Apart from your baseline goals think in terms of ecommerce metrics What kind of growth would you like to see postlaunch and how will you measure it For example whats your goal in terms of weekly online sales volume Do you plan to sell locally or internationally too Whats your plan for growing a customer lifetime value How many products do you plan to sell 2 Understand the intended shopping experience What kind of online shopping experience do you want to give your customers Some of the experiential features you may want to consider include but are not limited to Enabling your customers to filter search results by size color or price with the click of a button The ability to compare products sidebyside Offering an optimized onepage checkout experience Promotions discounts and other types of offers Think about whether your target audience wants a simple and quick shopping experience  as they might with necessities like some consumerpackaged goods  or if theyll take some time to browse your site and discover new products Youll likely want to structure your site for a different customer journey depending on your answer 3 Discuss platform options Luckily today you dont have to build your online store from scratch There are plenty of ecommerce solutions to choose from and you can find the right one for your needs There are advantages and disadvantages to the different ecommerce platforms out there which is why you need to know exactly which features you need to make your online business the best it can be Some of the most popular ecommerce website builders include BigCommerce Magento WooCommerce and Shopify or Shopify Plus Or some merchants with contentheavy sites may like to use WordPress  and several ecommerce platforms including BigCommerce offer integrations so you can combine your content and commerce 4 Add products Make sure its easy for you to add and edit product listings and that your inventory can sync across all of your sales channels This can simplify backoffice operations and help you avoid overselling your products When you do add products youll want to focus on these things Highquality product images Give your customers the confidence that if they order from you theyll receive exactly what they expect Detailed product descriptions Particularly for highly researched products make sure that you include all pertinent information product specs sizing information etc 5 Set payment and shipping settings A website developer can assist in the shopping cart and checkout process as well as how to integrate payment gateways into your site and get shipping set up Youll typically have many payment gateways to choose from You dont have to integrate them all but customers are increasingly interested in paying via different payment methods like buy now pay later Plus if youre selling crossborder youll want to choose payment gateways that support your target regions 6 QA and launch website Once you move your website from stage to production give it a quick testdrive to ensure that youre all set in terms of ecommerce website design performance and navigation Heres a quick checklist Review all callstoaction and form titles on the homepage and landing pages Test your checkout experience Doublecheck payment processing integrations credit cards PayPal Stripe etc Make sure that all images are highdefinition but optimized for load speed Look for missing product categories and descriptions Check that all links and forms are functional Verify that your tax settings are correct Ensure that all the inventory is properly listed Test your couponspromo codes Also make sure your digital storefront displays equally well on desktop and mobile and that the user experience is consistent throughout The Final WordLaunching an ecommerce business ranges in complexity and so do the platforms available to you Whether you start with a complex platform or a turnkey solution you may find you need some extra web development help at some point in your business lifecycle Now that you know about the web developers role in your ecommerce launch and maintenance process the functionality you need to consider as you evaluate tech specs and the steps you should take prior to launch youre ready to get started If you need assistance BigCommerce has a robust network of service and solution professionals at the ready to answer any questionsFAQs About Ecommerce Website DevelopmentWhat is the role of an ecommerce website developerEcommerce web developers play a critical role in making sure that potential customers can easily navigate your ecommerce store find what theyre looking for and checkout easily and safely They work with a range of skills from backend programming to frontend ecommerce web design and their responsibilities may vary depending on the type of store you have The right developer or team of developers has the capability to Design your ecommerce storefront to be both functional and beautiful Make it easy for customers to find what they want whether through filtering by size color or price Help you decide which features work best with the rest of your website content And the list could go onDo I need a frontend developer and a backend developerThat will depend largely on the complexity of your build If your ecommerce solution uses an open source framework then a backend developer may be more essential than someone focusing on design services though youll likely need both If youre using a SaaS platform youll probably need more frontend work than anything else  but you may also want someone wellversed in building APIs While most SaaS platforms have a relatively robust set of apps with prebuilt integrations further complexity is best handled by an expert How do I determine what features my ecommerce website needsDetermining the necessary features and functionality of your ecommerce website will vary based on your business model and unique needs Depending on your set goals and metrics create a list of features your ecommerce website needs These should be closely aligned with your customer lifecycle Here are some of the important features to account for Responsive design Strong SEO capabilities Page speed Ability to integrate with social media channels and marketplaces Multiple payment options and gateways CMS content management system integration Shopping cart design Product filtering 0 SHOPPING CART Sales Channels Amazon Facebook Instagram Face Mask name Scripts Sales by category Coats Jerseys TShirts Hats Pants Shorts le RIVET NUT A NUMBER OF UNITS 100 Mens Blue Sports Jacket ","https://www.freecodecamp.org/news/what-are-progressive-web-apps/, https://www.bigcommerce.com/articles/ecommerce-website-development/",Front-End Development,1916,5658
E-commerce Development,TABLE OF CONTENTSOptions for Building an Ecommerce WebsiteFunctionality To Consider When Developing An Ecommerce Website6 Steps For Developing a Custom Ecommerce WebsiteThe Final WordFAQs About Ecommerce Website DevelopmentWith an estimated 12 million to 24 million active ecommerce sites around the world its easy for an online store to get lost in the crowd The key to standing out Topnotch website development that gives customers the experience they need Ecommerce website development is the process of developing the technical aspects of your ecommerce website  how it functions accepts payments behaves in response to user action and appears aesthetically Valued at 11 billion in 2022 the web development services industry opens the door for business owners to launch userfriendly websites and solve their most pressing ecommerce challenges which could include Determining the right features and functionality for your ecommerce project Understanding which ecommerce framework might work best for you Integrating ecommerce into a current website site or website template In this article well talk about what ecommerce web development is how you can find a developer or team of developers to help you realize your vision and the steps to take before launch Lets dive in Options for Building an Ecommerce WebsiteWhen it comes to building out your ecommerce store youll likely come across three options Build your website from scratch aka open source Customize a SaaS softwareasaservice solution Harness the power of MACH architecture Build it from scratch If you already have a web development or IT team in place going the opensource route may be your best bet Opensource ecommerce platforms are solutions in which you can modify all aspects of the code meaning you can build your website from scratch with few to no customization limits However keep in mind that using an opensource solution often means your business is responsible for things like PCI compliance web hosting security issues manual patches and updates For this reason some brands may view open source as too cumbersome expensive and techheavy especially as your business grows and complexity increases Customize a SaaS solution Dont have the coding expertise or budget to build a solution from scratch Enter SaaS ecommerce SaaS is a subscriptionbased solution that is built and maintained by a thirdparty vendor and may be hosted in the cloud Instead of building and developing a custom solution yourself SaaS allows you to essentially rent the platform while the platform provider takes care of tasks such as product updates security hosting PCI compliance and everything else that comes with managing your own software For this reason SaaS solutions enable businesses to gotomarket quickly and affordably Some ecommerce solutions referred to as open SaaS even offer benefits from both opensource and SaaS platforms BigCommerce for example is one of the leading open SaaS ecommerce platforms for midmarket and enterprise brands With our open API merchants receive all the benefits of a SaaS platform  being hosted on behalf of BigCommerce a lower total cost of ownership and faster gotomarket time  as well as the flexibility to create custom integrations and functionality faster similar to using an opensource platform MACH Microservices APIFirst CloudNative and Headless For decades the traditional ecommerce model has tied together the frontend storefront and backend serverside into an allinone monolith setup While a monolith solution might be a smart choice for small and midsized SMB businesses with limited requirements it can present some challenges as your business scales and requires greater complexity such as launching multiple websites or expanding into new regions The solution MACH architecture MACH microservices APIfirst cloudnative SaaS and headless is a set of guiding principles using a bestofbreed approach to build enterprise software tech stacks Unlike monolithic architecture MACH allows you to choose the technology that best meets your business needs and future roadmap Microservices Microservices are small services that perform a very specific task and are brought together to build an application They are independently developed updated deployed and managed and each use different code APIfirst APIs application programming interface are what make it possible to connect and communicate to deliver content between two or more applications or services  which means the application needs to be built with APIs at the forefront Cloudnative A cloudnative application leverages the full capabilities of the cloud and SaaS technology to manage monitor and maintain the technology and license it through subscription services Headless Headless commerce architecture is the decoupling of the frontend presentation layer of a website from the backend ecommerce functionality This allows for greater design flexibility when creating the user interface and integrating various channels Monolith vs MACH A MACH Commerce Guide learn more about MACH and see if its right for you Download Your Guide How Do I Choose the Right Ecommerce Website Developer Next well look at what an ecommerce developer does and why its important that their skills align with your ecommerce web design needs According to research from PWC 73 of US consumers say customer experience is an important factor when purchasing online yet only 49 believe brands provide a good experience The best way to ensure your ecommerce web development team provides a better user experience on your site is by hiring one with experience designing andor developing for ecommerce With any luck or if like BigCommerce your platform has a strong partner program you can find ecommerce website development services that are familiar with the latest in ecommerce best practices and can produce a site that will delight your customers and boost your conversion rate Understand different developers strengths Some developers are great at bringing your brand to life through a beautifully designed frontend while others excel in backend customization and technical implementation When you evaluate developers for your online store make sure you know what their strengths are While some developers will be capable of both backend development and frontend design they more typically pick one as their primary focus Make sure that the developer you choose has skills aligned with your needs Here are some of the top elements to consider when developing your ecommerce website PCI compliance and web security SEO search engine optimization Multiple payment options and gateways CMS content management system integration Mobileresponsiveness Shopping cart design Product filtering Base your choice off your needs Dont choose a developer or development company until you deeply understand what you want from your ecommerce storefront and what skills will be necessary to make it happen For example if your ecommerce solution uses an opensource framework then a backend developer may be more essential than someone focusing on design though youll likely need both If youre using a SaaS platform you may need more frontend work than anything else  though you may also want someone wellversed in building APIs While most SaaS platforms have a relatively robust set of apps with prebuilt integrations further complexity is best handled by an expertFunctionality To Consider When Developing An Ecommerce WebsiteDifferent features and functionality you may want in your ecommerce site will vary based on your business model and unique needs Based on your set goals create a list of features your ecommerce website needs These should be closely aligned with your customer lifecycle For example a startup or small business may not need to support multiple currencies but this could be a crucial feature for a crossborder retailer An easy way to determine what shopping cart features you need is to work from general to specific List all the general musthaves such as preferred payment gateways or marketplace integrations Add extras that your business needs like automatic sales taxshipping rate calculation Prioritize all the nicetohaves from 1 to 5 with 1 being a crucial feature for driving revenues and 5 as a handy addon that could make your daytoday operations more efficient Responsive design By 2025 Statista forecasts that mobile commerce sales will make up over 10 of all US retail sales which would be a growth of 7 percent points since 2018 As more customers use mobile phones to shop online youll need a website that supports responsive mobilefriendly web design Or you could even have your web developer create a mobile app Either way the goal is to make sure you can deliver a consistent shopping experience whether your site is accessed on a desktop or mobile device Luckily the BigCommerce theme marketplace offers both free and premium fully responsive themes Professionally designed and developed using our Stencil theme platform our themes are optimized for multiple product catalogs and industries SEO capabilities SEO is a great distribution strategy for your content and an essential aspect of your website design Ranking highly on Google search engine for relevant keywords can help drive traffic to your site from interested users who are searching online SEO can organically deliver you potential clients with high intent who are more likely to convert which can make SEO traffic more costeffective Site speed According to a study by Google the probability of bounce increases dramatically with every couple seconds added to page load time Fastloading sites are also a plus for SEO since Google uses site speed as a ranking factor This is why you need to hire ecommerce website developers who know how to optimize your ecommerce store so that its not only functional and attractive but also fastloading CMS Content Management System A CMS content management system is crucial for an ecommerce site as it houses any dynamic content  such as blog posts visuals and any other blocks of content in a design  all in one place With a CMS youll be able to make changes to or add new content and the changes will be automatically reflected on your ecommerce website This way you can consistently keep your site updated with new content that supports your products Product Management Picture your favorite online retailer Chances are they consistently have the products in stock that you want they provide multiple versions of products and they offer promotions and discounts when needed As youre developing your ecommerce site make sure it has the functionality necessary to add edit and keep track of inventory so that you can consistently give customers the products they want Payments and Checkout In the age of Apple Pay PayPal and mobile wallets its no longer acceptable for ecommerce businesses to offer only one payment option In fact research shows that flexible and seamless payment options speed up the decisionmaking process for nine in 10 shoppers and even prompts them to spend more  which is why its crucial that your ecommerce platform can integrate with multiple payment gateways Luckily as a BigCommerce merchant you can build a custom checkout for your online shop and even offer oneclick checkout with apps like BoltSecurity Developing an online store means dealing with sensitive data such as customer phone numbers credit card numbers and other payment information  which means its your responsibility to handle it with care PCI Compliance standards must be met to accept payments or you may risk being charged fines termination of ability to accept payments loss of customer confidence and other fraudrelated financial consequences But the bare minimum provided by some platforms may not be enough Some platforms come with an SSL certificate but proper protection may mean thirdparty software or an additional investment in inhouse infrastructure Luckily BigCommerce stores come standard with Level 1 PCI compliance to make your site safe and secure This way you can spend your time building your business instead of worrying about security Integrations No ecommerce platform will come with every single feature you want natively Youll need to make sure your platform enables you to customize your site by offering plugins and integrations with solutions that you need How do you want your back office to run Many businesses prioritize connecting their ecommerce solution to existing ERP OMS PIM or CRM systems so make sure the integration you need is available with the platform you choose What kinds of digital marketing do you rely on If you want to deliver a personalized experience you may want to use a customer data platform Dig into what you can do with your data so you know whats possible with each ecommerce software Can you integrate your data with your email marketing system You may also want to consider things like onsite chat or SMS marketing and if you need to integrate with marketplaces like Amazon or with social media channels Marketing strategy As youre developing your online store begin building your ecommerce marketing strategy early on in the process This will help you to define the structure of your site and determine what features you may need For example if part of your marketing strategy is to advertise on social media channels you may want to incorporate social sharing options on your website Or if mobile commerce is a large part of your strategy then you may want to add push notifications or build a mobile app 6 Steps For Developing a Custom Ecommerce WebsiteIts not necessary  or even recommended  to build your ecommerce website from scratch There are many platforms that can help you create an ecommerce store with minimal coding or technical skill required on your part But determining your platform isnt the only thing you need to do before starting the development process Here are some things to consider before diving in 1 Understand your business goals The decision to sell online is a big one And you cant proceed with action until you figure out the operational bells and whistles To do that start with the why Why do you want to sell online To attract more business  thats easy But how exactly do you plan to make that happen Will you use your ecommerce business as an avenue for directtoconsumer sales Do you want to drive online traffic to supplement brickandmortar operations Do you want to expand a B2C business to B2B or vice versa Apart from your baseline goals think in terms of ecommerce metrics What kind of growth would you like to see postlaunch and how will you measure it For example whats your goal in terms of weekly online sales volume Do you plan to sell locally or internationally too Whats your plan for growing a customer lifetime value How many products do you plan to sell 2 Understand the intended shopping experience What kind of online shopping experience do you want to give your customers Some of the experiential features you may want to consider include but are not limited to Enabling your customers to filter search results by size color or price with the click of a button The ability to compare products sidebyside Offering an optimized onepage checkout experience Promotions discounts and other types of offers Think about whether your target audience wants a simple and quick shopping experience  as they might with necessities like some consumerpackaged goods  or if theyll take some time to browse your site and discover new products Youll likely want to structure your site for a different customer journey depending on your answer 3 Discuss platform options Luckily today you dont have to build your online store from scratch There are plenty of ecommerce solutions to choose from and you can find the right one for your needs There are advantages and disadvantages to the different ecommerce platforms out there which is why you need to know exactly which features you need to make your online business the best it can be Some of the most popular ecommerce website builders include BigCommerce Magento WooCommerce and Shopify or Shopify Plus Or some merchants with contentheavy sites may like to use WordPress  and several ecommerce platforms including BigCommerce offer integrations so you can combine your content and commerce 4 Add products Make sure its easy for you to add and edit product listings and that your inventory can sync across all of your sales channels This can simplify backoffice operations and help you avoid overselling your products When you do add products youll want to focus on these things Highquality product images Give your customers the confidence that if they order from you theyll receive exactly what they expect Detailed product descriptions Particularly for highly researched products make sure that you include all pertinent information product specs sizing information etc 5 Set payment and shipping settings A website developer can assist in the shopping cart and checkout process as well as how to integrate payment gateways into your site and get shipping set up Youll typically have many payment gateways to choose from You dont have to integrate them all but customers are increasingly interested in paying via different payment methods like buy now pay later Plus if youre selling crossborder youll want to choose payment gateways that support your target regions 6 QA and launch website Once you move your website from stage to production give it a quick testdrive to ensure that youre all set in terms of ecommerce website design performance and navigation Heres a quick checklist Review all callstoaction and form titles on the homepage and landing pages Test your checkout experience Doublecheck payment processing integrations credit cards PayPal Stripe etc Make sure that all images are highdefinition but optimized for load speed Look for missing product categories and descriptions Check that all links and forms are functional Verify that your tax settings are correct Ensure that all the inventory is properly listed Test your couponspromo codes Also make sure your digital storefront displays equally well on desktop and mobile and that the user experience is consistent throughout The Final WordLaunching an ecommerce business ranges in complexity and so do the platforms available to you Whether you start with a complex platform or a turnkey solution you may find you need some extra web development help at some point in your business lifecycle Now that you know about the web developers role in your ecommerce launch and maintenance process the functionality you need to consider as you evaluate tech specs and the steps you should take prior to launch youre ready to get started If you need assistance BigCommerce has a robust network of service and solution professionals at the ready to answer any questionsFAQs About Ecommerce Website DevelopmentWhat is the role of an ecommerce website developerEcommerce web developers play a critical role in making sure that potential customers can easily navigate your ecommerce store find what theyre looking for and checkout easily and safely They work with a range of skills from backend programming to frontend ecommerce web design and their responsibilities may vary depending on the type of store you have The right developer or team of developers has the capability to Design your ecommerce storefront to be both functional and beautiful Make it easy for customers to find what they want whether through filtering by size color or price Help you decide which features work best with the rest of your website content And the list could go onDo I need a frontend developer and a backend developerThat will depend largely on the complexity of your build If your ecommerce solution uses an open source framework then a backend developer may be more essential than someone focusing on design services though youll likely need both If youre using a SaaS platform youll probably need more frontend work than anything else  but you may also want someone wellversed in building APIs While most SaaS platforms have a relatively robust set of apps with prebuilt integrations further complexity is best handled by an expert How do I determine what features my ecommerce website needsDetermining the necessary features and functionality of your ecommerce website will vary based on your business model and unique needs Depending on your set goals and metrics create a list of features your ecommerce website needs These should be closely aligned with your customer lifecycle Here are some of the important features to account for Responsive design Strong SEO capabilities Page speed Ability to integrate with social media channels and marketplaces Multiple payment options and gateways CMS content management system integration Shopping cart design Product filtering 0 SHOPPING CART Sales Channels Amazon Facebook Instagram Face Mask name Scripts Sales by category Coats Jerseys TShirts Hats Pants Shorts le RIVET NUT A NUMBER OF UNITS 100 Mens Blue Sports Jacket ,https://www.bigcommerce.com/articles/ecommerce-website-development/,Full Stack Development,1055,3376
Web Analytics,"PlatformPlatformAnalyticsUnderstand the full user journeyExperimentTest analyze and optimize at scaleCustomer Data PlatformUnite data across teamsAnalyticsExperimentCustomer Data PlatformCapabilitiesIntegrationsConnect Amplitude to hundreds of partnersData ManagementComplete data you can trustCustomersDiscover why customers love AmplitudeAISelfservice data meets selfservice intelligenceIntegrationsData ManagementCustomersAIPlatformPlatformAnalyticsUnderstand the full user journeyExperimentTest analyze and optimize at scaleCustomer Data PlatformUnite data across teamsAnalyticsExperimentCustomer Data PlatformCapabilitiesIntegrationsConnect Amplitude to hundreds of partnersData ManagementComplete data you can trustCustomersDiscover why customers love AmplitudeAISelfservice data meets selfservice intelligenceIntegrationsData ManagementCustomersAISolutionsIndustryFinancial ServicesPersonalize the banking experienceB2BMaximize product adoptionMediaIdentify impactful contentHealthcareSimplify the digital healthcare experienceEcommerceOptimize for transactionsFinancial ServicesB2BMediaHealthcareEcommerceUse CaseGrow active usersGet users hooked from day oneIncrease customer lifetime valueUnderstand your customers like no one elseAccelerate monetizationTurn behavior into businessGrow active usersIncrease customer lifetime valueAccelerate monetizationSolutionsIndustryFinancial ServicesPersonalize the banking experienceB2BMaximize product adoptionMediaIdentify impactful contentHealthcareSimplify the digital healthcare experienceEcommerceOptimize for transactionsFinancial ServicesB2BMediaHealthcareEcommerceUse CaseGrow active usersGet users hooked from day oneIncrease customer lifetime valueUnderstand your customers like no one elseAccelerate monetizationTurn behavior into businessGrow active usersIncrease customer lifetime valueAccelerate monetizationResourcesLearnBlogThought leadership from industry expertsResource CenterExpertise to guide your growthGlossaryAll the terms you need to knowProduct BenchmarksUnderstand how your product comparesBlogResource CenterGlossaryProduct BenchmarksConnectCommunityConnect with peers in product analyticsEventsRegister for live or virtual eventsCommunityEventsSupportHelp CenterAnswers to every Amplitude questionDeveloper HubIntegrate and instrument AmplitudeAcademyBecome an Amplitude proHelp CenterDeveloper HubAcademyResourcesLearnBlogThought leadership from industry expertsResource CenterExpertise to guide your growthGlossaryAll the terms you need to knowProduct BenchmarksUnderstand how your product comparesBlogResource CenterGlossaryProduct BenchmarksConnectCommunityConnect with peers in product analyticsEventsRegister for live or virtual eventsCommunityEventsSupportHelp CenterAnswers to every Amplitude questionDeveloper HubIntegrate and instrument AmplitudeAcademyBecome an Amplitude proHelp CenterDeveloper HubAcademyPricingPricingLoginContact salesGet started , BlogPerspectivesBest PracticesInside AmplitudeCustomer StoriesContributorsPerspectivesBest PracticesInside AmplitudeCustomer StoriesContributorsWhat is Web Analytics Definition Examples  ToolsLearn what web analytics is which metrics you should track to improve website experience and helpful tools to overcome common issuesBest PracticesMarch 31 2022Darshil GandhiPrincipal Product Marketing Manager AmplitudeWeb analytics is the gathering synthesizing and analysis of website data with the goal of improving the website user experience Its a practice thats useful for managing and optimizing websites web applications or other web products Its highly datadriven and assists in making highquality website decisions You might also get ideas on how to improve your product and drive business growth from web analyticsProduct managers data scientists UX designers and others can use web analytics if theyre looking to enhance their website or product experience to meet customer needs They need to know which website metrics to track while also being mindful of the shortcomings of web analyticskey takeawaysWeb analytics refers to the process of collecting website data and then processing reporting and analyzing it to create an online strategy for improving the website experienceWeb analytics is important to help you Refine your marketing campaignsUnderstand your website visitorsAnalyze website conversionsImprove the website user experienceBoost your search engine rankingUnderstand and optimize referral sourcesBoost online salesUse a web analytics tool to automatically track key site performance metrics like bounce rate conversion rate monthly unique visitors and moreSome common issues with web analytics are that it can be overwhelming to keep track of so many metrics data is not always accurate and data privacy could be at risk Find an analytics tool that addresses these concerns effectivelyWhat is web analytics used forWeb analytics features like Amplitudes Pathfinder show how users interact with your siteWeb analytics is helpful for understanding which channels users come through to your website You can also identify popular site content by calculating the average length of stay on your web pages and how users interact with themincluding which pages prompt users to leaveThe process of web analytics involvesSetting business goals Defining the key metrics that will determine the success of your business and websiteCollecting data Gathering information statistics and data on website visitors using analytics toolsProcessing data Converting the raw data youve gathered into meaningful ratios KPIs and other information that tell a storyReporting data Displaying the processed data in an easytoread formatDeveloping an online strategy Creating a plan to optimize the website experience to meet business goalsExperimenting Doing AB tests to determine the best way to optimize website performanceYou can use this information to optimize underperforming pages and further promote higherperforming ones across your website For example French news publisher Le Monde used analytics to inform a website redesign that increased subscriber conversions by 46 percent and grew digital subscriptions by over 20 percent Le Monde was able to identify which paid content users engaged with the most then use that information to highlight topperforming content on the homepageThe importance of web analyticsYour companys website is probably the first place your users end up on to learn more about your product In fact your website is also a product Thats why the data you collect on your website visitors can tell you a lot about them and their website and product expectationsHere are a few reasons why web analytics are importantUnderstand your website visitorsWeb analytics tools reveal key details about your site visitorsincluding their average time spent on page and whether theyre a new or returning userand which content draws in the most traffic With this information youll learn more about what parts of your website and product interest users and potential customers the mostFor instance an analytics tool might show you that a majority of your website visitors are landing on your German site You could use this information to ensure you have a German version of your product thats well translated to meet the needs of these usersAnalyze website conversionsConversions could mean real purchases signing up for your newsletter or filling out a contact form on your website Web analytics can give you information about the total number of these conversions how much you earned from the conversions the percentage of conversions number of conversions divided by the number of website sessions and the abandonment rate You can also see the conversion path which shows you how your users moved through your site before they convertedBy looking at the above data you can do conversion rate optimization CRO CRO will help you design your website to achieve the optimum quantity and quality of conversionsWeb analytics tools can also show you important metrics that help you boost purchases on your site Some tools offer an enhanced ecommerce tracking feature to help you figure out which are the topselling products on your website Once you know this you can refine your focus on your topsellers and boost your product salesBoost your search engine optimization SEOBy connecting your web analytics tool with Google Search Console its possible to track which search queries are generating the most traffic for your site With this data youll know what type of content to create to answer those queries and boost your sites search rankingsIts also possible to set up onsite search tracking to know what users are searching for on your site This search data can further help you generate content ideas for your site especially if you have a blogUnderstand top performing contentWeb analytics tools will also help you learn which content is performing the best on your site so you can focus on the types of content that work and also use that information to make product improvements For instance you may notice blog articles that talk about design are the most popular on your website This might signal that your users care about the design feature of your product if you offer design as a product feature so you can invest more resources into the design feature The popular content pieces on your website could spark ideas for new product features tooUnderstand and optimize referral sourcesWeb analytics will tell you who your top referral sources are so you know which channels to focus on If youre getting 80 of your traffic from Instagram your companys marketers will know that they should invest in ads on that platformWeb analytics also shows you which outbound links on your site people are clicking on Your companys marketing team might discover a mutually beneficial relationship with these external websites so you can reach out to them to explore partnership or crossreferral opportunitiesExample metrics to track with web analyticsWebsite performance metrics vary from company to company based on their goals for their site Here are some example KPIs that businesses should consider tracking as a part of their web analytics practicePage visits  SessionsPage visits and sessions refer to the traffic to a webpage over a specific period of time The more visits the more your website is getting noticedKeep in mind traffic is a relative success metric If youre seeing 200 visits a month to a blog post that might not seem like great traffic But if those 200 visits represent highintent viewsviews from prospects considering purchasing your productthat traffic could make the blog post much more valuable than a highvolume lowintent pieceSource of trafficWeb analytics tools allow you to easily monitor your traffic sources and adjust your marketing strategy accordingly For example if youre seeing lots of traffic from email campaigns you can send out more email campaigns to boost trafficTotal website conversion rateTotal website conversion rate refers to the percentage of people who complete a critically important action or goal on your website A conversion could be a purchase or when someone signs up for your email list depending on what you define as a conversion for your websiteBounce rateBounce rate refers to how many people visit just one page on your website and then leave your siteInterpreting bounce rates is an art A high bounce rate could be both negative and positive for your business Its a negative sign since it shows people are not interacting with other pages on your site which might signal low engagement among your site visitors On the other hand if they spend quality time on a single page it might indicate that users are getting all the information they need which could be a positive sign Thats why you need to investigate bounce rates further to understand what they might meanRepeat visit rateRepeat visit rate tells you how many people are visiting your website regularly or repeatedly This is your core audience since it consists of the website visitors youve managed to retain Usually a repeat visit rate of 30 is good Anything below 20 shows your website is not engaging enoughMonthly unique visitorsMonthly unique visitors refers to the number of visitors who visit your site for the first time each monthThis metric shows how effective your site is at attracting new visitors each month which is important for your growth Ideally a healthy website will show a steady flow of new visitors to the siteUnique ecommerce metricsAlong with tracking these basic metrics an ecommerce companys team might also track additional KPIs to understand how to boost salesShopping cart abandonment rate shows how many people leave their shopping carts without actually making a purchase This number should be as low as possibleOther relevant ecommerce metrics include average order value and the average number of products per sale You need to boost these metrics if you want to increase salesWeb analytics toolsThere is a whole range of tools you can use for web analytics including tools that traditionally specialize in product analytics or experience analytics Some of these includeAdobe AnalyticsAmplitudeContentsquareCrazy EggfullstoryGlassboxGoogle AnalyticsHeapHotjarMixpanelPendoDont just take our word for it though Check out review sites like G2 for a roundup of the best web analytics toolsCommon issues with web analyticsWhile web analytics can be extremely useful for optimizing the website experience there are some drawbacks to it Some of these includeKeeping track of too many metricsThere are so many data points available to track It can be overwhelming to combine web analytics product analytics customer experience tools heatmaps and other business intelligence analytics to make sense of thingsAs a general rule only measure the metrics that are important to your business goals and ignore the rest For example if your primary goal is to increase sales in a certain location you dont need metrics about anything outside of that locationData is not always accurateThe data collected by analytics tools is not always accurate Many users may optout of analytics services preventing web analytics tools from collecting information on them They may also block cookies further preventing the collection of their data and leading to a lot of missing information in the data reported by analytics tools As we move towards a cookieless world youll need to consider analytics solutions that track firstparty data rather than relying on thirdparty dataYour web analytics tool may also be using incorrect data filters which may skew the information it collects making the data inaccurate and unreliable And theres not much you can do with unreliable dataData privacy is at riskUntracked or overly exposed data can cause privacy or security vulnerabilities People could reveal all sorts of personal information about themselves on your website including credit card details and their address Any breach to an analytics service provider that compromises your user data can be devastating for your business reputation Since privacy laws have become more stringent over the last decade globally its important you pay attention to cyber securityWebsite data is particularly sensitive Make sure your web analytics tools have proper monitoring procedures and security testing in place Take steps to protect your website against any potential threatsData doesnt tell the whole storyWhile web analytics are useful to learn how users are interacting with your website they only scratch the surface when it comes to understanding user behavior Web analytics can tell you what users are doing but not why they do it To understand behaviors you need to go beyond web analytics and leverage a behavioral analytics solution like Amplitude Analytics By looking at behavioral product data youll see which actions drive higher engagement retention and lifetime valueReady to explore your own dataReferencesConversion Rate Optimization MOZWhat does mobile friendly mean when it comes to websites ThryvImprove your performance on Google Search Google Search ConsoleHow to Find Your Most Popular eCommerce Products in Google Analytics MonsterInsightsHow to Find Best Selling Products Online via Google Analytics Optimize SmartWhat Is Web Analytics Your 101 on Analytics and How to Get Started ThemeisleOnline shopping cart abandonment rate in selected industries in March 2021 StatistaWelcome to Google Analytics Google AnalyticsCustomer  User Feedback Software QualarooMake your website better Instantly Crazy EggThe complete guide to heatmaps HotjarRecordings the complete guide HotjarThe best website survey tool 4Q3 Common Web Analytics Challenges  How To Solve Them LogaholicData Security  Privacy MarTechNow that you know more about web analytics make sure youre measuring the right metrics with our North Star Playbook Or see how website data looks in AmplitudeAbout the AuthorDarshil GandhiPrincipal Product Marketing Manager AmplitudeMore from DarshilDarshil Gandhi is a Principal Product Marketing Manager at Amplitude He leads technical marketing and collaborates with product and gotomarket teams on strategy positioning messaging campaigns and enablement He is a former solutions consulting team principal where he helped dozes of customer teams turn their their data into actionable insights and drive valuable outcomes He enjoys showcasing the power of Amplitudes platform analytics experiment CDP across use cases of acquisition retention and monetization Darshil graduated from Dartmouth College with a Masters in Engineering ManagementTagsAnalyticsMore Best PracticesBest PracticesDecember 22 20234 Ways Predictive Marketing Can Guide Customer PurchasesJulia DillonSenior Product Marketing Manager AmplitudeBest PracticesDecember 15 2023DataDriven Customer Segmentation StrategyRobbie WallaceSenior Engagement ManagerBest PracticesDecember 8 20235 Ways to Leverage User Statuses to Segment Your CustomersJon ShekSolutions ArchitectBest PracticesDecember 5 2023What Is Data Mining A Comprehensive Guide with ExamplesPragnya ParamitaGroup Product Marketing Manager Amplitude ","https://amplitude.com/blog/web-analytics, https://amplitude.com/blog/web-analytics",Analytics,959,2564
Mobile-First Design,What is Mobile First Design Why Its Important  How To Make ItVincent XiaFollow5 min readDec 21 20179ListenShareOn the Mobile World Congress in 2010 Eric Schmidt the CEO of Google put forward that designers should follow the mobile first rule in product design What does mobile first design mean Why is it important How to make it Ill answer these 3 questions in the following partWhat is Mobile First DesignTo understand the concept of mobilefirst design better you should know the two phrases below first1 Responsive Web Design RWDResponsive web design is a web design method that enables web to fit the screens of different devices automatically displaying the content in a way that people feel comfortable This greatly reduces users operations like panning zooming and scrolling when browsing the web2 Progressive Advancement  Graceful DegradationThese two concepts were put forward before responsive web design In order to make web or application interface display reasonably on different devices designers provide customized versions of product for different endsProgressive Advancement means that when we design a product first we build a version for the relatively lower browser like that on a mobile phone This version includes the most basic functions  features After that we tend to the advanced version for a tablet or PC which is created by adding interactions more complicated effects etc on the basic version for a better user experienceGraceful Degradation on the contrary starts the product design from an advanced end like desktop and builds a version with wellrounded features at the beginning Then designers make the product compatible with mobile ends by cutting some functions or contentsProgressive Advancement has won the game for now as far as I can see If UIUX designers start a product design with its desktop version they will inevitably want to make use of most of the advantages of the advanced end For example the hover effect which is supported by a cursor mouse HD images  complex charts which can display normally only when there is a recent bandwidth In this way the designers will make efforts to complete an amazing desktop version and only to find it can hardly be adopted on a mobile end unless they give up a lot of beautiful ideas If so the mobile end version will be more like an afterthought an incomplete product whichs been watered downBut if we take the mobile end product design as a starting point under the restrictions like bandwidth screen size and so on designers will naturally seize the key points of a product head for a lean  neat product with prioritized features When the platform is expanded to a tablet or PC designers are able to take advantages of the unique features of these advanced ends to strengthen the product step by step This might be the main reason that progressive advancement strategy is widely usedYou may ask why do you spend so much time on explaining the two concepts The answer is that mobile first is exactly a rule of progressive advancementMobile first as the name suggests means that we start the product design from the mobile end which has more restrictions then expand its features to create a tablet or desktop versionWhy Mobile First Principle Is So Important in Product DesignExcept for the victory of progressive advancement against graceful degradation as mentioned above we have more tangible reasons to believe that mobilefirst principle is important in product design That is the exploding of mobile use1 Mobile internet usage has surpassed desktop usage in 20162 People have spent more and more time on the internet from mobile ends3 Early in 2012 smartphone sales have overtaken PC salesThe exploding of mobile ends urges designers to pay attention to the mobile end and follow the mobile first rule in product designHow to Practice Mobile First Rule in Product DesignThe key to mobile first principle is in fact a contentcentered mindThe following part will explain the advancement of a product from a mobile phone end to a PC endLets make an application for hotel booking We first sort the content of the site by importance Website name Hotel Domestic Hotel Foreign Hotel Hour Room Special Hotel Time selector checkin time departure time My Order Customer service Promotion  AdvertisingThen we get a mobile end version like thisHotel Booking App  Created with MockplusDomestic foreign hotels and time selectors are the most important content They are located in the most prominent part of the interfaceBy adding more features on the mobile version and enlarging the promotion  advertising displaying area we get a desktop version like thisBesides when practicing the mobile first principle upon different website or mobile apps designers can quickly start with a handy prototyping tool to test their design timely find and resolve potential issues early onIn this way designers are able to create a product for multiple ends in a smooth and efficient way instead of ruthlessly removing those good features to get an afterthoughtIn short the mobile first principle has an important role in product design On the one hand it helps to save product design time and improve designers productivity On the other hand it forces designers to pay more attention to the content of a product which helps them to created neat and practical designsHowever as smartphones become more and more powerful the mobile end might no longer be considered as lower ends in the near future so the move first may not be an everlasting topic But for now its place in product design cannot be ignored ,https://medium.com/@Vincentxia77/what-is-mobile-first-design-why-its-important-how-to-make-it-7d3cf2e29d00,UI/UX Design,407,918
"Web Frameworks (e.g., Django, Flask, Express)", 30 Best Frontend and Backend Web Development Frameworks for 2024 Posted by GMI Blogger Posted in web development Dec 11 2023 at 418am The primary requirement to sell online is a website However while developing your website you can get confused about choosing the right framework You can use any web development framework with unique specialties which can even confuse experienced developers At the same time you should choose the right framework as your websites functionality and future depend on it To make it easier for you we have curated a list of the 26 best frontend and backend web development frameworks for 2024 Table of Content What is a Web Development FrameworkTop 5 Benefits of Using Web FrameworksClassification of Framework ArchitecturesDifferent Types of Web Development FrameworksFrontend Web Frameworks vs Backend Web Frameworks15 Best Frontend Web Development Frameworks and Key Features15 Best Backend Web Development Frameworks and Key Features7 Things to Check Before Choosing a Web FrameworksWrapping UpFrequently Asked Questions What is a Web Development Framework A web framework is a software framework that is developed to simplify the process of building a website It is the standard way to build and deploy web applications on the internet The main aim of frameworks for web development is to automate the common activities performed during the development phase These frameworks come with templating capabilities that allow you to present information in a browser libraries for database access session management and code reuse capabilities You can access these frameworks in several programming languages Top 5 Benefits of Using Web Frameworks Unlike other development tools frameworks come with a predefined codebase and guidelines for easy website development As a result it speeds up the development process and thereby reduces timetomarket Here are the top 5 benefits of using web frameworks 1 Easy Debugging and Maintenance Most programming languages dont give importance to code readability and maintenance But many popular website development frameworks do that Frameworks are recommended for custom web development because they have a lot to do with the ease of debugging and support There is a community of developers with every framework so that you can be assured of quick responses to any issue 2 Reduce Code Length If you are using frameworks there is no need to write long code lines for adding standard functionalities to a website Frameworks come with code generation features to promote simplicity and conciseness reducing the time and effort required by developers Moreover frameworks provide tools and functions that help developers automate regular tasks like authentication URL mapping caching etc 3 Improved Security Frameworks provide builtin security features and mechanisms that help developers protect websites from present and future security threats By using frameworks programmers can safeguard websites from various cyberattacks like data tampering DDoS SQL injections etc Moreover you can use opensource web frameworks to build custom security specifications for websites 4 Bootstrap Development Frameworks offer a variety of tools and packages to help developers bootstrap the development process By using frameworks programmers do not have to write all scripts from scratch If you have less experience in web development frameworks provide more ways to explore specific features just like an experienced developer Moreover frameworks handle most of the development processes from the beginning and significantly reduce coding time 5 Improves Code Efficiency  Reusability Web frameworks provide a fast responsive and efficient coding environment for developers In addition frameworks come with advanced features like hot reload and live reload leading to faster development cycles Also while using web frameworks developers do not need to write complex or multiple lines of code Instead they can use the predefined codebase to make easy modifications and perform easy bootstrapping Classification of Framework Architectures Framework architecture determines the relation between different elements of a framework The type of framework architecture plays a large role in the application functioning Framework architectures can be classified into 1 Model View Controller MVC or Model View Controller is a popular architecture type used by many frameworks In the MVC model the application is divided into three main components  the model the view and the controller Each component handles specific functions It makes the complex application development processes simple and manageable 2 ModelViewViewModel MVVM The MVVM model allows for clean and organized structuring of codes according to design patterns Here the data presentation logic is separated from the core business logic part The different code layers of MVVM are model view and ViewModel 3 Pushbased  Pullbased Pushbased architecture is actionbased while pullbased is componentbased Pushbased models start with action and then push the data to the view layer Pullbased architecture on the other hand starts with the view layer 4 Threetier organization Mostly used for clientserver applications the threetier architecture separates applications into three logical and physical computing tiers The three tiers are the application tier presentation tier and database tier Different Types of Web Development Frameworks Web development frameworks can be classified on the basis of the programming language that they are written in as well as their use cases Express for example is written in Nodejs Ruby on Rails in Ruby and Django in Python According to their use cases Angularjs and React are meant for frontend development and Django for backend development There are also frameworks designed to solve very specific problems such as database connections and security administration Now lets discuss frontend frameworks and backend frameworks separately 1 Frontend frameworks Frontend frameworks are designed to create elements for user interfaces so as to simplify your development process These frameworks provide prewritten reusable code snippets tools for styling form validation and so much more Some of these frameworks also help you optimize SEO and reduce your websites loading time Frontend frameworks are primarily based on HTML CSS and JavaScript Some of the most popular examples are AngularJS React Vuejs etc 2 Backend frameworks Backend frameworks help you to develop the server of your website quickly and efficiently These frameworks are used for user authentication setting up a secure connection and connecting with the database Different frameworks are used for different languages to develop the server such as Express for Nodejs Django for python etc You have a lot of options to choose from in terms of both programming language and frameworks Frontend Web Frameworks vs Backend Web Frameworks Frameworks are web development tools specially built to make the web development process faster and more secure But depending on their use cases frameworks can be categorized into two Frontend frameworks and backend frameworks Let us quickly look at their differences to deepen our understanding Frontend FrameworkBackend FrameworkA frontend framework is used to develop the front end of a website or application The frontend is the portion of a website that a user sees and interacts withA backend framework is a library of tools and modules that aid in the development of a websites architecture It handles the serverside functionsFrontend frameworks provide prewritten code snippets that can be used as reusable components and templatesBackend frameworks are used for user authentication database manipulation and session handling These frameworks also provide reusable prewritten code snippets to establish efficient connections for your front end and back endFrontend frameworks help you to create SEOoptimized mobilefriendly websites with responsive code snippets used for developing components in your websiteThe primary purpose of using backend frameworks is for URLrouting storing usergenerated data and their authentication keys and security managementSome of the most popular frameworks for the front end are React Vuejs AngularJS Bootstrap and EmberjsDjango ExpressJS Ruby on rails and NET are popular frameworks used for building the backend of web applicationsThe most widely used frontend language is JavaScript HTML and CSS are used for the markup and styling of the website respectivelySome of the most widely used backend languages are NodeJS Python Ruby and PHP 15 Best Frontend Web Development Frameworks and Key Features Frontend frameworks are one of the pioneer aspects of the web design and development process These frameworks decide the aesthetics visual appeal and user experience of your web application At the same time there are many options available To make it easier for you we have listed the thirteen best frontend frameworks for 2024 AngularReactVuejsEmberjsBackbonejsSveltePreactLitElementAlpinejsASPNET CoreJQuerySemantic UIFoundationKnockoutjsTailwind CSS 1 Angular Developed by Google and launched in 2016 Angular is one of the best frontend development frameworks It was initially released in 2010 as AngularJs and then improved to the popular version with an aim to overcome the limitations of conventional frameworks Angular is known as the only framework based on Typescript It supports twoway data binding which means the view and the model are synchronized in realtime and any change in one will instantly be reflected in the other It is remarkably stable and has no reports of a critical breaking change in the last five years Key Features Comprehensive framework with controllers libraries directives and moreBestsuited for singlepage applicationsCompatible with MVC architectureAngular is extensively used and has excellent tooling support as well as vast community supportPopular as the most secure clientside web framework and offers highly secure features like DOM sanitationBatteries included framework that offers an endtoend development experience Angular GitHub Link httpsgithubcomangular 2 React Released by Facebook in 2013 React has become very popular among enterprises and developers It is now one of the most preferred Java frameworks and is the most used frontend website development framework according to a Stack Overflow survey Facebook developed Reactjs during their initial stages of growth when they had to undergo constant improvements due to new feature additions and needed an efficient way to fix code maintainability issues A most noteworthy feature of React is its virtual Document Object Model DOM that enhances the framework with strong functionality Furthermore with the introduction of a crossplatform mobile development framework React Native it has now captured a significant share in the mobile market too Top react native development companies have been using this framework to build innovative applications Key Features Integrated with numerous librariesIdeal for singlepage applicationsReact is extremely flexible as software engineers have used it to develop applications for different kinds of user interfaces including web mobile desktop smart TVs etcCompared to other frontend frameworks React offers the best serverside rendering with excellent SEO supportReact features are tested with 27 billion Facebook users therefore it is the most disruptive and innovative framework React GitHub Link httpsgithubcomfacebookreact 3 Vuejs Vue was released in 2014 by an exGoogle engineer combining the good parts of AngularJS and React Since then the framework has grown to be one of the most popular purely communitydriven Web frameworks Whats most attractive about Vue is that it is a simple web development framework unlike Angular Further it has a small size and offers twoway data binding Moreover the framework is componentbased and has a visual DOM model making it an efficient as well as versatile choice Key Features The Vuejs framework is progressiveIt is based on the modelviewviewmodelMVVM architectureCreates singlepage apps and user interfaces for web applicationsAllows easy integration with any third party tool or applicationVue comes with the endtoend application development functionality of Angular and View layer with external data flow features of React The framework offers premium quality documentation It has a huge following in China and thus offers Chinese documentation tooIt is 100 communitydriven and thus its not driven by the need of any particular organization Vuejs GitHub Link httpsgithubcomvuejs 4 Emberjs Released in 2016 Ember is an opensource JSbased framework It is popular for providing comprehensive solutions for application flow and data management It offers twoway data binding and is also a componentbased framework It has a steep learning curve because of its rigid structure however it is a flawless and fast development framework and big companies like Apple and LinkedIn use it for their development Key Features Users can debug codes with this frameworkBased on the MVVM architectureThe framework comes with a group of APIs and can process similar tasks in one goEmber offers a complete front end stack  it has a router services and asset pipelineHas the best routing  URLs have route handlers enabled to view conceivable states of applications Emberjs GitHub Link httpsgithubcomemberjs 5 Backbonejs Backbone is a popular lightweight web framework that is used for building rich singlepage web applications It is one of the fastest and easiest JavaScript frameworks that is based on Model View Presenter MVP This framework is a great choice for developing dynamic applications as it is efficient in handling updates dynamically maintaining the client and synchronizing with the server Key Features Comes with automatic updating of HTML code and offers 100 extensionsBackbone has a backend syncing feature that gives great support to RESTful APIsUsing Backbone conventions developers can omit tedious coding Backbonejs GitHub Link httpsgithubcomjashkenasbackbone 6 Svelte Svelte is a popular contender against React Vue and Angular Developers prefer it for building interactive web pages  for its cleartoread HTMLX templating and aesthetically pleasing look It is one of the modern web development frameworks and is hailed for its improved reactivity scalability and speed Key Features It does not have any virtual DOMIt has incorporated reactivity into its languageWith a simple format written in Typescript it reduces coding complexityThe design philosophy of Svelte is similar to Python and comes with an excellent tutorial with a realtime interfaceOffers robust and goodlooking APIs  from features to syntax installation size and semantics Svelte optimizes code during compilation propagating changes with a minimal overhead during runtime Svelte GitHub Link httpsgithubcomsveltejs 7 Preact Preact is another JSbased framework that claims to be a faster alternative to React It comes in a smaller size and hence you do not have to worry about performance issues Preact is based on the ES6 framework and is significantly adopted by the JS developers community It is known as a lightweight form of React and is suitable for developing dynamic web applications Key Features Preact has less Javascript  which means less execution time and helps to keep the framework under controlIt comes with a faster virtual DOM library gets batch updates and is tuned for maximum performanceIt is lightweight and fun to use Preact uses standard HTML attributes and lets developers to be productive right from the start Preact GitHub Link httpsgithubcompreactjs 8 LitElement LitElement is a base class used to create quick and lightweight web components which work on any web page It uses litHTML to render into the Shadow DOM Moreover LitElement can add an API for managing attributes and properties Key Features You can easily share the web components of LitElement across your organizationThe components can be used anywhere  in your CMS main document or a framework like Vue or ReactAs it uses litHTML only the dynamic parts of your UI are rendered and thus DOM updates are quick LitElement GitHub Link httpsgithubcomlit 9 Alpinejs Alpine is the best option if you work on a small project that only needs one or two components It is popular among developers as it is lightweight and leaves a minimal footprint on the application Key Features If your project only needs minimal JavaScript and needs only one or two components like sidebars dropdowns etc then Alpinejs is the best choiceIt can be used to enhance HTML syntax by using new directives and JavaScript injectionsYou can create responsive interfaces in declarative mode through a frontend libraryLets you add JavaScript Behavior to HTML markupsThe most significant feature of Alpine is its size  with only about 4 KB it works great with your frontend templatesAlpine is developerfriendly and allows you to focus on development and less on configurationIt allows you to harness Vue React or Angular frameworks declarative and reactive nature at less cost Alpinejs GitHub Link httpsgithubcomalpinejs 10 ASPNET Core ASPNET Core was an opensource web framework introduced by Microsoft in line with the latest web development trends It is a modular framework that can run on multiple platforms like Windows Mac or Linux Key Features Framework for developing web applications on the NET platformA free crossplatform opensource framework for creating cloudenabled web appsIts modular design is key and works with most popular JavaScript clientside libraries like React Angular Vue and EmberOffers one of the best tooling support as popular IDEs like Visual Studio and VS Code is also developed by MicrosoftASPNET is lauded as one of the fastest web application frameworks is lightweight and fast ASPNET core GitHub Link httpsgithubcomdotnetaspnetcore 11 JQuery JQuery is one of the oldest frontend development frameworks which was launched in 2006 Even so it is still quite popular widely used and is undergoing constant development to remain significant among the present technologies JQuery is simple easy to use and eliminates the need to write extensive javascript codes The framework optimizes the functionality of a website by manipulating the CSS and DOM Key Features A compact fast and lightweight JavaScript libraryAJAX call and DOM manipulation easierHTTP requests are simplified and streamlinedFlexible DOM allows components to be added or eliminated easilyEfficient in building desktopbased JavaScript applications with simple and crisp code jQuery GitHub Link httpsgithubcomjquery 12 Semantic UI Launched in 2014 Semantic UI is one of the latest additions to the frontend web development frameworks It is a unique framework that exhibits an intuitive UI and has been developed with a focus on establishing a language for sharing UI The codes are simple and use natural language making them selfexplanatory So it is easy to use even for newcomers Key Features It has prebuilt semantic components that facilitate the creation of responsive and aesthetically pleasing layouts using humanfriendly HTMLThe framework has rich UI components and offers elevated responsiveness and receptivenessIntegration with several third party libraries ensures an optimized and unified development environmentThe framework has exceptional functionality and simplicity Semantic UI GitHub Link httpsgithubcomSemanticOrgSemanticUI 13 Foundation Foundation is an advanced web development framework that is used for enterpriselevel development It lets you develop responsive exquisite and agile websites It is somewhat challenging for freshers to learn however its amazing features like GPU acceleration for smooth animations and fast mobile rendering makes it a noteworthy framework among developers Key Features A free opensource frontend framework for building responsive websites and applicationsBuilt on Sass and SCSS Sassy CSS languagesOffers everything for building a responsive website such as a responsive grid HTML and CSS UI components templates and code snippetsThe framework offers the provision to customize user experience for different devicesIt offers data interchange attributes which means that for mobiles it loads lightweight sections whereas for larger devices it loads heavy sectionsOne of the best mobile friendly front end frameworks on the market Foundation GitHub Link httpsgithubcomfoundation 14 Knockoutjs Web development is increasingly using JavaScript and consequently there is a high demand for JavaScript frameworks and libraries Knockoutjs is a JavaScript package that enables users to create desktoplike interfaces with a clean underlying data model A large variety of clientside and serverside technologies are compatible with Knockoutjs Key Features Using a declarative binding method Knockoutjs offers a way to connect the model and view model with the view HTML contains declarations of the bindingsIt is based on the MVVM frameworkIt has dependency tracking based on observables and subscribers It offers templates which are useful when you have to use the same UI structure several timesThe UI is automatically updated if the view model is modified and vice versa Knockoutjs GitHub Link httpsgithubcomknockout 15 Tailwind CSS Given that it is based on a utilityfirst strategy Tailwind CSS offers many predefined CSS classes that may be used to style different user interface components It offers a versatile and adaptable technique to create user interfaces Key Features The thickness color style etc of the underlines can be changed using the fancy underlines provided by TailwindThe use of customized CSS is made possible by the arbitrary properties which you can mix with many different modifiers like hover and lgIt has a multicolumn layout which can control the number of columns within an element Tailwind CSS GitHub Link httpsgithubcomtailwindlabstailwindcss 15 Best Backend Web Development Frameworks and Key Features Backend frameworks have become an integral part of web development today Finding the right framework is important for developers to ensure optimal performance and scalability Here are the thirteen best backend frameworks for 2024 ExpressjsNextjsDjangoRuby on RailsLaravelGatsbyNuxtjsSpringKoaNestJSFlaskPhoenixCakePHPMeteorHapi 1 Expressjs Expressjs or Express is an open source web development framework that provides a robust middleware system for Node jsbased applications With features like routing debugging and fast server side programming Express is one of the best backend frameworks It is easy to learn provides exceptional performance and offers minimalistic functionalities Key Features A nodejs web application framework that supports web and mobile app developmentMinimalistic serverside rendered framework It is the goto serverside framework in NodejsSupports endtoend application development MVC pattern with view layer supporting 14 template engine Middleware routing and templatingMature and stable framework as its in active development for over ten years Expressjs GitHub Link httpsgithubcomexpressjs 2 Nextjs NextJS is a React framework used to develop singlepage JSbased applications It is preferred for being a single command toolkit that doesnt need configuration Key Features Comes with builtin CSS support  so developers can easily import CSS files from JSOffers nextimage component Thus developers can automatically optimize imagesOffers Automatic TypeScript compilation so that Angular development is easier Nextjs GitHub Link httpsgithubcomvercelnextjs 3 Django Django is a highly popular Pythonbased framework that developers have highly adopted over the last decade Django is currently one of the major serverside frameworks  big names like Google YouTube and Instagram use it It is a featurerich scalable and versatile framework that is most efficient for the development of databasedriven websites The security speed of development and low learning curve makes it one of the best backend frameworks of today Key Features Compared to other opensource frameworks Django offers the best documentationDjango has the edge over other frameworks in the case of SEO optimizationOffers extensibility via pluggable apps you can easily plug thirdparty applications Django GitHub Link httpsgithubcomdjango 4 Ruby on Rails Ruby on Rails was introduced as a framework that supported the MVC pattern when writing a simple hello world application that needed significant effort It is a pioneering web framework that has influenced many other frameworks in this list Some noteworthy advantages of Ruby on Rails are that it is timeefficient costeffective and highly scalable Key Features A serverside web application development frameworkUses HTML CSS and JS for UI and JSON or XML for data transferUsed for creating web applicationsOffers Localization feature to integrate a predesigned code for a bigger projectCan run its own set of tests on the code you write saving time and effort in quality assuranceHas vast libraries to equip a developer with all the tools for highquality development Ruby on Rails GitHub Link httpsgithubcomrails 5 Laravel Laravel follows the MVC architectural pattern and follows Ruby on Rails philosophy It comes with many outofthebox functionalities for enterprise web development Laravel has a great ecosystem of tool sets that allow you to build solutions using PHP quickly It is a highly versatile framework and allows developers to be flexible and creative thereby making it one of their most preferred choices Key Features Laravel offers an inbuilt ORM  aiding developers to query database tables using a simple PHP syntax without writing any SQL codeSupports MVC architecture for a faster development processComes with an innovative template engine that allows you to create dynamic websites Laravel GitHub Link httpsgithubcomlaravel 6 Gatsby Gatsby is a popular framework for React Developers It is preferred for creating a superfast web experience that integrates with your preferred services Gatsby is mostly used to build blogs landing pages and ecommerce websites Key Features Developers get all the features of React for a fully customized user experienceIts a static site generator doesnt connect with the database or sensitive information so you dont need to worry about securityGatsby follows a PRPL architectural pattern developed by Google which helps to improve your sites performance Gatsby GitHub Link httpsgithubcomgatsbyjs 7 Nuxtjs Nuxt is an opensource framework that is aimed at making web development simple and powerful It is built upon Vuejs offering excellent development features like automatically generated routes SEO improvement and improved meta tags management Key Features Nuxt is well known for providing a friendly experience  you get descriptive error messages and detailed documentation besides having a highly supportive community Offers a modular architecture  developers may choose from almost 50 modules for a fast and easy development processYou can easily add Google analytics or generate a sitemap Developers get the benefits of a progressive web app from Nuxt Nuxtjs GitHub Link httpsgithubcomnuxt 8 Spring Introduced in 2002 Spring has grown to become the primary Web framework in Javabased development It is renowned for evolving with the changing web development landscape besides making Java relevant when Cloud computing is gaining importance Key Features Testing support and other major technologies that assist with validation email dependency injection etcOffers data access and transaction management for your data storage needsBeing part of a large ecosystem Spring supports additional Cloud Native development Eventdriven application development Batch processing and much more Spring GitHub Link httpsgithubcomspringprojects 9 Koa The team behind Express designed Koa Compared to other frameworks it is more expressive smaller and provides a robust foundation for API Moreover Koa is free from Middleware and allows developers to handle errors efficiently Key Features Koa is popular for using generators that clean up all the mess in your code caused by callbacks making the code more manageableYou get excellent support as Koas development team has a proven track record behind the widely used ExpressJSThe framework is very lightweight  has only 550 lines of code Koa GitHub Link httpsgithubcomkoajs 10 NestJS Nest is a NodeJS based framework that offers a complete kit for developing reliable efficient and scalable serverside web applications Also with realtime rendering Nest allows you to find out how your app looks in the browser Key Features Its quite flexible due to the modular architecture  you can use any other front end library with the frameworkOffers a Dependency injection system so you only have to import the user module  the controller will do the restYou get to use controllers and services  making it easy to catch an exception in case of any errors Nestjs GitHub Link httpsgithubcomnestjs 11 Flask Flask is a microweb framework that uses Python programming language A micro framework is one that does not require specific libraries or tools Flask is a lightweight framework suitable for development of small projects But it also supports extensions which can be utilized if you want to build large projects Key Features The framework has a modular nature and supports modular coding which makes development simple It also helps to perform enhanced testingIt has only few abstraction levels between user and databasecache and thus delivers high performanceThe development is quite simple Someone who is familiar with Python can easily learn Flask Flask GitHub Link httpsgithubcompalletsflask 12 Phoenix Written in a programming language called Elixir Phoenix uses server side MVC pattern It is based on the Plug library and the Cowboy Erlang framework The platform was developed to assist the shaping of high performing and scalable applications It is a reliable backend web development framework that upholds productivity and fault tolerance Key Features To enhance productivity and code maintainability the framework enhances the MVC architecture with new conceptsUsing inbuilt Presence and Channel technologies realtime interaction between developers and users can be easily carried out to monitor connectionsPhoenix is a suitable platform for production with its features like live dashboard and integrated instrumentation Phoenix GitHub Link httpsgithubcomphoenixframework 13 CakePHP One of the oldest development frameworks CakePHP was launched in 2005 for PHP development It is an open source web framework that follows the MVC architecture Being a simple and secure platform for development of big and small projects CakePHP is a popular tool among developers CakePHP employs data mapping active record convention over configuration and several other popular concepts Key Features Offers CRUD functionality that allows developers to create read update and delete actions within an applicationIt employs a featurerich Object Relational Mapping ORM technique for converting dataWithout requiring much Apache configuration it can be made functional across website directories CakePHP GitHub Link httpsgithubcomcakephp 14 Meteorjs With Meteorjs an opensource fullstack framework web developers have access to thousands of libraries Its perfect for making speedy prototypes Key Features All of the wellknown frontend frameworks including Angular React Vue Svelte and Blaze are readily integrated with Meteor out of the boxMeteorjs developers can access many community resources like atmosphere slack community etcMeteor cloud can host monitor and manage Meteor apps Meteorjs GitHub Link httpsgithubcommeteor 15 Hapi Published in 2012 Hapi was created by a team of developers at Walmart Labs led by Eran Hammer Hapi is a free web development framework for Nodejs that may be used to create applications APIs and services Key Features Cookies that are signed and encrypted rotation of secrets or keys and HTTP security headers are all methods used to increase the security of appsEndtoend code hygiene which aids programmers in writing distributable maintainable codeDependable updates and secure defaults  Hapi limits error messages that could contain information leaks or vulnerabilities that echo backThe most complete authorization API in Nodejs is the Integrated Authorization and Authentication ArchitectureA sizable collection of official plugins designed to take the place of the middleware found in frameworks like express Hapi GitHub Link httpsgithubcomhapijs 7 Things to Check Before Choosing a Web Framework By now you might have decided on the best framework for your web application Chances are you are already familiar with the specific framework and you are ready to begin the project But are you sure it is the most appropriate framework for you To help you finalize the perfect framework here are five things to keep in mind 1 Good Documentation Most of the time even a code written by yourself can seem difficult to understand when you come back after a few months However while using frameworks you are working with someone elses code  so pick a framework with good documentation and training to utilize the framework to its complete potential 2 Functionality Choose a framework that fits your requirements rather than picking one for its popularity For example you do not want a fullstack framework if you need only routing functionality First understand your specific needs then evaluate different options 3 Consistency Even though a framework cannot replace coding standards and internal policies choosing a good one can help you maintain consistency  especially if your developers are working from different places 4 Business Factors Consider your business needs while finalizing a framework For example if you are a small business trying to partner with a big company you will go for the framework used by the larger organization So bear in mind that there might be future risks in managing it 5 Customization and Configuration Developers should be able to modify the frameworks functionality to conform to the unique requirements and specifications of the project ensuring that the framework is appropriate for the project and flexible enough to meet its specific requirements 6 Licensing Some frameworks have stringent licensing requirements which may restrict how they can be used or distributed Its crucial to pick a framework whose license complements the projects aims and purposes 7 Support Make sure that the framework you choose has an active community for support Once you start using a framework its an integral part of your web app So without support you will have to maintain it yourself or rewrite the code Wrapping Up It is important to choose a framework that matches the nature of your project For instance serverside rendering faster development and SEO would be your priority We believe this list of the best frontend and backend frameworks and their features will help you choose the best one Also please note this is not an allinclusive list  we have picked the ones we think as the best There are many more excellent frameworks in the market Frequently Asked Questions 1 Which is the easiest web framework One of the easiest web frameworks for beginners to learn is React It has a low learning curve and is a userfriendly framework 2 Which framework should I learn in 2024 React and Angular are two frameworks that you can learn in 2024 owing to their flexibility and demand 3 Which JavaScript framework should I learn React Angular and Vue are our top three choices for JavaScript frameworks that you should learn 4 Which is the most popular framework for web development According to Statista the most used web development framework in 2021 is Reactjs with 4014 of developers preferring it 5 Why are frameworks useful Frameworks simplify website development by providing a common structure So developers dont have to do everything from scratch and can build upon the framework This saves time money and effort Visited 1670 times 3 visits today Sharing is caring Facebook Twitter Pinterest Related posts 41 Web Development Trends That Will Change the Way You Create Websites in 2024 Users today interact with websites differently than they did five years ago To be precise they now use voice commands Top 15 SEO KPIs to Track Performance in 2024 Infographics In the world of Search Engine Optimization SEO Key Performance Indicators KPIs serve as the compass that guides our journey Best 4 Web Development AddOns For Firefox In the context of user popularity Firefox comes second only to Google Chrome and is a trusty fallback when Chrome 22 Best Programming Languages for Web Development in 2024 Web development has made significant strides since its inception in the early 90s Today it stands as a highly soughtafter  Vv Vues Bg BACKBONES S SVELTE PREACT ASPNET re S jQuery Knockout Exess ils NEXT Laravel  Gatsby ZA NUXTJS  spring kKOa METER Davi sorely ees  Bape DUBAI TOURISM STATISTICS eu A Google Analytics Frontend Framework Backend Framework 0 Frontend Framework Backend Framework 1 A frontend framework is used to develop the front end of a website or application The frontend is the portion of a website that a user sees and interacts with A backend framework is a library of tools and modules that aid in the development of a websites architecture It handles the serverside functions 2 Frontend frameworks provide prewritten code snippets that can be used as reusable components and templates Backend frameworks are used for user authentication database manipulation and session handling These frameworks also provide reusable prewritten code snippets to establish efficient connections for your front end and back end 3 Frontend frameworks help you to create SEOoptimized mobilefriendly websites with responsive code snippets used for developing components in your website The primary purpose of using backend frameworks is for URLrouting storing usergenerated data and their authentication keys and security management 4 Some of the most popular frameworks for the front end are React Vuejs AngularJS Bootstrap and Emberjs Django ExpressJS Ruby on rails and NET are popular frameworks used for building the backend of web applications 5 The most widely used frontend language is JavaScript HTML and CSS are used for the markup and styling of the website respectively Some of the most widely used backend languages are NodeJS Python Ruby and PHP,https://www.globalmediainsight.com/blog/web-development-frameworks/,Back-End Development,1603,5853
Full Stack Development,"Software DevelopmentData Science  Business AnalyticsAI  Machine LearningProject ManagementCyber SecurityCloud ComputingDevOpsBusiness and LeadershipQuality ManagementSoftware DevelopmentAgile and ScrumIT Service and ArchitectureDigital MarketingBig DataCareer FasttrackEnterpriseOther SegmentsArticlesEbooksFree Practice TestsOndemand WebinarsTutorialsLive Webinars Name Date Place 0 Name Date Place 1 Full Stack Developer  MEAN Stack Cohort starts on 17th Jan 2024 Weekend batch Your City View Details 2 Full Stack Developer  MEAN Stack Cohort starts on 31st Jan 2024 Weekend batch Your City View Details, Trending nowList to String in PythonArticleBreaking Down Different Types of Technology 2024ArticleThe Ultimate Guide to Top Front End and Back End Programming Languages for 2021EbookHow to Become a Software EngineerArticleHow to Become a Front End DeveloperArticleHow to Become a Python Developer A Complete GuideTutorial20 Most Popular Programming Languages to Learn in 2024ArticleTop 40 Coding Interview Questions You Should KnowArticleSteer Your Full Stack Development Career Ahead in 2024 with IIT Madras PravartakWebinarTop 50 Salesforce Interview Questions and Answers for 2024ArticleWhat is Full Stack DevelopmentBy SimplilearnLast updated on Aug 29 202315607Table of ContentsView More What is Full Stack Development Full stack development is the process of designing creating testing and deploying a complete web application from start to finish It involves working with various technologies and tools including frontend web development backend web development and database development And full stack development is a term used to describe a software engineer or developer who works with both the front and back end of a website or application A fullstack developer is comfortable working with frontend and backend technologies that power a website or application Fullstack developers are often responsible for the entire web application development process from start to finish which means they must have a strong understanding of all the technologies and tools involved in web development They also need to work effectively with others on a team as web development is typically a collaborative process Most fullstack developers have a firm foundation in web development technologies such as HTML CSS and JavaScript They also have experience with serverside technologies such as PHP Ruby on Rails and Nodejs In addition to their technical skills fullstack developers also deeply understand how the various parts of a website or application work together Fullstack developers are in high demand because they can build a website or application from start to finish and quickly identify and fix any problems that may arise If youre looking to hire a fullstack developer ask about their experience with frontend and backend technologies Client Software Front End Client software also known as a front end is a type of software that interacts with users It is responsible for the graphical user interface GUI that users see and interact with It allows users to access and use the features and functions of the underlying software or system Client software typically runs on a users local machine instead of being hosted on a remote server In many cases the client software makes the users experience with a particular system or application possible Frontend Languages Several languages can be used for frontend development including HTML CSS and JavaScript Each language has its strengths and weaknesses so its essential to choose the correct language for the task HTML is the most basic of the three languages and is used to structure content on a web page CSS is used to style the content on a web page and can be used to create sophisticated layouts JavaScript is used to add interactivity to a web page and can be used to create dynamic content Want a Top Software Development Job Start HereFull Stack DevelopmentMEANExplore Program FrontEnd Frameworks and Libraries There are many frontend frameworks and libraries available to developers today Some of the most popular include React Angular and Vue Each of these frameworks has its benefits and drawbacks so choosing the one thats right for your project is essential React is a popular choice for many developers because its easy to learn and use Angular is a good choice for larger projects because its more featurerich Vue is a good choice for smaller projects because its lightweight and easy to use No matter which frontend framework you choose ensure youre familiar with it before starting your project In addition to the frameworks themselves several utility libraries can be used to supplement your development efforts These include libraries like Lodash Momentjs And Axios Again choosing a suitable library for the job is essential as each has unique capabilities Server Software Back End Server software also known as the backend software is responsible for managing and coordinating the activities of the server It is responsible for ensuring that the server is up and running and that all the different server components are functioning correctly Server software also provides an interface for users to interact with the server and for administrators to manage the server Some popular server software programs include Apache HTTP Server Microsoft IIS and Nginx These programs handle serverside tasks like hosting web pages taking user requests and sending responses To run a website or application you will need to have a server running server software This software allows users to interact with your site or application Without server software there would be no way for users to request data or information from your site Server software is an integral part of any website or application It is essential for anyone who wants to run a website or application to have a basic understanding of how it works Backend Languages There are a variety of backend languages that can be used to develop a website or application PHP Java Python and Ruby are the most popular backend languages Each language has its strengths and weaknesses so its essential to choose the correct language for the project PHP is a good choice for small projects that require simple functionality and Java is a good choice for larger projects that require more complex functionality Python is a good choice for projects requiring much data processing and Ruby is a good choice for projects requiring a lot of user interaction BackEnd Frameworks and Libraries Various backend frameworks and libraries are available to developers today These frameworks and libraries can be used to build web applications mobile applications and desktop applications Some popular backend frameworks and libraries include Ruby on Rails Laravel and Nodejs Each of these frameworks and libraries has its unique benefits and drawbacks Developers should carefully evaluate the needs of their project before choosing a backend framework or library Want a Top Software Development Job Start HereFull Stack DevelopmentMEANExplore Program Popular Stacks There are a few popular stacks that developers often use The most popular stack is the MEAN stack which is used for developing web applications and consists of MongoDB Expressjs AngularJS and Nodejs Another popular stack is the LAMP stack which is also used for developing serverside applications and it includes Linux Apache MySQL and PHP Advantages and Disadvantages of Full Stack Development Advantages There are many advantages to fullstack development The most obvious benefit is that it allows developers to understand the entire web development process thoroughly and this comprehensive understanding can lead to more efficient and effective development Another advantage of fullstack development is that it can make development more efficient overall Fullstack developers can more easily identify potential bottlenecks and issues by thoroughly understanding the frontend and backend development process This can help save time and money by preventing development problems before they occur Fullstack development can also help create more cohesive and userfriendly websites and applications By having a deep understanding of both the frontend and backend development process fullstack developers can create a more unified user experience that can lead to increased customer satisfaction and loyalty Overall fullstack development provides many benefits that can lead to more efficient effective and userfriendly web development Disadvantages There are a few potential disadvantages to fullstack development One is that because fullstack developers need to have a broad range of skills they may not be as deep in any particular area as a specialist which could lead to issues if a project requires an intense level of specific expertise Another potential disadvantage is that because fullstack developers need to be able to work with a variety of technologies they may need to spend more time keeping up with new developments than specialists who only need to focus on one area Finally fullstack development can be more complex and timeconsuming than technological development so it may not be the best option for small projects or tight deadlines Looking to accelerate your career as a skilled Full Stack Web Developer Leverage Caltech CTMEs academic excellence in a unique bootcampstyle Post Graduate Program in Full Stack Web Development Enroll Now Conclusion Hope this article was able to give you a clear understanding about full stack development If you are looking to enhance your web development skills we would highly recommend you to check Simplilearns Post Graduate Program in Full Stack Web Development This program designed in collaboration with Caltech CTME can help you gain the relevant web development knowledge and make you jobready in just six months If you have any questions or queries feel free to post them in the comments section below Our team will get back to you at the earliest Find our Full Stack Developer  MEAN Stack Online Bootcamp in top citiesNameDatePlace Full Stack Developer  MEAN Stack Cohort starts on 17th Jan 2024 Weekend batchYour CityView Details Full Stack Developer  MEAN Stack Cohort starts on 31st Jan 2024 Weekend batchYour CityView DetailsAbout the AuthorSimplilearnSimplilearn is one of the worlds leading providers of online training for Digital Marketing Cloud Computing Project Management Data Science IT Software Development and many other emerging technologiesView MoreRecommended ProgramsFull Stack Web Developer  MEAN Stack 893 LearnersLifetime AccessPost Graduate Program in Full Stack Web Development 2344 LearnersLifetime AccessCaltech Coding Bootcamp 767 LearnersLifetime AccessLifetime access to highquality selfpaced elearning contentExplore Category Next ArticleWhat Makes a Full Stack Web DeveloperBy Simplilearn4815May 24 2023Recommended ResourcesAWS Introduction GuideEbookThe Path to a Full Stack Web Developer CareerArticleThe Perfect Guide for All You Need to Learn About MEAN StackTutorialAWS Basics A Beginners GuideEbookAverage Full Stack Developer SalaryArticleImplementing Stacks in Data StructuresTutorialprevNext Name Date Place 0 Name Date Place 1 Full Stack Developer  MEAN Stack Cohort starts on 17th Jan 2024 Weekend batch Your City View Details 2 Full Stack Developer  MEAN Stack Cohort starts on 31st Jan 2024 Weekend batch Your City View Details","https://www.simplilearn.com/what-is-full-stack-development-article, https://www.simplilearn.com/what-is-full-stack-development-article",Full Stack Development,636,1730
"Testing and Debugging (e.g., unit tests, integration tests)", Products Web Testing Test websites or web apps on real browsers App Testing Test iOS  Android mobile apps on real devices Manual Testing Live Crossbrowser testing Accessibility Testing Test WCAG compliance Test Automation Automate Browser automation grid Automate TurboScale Automation on your Cloud Accessibility Automation Automate WCAG testing Percy Visual testing  review Low Code Automation Automation without coding Management  Optimization Test Management Unify  track all test cases Test Observability Test debugging  insights For Teams Enterprise Code Quality Empower teams with BrowserStack for Enterprise Explore BrowserStack Code Quality  Manual Testing App Live Real device testing Test Automation App Automate Real device automation cloud App Percy Visual testing for mobile apps Management  Optimization Test Management Unify  track all test cases Test Observability Test debugging  insights For Teams Enterprise Code Quality Empower teams with BrowserStack for Enterprise Explore BrowserStack Code Quality Developers Documentation Support Status Release Notes Open Source Events Test University Beta ChampionsLive for TeamsPricingSign inFree Trial Oo BrowserStack How to testa apk file ce BrowserStack Introducing BrowserStack SDK A plugandplay solution to run your test suite on the BrowserStack Cloud with no code changes  What is Test Management Benefits Challenges  Best Practices 7 O BrowserStack r Aspect Testing Debugging 0 Aspect Testing Debugging 1 Purpose and Objectives Validate software functionality performance and usability Ensure adherence to requirements and specifications Identify and fix errors bugs and issues in the code Resolve unexpected behaviors and defects 2 Timing and Scope Stage of SDLC Conducted throughout the development lifecycle from early requirements gathering to postrelease Broad scope covering all aspects of the software Typically performed after the testing phase during development or postrelease and focused on resolving specific reported issues or unexpected behaviors Narrow scope targeting specific areas of the codebase 3 Roles and Responsibilities Testers or quality assurance professionals typically carry out testing They create test plans execute test cases and report issues Debugging is primarily the responsibility of developers They analyse code identify the root cause of issues and apply fixes 4 Types of Issues Addressed Testing addresses functional performance usability and other requirementsbased issues It verifies expected behavior and detects deviations Debugging focuses on finding and resolving errors bugs and unexpected behaviors in the code It targets specific issues reported by users or identified during testing 5 Tools and Techniques Used Testing utilizes test management systems automated testing frameworks and performance testing tools Techniques include creating test cases test data and test environments Debugging employs debugging tools provided by IDEs log analysis tools code analyzers and stepthrough debugging techniques Developers may also use code profilers memory analyzers and errortracking systems 6 ImportancePriority in Software Development Testing ensures software quality reduces defects and improves user experience It helps in identifying issues early and reducing risks Debugging is essential for resolving reported issues fixing errors and maintaining a stable and reliable software system It addresses specific issues that impact functionality stability and user satisfaction It plays a critical role in delivering bugfree software,https://www.browserstack.com/guide/difference-between-testing-and-debugging,Testing and Debugging,261,490
Websockets for Real-Time Communication,GUIDEWhat are WebSocketsWhat are WebSocketsA WebSocket is a communication protocol that provides fullduplex communication channels over a single TCP connection It enables realtime eventdriven communication between a client and a serverUnlike traditional HTTP which follows a requestresponse model WebSockets allow bidirectional communication This means that the client and the server can send data to each other anytime without continuous pollingWhat are WebSockets Used ForWebSockets are used for realtime eventdriven communication between clients and servers They are particularly useful for building applications requiring instant updates such as realtime chat messaging and multiplayer gamesIn traditional HTTP the client sends a request to the server and the server responds with the requested data This requestresponse model requires continuous polling from the client to the server which can result in increased latency and decreased efficiencyOn the other hand WebSockets establish a persistent connection between the client and the server This means that once the connection is established the client and the server can send data to each other at any time without continuous polling This allows realtime communication where updates can be sent and received instantlyFor example when a user sends a message in a chat application it can be instantly delivered to all other users without refreshing the page or making frequent HTTP requests This results in a more seamless and efficient user experienceFurthermore Web Sockets also allow for bidirectional communication meaning that both the client and the server can send data to each other This opens up possibilities for more interactive and engaging applications where the server can push updates or notifications to the client without the client explicitly requesting themDrawbacks of Web SocketsThe drawbacks of WebSockets includeBrowser Support Although most modern browsers support WebSockets some older ones do not This can limit the reach of your application and require additional fallback mechanisms for older browsersProxy and Firewall Limitations Some proxy servers and firewalls may block or interfere with WebSocket connections This can cause connectivity issues especially in corporate or restricted network environmentsScalability Web Sockets maintain a persistent connection between the client and the server which can strain server resources when dealing with many concurrent connections Proper load balancing and resource management techniques must be implemented to ensure scalability Opensource resources like Socketio are not great for largescale operations or quick growthStateful Nature Unlike traditional HTTP which is stateless WebSockets are stateful This means that the server needs to maintain the connection state for each client leading to increased memory usage and potential scalability challengesSecurity Considerations With the persistent connection established by WebSockets there is a need for proper security measures to protect against potential vulnerabilities such as crosssite scripting XSS and crosssite request forgery CSRF Secure WebSocket connections wss using SSLTLS encryption should be implemented to ensure data privacy and integrityIf a connection over Web Sockets is lost there are no included load balancing or reconnecting mechanismsIt is still necessary to have fallback options like HTTP streaming or long polling in environments where Web Sockets may not be supportedFeatures like Presence do not work well over WebSocket connections because disconnections are hard to detectWebSockets vs HTTP vs web servers vs pollingHTTP connections vs WebSocketsTo understand the WebSocket API it is also important to understand the foundation it was built on  HTTP Hypertext Transfer Protocol and its requestresponse model HTTP is an application layer protocol and the basis for all webbased communication and data transfersWhen using HTTP clientssuch as web browserssend requests to servers and then the servers send messages back known as responses The web as we know it today was built on this basic clientserver cycle although there have been many additions and updates to HTTP to make it more interactive There are currently a few viable and supported versions of HTTPHTTP11 and HTTP2and a secure version known as HTTPSBasic HTTP requests work well for many use cases such as when someone needs to search on a web page and receive relevant nontimesensitive information However it is not always best suited for web applications requiring realtime communication or data that needs to update quickly with minimal latency Whenever the client makes a new HTTP server request the default behavior is to open a new HTTP connection This is inefficient because it uses bandwidth on recurring nonpayload data and increases latency between the data transfers Additionally HTTP requests can only flow in one directionfrom the client side There is traditionally no mechanism for the server to initiate communication with the client The server cannot send data to the client unless it requests it first This can create issues for use cases where messaging needs to go out in real time from the server side Short polling vs WebSocketsOne of the first solutions for receiving regular data updates was HTTP polling Polling is a technique where the client repeatedly sends requests to the server until it updates For example all modern web browsers offer support for XMLHttpRequest one of the original methods of polling serversThese earlier solutions were still not ideal for efficient realtime communicationshort polling is intensive because for every request the nonpayload data is resent and must be parsed including the header HTML the web URL and other repetitive information that wastes resourcesLong polling vs Web SocketsThe next logical step to improve latency was HTTP long polling When long polling the client polls the server and that connection remains open until the server has new data The server sends the response with the relevant information and then the client immediately opens another request holding again until the next update Long polling can hold a connection open for a maximum of 280 seconds before automatically sending another request This method effectively emulates an HTTP server pushLong polling provides fast communication in many environments and is widely used often as opposed to true pushbased methods like WebSocket connections or Server Side Events SSE Long polling can seem intensive on the server side as it requires continuous resources to hold a connection open but it uses much less than repeatedly sending polling requestsRead more on Long Polling vs Websockets What are WebSockets used forDevelopers invented WebSockets to facilitate realtime results effectively WebSockets initiate continuous fullduplex communication between a client and WebSocket server This reduces unnecessary network traffic as data can immediately travel both ways through a single open connection This provides speed and realtime capability on the web Websockets also enable servers to keep track of clients and push data to them as needed which was not possible using only HTTPWebSocket connections enable the streaming of text strings and binary data via messages WebSocket messages include a frame payload and data portion Very little nonpayload data gets sent across the existing network connection this way which helps to reduce latency and overhead especially when compared to HTTP request and streaming modelsGoogle Chrome was the first browser to include standard support for WebSockets in 2009 RFC 6455The WebSocket Protocolwas officially published online in 2011 The WebSocket Protocol and WebSocket API are standardized by the W3C and the IETF and support across browsers is very commonHow do WebSockets work and their connectionsBefore a client and server exchange data they must use the TCP Transport Control Protocol layer to establish the connection Using their WebSocket protocol webSockets effectively run as a transport layer over the TCP connectionOnce connected through an HTTP requestresponse pair the clients can use an HTTP11 upgrade header to switch their connection from HTTP to WebSockets WebSocket connections are fully asynchronous unlike HTTP11 however WebSocket connection is established through a WebSocket handshake over the TCP During a new WebSocket handshake the client and server also communicate which subprotocol will be used for subsequent interactions After this is established the connection will run on the WebSocket protocolIt is important to note that when running on the WebSocket protocol layer WebSockets require a uniform resource identifier URI to use a ws or wss scheme similar to how HTTP URLs will always use a http or https schemeWhat libraries are available for implementing WebSocketsSeveral libraries can provide the necessary tools and functionalities when implementing WebSockets in your realtime chat and messaging applications These libraries offer a wide range of features and support for different programming languages making it easier for developers to integrate WebSockets into their applications Here are some of the popular libraries that you can consider1 SocketIO SocketIO is a widely used library that provides realtime bidirectional eventbased communication between the browser and the server It offers features like automatic reconnection fallback options and support for various transports making it an excellent choice for building scalable and reliable applications SocketIO supports multiple programming languages including JavaScript Python and Java2 SignalR SignalR is a realtime communication library developed by Microsoft It allows you to build realtime web applications by providing a simple API for creating WebSockets connections SignalR supports serverside and clientside implementations and can be used with NET JavaScript and other languages It also offers automatic connection management broadcasting messages and scaling across multiple servers3 SockJS SockJS is a JavaScript library that provides a WebSocketlike object in the browser even if the server doesnt support WebSockets It offers a fallback mechanism that uses alternative transport protocols such as HTTP longpolling allowing your application to work in environments where websockets are unavailable SockJS can be used with various backends and programming languages including Nodejs Java and Python4 ws ws is a simple and lightweight WebSocket implementation for Nodejs It provides a straightforward API for creating WebSocket servers and clients making it easy to integrate websockets into your Nodejs applications ws offers permessage compression automatic reconnection and customizable options for handling incoming and outgoing messages5 Django Channels Django Channels is a library that extends the capabilities of the Django web framework to handle realtime applications It supports websockets and other protocols like HTTP longpolling and ServerSent Events Django Channels allows you to build realtime chat and messaging applications using the familiar Django syntax and toolsReasons to consider WebSockets for realtime communicationWebsockets provide realtime updates and open lines of communicationWebsockets are HTML5 compliant and offer backward compatibility with older HTML documents Therefore all modern web browsersGoogle Chrome Mozilla Firefox Apple Safari and more support them WebSockets are compatible across Android iOS web and desktop platformsA single server can have multiple WebSocket connections open simultaneously and multiple connections with the same client which opens the door for scalabilityWebSockets can stream through many proxies and firewallsThere are many opensource resources and tutorials for incorporating WebSockets in an application like the Javascript library Socketio PubNubs Take on WebSockets vs Long PollingPubNub takes a protocolagnostic stance but in our current operations we have found that long polling is the best bet for most use cases This is partly because of the maintenance and upkeep required to scale WebSockets on the backend and potential issues that can arise when you can not easily identify a disconnection WebSockets are a great tool but long polling works reliably in every situationPubNub uses long polling to ensure reliability security and scalability in all networking environments not just most Long polling can be as efficient as WebSockets in many realworld realtime implementations We have developed a method for efficient long polling  written in C and with multiple kernel optimizations for scalePubNub is a realtime communications platform that provides the foundation for authentic virtual experiences like live updates inapp chat push notifications and more The building block structure of our platform allows for extra features like Presence operational dashboards or geolocation to be incorporated PubNub also makes it extremely easy to scale especially compared to socket frameworks like Socketio or SocksJSSummaryTo conclude WebSockets are a very useful protocol for building realtime functionality across web mobile and desktop variants but they are not a onesizefitsall approach WebSockets are just one tool that fits into a larger arsenal when developing realtime communicationbased applications that require low latency It is possible to build off of basic WebSocket protocol incorporate other methods like SSE or long polling and construct an even better more scalable realtime application The problem is that when you use WebSockets the shortcomings can be difficult to manage if you are not an expert in building realtime systemsUsing PubNub provides a better user experience saves significant development time and maintenance costs speeds up time to market and reduces the complexity of what your engineering and web development team will need to develop manage and grow With over 15 points of presence worldwide supporting 800 million monthly active users and 99999 reliability youll never have to worry about outages concurrency limits or any latency issues caused by traffic spikes PubNub is perfect for any application that requires realtime dataSign up for a free trial and get up to 200 MAUs or 1M total transactions per month includedContents ,https://www.pubnub.com/guides/websockets/,Front-End Development,752,2118
"Cloud Computing Services (e.g., AWS, Azure)", What is cloud computing A beginners guide Start free What is cloud computing What is Azure Azure vs AWS Cloud terminology Benefits Cloud deployment types Cloud computing models Uses Resources FAQ What is cloud computing What is Azure Azure vs AWS Cloud terminology Benefits Cloud deployment types Cloud computing models Uses Resources FAQ Free account Simply put cloud computing is the delivery of computing servicesincluding servers storage databases networking software analytics and intelligenceover the internet the cloud to offer faster innovation flexible resources and economies of scale You typically pay only for cloud services you use helping you lower your operating costs run your infrastructure more efficiently and scale as your business needs change Top benefits of cloud computing Cloud computing is a big shift from the traditional way businesses think about IT resources Here are seven common reasons organizations are turning to cloud computing services Cost Moving to the cloud helps companies optimize IT costs This is because cloud computing eliminates the capital expense of buying hardware and software and setting up and running onsite datacentersthe racks of servers the roundtheclock electricity for power and cooling and the IT experts for managing the infrastructure It adds up fast Speed Most cloud computing services are provided self service and on demand so even vast amounts of computing resources can be provisioned in minutes typically with just a few mouse clicks giving businesses a lot of flexibility and taking the pressure off capacity planning Global scale The benefits of cloud computing services include the ability to scale elastically In cloud speak that means delivering the right amount of IT resourcesfor example more or less computing power storage bandwidthright when theyre needed and from the right geographic location Productivity Onsite datacenters typically require a lot of racking and stackinghardware setup software patching and other timeconsuming IT management chores Cloud computing removes the need for many of these tasks so IT teams can spend time on achieving more important business goals Performance The biggest cloud computing services run on a worldwide network of secure datacenters which are regularly upgraded to the latest generation of fast and efficient computing hardware This offers several benefits over a single corporate datacenter including reduced network latency for applications and greater economies of scale Reliability Cloud computing makes data backup disaster recovery and business continuity easier and less expensive because data can be mirrored at multiple redundant sites on the cloud providers network Security Many cloud providers offer a broad set of policies technologies and controls that strengthen your security posture overall helping protect your data apps and infrastructure from potential threats Types of cloud computing Not all clouds are the same and no single type of cloud computing is right for everyone Several different models types and services have evolved to help offer the right solution for your needs First you need to determine the type of cloud deployment or cloud computing architecture that your cloud services will be implemented on There are three different ways to deploy cloud services on a public cloud private cloud or hybrid cloud Learn more about public private and hybrid clouds Public cloud Public clouds are owned and operated by thirdparty cloud service providers which deliver computing resources like servers and storage over the internet Microsoft Azure is an example of a public cloud With a public cloud all hardware software and other supporting infrastructure is owned and managed by the cloud provider You access these services and manage your account using a web browser Private cloud A private cloud refers to cloud computing resources used exclusively by a single business or organization A private cloud can be physically located on the companys onsite datacenter Some companies also pay thirdparty service providers to host their private cloud A private cloud is one in which the services and infrastructure are maintained on a private network Hybrid cloud Hybrid clouds combine public and private clouds bound together by technology that allows data and applications to be shared between them By allowing data and applications to move between private and public clouds a hybrid cloud gives your business greater flexibility and more deployment options and helps optimize your existing infrastructure security and compliance Types of cloud services IaaS PaaS serverless and SaaS Most cloud computing services fall into four broad categories infrastructure as a service IaaS platform as a service PaaS serverless and software as a service SaaS These are sometimes called the cloud computing stack because they build on top of one another Knowing what they are and how theyre different makes it easier to accomplish your business goals IaaS The most basic category of cloud computing services With infrastructure as a service IaaS you rent IT infrastructureservers and virtual machines VMs storage networks operating systemsfrom a cloud provider on a payasyougo basis PaaS Platform as a service PaaS refers to cloud computing services that supply an ondemand environment for developing testing delivering and managing software applications PaaS is designed to make it easier for developers to quickly create web or mobile apps without worrying about setting up or managing the underlying infrastructure of servers storage network and databases needed for development SaaS Software as a service SaaS is a method for delivering software applications over the internet on demand and typically on a subscription basis With SaaS cloud providers host and manage the software application and underlying infrastructure and handle any maintenance like software upgrades and security patching Users connect to the application over the internet usually with a web browser on their phone tablet or PC Serverless computing Overlapping with PaaS serverless computing focuses on building app functionality without spending time continually managing the servers and infrastructure required to do so The cloud provider handles the setup capacity planning and server management for you Serverless architectures are highly scalable and eventdriven only using resources when a specific function or trigger occurs Browse a dictionary of common cloud computing terms Uses of cloud computing Youre probably using cloud computing right now even if you dont realize it If you use an online service to send email edit documents watch movies or TV listen to music play games or store pictures and other files its likely that cloud computing is making it all possible behind the scenes A variety of organizationsfrom tiny startups to global corporations government agencies to nonprofitshave embraced cloud computing technology for all sorts of reasons Here are a few examples of whats possible with cloud services from a cloud provider Create cloudnative applications Quickly build deploy and scale applicationsweb mobile and API Take advantage of cloudnative technologies and approaches such as containers Kubernetes microservices architecture APIdriven communication and DevOps Store back up and recover data Protect your data more costefficientlyand at massive scaleby transferring your data over the internet to an offsite cloud storage system thats accessible from any location and any device Stream audio and video Connect with your audience anywhere anytime on any device with highdefinition video and audio with global distribution Deliver software on demand Also known as software as a service SaaS ondemand software lets you offer the latest software versions and updates to customersanytime they need anywhere they are Test and build applications Reduce application development cost and time by using cloud infrastructures that can easily be scaled up or down Analyze data Unify your data across teams divisions and locations in the cloud Then use cloud services such as machine learning and artificial intelligence to uncover insights for more informed decisions Embed intelligence Use intelligent models to help engage customers and provide valuable insights from the data captured How to choose a cloud provider Microsoft and cloud computing Microsoft is a leading global provider of cloud computing services for businesses of all sizes To learn more about the Microsoft cloud platform and how Microsoft Azure compares to other cloud providers see What is Azure and Azure vs AWS And to accelerate your cloud journey with best practices resources and expert help see the Azure Migration and Modernization Program Additional resources Explore Azure demo series Customer stories Developer stories Guides and webinars Forrester Executive Guide to the Cloud Migrating and Modernizing Your Workloads with Azure webinar Events and Virtual Training Days Learn more Developer community newsletter Azure cloud concepts tutorial Student developer resources Frequently asked questions What is the cloud The cloud is an extensive network of remote servers around the world These servers store and manage data run applications and deliver content and services like streaming videos web mail and office productivity software over the internet Storing your files and data in the cloud frees you from relying on local computers and servers Instead you can access your data online from any internetcapable device whenever and wherever you want Learn more What is multicloud computing Multicloud computing entails using multiple cloud computing services from more than one cloud provider for the same type of IT solutions or workloads A multicloud strategywhich may include both private and public cloudshelps organizations mitigate risk and offers them increased workload flexibility Choosing different offerings and capabilities from more than one cloud provider enables organizations to build solutions that are best suited to their specific IT needs Learn more What skills are required for cloud computing In general cloud computing does not require technical IT experience Cloud computing simply refers to the delivery of computing services over the internet including storage databases software and analytics Whether you have a basic understanding of computing concepts and terminology or are a more technical worker you can apply the onpremises computing knowledge and skills you currently have to the cloud Learn more How much does cloud computing cost Cloud providers typically employ a payasyougo pricing model which means that organizations only pay for the cloud services that they use This helps companies reduce their operating costs run their infrastructure more efficiently and scale their cloud computing costs up or down according to changing business needs For example Azure offers payasyougo pricing with no upfront commitment and free services that include popular services free for 12 months and 55 other services free always ,https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/what-is-cloud-computing,Cloud Computing,630,1681
DevOps Practices for Web Development,The world wide web is more than just a world its a vast universe that provides users with millions of websites and applications with limitless possibilities To create all of this content and software web developers need to collaborate efficiently and quickly to respond to any necessary modifications and continue building and maintaining their productsWeb developers have many methodologies to create the best product possible and one of those methods guarantees efficiency throughout the process of not only building and designing sites but also maintaining and updating them continuously Once software has been developed web development teams also have the responsibility to improve upon and update their work But what does this have to do with DevOps Lets check it outWhat is DevOpsThe word DevOps is composed of two words development and operations They are both two parts of a complete set of practices that guide and assist software developers in their design and maintenance process There are two teams that collaborate to carry these outDevelopment team this group of programmers focuses on building designing and coding the software testing and improving the code as needed Operations team unlike the development team the operations team works on deployment maintenance and troubleshooting the infrastructure of the productDevelopment and operations teams sometimes work separately on their respective duties but DevOps practices entail consistent communication Since they are not siloed they are fully aware of what the other team is tasked with at all times Along with the help of automation the two teams are constantly investing their time in developing and improving their product in a continuous deployment and integration pipeline The DevOps lifecycle is also an important aspect of their management style that shows how both teams are both collaborating and working independently Representing its continuous nature the DevOps lifecycle takes on the shape of an infinity loop On one side of the loop the development team plans discovers builds and tests on the other side the operations team deploys operates observes and provides continuous feedbackBy leveraging the DevOps lifecycle DevOps teams engage in a continuous deployment and continuous integration pipelineDevOps a breakdownWhat is Web DevelopmentEvery website or application with which you interact relies on web developers carrying out a lot of coding and designing When designing web pages and applications they use two types of web development front end development and back end development however a third type of development exists called full stack developmentFront end developmentWhen users interact with a website or application they are directly making contact with front end developed code Front end developers write the code for all the visible and clickable aspects of pages and must use the following codesHTMLJavaScriptCSS3Back end developmentWhere front end entails all the visible and clickable aspects back end development is the opposite everything with which the user cant directly interact The back end is the server side where data is stored and is just as important as the front end although users dont see it The following languages are necessary for back end developersPHPPythonNetRubyOther essential skills include expertise with one or several of the following database technologiesOracleMySQLMicrosoft SQL ServerAlthough these two types of development are necessary to create a website there are developers that work on a third type of developmentThe Ten Best Programming Languages to LearnFull stack developmentWhy do just one or the other when you can do both Full stack developers are trained to do both back and front end development with a variety of skills they are very versatile and adaptable What Responsibilities do DevOps Engineers HaveWhen youre a DevOps engineer you have a lot to keep in mind in terms of your responsibilities since these duties will be allencompassing You must know how to take on both development and operations teams responsibilities the development side consists of the following dutiesCoding developers have to know how to code to create and design their current productTest ensuring that the code is working as it should is crucial in the developers process although they normally set up automated systems to carry them out developers still need to check up on themPlan a great amount of planning is necessary to make the best product possible and developers need to create a plan for the product and the full processReview the code that developers are writing for their projects doesnt just statically stay there they need to build upon it and review it to keep improving their code throughout the processThe operations team has very different duties that they must carry out said duties includeDeployment when the product is released the operations team ensures that the product is working as planned Operation the product has been deployed and as the product is live the IT team focuses on providing the services promised to clients Monitor if there are any problems that arise postdeployment the IT team must take note of them and attempt to resolve them if possibleFeedback anything that the operations team encounters or has been told by clients must be returned back to the development team so that they can improve the productAlthough they normally operate as separate teams that collaborate DevOps engineers bring the two worlds together as a nexus and their duties truly depend on where they are working and what the team needs from them Nevertheless engineering infrastructure mapping DevOps knowledge and advocacy and system maintenance are other skills that will likely be necessary for a DevOps engineerLearning DevOps for your Web DevelopmentHow do DevOps and Web Development DifferIt is easy to contrast DevOps and web development since DevOps is a set of practices that software development teams use to design the best product possible and keep improving it in continuous loops web development is the process of creating web pages and applications To put it simply one is a methodology and the other is a field of studyA web development team may decide to adopt DevOps as their methodology for their product and that would be simply one of the strategies that they employ for their teams along with agile scrum waterfall or lean It all depends on which one is the most appropriate for the team and even the individual projectStartUp Methodologies AgileHow do Web Developers and DevOps Engineers Work TogetherThere are several ways for project managers to manage their teams and most use a mixture of methodologies to find the right balance for what will best fit When DevOps engineers are working alongside web developers they are not only taking on assisting in both developmental and operational tasks but also they are advocating and leading teams in DevOpsDevOps for web development is the same as what other DevOpsled teams employ the DevOps lifecycle and communication and collaboration between the two teams to create a continuous deployment and integration pipeline however web development teams are usually more focused on the development part of the process As a result web developers will need to be put into teams that DevOps engineers help facilitate and organize DevOps engineers usually head project management of teams of web developers although this will always be dependent upon the project and what it requires DevOps engineers would also develop automated processes that assist in testing and completing the project as web developers mostly focus on the creating reviewing and maintenance DevOps for web developers is possible and all boils down to strong leadershipIn the tech world web development and DevOps are integral parts of project management one is the methodology and the other the process of creating the product Web development is a basic necessity nowadays but DevOps is just one of many methodologies although it is becoming more and more popular If you would like to work as a web developer or even learn relevant skills to become a DevOps engineer the best route would be an Ironhack bootcamp like our Web Development Bootcamp Check it out hereDiscover Web Development with Ironhack ,https://www.ironhack.com/gb/blog/the-role-of-devops-in-web-development,DevOps,457,1313
Continuous Integration/Continuous Deployment (CI/CD), Home Software Development CICD What is CICD Continuous integration and continuous delivery explained CICD is a best practice for devops and agile development Heres how software development teams automate continuous integration and delivery all the way through the CICD pipeline By Isaac Sacolick Contributor InfoWorld  doguhakan  Getty Images Table of Contents CICD defined Automating the CICD pipeline How continuous integration improves collaboration and code quality Stages in the continuous delivery pipeline CICD tools and plugins CICD with Kubernetes and serverless architectures Next generation CICD applications Conclusion Show More Continuous integration CI and continuous delivery CD also known as CICD embodies a culture and set of operating principles and practices that application development teams use to deliver code changes both more frequently and more reliablyCICD is a best practice for devops teams It is also a best practice in agile methodology By automating code integration and delivery CICD lets software development teams focus on meeting business requirements while ensuring that software is high in quality and secureCICD definedContinuous integration is a coding philosophy and set of practices that drive development teams to frequently implement small code changes and check them in to a version control repository Most modern applications require developing code using a variety of platforms and tools so teams need a consistent mechanism to integrate and validate changes Continuous integration establishes an automated way to build package and test their applications Having a consistent integration process encourages developers to commit code changes more frequently which leads to better collaboration and code quality Continuous delivery picks up where continuous integration ends and automates application delivery to selected environments including production development and testing environments Continuous delivery is an automated way to push code changes to these environmentsAutomating the CICD pipelineCICD tools help store the environmentspecific parameters that must be packaged with each delivery CICD automation then makes any necessary service calls to web servers databases and other services that need restarting It can also execute other procedures following deploymentBecause the objective is to deliver quality code and applications CICD also requires continuous testing In continuous testing a set of automated regression performance and other tests are executed in the CICD pipeline A mature devops team with a robust CICD pipeline can also implement continuous deployment where application changes run through the CICD pipeline and passing builds are deployed directly to the production environment Some teams practicing continuous deployment elect to deploy daily or even hourly to production though continuous deployment isnt optimal for every business applicationOrganizations that implement a CICD pipeline often have several devops best practices in place including microservices development serverless architecture continuous testing infrastructure as code and deployment containers Each of these practices improves process automation and increases the robustness of cloud computing environments Together these practices provide a strong foundation to support continuous deployment How continuous integration improves collaboration and code qualityContinuous integration is a development philosophy backed by process mechanics and automation When practicing continuous integration developers commit their code into the version control repository frequently most teams have a standard of committing code at least daily The rationale is that its easier to identify defects and other software quality issues on smaller code differentials than on larger ones developed over an extensive period In addition when developers work on shorter commit cycles it is less likely that multiple developers will edit the same code and require a merge when committingTeams implementing continuous integration often start with the version control configuration and practice definitions Although checking in code is done frequently agile teams develop features and fixes on shorter and longer timeframes Development teams practicing continuous integration use different techniques to control what features and code are ready for productionMany teams use feature flags a configuration mechanism to turn features and code on or off at runtime Features that are still under development are wrapped with feature flags in the code deployed with the main branch to production and turned off until they are ready to be used In recent research devops teams using feature flags had a ninefold increase in development frequency Feature flagging tools such as CloudBees Optimizely Rollouts and LaunchDarkly integrate with CICD tools to support featurelevel configurationsAutomated buildsIn an automated build process all the software database and other components are packaged together For example if you were developing a Java application continuous integration would package all the static web server files such as HTML CSS and JavaScript along with the Java application and any database scripts Continuous integration not only packages all the software and database components but the automation will also execute unit tests and other types of tests Testing provides vital feedback to developers that their code changes didnt break anythingMost CICD tools let developers kick off builds on demand triggered by code commits in the version control repository or on a defined schedule Teams need to determine the build schedule that works best for the size of the team the number of daily commits expected and other application considerations A best practice is to ensure that commits and builds are fast otherwise these processes may impede teams trying to code quickly and commit frequentlyContinuous testing and security automationAutomated testing frameworks help quality assurance engineers define execute and automate various types of tests that can help development teams know whether a software build passes or fails They include functionality tests developed at the end of every sprint and aggregated into a regression test for the entire application The regression test informs the team whether a code change failed one or more of the tests developed across the functional areas of the application where there is test coverageA best practice is to enable and require developers to run all or a subset of regression tests in their local environments This step ensures developers only commit code to version control after code changes have passed regression tests Regression tests are just the beginning however Devops teams also automate performance API browser and device testing Today teams can also embed static code analysis and security testing in the CICD pipeline for shiftleft testing Agile teams can also test interactions with thirdparty APIs SaaS and other systems outside of their control using service virtualization The key is being able to trigger these tests through the command line a webhook or a web service and get a success or failure responseContinuous testing implies that the CICD pipeline integrates test automation Some unit and functionality tests will flag issues before or during the continuous integration process Tests that require a full delivery environment such as performance and security testing are often integrated into continuous delivery and done after a build is delivered to its target environmentsStages in the continuous delivery pipelineContinuous delivery is the automation that pushes applications to one or more delivery environments Development teams typically have several environments to stage application changes for testing and review A devops engineer uses a CICD tool such as Jenkins CircleCI AWS CodeBuild Azure DevOps Atlassian Bamboo Argo CD Buddy Drone or Travis CI to automate the steps and provide reportingFor example Jenkins users define their pipelines in a Jenkinsfile that describes different stages such as build test and deploy Environment variables options secret keys certifications and other parameters are declared in the file and then referenced in stages The post section handles error conditions and notificationsA typical continuous delivery pipeline has build test and deploy stages The following activities could be included at different stages Pulling code from version control and executing a build Enabling stage gates for automated security quality and compliance checks and supporting approvals when required Executing any required infrastructure steps automated as code to stand up or tear down cloud infrastructure Moving code to the target computing environment Managing environment variables and configuring them for the target environment Pushing application components to their appropriate services such as web servers APIs and database services Executing any steps required to restart services or call service endpoints needed for new code pushes Executing continuous tests and rollback environments if tests fail Providing log data and alerts on the state of the delivery Updating configuration management databases and sending alerts to IT service management workflows on completed deployments A more sophisticated continuous delivery pipeline might have additional steps such as synchronizing data archiving information resources or patching applications and librariesTeams using continuous deployment to deliver to production may use different cutover practices to minimize downtime and manage deployment risks One option is configuring canary deployments with an orchestrated shift of traffic usage from the older software version to the newer one CICD tools and pluginsCICD tools typically support a marketplace of plugins For example Jenkins lists more than 1800 plugins that support integration with thirdparty platforms user interface administration source code management and build managementOnce the development team has selected a CICD tool it must ensure that all environment variables are configured outside the application CICD tools allow development teams to set these variables mask variables such as passwords and account keys and configure them at the time of deployment for the target environmentContinuous delivery tools also provide dashboard and reporting functions which are enhanced when devops teams implement observable CICD pipelines Developers are alerted if a build or delivery fails The dashboard and reporting functions integrate with version control and agile tools to help developers determine what code changes and user stories made up the build Measuring CICD success with devops KPIs The impact of implementing CICD pipelines can be measured as a devops key performance indicator KPI Indicators such as deployment frequency change lead time and incident meantime to recovery MTTR are often improved by implementing CICD with continuous testing However CICD is just one process that can drive these improvements and there are other prerequisites to improving deployment frequencies CICD with Kubernetes and serverless architecturesMany teams operating CICD pipelines in cloud environments also use containers such as Docker and orchestration systems such as Kubernetes Containers allow for packaging and shipping applications in a standard portable way Containers make it easy to scale up or tear down environments with variable workloadsThere are many approaches to using containers infrastructure as code IaC and CICD pipelines together Free tutorials such as Kubernetes with Jenkins or Kubernetes with Azure DevOps can help you explore your optionsAnother option is to use a serverless architecture to deploy and scale your applications In a serverless environment the cloud service provider manages the infrastructure and the application consumes resources as needed based on its configuration On AWS for example serverless applications run as Lambda functions and deployments can be integrated into a Jenkins CICD pipeline with a plugin Azure serverless and GPS serverless computing are similar servicesNext generation CICD applicationsYou may be wondering about some of the more advanced areas for CICD pipeline development and management Here are a few notable ones MLOps is the IaC and CICD of machine learning models and supports infrastructure integration and deployment to training and production environments Synthetic data generation techniques use machine learning to create data sets used by test automation engineers to test APIs and by data scientists to train models AIOps platforms or machine learning and automation in IT Ops aggregate observability data and correlates alerts from multiple sources into incidents Automations can trigger CICD deployments and rollbacks as required Teams working on microservices create reusable pipelines to support and scale development and review options on Azure and AWS Engineers use CICD in other areas including network configuration embedded systems database changes IoT and ARVR ConclusionTo recap continuous integration packages and tests software builds and alerts developers if their changes fail any unit tests Continuous delivery is the automation that delivers applications services and other technology deployments to the runtime infrastructure and may execute additional testsDeveloping a CICD pipeline is a standard practice for businesses that frequently improve applications and require a reliable delivery process Once in place the CICD pipeline lets the team focus more on enhancing applications and less on the details of delivering it to various environmentsGetting started with CICD requires devops teams to collaborate on technologies practices and priorities Teams need to develop consensus on the right approach for their business and technologies Once a pipeline is in place the team should follow CICD practices consistently Next read this The best open source software of 2023 Do programming certifications still matter Cloud computing is no longer a slam dunk What is generative AI Artificial intelligence that creates Coding with AI Tips and best practices from developers Why Wasm is the future of cloud computing Related CICD Software Development App Testing Development Tools Containers Isaac Sacolick is president of StarCIO and the author of the Amazon bestseller Driving Digital The Leaders Guide to Business Transformation through Technology and Digital Trailblazer Essential Lessons to Jumpstart Transformation and Accelerate Your Technology Leadership He covers agile planning devops data science product management and other digital transformation best practices Sacolick is a recognized top social CIO and digital transformation influencer He has published more than 900 articles at InfoWorldcom CIOcom his blog Social Agile and Transformation and other sites Follow Copyright  2023 IDG Communications Inc ,https://www.infoworld.com/article/3271126/what-is-cicd-continuous-integration-and-continuous-delivery-explained.html,DevOps,752,2182
Web Development Tools and IDEs, Web Pro Dec 21 2023 Wanda C 20min Read 20 Best Web Development Tools to Improve Your Workflow Copy link Copied As a web developer youre responsible for creating reliable web applications This involves not only coding but also complex and timeconsuming tasks such as debugging errors and managing servers Luckily web development tools can streamline the entire process while maintaining high quality These tools often come equipped with automation and security features that can improve the performance of web applications With a multitude of web application development tools constantly evolving choosing the most suitable one can be daunting In this article well guide you through the process of selecting the best web development tools Well also provide a list of the top 20 options catering to both beginners and advanced developers Download Website Launch Checklist What to Look for When Choosing a Web Development ToolTop 10 Web Development Tools for Beginners1 GitHub2 Chrome Developer Tools3 Sublime Text4 Marvel5 Visual Studio Code6 Node Package Manager npm7 Sass8 Bootstrap9 Grunt10 Ruby on RailsTop 10 Web Development Tools for Advanced Developers1 Postman2 Docker3 Kubernetes4 Sketch5 NGINX6 Flutter7 ReactJS8 Angular9 Vuejs10 LaravelWeb Development Tools FAQWhich Tool Is Best For Beginner DevelopersWhat Are the Different Types of Web Development What to Look for When Choosing a Web Development Tool Using web development tools is crucial when working as a web developer as they help you create edit maintain and troubleshoot applications To list the best tools for web development we considered the following aspects Complexity Before investing in a web development tool ensure it meets your actual needs and capabilities Security A good web development tool should provide web application security solutions like crosssite scripting XSS management Web Application Firewalls WAF and security audits to protect your app from cyber attacks Scalability The tool should work with small and large projects Cost Consider its pricing system as some web developer tools are free while others have a monthly or yearly subscription system Programming languages Pick web development tools that are compatible with the programming language you use Platform support Check if the web development tool will provide adequate assistance and support in case of software issues In this article we have suggested some of the top web development tools available each of which serves a unique purpose Code editors They come with builtin features that make writing and editing code easier such as syntax highlighting code autocompletion and a debugger Browser developer tools They allow developers to preview HTML and CSS changes as well as write and debug JavaScript code directly on a browser Web prototype software The web development tool should include everything you need to create interactive prototypes wireframes and UXUI design projects Package managers They make it easy to download and install framework and library dependencies Version control systems VCS They help manage and track code changes improving communication in collaborative projects Web application frameworks Frameworks provide a premade codebase and guidelines to make web development easier Task runners Automate repetitive tasks so you dont have to micromanage each one API testing tools They facilitate early testing of an apps core functionality before its launch JavaScript libraries A collection of prewritten code snippets for carrying out common JavaScript tasks Container management software The applications source code is bundled together with its libraries and dependencies As a result it can run quickly and reliably on any platform CSS preprocessors They automate repetitive tasks such as reducing code errors producing reusable code snippets and maintaining code compatibility Web servers Stores and transfers website data in response to a request Pro Tip Ready to host your client project Explore the Hostinger for professionals offer Top 10 Web Development Tools for Beginners If youve just started your career as a web developer here are the 10 best web development tools to improve your workflow 1 GitHub GitHub is an opensource cloudbased Git repository hosting service that offers a webbased graphical interface It can be an excellent platform for expanding your networks and building a personal brand as a web developer It also comes with flexible project management tools to help organizations adapt to any team project or workflow GitHub offers a free plan with unlimited repositories and collaborators and 500 MB of storage space To get GitHubs additional features like advanced auditing and access to GitHub Codespaces youll need to purchase one of its paid plans Key Features GitHub Copilot An AIdriven tool that suggests code completions and functions based on your coding pattern It also autofills repetitive code and enables unit tests for your projects Pull requests and code review With GitHub you can assign up to 10 people to work on a specific issue or pull request This makes tracking the progress of a project more manageable Codespaces Includes everything you might need to create a repository including a text editor bug tracking tools and Git commands Its accessible through Visual Studio Code or other browserbased editors Automation With GitHub you can automate tasks such as CICD testing project management and onboarding Vast integration options Extend GitHubs functionality with various thirdparty web apps available on the GitHub Marketplace Many integrations like Zenhub Azure Pipelines and Stale are exclusive to GitHub users Mobile support GitHubs mobile app is available for iOS and Android enabling users to manage their projects on the go Extensive security features It features a code scanning tool to identify security flaws and a security audit log to track the actions of team members Also GitHub is SOC 1 and SOC 2 compliant User management tools Set different levels of access and permissions to your account and resources for different contributors Cons Commandline knowledge Prior commandline experience is necessary to use GitHub efficiently Pricing Its subscription price is quite high when compared to competitors 2 Chrome Developer Tools Chrome Developer Tools are a set of web editing and debugging tools built into the Google Chrome browser Using it developers can easily view and update web pages styles debug JavaScript code and optimize website speed This web application development tool offers helpful commands and shortcuts for navigating its UI and running certain tasks like disabling JavaScript Key Features Local overrides Save any changes youve made to any web page on your local computer and automatically override its data Lighthouse A tool to perform audits on web pages and autogenerate reports based on performance accessibility progressive web apps PWA and SEO This allows users to identify areas of improvement and take action accordingly Web design features Web designers can check various web page designs and layout changes with its Inspect Element tool Use its interactive Color Picker to grab colors from any website element and switch between color modes Console utility This feature is used for debugging JavaScript code Users can also create live expressions and pin them at the top of the console to monitor their values in real time Profiling tools View memory usage of a web page with Chrome Task Manager It is often used to identify memory leaks or bloat that can slow down a sites performance Builtin security features They verify the authenticity of a web page by enabling users to view a sites SSL certificate and TLS status Device mode Test your website designs responsiveness modify device performance and limit network speed Cons Steep learning curve Less experienced users will need time to explore all the development tools available and learn how to use them Limited code editing capabilities It doesnt provide a way for web developers to write or modify source code directly 3 Sublime Text Sublime Text is the best option for beginners who have just started learning how to code Its an allinone text editor for code markup and prose Its lightweight yet still offers the advanced features youd expect from a great text editor For example developers can enable simultaneous editing to control multiple cursors and edit several lines of code at once This code editor can be downloaded for free but youll need a license to use it Sublime Text licenses cost 99 for personal use and 65year for business use Key Features Goto Anything Enables users to quickly switch between files and functions Minimap Displays the density and shape of the code to users This is helpful when editing lengthy code JavaScript ecosystem support Sublime Texts smart syntaxbased features are easily accessible with Typescript JSX and TSX Python API Using the Python API users can install external plugins to extend the functionality of Sublime Text Multiple selections Users can find change rename and manipulate multiple code lines Crossplatform functionality Its single software license runs on any computer and operating system Cons Lack of indexing capabilities Unfortunately users cant index files without slowing down the code editors performance Incessant payment popups Users cant disable the continuous popup that prompts them to purchase or update their licenses 4 Marvel Marvel is one of the best wireframing tools to quickly and easily design different projects This webbased collaborative design platform offers robust prototyping and user testing features Because of its userfriendly interface web developers and designers of all levels can use Marvel to create highquality mockups and design specifications for their web applications in no time In addition to a free plan that comes with limited features Marvel offers three premium plans Pro at 12month Team at 42month and Enterprise which is available upon request This wireframing tool is also offered at a discounted rate for nonprofits and students Key Features Developer handoff This tool automatically generates CSS Swift and Android XML code for elements and packages them into a shareable URL User testing Collect feedback from your stakeholders and target audience by recording their screen audio and video as they use your prototype Integrations If youre looking to expand Marvels design capabilities the platform supports integrations with popular social media apps like YouTube and project management and productivity apps like Dropbox Microsoft Teams and Jira Customizable templates Choose from hundreds of draganddrop templates to create wireframes for popular device types Cons No offline version Since Marvel is a webbased app users cant use it without an internet connection Lack of animation features Some users have expressed concerns about Marvels limited capabilities for creating animations which hinder their ability to create dynamic prototypes 5 Visual Studio Code Visual Studio Code is an opensource code editor that runs on Windows Linux and macOS It includes builtin features such as syntax highlighting autocomplete and Git commands to make coding faster and easier In addition to a builtin terminal and debugger it supports code analysis tools and software integrations with other powerful web development tools like Git PHP CS Fixer and ESLint Visual Studio Code is completely free to use You can download the Insiders version to access the tools latest releases and new features Its also possible to install both versions and use them together or independently Key Features Support to the best programming languages This web development tool works with various languages including C JavaScript and Python A huge library of extensions There are various themes and plugins available within its marketplace User interface customization The Visual Studio code editor is customizable allowing you to debug the code with breakpoints call stacks and an interactive console Command Palette function Makes it easy for users to find different commands and operations For example typing in Python will show all commands for this language IntelliSense It provides code suggestions based on variables syntax and the programming language in use Syntax highlighting It displays code in different colors and fonts depending on the keywords and coding language Git integration Users can perform several Git commands like commit pull and push It also displays a color indicator when changes are made to the Git repository Split view Enables you to work on two projects at the same time Cons Stability issues with plugins Users have reported that VS Code often crashes when installing or running multiple plugins simultaneously Resourceheavy This web development tool takes up a lot of disk space which may cause the system to slow down 6 Node Package Manager npm Node Package Manager npm is a JavaScript software registry for sharing and deploying local or global packages JavaScript developers can use npm to find and install code packages for their networking applications or serverside projects Using npm packages simplifies the development process as developers dont have to write new code for each functionality that their project requires The free version of npm includes unlimited public packages However if you want to enhance its functionality there are also two paid plans available Pro for 7month with unlimited packages and Team for 7month with teambased management options Key Features Commandline interface CLI The npm CLI allows users to install and manage versions and dependencies of packages Security auditing features It detects security flaws in your project and generates an assessment report Large registry Take advantage of npms publicly accessible database of JavaScript packages including their software and metadata Repository npm is a repository for opensource projects so developers can share their source code with other users Some of the packages available in the npm repository include Angular jQuery and React Collaboration features Its Team plan allows users to control team permissions and integrate workflows Cons Dependencies issues Issues may arise if people dont manage their dependency versions actively Decreased performance Many developers reported that adding dependencies makes the package installation process slower disrupting the workflow 7 Sass Syntactically Awesome Style Sheets Saas is one of the most popular preprocessors for the CSS framework CSS developers mostly use it to add more logical syntax to a CSS site such as variables nested rules and loops This web development tool is also great for learning how to make websites because it lets you change colors fonts and other user interface elements Moreover Sass facilitates easy design sharing within and across projects allowing seamless project management Key Features Builtin frameworks Get easy access to powerful authoring frameworks like Bourbon Compass and Susy Beginnerfriendly This web development tool is easy to configure and doesnt have a steep learning curve Great reputation and large community support Saas is widely used by leading tech companies It also has a large community and responsive support for resolving bug issues and releasing improvements LibSass Implements Saas in CC to allow easy integration with different languages Cons Slow performance when handling large files Users may experience occasional brief freezes or slow loading times especially when dealing with bigger files Longer compilation time Compiling Sass code requires users to install Ruby or LibSass 8 Bootstrap Bootstrap is a widelyused frontend development framework for creating responsive web applications It features various HTML CSS and JavaScriptbased scripts for web design components and functions saving web developers a lot of time from having to code them manually Anyone with basic knowledge of HTML CSS and JavaScript can easily navigate it You can also learn Bootstrap by developing themes for popular CMSs like WordPress Key Features Customizable Web developers can customize Bootstrap with builtin variables CSS variables color systems Sass files and more options Responsive features Using predefined HTML and CSS components Bootstrap automatically resizes images based on the users screen size Grid system Bootstraps predefined grid system saves you the hassle of creating one from scratch Instead of entering media queries in the CSS file you can make a grid within an existing one Bundled JavaScript libraries It includes a set of JavaScript libraries making it easy to operate alerts tooltips and modal windows Browser compatibility Bootstrap is compatible with all modern browsers Making your site accessible across browsers helps reduce the bounce rate and improves search ranking Comprehensive documentation Bootstraps documentation page provides detailed guides on using the tool and its features Users can also copy and modify the code samples in the documentation for their projects Cons Uniform design As Bootstrap has a consistent visual style it requires a lot of customization to make your projects stand out Otherwise every website built with this framework will share the same structure and design Large file sizes While Bootstrap lets you build responsive sites easily it produces large files resulting in slower loading times and battery drain Suggested Reading HTML Cheat Sheet New HTML5 Tags Included CSS Cheat Sheet  The Complete PDF for Beginners and Professionals 9 Grunt Grunt is a powerful JavaScript task runner for automating repetitive tasks like unit testing minification and compilation It enables users to improve project efficiency by reducing development time Web developers can use Grunt to implement coding style guides throughout the code base of their project to ensure consistency and readability It also has linting and image optimization capabilities Grunts code which is released under the MIT license can be downloaded from its official website and is also available for free on GitHub Key Features npm integration Users can easily add and publish their Grunt plugins on npm Essential JavaScript tools Gain access to a wide range of predefined plugins that can be used to perform JavaScript tasks on static content Highly customizable It enables developers to create extend and modify custom tasks to meet their specific requirements Each task also has its own configurable settings Cons Compatibility issues Minimal compatibility with older versions Delay in plugin updates Users will have to wait to access updated npm packages on Grunt 10 Ruby on Rails Ruby on Rails is a popular fullstack framework for building reliable web apps quickly This framework can be used for serverside development such as managing servers databases and files On the client side it can be used to render HTML and update web pages in real time For that reason it has become one of the most popular web technologies for eCommerce businesses and startups when developing desktop and web applications Hostinger offers a web development framework and operating system template allowing you to install Ruby on Rails on Ubuntu in a few simple steps Key Features Automated testing tool Enables users to test code without installing thirdparty tools or external plugins Builtin libraries Offers free and opensource packages called RubyGems Download a gem to extend the functionality of your web app Integration with frontend frameworks It is compatible with popular frontend frameworks like Angular React and Vuejs Data protection Features a default security protection against several types of cyber attacks This is especially useful when creating an eCommerce site that requires you to secure sensitive information like payment and customer data Active community It is backed by a community that actively resolves issues and makes continuous improvements to ease development Industry standards Promotes quality standards and best practices in web development like DRY Dont Repeat Yourself and CoC Convention over Configuration Cons Slow speed It has a slow runtime speed especially when working on large projects Less flexibility Ruby on Rails is unsuitable for developing a featurerich app Top 10 Web Development Tools for Advanced Developers Here are the ten best options for experienced developers looking for web development tools to scale up their skills and projects 1 Postman Initially a Google Chrome extension Postman has now become one of the top application programming interface API testing tools It provides an easy way for web developers to build test share and modify APIs It offers several builtin features for API monitoring debugging and running requests to make working with APIs easier There are also shared workspaces for better collaboration As for pricing Postman offers a free version with basic functionality There are also three paid plans available offering more advanced features Basic includes 30day collection recovery and a single custom domain for 12month per user billed annually Professional offers single signon SAML and basic roles and permissions for 29month per user billed annually Enterprise comes with domain capturing and analytics tools for 99month per user billed annually Key Features Collaboration features Tools like team discovery commenting and workspace improve team collaboration API monitoring and reporting features Visualize API data through reports including testing documentation and monitoring The reports also enable users to monitor performance and servicelevel agreement SLA compliance Desktop interface Its easy to navigate and lets users easily manage their APIs and see other members tasks on the workspace API governance Identifies inconsistency and security issues during API design and testing enabling users to develop more secure and highquality projects CICD integration Postmans Newman feature enables users to integrate their APIs with popular code deployment pipeline tools such as Bamboo Jenkins and TeamCity It also lets users upload files and create custom reports API documentation tools Allows for the automatic creation of professional API documentation that can be shared either publicly or exclusively with your team members With good documentation customers will be able to use and integrate your API effectively Cons Limited sharing capabilities on the free version Its free plan only allows API sharing for up to three users No reusable code Its not a great option for code management since it doesnt let users reuse code 2 Docker Docker is an opensource tool for deploying applications inside virtual containers Using Docker containers allows developers to quickly deploy and scale applications across multiple environments Thats because it combines the applications source code with the libraries and dependencies required to run it Check out our Docker cheat sheet to help you out Docker offers a free plan with unlimited public repositories and three paid plans Pro includes advanced productivity features for 5month while Team comes with advanced collaboration features for 7month per user The Business plan offers centralized management and advanced security capabilities for 21month per user Key Features Container development Docker offers container versioning an automated container builder and reusable container templates It also has an opensource repository of usermade containers Wide community Docker has thousands of active contributors on developer websites like StackOverflow as well as a community forum and a dedicated Slack channel Portability One of Dockers greatest strengths is its portability It enables users to create or install a complex application on a machine and know that it will function properly Automation Users can easily automate their work using cron jobs and Docker containers Automation allows developers to avoid timeconsuming and repetitive tasks Cons Potential security risks Due to Dockers reliance on the host OS malicious code within containers has the potential to spread to the host Slow performance Running an app via Docker may be faster than using a virtual machine but it is still slower than running an app directly on a physical server Pro Tip Using Docker on VPS will help you have more control over your server and its resources 3 Kubernetes Kubernetes K8s is an opensource container orchestration platform for deploying scaling and managing modern web applications It organizes the application containers into logical units for easy discovery and management The platform offers features to help users deliver applications consistently and easily transfer workloads To prevent a total outage it is constantly deploying and monitoring changes to your application and its configuration Key Features Portability Kubernetes can run on various infrastructures including onpremises data centers or public private and hybrid cloud Configuration management Kubernetes Secrets stores sensitive data such as authentication tokens SSH keys and passwords Moreover it allows users to build and update secrets without rebuilding container images and exposing secrets in stack configurations Automatic bin packing Provides automatic scaling of each container based on custom metrics and resources available Service discovery and load balancing It automatically exposes containers with their own DNS names and IP addresses It also enables load balancing when there are traffic surges to maintain stability Selfmonitoring Kubernetes performs health checks of your applications to prevent potential issues Storage orchestration It mounts your chosen storage system to decrease latency and improve the user experience Selfhealing capabilities Optimizes the performance of your applications by monitoring and replacing unhealthy containers Cons Steep learning curve Kubernetes is difficult to learn even for experienced developers To use it effectively youll need to have basic knowledge of container orchestration and cloud computing Limited and expensive human resources There are not many professionals listed on platforms like Fiverr Also hiring Kubernetes professionals can be costly for small to mediumsized companies 4 Sketch Sketch is one of the best web development tools for designing pixelperfect graphics It includes a robust vectorbased design toolkit that makes it easy to create all kinds of interfaces and prototypes Sketch includes the ability to export presets and code nondestructive vector editing integration with hundreds of plugins prototyping and collaborative tools Sketch has two premium plans Standard at 9month per editor or 99year per editor Both offer unlimited free viewers which developers can use to inspect the design There is also a Business plan for teams of 25 editors with prices available upon request Those who want to try Sketch before committing to a paid plan can do so with a 30day free trial Key Features Coediting Enables web designers and web developers to work together on the same project in real time Powerful extensions It offers several thirdparty plugins and integrations to enhance its functionality and simplify your development workflow Various design tools Sketch simplifies mockup creation by providing intuitive draganddrop features like Sketch Symbols for creating reusable design components and Smart Guides for accurate alignment Developer handoff Developers can use this feature to copy design style values and export assets Data linking features It enables users to import data from text files into mockups Cons Exclusive for macOS The drawback of this web design tool is that it only supports macOS which limits crossplatform collaboration Lack of prototyping features Sketch only allows users to develop a basic prototype To create prototypes with advanced animations and functions theyll need to find additional tools in its plugin library 5 NGINX NGINX is an opensource web server software that can act as a load balancer HTTP cache and reserve proxy Its ability to handle multiple connections at high speed makes it ideal for developing resourceintensive websites Over 110 million sites worldwide use NGINX Plus and NGINX Open Source to safely and quickly distribute their content Some popular sites that use it include LinkedIn Netflix and Pinterest NGINXs configurable settings make it easy to finetune the server to your needs It supports multiple protocols SSLTLS encryption basic HTTP authentication load balancing and URL rewriting Key Features Low memory consumption As NGINX handles requests asynchronously it doesnt take up a lot of memory Great resources There is a lot of documentation about how to use NGINX such as eBooks webinars glossaries and video tutorials Builtin security features NGINX security controls include ratelimiting which protects your server from DDoS attacks by reducing users requests It restricts them by granting or denying access based on IP addresses Great support NGINX provides a mailing list and a public support forum to assist users with any development issues Cons Limited Windows support As NGINXs primary operating systems are Linux and Unix it has limited capabilities when running on Windows Less suited for managing dynamic sites NGINX is great for serving static sites but it still needs thirdparty programs like FastCGI to serve dynamic content 6 Flutter Flutter is a web development tool for building crossplatform mobile applications It is an opensource project supported by Google Its most recent version is compatible with popular operating systems like Android iOS Linux and Windows opening up even more possibilities for crossplatform consistency and cost savings Flutter is an excellent tool for creating custom app designs It includes many builtin tools such as an app builder and UI widgets to help you provide a better inapp user experience Key Features IDE support Flutter offers support for IDEs and code editors Some of them include Android Studio IntelliJ IDEA and Emacs Mobile development Users can create an app for both Android and iOS simultaneously Hot reload A feature that lets developers make changes to the code and view them in real time This enables a faster development process as it streamlines the testing and review processes Variety of widgets It offers various custom widgets for developing a fully functioning application There are also two designspecific widgets available Cupertino Design for iOS and Material Components Responsiveness Your app will adjust to various screen sizes thanks to Flutters declarative nature and layout system Responsiveness is one of the most important aspects when designing a mobilefriendly site Cons Large file sizes One of Flutters drawbacks is that its apps are typically larger than native ones Dart knowledge To use the tool effectively users must be familiar with Dart 7 ReactJS ReactJS is a free and opensource JavaScript library for creating modern and responsive web and mobile app user interfaces One of the primary benefits of using ReactJS is that you can easily write and prebuild components which makes the development process faster and more efficient Additionally it can be used for server rendering with Nodejs and to power mobile apps with React Native Developers can use React VR to build virtual reality sites with 360degree experiences Key Features Virtual Document Object Model DOM It arranges HTML XHTML or XMLbased documents into an organized structure more acceptable to web browsers while parsing different web app elements Reusable components ReactJS components have their own logic and controls which makes it easier to track code in large projects SEOfriendly Its rendering feature significantly reduces page load times helping your app rank higher in search engine results Lightweight It is absolutely lightweighted because the data from the user side can be easily represented on the server side simultaneously Oneway data binding Reacts oneway data binding eases the debugging process Any child component changes wont affect the parent structure reducing the risk of errors Easy migration It is usually very easy to switch between versions and Facebook has code mods that automate much of the process Cons Poor documentation Due to its frequent updates Reacts documentation can be slightly outdated Limited features Since Reactjs focuses mainly on the UI part of the app youll need to choose different web technologies to cover other development areas 8 Angular Angular is a frontend web development application framework for creating a wide range of apps including singlepage applications SPAs progressive web applications PWAs and large enterprise apps Written in Typescript it helps web developers write consistent and cleaner code With its wide variety of UI components web designers can quickly build dynamic web applications In addition it has a twoway data binding function that lets users modify the applications data via the user interface Angular is a framework that can work effectively with a variety of backend languages while also combining business logic and UI Key Features Custom directives Enhances functionality in HTML and CSS to build dynamic web applications Various modules Performing unit tests is easy thanks to the frameworks wellorganized modules and components Support progressive web applications PWA Angularbased web apps are compatible with both Android and iOS platforms Twoway data binding Enables singular behavior for the app which minimizes risks of possible errors Powerful CLI Angular CLI simplifies the developers job by providing a set of useful coding tools Users can also add thirdparty libraries to solve complex software issues RxJS Provides an effective way to share data reducing the number of resources needed Integration with code editors and IDE Get access to intelligent code completion inline error checking and feedback directly from your preferred code editor or IDE Dependency injection DI This feature splits an application into a group of components to be injected into one another as dependencies Cons Limited SEO capabilities One of the biggest drawbacks is its use of clientside rendering by default which can make crawling and indexing Angularbased sites more difficult for search engines JavaScript knowledge It can be challenging for developers to learn Angular without understanding basic JavaScript Limited CLI documentation Even though the command line is a key part of Angular there isnt much information about it on GitHub Developers need to spend extra time exploring threads to get answers 9 Vuejs Vuejs is a frontend development tool to help developers build web applications and mobile apps with ease Programmers can also use Vuejs to create clickable prototypes With its databinding features it can handle a lot of animations graphics and interactive elements Through its GitHub repository it offers webbased development tools for bug fixing It also includes an HTMLbased template for updating the DOM with Vue information which simplifies the task of creating a user interface Key Features Declarative rendering Provides the ability to manage HTML already rendered by the server Reactivity Tracks change to the JavaScript state and automatically updates the DOM when a change is made Reusable components Users can generate reusable code templates for future projects Animation features Offers a huge library of transition and animation effects Moreover users can easily add thirdparty animation libraries to make the interface more interactive Computed Properties Monitors changes to UI elements and performs the necessary calculations without coding Lightweight Vuejs scripts dont take up a lot of storage space and have fast performance Cons Limited amount of plugins It might be hard to find plugins for Vuejs This typically leads developers to switch to different frameworks Weak support to mobile platforms Vuejs apps can have issues when running on older iOS and Safari browsers 10 Laravel Laravel is an opensource web application framework that enables PHP developers to create everything from singlepage websites to enterpriselevel applications It has an impressive set of tools including a template engine and a task scheduler to help developers avoid tedious web development tasks With a robust control container and a flexible migration system along with integrated unit testing support Laravel allows developers to build any type of web application It also offers multiple bundles for a modular packaging system and its dependencies facilitating code reuse Deploying Laravel on a production server is also simple This framework offers Laravel Forge a centralized platform for installing and managing your applications dependencies Key Features Builtin Objectrelational Mapper ORM It allows web developers to query database tables using a simple PHP syntax without writing any SQL code Enhanced security Laravel provides users with enterpriselevel security features to help fix security problems and speed up the debugging process Variety of resources and packages Its compatible with other web app frameworks like React and Vuejs Users can also add packages from Yarn and Node Package Manager Template engine It has a templating engine called Blade that allows you to build unique layouts The layout can be used in other views so the design and structure are consistent throughout the development process Supports ModelViewController MVC This feature helps manage your projects efficiently to improve the applications performance security and scalability Builtin libraries Over 20 preinstalled libraries are available to extend your apps functionality For example Laravel Cashier offers features for processing coupons changing subscription formats and generating PDF invoices Task Scheduling It lets users schedule and manage tasks with cron jobs Cons Problems with certain updates Some users experience lagging after updates Limited support Users will have to turn to the Laravel community for help if they face any issues Conclusion Web development tools are necessary to reduce the complexity of frontend and backend development workflows Choosing tools that fit your budget and project scale can influence its success and efficiency These IT tools can take many forms including code or text editors version control systems VCS web frameworks debuggers libraries prototyping tools and container software In this article we have listed the top 20 web development tools available for beginners and software professionals alike If you have other suggestions dont hesitate to leave us a comment below Learn More About Web Development Top 40 Web Development Companies What Is a Development Environment Best Website Optimization Tools to Improve Site Speed Web Development Tools FAQ The following questions and answers will help you understand web development tools better Which Tool Is Best For Beginner Developers For beginner developers tools like Codecademy Udacity and FreeCodeCamp are ideal They offer interactive courses and tutorials for learning programming languages such as HTML CSS and JavaScript Additionally text editors like Visual Studio Code and Atom are popular choices for writing and editing code What Are the Different Types of Web Development The different types of web development include frontend backend and fullstack development Frontend development focuses on the user interface and user experience of a website while backend development deals with serverside and database management Fullstack development involves both frontend and backend development The author Wanda Chung Wanda enjoys helping people become more successful online by sharing her expertise in digital marketing and website development In her free time she loves reading mystery books thrifting for vintage clothes and exploring aesthetic cafes More from Wanda Chung Copy link Copied Rapid prototyping testing and handoff for modern design teams Marvel has everything you need to bring ideas to life and transform how you create digital products with your team Placing the power of design in everyones hands Gorton Features Examples Blogandmore v Enterprise Pricing signin ERED Dvne Badge Bottom Sheet Dateicer Dialog Expansion Panel Form eld Autocomplete Suapeete relat ops the  SECGTSOISE card Angular Material offers a wide variety of Ul components based onthe Material Desion specification oP ea Bot winProgess CO submited Checkbox Cepturesbacean pu wt owe 0 Bottom Sheet Amenities Chips x Core mB Button toggle Datepicker V wWuejs Q searen Docs  API Playground Ecosystem  About  Sponsor Partners naoyvaga The Progressive JavaScript Framework An approachable performant and versatile framework for building web user interfaces PRR cet started  instal ,https://www.hostinger.com/tutorials/web-development-tools,Development Tools,1781,6248
Agile and Scrum Methodologies, Home Blog Tech Industry What is Agile Scrum Last updated December 14th 2021 What is Agile Scrum Tech Industry Since it was first introduced in the 1990s the Agile way of working has come into its own and Agile frameworks have been rolled out across businesses globally One of the most popular frameworks is AgileScrum But why What do the terms Agile and Scrum really mean and how do they translate into the business world today In this blog we will cover the following topics What is AgileScrum Model DefinitionThe Benefits of Agile Development ScrumAgile vs ScrumThe Scrum Team what to expect when working as a Part of a Scrum TeamHow agile can work with remote membersAgile Scrum Approach VS Other Agile ApproachesAgile Scrum at FDM What is Agile Agile is a method of working which revolves around continual development and collaboration The Agile Framework brings together a group of people into a project with the flexibility to choose their way of working as a team operating within guidelines but choosing their boundaries It encourages teamwork selforganisation and accountability within a team project Most significantly this method allows for the ability to be responsive to change For example the Agile way of working facilitates any changes that might occur in customer requirements in a timely manner It also ensures that a company can supply an ongoing responsive product release in smaller iterations An Agile mindset is necessary to create and develop highperforming teams who in turn deliver value to their customers in a shorter time frame which leads to a quicker return on investment The 12 Principles of Agile Satisfy the customerEmbrace changing requirementsDeliver working software within a short timescaleCollaborate across teams and eliminate silosCreate a motivated environment to empower team members and provide them with the support they need to complete projects successfullyFacetoface interactions for improved communicationMeet customer expectations with functioning productsMaintain sustainable developmentContinual technical excellenceKeep it simple to maximise efficiencySelforganised teams offer most valueReflect on your work regularly to continuously improve Scrum Model Definition What is Scrum As per the official Scrum Guide Scrum is not exactly a methodology but rather a simple framework for effective team collaboration on complex projects Scrum gets its name from rugby terminology and just like a rugby team encourages members to learn from experience and continuously improve It involves specific values commitments events and artefacts which all ensure the seamless running of a project The Scrum Process Model is also known as the Scrum Software Delivery Framework However it is not only used to develop software for businesses its also widely used in hardware development marketing and business operations among other things including SpaceX In short the Scrum process begins with a Product Owner who orders work into a Product Backlog which contains a prioritised list of work for the development team The Scrum team then executes the work in increments otherwise known as Sprints Sprints are typically 24 weeks long and help break the project down into smaller tasks Once a Sprint is complete the team takes time for reflection to collate project feedback before moving onto the next Sprint A Sprint is regarded as a complete Increment of the product providing the customer with a value at every stage Heres a simple breakdown of the process The Benefits of Agile Development Scrum Agile Scrum provides a range of benefits for all parties involved in the process including development teams customers and vendors These include Enhance Quality Output Scrum development teams have a clear definition of requirements take on regular feedback and continuously improve As such they ensure a seamless process and produce higher quality products Scrum teams use The Definition of Done a preagreed set of items that must be completed for a project to be considered done and released This ensures that the project is completed to the highest standards and covers everything from development and testing to integration and documentation Higher Customer Satisfaction Scrum frameworks foster a close relationship between the Scrum team and clients to ensure better communication and understanding of project requirements Clients receive a functioning product after every Sprint and are given the opportunity to provide their feedback at every stage to ensure they are completely satisfied with the end result Decrease Time to Market Agile Scrum helps encourage faster delivery times in comparison to traditional working methodologies The main reason for this is that the development team is provided with a prioritised list of tasks and a functioning product or feature is produced after each Sprint This means that clients do not have to wait for the whole project to be complete in order to release the product to the market Increase Return On Investment Scrum projects produce a higher return on investment as projects take much less time to complete demonstrating value to the customer every 2 to 4 weeks In fact Scrum has been proven to deliver value to the client apprxoinatemy 3040 faster than traditional working practises Additionally the Scrum framework involves constant evaluation and corrections which reduces risk and prevents errors which could be costly and timeconsuming Boost Team Morale A Scrum team is selforganising which enables members to arrange themselves in roles most suited to their strengths and be more experimental creative and innovative in their work Daily standups can also help to reduce friction or frustrations between team members caused by miscommunication and provide an opportunity for members to learn from one another which contributes to better team morale overall In addition the sustainable and disciplined nature of the Scrum framework means that teams are less likely to experience burnout from excessive workloads or irregular periods of intense work Encourage Collaboration and Responsibility All Scrum team members work in close collaboration and take part in a daily standup meeting to outline priorities This means that everyone knows what they are responsible for within the project and can take ownership of performance Daily standups also provide an opportunity for team members to seek support from other team members and raise any concerns More Product Control and Governance Throughout a Scrum project team members have the opportunity to constantly reflect and improve resulting in better control over product performance overall With every Sprint the product can be refined according to stakeholder feedback and any issues can be addressed before the end product is delivered Improve Project Progress Visibility All project timelines and budgets are based on real performance data and provide a realistic goal to work towards As a result the Scrum team is able to provide clients with better visibility across the project which increases customer satisfaction but also helps keep progress on track internally This is communicated clearly to all stakeholders and Scrum team members for full transparency and maximum efficiency Daily standup meetings are key for identifying any potential progress blockers and providing solutions to keep the project going smoothly Reduce Risk Agile Scrum follows an adaptable process which enables teams to easily incorporate changes on an ongoing basis and mitigate risks to prevent project failure Traditional development teams can often waste time and money without demonstrating value and providing ROI as there is less evaluation and correction throughout the project Whereas with Scrum a tangible product is produced after every Sprint and any failed products can be discontinued early Agile vs Scrum Here are some key similarities and differences between Agile and Scrum methodologies AgileScrumAgile is a development philosophy Scrum is a type of Agile framework Agile is an iterative and adaptive approach to project management with high levels of stakeholder engagement Scrum is broken down into Sprints providing a incremental flow of deliverables Agile teams are crossfunctional Scrum teams have very specific team roles but are encouraged to be Tshaped to supplement their expertise in one area with additional but lessdeveloped skills in associated areas Not all Agile frameworks conduct Sprints In the Scrum process the product is delivered after each Sprint for customer feedback before continuing with the next Sprint Design should be kept simple to ensure maximum efficiency with little risk Design can be more experimental Agile requires facetoface interactions within teams can be both physical and virtual As an Agile framework Scrum projects involve a daily scrum meeting or event These interactions can be both physical and virtual The Scrum Team what to expect when working under Scrum Project Management The Scrum framework can only function when a dedicated team is brought together to fulfil the requirements of an organisation One of the main and most important characteristics of a Scrum Team is the fact that they are selfmanaging This means that they hold themselves accountable as professionals and are flexible and creative in order to accomplish their work in the best way possible A Scrum Team consists of a Product Owner a Scrum Master and Developers who are responsible for different aspects of the project Here is a brief overview of a Scrum Team Product Owner There is only one Product Owner per Scrum team who is accountable for the work required They are knowledgeable about the product and business requirements and accountable for maximising the value of the work generated by the Scrum team The Product Owner articulates the intent by having a clear product goal that is communicated with the Scrum team Scrum Master The Scrum Master plays the role of a coach mentor and leader to those within the Scrum Team and is responsible for the promotion of Scrum within the wider organisation They ensure that individuals internal and external to the team understand the theory behind Scrum best practises rules and Scrum values The Scrum Master has two accountabilities Enacting scrum as per the Scrum guide Maximising the effectiveness of the Scrum team The Developers The Developers are a team of at least three and a maximum of eight people This is the optimum number since less than three would lead to a decrease in interaction and more than eight would be too difficult to coordinate which contradicts one of the key principles of Scrum teams  selfmanagement The Developers work together within a timeframe known as a Sprint to produce a readytorelease product in line with the definition of Done They participate in Daily Scrums and  Sprint Reviews where they collaborate inspect their performance and forecast what is required in the upcoming Sprint work At the end of each Sprint the entire Scrum Team participates in a Sprint review to inspect the work done how it was executed and decide what to do next adapt the product backlog if needed which is the list of all activities that are needed in the product To find out more about a Scrum Team Events and Artefacts please see the Official Scrum Guide How Agile Can Work With Remote Members Traditionally Agile teams thrive on facetoface interactions and streamlined communication However in light of the COVID19 pandemic Agile teams have been forced to adapt and find new ways of working remotely Agile teams can work efficiently from different geographical locations which is ideal to accommodate modern flexible working arrangements and global workforces This way of working is called a distributed Scrum team According to Gartner By 2022 90 of agile development teams will include remote work as part of business continuity planning so onboarding remote practises within Scrum teams will become essential The key to effective remote Scrum teams is communication starting with the daily Scrum meeting It is important to keep a set time for the daily scrum meetings and ensure everyone participates It may also be useful to use interactive whiteboards video conferencing or screen sharing For this you will need to ensure all team members have secure and reliable technology from wherever they are based Agile Scrum Approach VS Other Agile Approaches There are a range of other Agile approaches including Kanban DevOps SAFe and Lean however Scrum is the most widely used Agile Scrum Framework remains the simplest method that has been tested over 20 years and proven to provide maximum productivity Like other Agile Frameworks Agile Scrum is particularly effective for complex systems and is adaptable depending on requirement changes however what sets Scrum apart is its purpose Agile Scrum is focused on continuous improvement Lets take a look at some other Agile approaches Scrum vs Waterfall Waterfall takes a linear approach to Project Management Project requirements are gathered at the beginning of the project and a roadmap is created accordingly Waterfall gets its name from the way each stage of the project flows into the next One of the key differences between Waterfall and Scrum are the level of involvement from stakeholders and the size of the project Waterfall is more suitable for smaller projects whereas Scrum works well for larger projects Scrum vs Kanban Kanban is a type of framework that uses a tool called a Kanban board hence the name which visualises work processes A Kanban board includes columns which each represent a stage in the project and contain sticky notes underneath for each task to be completed which move across the board horizontally as progress is made The main difference between Kanban and Scrum is that Kanban is a workflow management tool focusing on continuous and more fluid processes whereas Scrum is based on short structured work Sprints At FDM we teach in multiple working frameworks including Agile Waterfall and Scrum This training ensures our consultants are adaptable and have the ability to succeed in various working environments with our leading clients Agile Scrum at FDM FDM is leading the way in Agile working in particular with Scrum and provides expert training in Agile Scrum Framework to all our team members and trainees Product Owners across FDM have introduced Scrum through multiple Agile Pods this past year As a result both FDM consultants and our clients have seen firsthand how effective Scrum is in a business working environment where flexibility and collaboration are key to achieving tangible business products and results If youre looking to kickstart your career in technology check out the FDM Technical Graduate Programme to find out more Related Articles A Guide to LowCode NoCode in Software Development From Drones to Underground Marvels Unleashing the Tech Wonders of Vivid Sydney A Guide to Psychological Safety in the Technology Industry Most Popular Articles 5 Reasons You Should Become a Software Developer or Engineer 5 Exciting Uses for Virtual Reality 7 Benefits of Learning to Code Agile Scrum 0 Agile Scrum 1 Agile is a development philosophy Scrum is a type of Agile framework 2 Agile is an iterative and adaptive approach to project management with high levels of stakeholder engagement Scrum is broken down into Sprints providing a incremental flow of deliverables 3 Agile teams are crossfunctional Scrum teams have very specific team roles but are encouraged to be Tshaped to supplement their expertise in one area with additional but lessdeveloped skills in associated areas 4 Not all Agile frameworks conduct Sprints In the Scrum process the product is delivered after each Sprint for customer feedback before continuing with the next Sprint 5 Design should be kept simple to ensure maximum efficiency with little risk Design can be more experimental 6 Agile requires facetoface interactions within teams can be both physical and virtual As an Agile framework Scrum projects involve a daily scrum meeting or event These interactions can be both physical and virtual Font resizennIncrease font sizenIncrease font sizenDecrease font sizenDecrease font sizenReset font sizenReset font sizenUnderline linksnUnderline linksnHighlight linksnHighlight linksnnContrastnnAnAnA 0 Font resizennIncrease font sizenIncrease font sizenDecrease font sizenDecrease font sizenReset font sizenReset font sizenUnderline linksnUnderline linksnHighlight linksnHighlight linksnnContrastnnAnAnAPage  1  WHAT IS THE ROI OF AGILE VS TRADITIONAL METHODS An analysis of XP TDD Pair Programming and Scrum  Using Real Options  Monte Carlo Analysis See httpdavidfricocomagilebenefitsxls  Dr David F Rico  PMP CSEP  EBAS  BAF FCP FCT ACP CSM SAF E DEVOPS Related Textbook  Rico D F Sayani H H  Sone S 2009 The business value of agile software methods  Maximizing ROI with justintime processes and documentation Ft Lauderdale FL J Ross Publishing httpwwwamazoncomdp1604270314 Abstract Little is known about the costs a nd benefits of Agile Methods s ince their popularization in 1999 though 67 of projects use them and 75 books and 100s of papers have been written about them The purpose of this article is to analyze the costs and benefit s reported in studies of new product development approaches such as Agile Methods as compared to tho se of Traditional Methods Over 300 articles on Agile Methods were examined cost schedul e productivity quality and customer satisfaction data we re found in 69 studies and ROI data were identifie d in 29 studies Agile Methods ROI was four times more than expensive Traditiona l Methods two times less than inexpensive ones and the be st Agile and Traditional Metho ds had equal ROI see Figure 1 However it may not be proper to compare Traditional Methods op timized for productivity and quality to Agile Methods optimize d for customer satisfaction p roject success and risk reduction Introduction The US and worldwide informa tion technology industry continue s to grow at an amazing rate In 2006 software industry revenues reached 393 billion and businesstoconsumer B2C and businesstobusiness B2B electronic commerce revenue reached 220 billion and 27 trillion Likewise the number of Internet websites now exceeds 136 million the number of US Internet shoppers is in excess of 147 m illion and the number of Internet users is greater than 13 billion 1 Accordingly information technology is the seco nd leading contr ibutor to the US economy and contributes to more than 50 of labor productivity growth in th e top 10 industrialized nations Also in 2006 US firms spent ove r 251 billion in information technology investments and the US Department of Defense used 447 billion to acquire information technology based systems This flurry of activity led to more than 6 million US informa tion technology jobs 450000 projects 265000 certified project managers and 36000 Scrum masters to help manage them Finally 900000 firms used ISO 9001 for quality management 300000 projects used Agile Methods for software de sign and 840 firms used CMMI  for process improvement in 2006 4133 3272 2826 1788 871 229 173 050010001500200025003000350040004500 PSPsm Inspections TSPsm Agile SWCMM ISO 9001 CMMI Figure 1 Methods for Managing Information Technology Projects with decreasing ROI from left to right  Personal Software Process PSP Team Software Process TSP SoftwareCapability Maturity Mode l SWCMM and Capability Mat urity Model Integration CMMI are registered in the US Patent and Trademark Office by Carnegie Mellon University CMU Page  2  Agile Methods Agile methods are lightweight sof tware design processes based o n small teams using flexible technologies to iteratively impr ove software using customer fee dback to converge on solutions Kent Beck is credited with cre ating Agile Methods by devising E xtreme Programming in 1998 though XP was just one in a long lin e of hundreds of software m ethods dating back to 19682 According to the Agile Manifesto the major factors of Agile Methods are 1 early customer involvement 2 iterative devel opment 3 selforganizing tea ms and 4 adaptation to change Early customer involvement was known as toplevel commitment m anagement involvement user involvement user particip ation lead users and participa tory design from 1950 to 1980 Iterative development was known a s concept testing beta testin g and probing in marketing and iterative incremental evolutio nary spiral and timeboxed de velopment in the software field Self organizing teams were known as self organizing dynamic tea ms self determined groups small decisionmaking groups tas k oriented groups and autonomous groups up to the 1960s Adaptability came from organis mic biology cybernetics systems theory systems dynamics double loop learning adaptive or ganizations learning organiza tions and systems thinking Thomas Edisons success is att ributed to the use of agile new product development processes along with Lockheeds SR71 NASA s Apollo program and the Jet Propulsion Laboratory 3 But direct antecedents of Agile Methods include Joint Applicat ion Design Rapid Application Development Participatory Des ign SynchandStabilize Judo St rategy and Internet Time4 Agile methods include Extreme Programming Scrum Feature Drive n Development Dynamic Systems Development Lean Development Crystal Methods and Ada ptive Software Design5 By 2003 66 of the worlds project s were using Agile Methods and 90 of those were using Extreme Programming XP6 although the number of projects using XP has declined to 237 The number of software projects using Scrum is increasing and i t has caught the fancy of big firms like Google Yahoo and Microsoft and as many as 50000 projects may be using Scrum The latest trend is to mixandmatch Scrum and XP to tap into practices like Pair Programming PP and TestDriven Development TDD to increase productivity and quality see Figure 28 Agile Methods have capabilities beyond Traditional MethodsThat is the ability to successfully deliver results quickly and inexpensively on complex projects w ith illdefined requirements Figure 2 Agile Methods and Practices with oftenreported costs and benefitsPage  3  Agile Methods Costs and Benefits A primary goal of this study was to examine scholarly studies o f Agile Methods and survey the range of quantitative costs and be nefits associated with the us e of Agile Methods see Table 1 Data were compared to costs a nd benefits of Tra ditional Methods such as CMMI see Table 29 Agile Methods emphasize teams working software customer colla boration and responding to change while Traditional Met hods focus on contracts plans pr ocesses documents and tools10 The SEI study identified 99 data points on cost schedule productivity quality satisfaction and ROI gains from 25 organizations as reported by CMMIrelated literature from SEI conferences Its important to note that CMMI data are optimistic and often come from CMMI proponents rather than scholarly research s tudies such as experiments sur veys or other scientific methods Oftentimes the percentages are only relative proportions and d o not state the actual costs and benefits eg large CMMI initiatives cost millions of dollars and oftentimes do not succeed Some of these data came from m ixing and matching Traditional Me thods such as Inspections PSPsm TSPsm Six Sigma and others to gain synergy not possible within a C MMI environment Nonetheless these data represent a major milestone in the rese arch on Traditional Methods for software process improvement sof tware development and information systems IS research Two similar studies on the costs and benefits of SWCMM were gathered by the Data and Analysis Center for Software DACS11 and software development researchers in Israel12 Table 1 Agile Methods Costs and Benefits No Category Low Median High Points 1 Cost 10 26 70 9 2 Schedule 11 71 700 19 3 Productivity 14 122 712 27 4 Quality 10 70 1000 53 5 Satisfaction 70 70 70 1 6 ROI 240 2633 8852 29 Table 2 Traditional Met hods Costs and Benefits No Category Low Median High Points 1 Cost 3 20 87 21 2 Schedule 2 37 90 19 3 Productivity 9 62 255 17 4 Quality 7 50 132 20 5 Satisfaction 4 14 55 6 6 ROI 200 470 2770 16 Using the SEI cost and benefit summary as a framework cost schedule productivity quality satisfaction and ROI data were gathered from over 300 scholarl y articles about Agile Methods In Table 1 and Table 2 the category represents the benefits of Agile and Traditional Methods while the low median and high rep resent the range of reported benefits within each category This was a laborious process because relevant articles on Agil e Methods had to be identified and categorized and then cost and be nefit data had to be extracted and normalized for comparison The original goals were limite d in scope and consisted of gathe ring a small amount of data in order to gain an appreciation f or the range of costs and benefits possible with Agile Methods However this quickly blossome d into a twomonth long effort du e to the number of studies on Agile Methods the amount of data  and the process of data clea nsing for comparative analysis In the end cost schedule pr oductivity quality and satisfac tion data from 69 scholarly studies were utilized consisting of 36 experiments 25 cases 6 survey s and 2 simulations see Table 3 On average studies of Agile Met hods reported 29 better cost 91 better schedule 97 better productivity 50 better qualit y 400 better satisfaction and 470 better ROI than CMMI  The complete results were comp iled into an ROI spreadsheet mode l on the costs and benefits of Agile Methods and represent one of the largest collections of d ata on Agile Methods todate13 Several good studies of Pair Pr ogramming and Test Driven Develo pment also served as an inspiration for this study as well as sources of additional cos t and benefit data on Agile Methods Page  4  Table 3 Agile Methods Costs and Benefits identified from an a nalysis of over 300 studies No Authors Year Tech Cost Sched Prod Quality Satis Method N 1 Abrahamsson 2003 XP 88 Case 4 2 Abrahamsson 2007 General 70 700 250 Case 1800 3 AlKilidar et al 2005 PP 13 Ex p 121 4 Arisholm et al 2007 PP 11 23 Exp 295 5 Back Hirkman  Milovanov 2004 XP 87 Ex p 8 6 Bhat  Na gappan 2006 TDD 71 Case 12 7 Bipp Lepper  Schmeddin g 2008 PP 62 Ex p 95 8 Canfora et al 2006 PP 14 20 Exp 70 9 Canfora et al 2007 PP 39 39 Ex p 18 10 Cohn 2008 Scrum 405 71 Case 7 11 Dalcher Benediktsson  Thorber gsson 2005 XP 21 384 Ex p 55 12 Damm  Lundber g 2006 TDD 56 Case 100 13 Drobka Noftz  Ra ghu 2004 XP 289 63 Case 29 14 Erdo gmus Morisio  Torchiano 2005 TDD 28 Exp 24 15 Fitzgerald Hartnett  Conbo y 2006 Scrum 700 Case 45 16 Flohr  Schneider 2006 TDD 27 Exp 18 17 Geor ge 2002 TDD 16 Ex p 138 18 Geor ge  Williams 2003 TDD 18 Exp 24 19 Geor ge  Williams 2004 TDD 18 Ex p 24 20 Heiber g et al 2003 PP 16 Exp 100 21 Huan g  Holcombe 2008 TDD 172 Ex p 274 22 Hulkko  Abrahamsson 2005 PP 18 46 Case 18 23 Ilieva Ivanov  Stefanova 2004 XP 12 41 13 Ex p 8 24 Janzen  Saiedian 2008 TDD 34 Exp 64 25 Jensen 2003 PP 127 1000 Case 10 26 Jones 2008 Scrum 74 Case 5 27 Kaufmann  Janzen 2003 TDD 50 50 Ex p 8 28 Kuppuswami et al 2003 XP 28 Sim na 29 Layman 2004 XP 61 48 Case 21 30 Lui  Chan 2004 PP 24 Exp 3 31 Lui  Chan 2006 PP 23 Ex p 40 32 Lui Chan  Nosek 2008 PP 70 Exp 15 33 Made yski 2006 PP 14 Ex p 188 34 Made yski  Szala 2007 TDD 18 45 Case 1 35 Mann 2004 TDD 81 Case 7 36 Maurer  Martel 2002 XP 66 Case 9 37 Maximilien  Williams 2003 TDD 50 Case 9 38 McDowell et al 2003 PP 27 Exp 555 39 McDowell et al 2006 PP 27 Case 486 40 Melis et al 2006 TDD 36 Case 4 41 Mendes AlFakhri  LuxtonReill y 2005 PP 10 Ex p 300 42 MolokkenOstvold  Jor gensen 2005 General 12 Surve y 42 43 Muller 2005 PP 29 Ex p 38 44 Muller 2006 PP 29 11 Exp 18 45 Muller 2007 PP 50 Ex p 21 46 Muller  Padber g 2003 XP 20 Sim na 47 Nawrocki  Wo jciechowski 2001 PP 25 15 Ex p 21 48 Nosek 1998 PP 29 36 Exp 15 49 Pande y et al 2003 PP 40 20 40 Ex p 10 50 Phon gpaibul  Boehm 2006 PP 24 34 Exp 104 51 Reifer 2003 XP 10 53 20 Surve y 18 52 Rico 2007 General 51 65 56 63 70 Surve y 122 53 Saff  Ernst 2004 TDD 16 Ex p 39 54 Sanchez Williams  Maximilien 2007 TDD 40 Case 17 55 Schatz  Abdelshafi 2005 Scrum 29 30 Case 90 56 Schatz  Abdelshafi 2005 TDD 75 Case 90 57 Sutherland 2007 Scrum 712 Case 5 58 Talb y et al 2006 TDD 90 Case 60 59 Van Schooenderwoert 2006 XP 192 89 Case 4 60 Vanhanen  Lassenius 2005 PP 42 Exp 20 61 Version One 2006 General 10 18 17 17 Surve y 722 62 Version One 2007 General 11 16 17 17 Surve y 1681 63 Williams 2001 PP 47 15 Ex p 41 64 Williams et al 2003 PP 16 Exp 575 65 Williams Maximilien  Vouk 2003 TDD 40 Case 14 66 Wilson Hoskin  Nosek 1993 PP 38 Exp 34 67 Wolf  Roock 2008 General 72 78 74 Surve y 200 68 Xu  Ra jlich 2006 PP 48 201 21 Exp 12 69 Ynchausti 2001 TDD 153 Case 5Page  5  ROI Metrics and Models A significant concept or princip le within Agile Methods is the notion of creating business value which often means delivering working software through the proce ss of iterative development This is clearly evident by analy sis of the first principle of t he Agile Manifesto Our highest priority is to satisfy the cus tomer through early and continuou s delivery of valuable software This stands in opposition to the cen tral concept or principle w ithin some Traditional Methods in which creating processes and docum entation is considered the ma in measure of business value14 Within some Traditional Methods writing documentation is consi dered paramount to the quality maintainability reliability a nd safety of mission critical sy stems such as aviation electronics15 While Agile Methods use programmi ng for creating business value  some equate them with hacking illconceived prototy pes and coding without documented requirements and design16 The advent of Agile Methods was a return to fundamentalsThat i s software craftsmanship versus documentation which has been a mantra of the commercial software industry for years17 Traditional Methods are usuall y used on extraordinarily large s ystems in which public funds are necessary to pay for Acquisition Category I programs eg spacecraft aircraft missiles etc Table 4 ROI Metrics showing si mplicity of return on investmen t formulas and their order of application Metric Definition Formula Costs sum of costs Total amount of money sp ent on Agile Methods  n iiCost 1 Benefits sum of benefits Total amount of money gain ed from Agile Methods  n ii Benefit 1 BCR benefit to cost ratio Ratio of Agile Methods benefits to costs CostsBenefits ROI return on investment Ratio of adjusted Agile M ethods benefits to costs  100 CostsCosts Benefits NPV net present value Discounted cash flow s of Agile Methods  Years iYearsiCostsRate DiscountBenefits 10 1  BEP breakeven point Point when benefits exceed costs of Agile Methods MonthsNPVCosts60 ROA real options analysis Value realized from strategic delay due to risk  Years Ratee Costs d N Benefits d N    2 1 d1  lnBenefits  Costs  Rate  05 Risk2 Years Risk Years d2  d1  Risk   Years However Agile Methods elevate business value beyond just the activities of creating working software at regular intervals Agile Methods go on to define bus iness value in terms of ROI 18 This is clearly evident within A gile Methods such as Extreme Pr ogramming and Scrum where user stories requirements are prioritized based on business value eg ROI NPV etc19 With this second definition of busin ess value inmind the most often cited measure of business value for prioritizing requirem ents is ROI or any closely related family of business metrics20 ROI metrics are used to evalua te the economic value of one or m ore investments in information technology and are often expressed as simple ratios of benefits to cost less the costs of course21 Seven metrics were used for valu ation of Agile Methods Costs Benefits Benefit to Cost Ratio Return on Investment Net Prese nt Value Break Even Point and Real Options see Table 422 ROI metrics are slight varia tions created over the last 100 yea rs eg benefits rel ative to costs and each is good for measuring the business value of Agile Meth ods with increasing accuracy Page  6  Agile Methods Costs As shown in Table 4 the first basic input necessary to estimat e the ROI of Agile Methods is cost so it was necessary to identify studies of Agile Methods with c ost measures for estimating ROI Therefore software productivity and quality measurement data s uch as lines or code or function points and quality measures such as defect density had to be id entified in order to estimate ROI This data could then serve as th e basis for establishing the em pirical cost estimating relationships necessary to design top down parame tric models for estimating t he costs of using Agile Methods Table 5 Agile Methods Productivity and Quality Data identifie d from an analysis of over 300 studies No Authors Year Tech LOCHour DefKLOC Method N 1 Abrahamsson 2003 XP 192550 21450 Case 4 2 Abrahamsson  Koskela 2004 XP 169000 14300 Case 4 3 Back Hirkman  Milovanov 2004 XP 80000 07000 Exp 8 4 Bowers et al 2002 XP 181731 00325 Case  5 Dalcher Benediktsson  Thorbergsson 2005 XP 148667 Exp 55 6 Hashmi  Baik 2008 XP 168420 Case 19 7 Ilieva Ivanov  Stefanova 2004 XP 202030 00032 Exp 8 8 Layman 2004 XP 91154 06250 Case 21 9 Layman et al 2006 XP 133846 16200 Case 8 10 Manzo 2002 XP 430000 05000 Case 17 11 Maurer  Martel 2002 XP 170000 Case 9 12 Van Schooenderwoert 2006 XP 35000 01700 Case 4 13 Williams Layman  Krebs 2004 XP 98077 02400 Case 19 14 Huang  Holcombe 2008 TDD 123800 Exp 274 15 Madeyski  Szala 2007 TDD 461800 Case 1 16 Maximilien  Williams 2003 TDD 37000 Case 9 17 Williams Maximilien  Vouk 2003 TDD 06100 Case 14 18 Baheti Gehringer  Stotts 2002 PP 166370 Exp 132 19 Erdogmus  Williams 2003 PP 434780 58500 Case 41 20 Hulkko  Abrahamsson 2005 PP 156667 41500 Case 18 21 Nawrocki  Wojciechowski 2001 PP 492500 Exp 21 22 Pandey et al 2003 PP 224462 23900 Exp 10 23 Vanhanen  Korpi 2007 PP 154667 05500 Case 4 24 Vanhanen  Lassenius 2005 PP 178403 03250 Exp 20 25 Xu  Rajlich 2006 PP 864502 08651 Exp 12 26 Cohn 2008 Scrum 59050 29000 Case 7 27 Jones 2008 Scrum 57400 85000 Case 5 28 Schatz  Abdelshafi 2005 Scrum 04350 Case 90 29 Sutherland 2006 Scrum 46858 Case 5 Data from Table 5 were averaged t o establish the cost estimatin g relationships to design top down parametric models used to est imate the ROI of Agile Methods see Table 6 and Table 7 An average programming productivi ty measurement was taken of th e 26 data points in Table 6 and was used to construct an empir ical cost mode l called Agile Methods for the entire data set The cost and quality models in T able 6 and Table 7 were then be used to estimate the software development and maintenance cost s of Agile Methods along with their benefits hence ROI The method for estimating the ROI of Agile Methods will be expl ained in the next section Table 6 Agile Methods Cost Models No Tech Low Median High Pts Cost Model 1 XP 035000 161575 430000 13 LOC161575 2 TDD 123800 292800 461800 2 LOC 292800 3 PP 154667 334044 864502 8 LOC334044 4 Scrum 046858 054436 059050 3 LOC 054436 5 Agile 035000 212374 864502 26 LOC 212374Table 7 Agile Methods Quality Models No Tech Low Median High Pts Qualit y Model 1 XP 00032 07466 21450 10 07466  KLOC 100 2 TDD 06100 21550 37000 2 21550  KLOC 100 3 PP 03250 23550 58500 6 23550  KLOC 100 4 Scrum 04350 39450 85000 3 39450  KLOC 100 5 Agile 00032 17972 85000 21 17972  KLOC 100Page  7  Agile Methods Benefits There are two ways to increase bus iness value or ROI a increasing volume and revenue while maintaining current costs or b reducing costs while maintaini ng current volume and revenue23 This study uses the latter eg r educe costs while maintainin g volume and revenue which is known as cost of quality CoQ tot al cost of ownership TCO and total lifecycle cost TLC24 Unless previously stated we can t predict the business value o r ROI of an Agile Methods study However we can predict costs of software development and maint enance given the right data This is especially true for software maintenance costs which c an be predicted using software quality measurements from the software development phase such a s defect density DefKLOC Together the software developm ent and maintenance costs consti tute the CoQ TCO and TLC That is cradletograve costs of software analysis design development test and maintenance Table 8 Total L ifecycle Costs No Tech Total Lifecycle Cost Model Costs 1 XP 10000 161575  07466 10100 100 136548 2 TDD 10000 292800  21550 10100 100 249653 3 PP 10000 334044  23550 10100 100 265437 4 Scrum 10000 054436  39450 10100 100 578202 5 Agile 10000 212374  17972 10100 100 226805 In order to estimate total lifecy cle costs both software devel opment and maintenance costs have to be estimated and then adde d together using cost and quality models from Table 6 and Table 7 First software development co sts are estimated using the cost models from Table 6 and then the software maintenance costs are estimated utilizing the quality models from Table 7 see Table 8 A baseline size of 10000 lines of code is used for software de velopment and a baseline effort of 100 hours is used for software main tenance along with a conversion rate of 100 US dollars The software development cost model is a simple linear model ba sed on productivity measures but maintenance cost is based on 100 hours of effort for each d efect which escapes development This methodology assumes a ratio of 110100 ratio for pretest  test and maintenance effort 25 Table 9 Total Lifecycle Benefits No Tech Total Lifecycle Benefit Model Benefits 1 XP 10000 1051 666667 9 100 TLC 4373449 2 TDD 10000 1051  666667  9 100  TLC 4260344 3 PP 10000 1051 666667 9 100 TLC 4244560 4 Scrum 10000 1051  666667  9 100  TLC 3931795 5 Agile 10000 1051 666667 9 100 TLC 4283192 In order to estimate total lifecy cle benefits the total lifecy cle costs of using Agile Methods were subtracted from the estimated total lifecycle costs of Traditio nal Methods as shown in Table 9 Some assumptions were that the total lifecycle costs of Traditi onal Methods exceeded the total lifecycle costs of Agile Met hods and Agile Methods dont excee d costs of Traditional Methods The major terms of the benefit m odels represent the total lifec ycle costs of a 10 defect rate and a 051 LOChour productivity rate less the benefits of finding 6667 of the defects by testing The TLC methodology used here to es timate the costs benefits and ROI has been outlined in a number of publications 21 and the complete results are av ailable in an ROI spreadsheet m odel13 Page  8  Agile Methods Return on Investment The total lifecycle cost and bene fit models for each of the Agi le Methods from Table 8 and Table 9 were combined with the ROI met rics from Table 4 to estimate t he ROI data shown in Table 10 Extreme Programming had the low est overall tota l lifecycle cost at 136548 followed by Test Driven Development Pair Programming and Scrum around 249653  265437 and 578202 As a result Extreme Programmi ng had the highest return on investment at 3103 followed by Test Driven Development Pair Programming and Scrum at around 1607 1499 and 580 Pair Programming had the highest o verall average productivity a t 33 LOCHour followed by Test Driven Development Extreme Programming and Scrum around 29 16 and 5 LOCHour Extreme Programming had the high est overall quality at 08 Defe ctsKLOC followed by Test Driven Development Pair Programming and Scrum at around 22 24 and 4 DefectsKLOC Extreme Programming had half the p roductivity of Pair Programmi ng however it had six times better quality than all the othe r methods combined leading to lower total costs and higher ROI Table 10 Agile Methods Return on Investment estimated from pr oductivity and quality data No Tech Prod Quality Costs Benefits BCR ROI NPV BEP CostPe r Risk ROA 1 XP 161575 07466 136548 4373 449 321 3103 3650401 4263 34137 2123 4267105 2 Agile 212374 17972 226805 4283192 191 1788 3481992 12010 56701 6227 4110308 3 TDD 292800 21550 249653 4260 344 171 1607 3439359 14629 62413 6795 4074506 4 PP 334044 23550 265437 4244560 161 1499 3409908 16599 66359 7130 4050918 5 Scrum 54436 39450 578202 3931 795 71 580 2826320 85029 1445 51 10000 3660805 The ROI data for Agile Methods in Table 10 were combined with p rior ROI data for Traditional Methods 22 in order to compare the ROI of Agile vs Traditional Methods  as shown in Table 11 Some Traditional Methods were e xpected to top the list in this analysis which they did because the ROI methodology used in this study rewards methods with hig h quality low defect density Most Agile Methods were expect ed to rank better than expensive Traditional Methods which they did because the costs of implementing expensive Traditio nal Methods tends to be high Although Extreme Programming was expected to top the list of A gile Methods which it did Extreme Programming ranked third a head some of the industrys premier Traditional Methods Extreme Programming ranked almost second on the strength of quality rather than productivity which was half its nearest competitors because total lifecycle cost rewards quality handsomely The best traditional methods remove defects before testing to m inimize total lifecycle costs Table 11 Agile vs Tra ditional Methods Ret urn on Investment e stimated from productivity and quality data No Method Costs Benefits BCR ROI NPV BEP CostPer Risk ROA 1 PSPsm 105600 4469997 421 4133 3764950 945 26400 644  4387756 2 Inspection 82073 2767464 341 3272 2314261 51677 20518 2678 2703545 3 XP 136548 4373449 321 3103 3650401 4263 34137 3078  4267105 4 TSPsm 148400 4341496 291 2826 3610882 5760 37100 3733 4225923 5 Agile 226805 4283192 191 1788 3481992 12010 56701 6183 4110118 6 TDD 249653 4260344 171 1607 3439359 14629 62413 6613 4073167 7 PP 265437 4244560 161 1499 3409908 16599 66359 6867 4048404 8 SWCMM 311433 3023064 101 871 2306224 153182 77858 8351 2828802 9 Scrum 578202 3931795 71 580 2826320 85029 144551 9038 3622271 10 ISO 9001 173000 569841 31 229 320423 1196206 43250 9866 503345 11 CMMI 1108233 3023064 31 173 1509424 545099 277058 100 00 2633052 Page  9  Conclusion The main purpose of this articl e was to identify analyze and summarize the costs and benefits of Agile Methods found in the best pos sible literature eg expe riments surveys and case studies Not only did we find 69 studies w ith cost and benefit data but we found more better quality studies with an average of 200 better performance than big and expensive Traditional Methods We also found 29 studies of Agile Methods with the productivity and quality data necessary to estimate ROI using metrics that would enable the comparison of Agile vs Traditional Methods This analysis showed that Ag ile Methods are almost as good as the best Traditional Methods under the light of total lifecycle cost analysis which tends t o reward methods with high quality  Agile Methods werent born yesterday  Agile Methods are based on early customer involvement iterative developmen t self organizing teams and adaptability to change which originated from agile new product development approaches datin g back to the 19th century  Agile Methods scale up to large problems  Agile new product development methods have been used for many larges cale complex research and devel opment projects such as Lockheeds SR71 NASAs Apoll o and the Jet Propulsion Laboratorys deep space probes  Agile Methods may not be in use by very large organizations  Agile Methods are used by 70 of small to mediumsized projects however larger proje cts use Traditional Methods so the relevance of Agile Methods to large complex projects needs to be convincingly made  Agile Methods can learn something from traditional methods  Agile Methods should apply traditional quality and rel iability theory which holds t hat defects are less expensive to eliminate early in the lifecycl e and late defect removal has a negative multiplicative effect  Agile Methods hybrids are the latest trends  Agile Methods are being combined with one another to gain synergies no t possible with any one approac h such as XP and Scrum Agile and Traditional Methods are also being combined to tap in to one anothers capabilities  Agile Methods require nontraditional measures  Traditional Methods were optimized for productivity and quality which r ewards them using total lifecycle cost analysis but Agile Methods should focus on project su ccess and customer satisfacti on where they shine best  Agile Methods lend themselves to advanced economic models  Agile Methods lend themselves to valuation methods s uch as real options therefore researchers should focus on real options as a way of explaining the superiority of Agile Methods on complex projects  Agile Methods adoption involves tradi tional critical success factors  Executive commitment resources leadersh ip strategy culture incentive s training tools execution consulting measurement and imp rovement are vital to the adoption of Agile Methods  Agile Methods adoption also involves nontraditional criti cal success factors  Lest we forget the Agile Manifesto emphasis on individuals and interactions working software customer collaboration and res ponding to change are nontraditional critical success factors In conclusion not all Agile and T raditional Methods are created equal there are pitfalls for using any method with a low ROI and the re are lessons to be learned from the best software methods However it may not be fair to compare methods optimized for pr oductivity and quality to those optimized for speed satisfaction project success and optimal ROI in the face of increasing risk Its important to note that the power of Agile Methods is not i n minimizing lifecycle costs but maximizing business value thr ough successful delivery of workin g software in the face of risk Agile Methods are a unique paradi gm which cannot be easily gra sped through traditional means The concepts in this paper were expanded into a textbook 26 and newer studies 27 28 29 30 31 Page  10  References 1 Rico D F 2007 Effects of agile methods on website quality for electronic commerce  Retrieved August 10 2008 from httpdavidfricocomrico07qpdf 2 Rico D F Sayani H  H  Field R F 2008 History of c omputers electronic commerce and agile methods In M V Zelkowitz Ed Advances in computers Emerging technologies  Vol  73 San Diego CA Elsevier 3 Thomke S 2003 Experimentation matters  Unlocking the potential of new technologies for innovation  Boston MA Harvard Business School Press 4 Rico D F 2008 Effects of agile methods on website quality for electronic commerce Proceedings of the 41st Annual Hawaii International Conference on System Sciences HICSS 2008  Waikaloa  Big Island  Hawaii  5 Highsmith J A 2002 Agile software development ecosystems  Boston MA Addison Wesley 6 Johnson M 2002 Agile methodologies  Survey results  Victoria Australia Shine Technologies 7 Ambler S W 2006 Agile adoption rate survey  March 2006  Retrieved September 17 2006 from httpwwwambysoftcomdownloads surveysAgileAdoptionRatespp t 8 Fitzgerald B Hartnett G  Conboy K 2006 Customising agile methods to software practices at intel shannon European Journal of Information Systems 15 2 200213 9 SEI 2005 SEI performance results Retrieved August 10 2008 from httpwwwseicmueducmmi2005resultshtml 10 Agile Manifesto 2001 Manifesto for agile software development Retrieved November 29 2006 from httpwwwagilemanifestoorg 11 Rico D F 2000 Using cost benefit analyses to develop software process improvement SPI strategies Contract Number SP070098D4000 Rome NY Air Force Research Laborato ryData and Analysis C enter for Software 12 Galin D  Avrahami M 2006 Are CMM program investments b eneficial Analyzing past studies IEEE Software 23 6 8187 13 Rico D F 2008 What is the ROI of agile vs traditional methods  An analysis of extreme programming testdriven development pair programming and scrum using real options  Retrieved June 28 2008 from httpdavidfricocomagilebenefitsxls  Expanded with more data and extensive Monte Carlo Analysis 14 International Standards Organization 2008 Systems and software engineering  Software life cycle processes ISOIEC 12207 Geneva Switzerland Author 15 Radio Technical Commission for Aeronautics 1999 Software considerations in airborne systems and equipment certification DO178B Washington DC Author 16 McCormick M 2001 P rogramming extremism Communications of the ACM 44 6 109111 17 McBreen P 2001 Software craftsmanship  The new imperative  Boston MA AddisonWesley 18 Agile Project Leadership Network 2008 Declaration of interdependence  Retrieved August 10 2008 from httpwwwpmdoiorg 19 Beck K  Fowle r M 2001 Planning extreme programming  Upper Saddle River NJ AddisonWesley 20 Schwaber K 2004 Agile project management with scrum  Redmond WA Microsoft Press 21 Rico D F 2004 ROI of software process improvement  Metrics for project managers and software engineers  Boca Raton FL J Ross Publishing 22 Rico D F 2007 Practical metrics and models for ROI with real options  Retrieved November 28 2007 from httpdavidfricocomrico07bpdf 23 Garrison R H  Noreen E W 1997 Managerial accounting  Boston MA McGrawHill 24 Campanella J 1999 Principles of quality costs  Principles implementation and use  Milwaukee WI Quality Press 25 McGibbon T Ferens D  Vienneau R L 2007 A business case for software process improvement  Measuring the return on investment from software engineering and management  Griffiss AFB NY AFRLIFT DACS 26 Rico D F Sayani H H   Sone S 2009 The business value of agile software methods  Maximizing ROI with justintime processes and documentation  Ft Lauderdale FL J Ross Publishing 27 Rico D F 2012 The cost of quality CoQ for agile vs traditional project management  Retrieved January 29 2012 from httpdavidfricocomricoapmcoqpdf 28 Rico D F 2014 18 reasons why agile cost of quality CoQ is a fraction of traditional methods  Retrieved June 25 2014 from httpdavidfricocomagilevstradcoqpdf 29 Rico D F 2016 Business value ROI and cost of quality CoQ for devops Retrieved June 1 2016 from httpdavidfricocomricodevopsroipdf 30 Rico D F 2017 US dod vs amazon 18 architectural principles to build fighter jets like amazon web service using devops  Retrieved January 26 2017 from httpdavidfricocomdodagileprinciplespdf 31 Rico D F 2018 Lean and agile contracts  21 principles of collaborative contracts and relationships  Retrieved June 29 2018 from httpdavidfricocomcollaborativecontractprinciplespdf FDM Group Limited Cottons Centre Cottons Lane London SE1 2QG UK 44 0 203 056 8240 enquiriesfdmgroupcom fdmgroupcom FDM Group Limited registered in England and Wales under Company Number 02542980 Registered Office 3rd Floor Cottons Centr e Cottons Lane London SE1 2QG UK  USA  CANADA  GERMANY  POLAND  IRELAND  THE NETHERLANDS SOUTH AFRICA  HONG KONG  SINGAPORE  CHINA  AUSTRALIA  NEW ZEALAND FDM Group Limited Carbon Reduction Plan Company name FDM Group Limited Publication date July 2023 Commitment to achieving Net Zero FDM Group Limited is committed to achieving Net Zero emissions by 2050 FDM Group is fully committed to playing its part in addressing the climate crisis and has committed to delivering Net Zero emissions across all scopes by 2050 At a consolidated Group l evel we have developed ambitious near term s cience based targets in li ne with a 15C limit to global warming which have been validated by the Science Based Targets initiative  Our commitment to delivering Net Zero emissions applies to all entities within the Group with the following minimum boundaries  Scope 1 D irect emissions from owned or controlled sources  Scope 2 I ndirect emissions from the generation of purchased electricity heating and cooling that FDM consumes  Scope 3 All other indirect emissions that occur within our value chain over which we have operational control including o Category 1 Purchased goods and services o Category 2 Capital goods o Category 3 Fuel  and energy related activities not included in scope 1 or scope 2 o Category 5 Waste generated in operations o Category 6 Business travel o Categ ory 7 Employee commuting The calculation of Scope 3 emissions is complex  For the purposes of this UK Plan we are reporting only on the following Scope 3 sub categories Category 5 waste generated in operations  Category 6 business travel  and catego ry 7 employee commuting This report does not include reporting of Scope 3 sub categories 1 2 and 3 We monitor these emissions at a Group level FDM Group has nil emissions for the following Scope 3 sub categories  which are not applicable to FDM at a UK or Group level  Category 4 Upstream transportation and distribution  Category 8 Upstream leased assets  Category 9 Downstream transportation and distribution  Category 10 Processing of sold products  Category 11 Use of sold products  Category 12 Endoflife treatment of sold products  Category 13 Downstream leased assets  Category 14 Franchises  and Category 15 Investments  fdmgroupcom FDM Group Limited registered in England and Wales under Company Number 02542980 Registered Office 3rd Floor Cottons Centr e Cottons Lane London SE1 2QG UK  USA  CANADA  GERMANY  POLAND  IRELAND  THE NETHERLANDS SOUTH AFRICA  HONG KONG  SINGAPORE  CHINA  AUSTRALIA  NEW ZEALAND Baseline emissions footprint Baseline emissions are a record of the greenhouse gases that have been produced in the past and were produced prior to the introduction of any strategies to reduce emissions Baseline emissions are the reference point against which emissions reduction can be measured FDMs base year is the 12 months to 31 December 2020 Emissions reporting Total emissions tCO 2e Base year 2020 2021 Reporting Year 2022 Scope 1 57 44 59 Scope 2 market based 100 39 0 Scope 3 included sources Subcat 5 Waste generated in operations Subcat 6 Business travel Subcat 7 Employee commuting 7 43 428 4 41 238 12 59 394 Total emissions 635 366 524 Intensity ratio 2020 2021 2022 Emissions per employee tCO 2e per employee 026 015 018 Average No of UK employees 2418 2438 2964 fdmgroupcom FDM Group Limited registered in England and Wales under Company Number 02542980 Registered Office 3rd Floor Cottons Centr e Cottons Lane London SE1 2QG UK  USA  CANADA  GERMANY  POLAND  IRELAND  THE NETHERLANDS SOUTH AFRICA  HONG KONG  SINGAPORE  CHINA  AUSTRALIA  NEW ZEALAND Emissions reduction targets FDM Group is committed to achieving Net Zero emissions by 2050 In order to continue our progress to achie ve Net Zero we have adopted the following near term carbon reduction targets  FDM Group is committed  to reduce its absolute Scope 1 and 2 greenhouse gas emissions by 50 by 2030 from a 2020 base year and  to reduce its Scope 3 greenhouse gas emissions by 62 per fulltime employee by 2030 from a 2020 base year Carbon reduction projects Completed carbo n reduction initiatives The following environmental management measures and projects have been completed or implemented since the 20 20 baseline The annual carbon emission reduction achieved by these schemes equate s to approximately 100 tCO 2e  Through dialogue with our landlords the electricity supplied to all our UK centres is now sourced from 100 renewable energy sources  Paper reduction the implementation of a new time recording and billing system in 2020 significantly reduced our paper usage  The Company no longer has two company cars which were used as pool cars for business usage only   We have contracted with our principal supplier of IT hardware regarding a recycling scheme for our IT laptops and  We are virtualising our IT estate Our electricity requirement is lower because our cloud based systems and data are hosted at efficient datacentres run by Microsoft Azure that flex capacity in line with our usage  In the future we hope to implement furt her measures  Continue dialogue with our landlords in all our locations to reduce our consumption of electricity and natural gas  Continue dialogue and engagement with our top suppliers to reduce our Scope 3 emissions from purchased goods and services fdmgroupcom FDM Group Limited registered in England and Wales under Company Number 02542980 Registered Office 3rd Floor Cottons Centr e Cottons Lane London SE1 2QG UK  USA  CANADA  GERMANY  POLAND  IRELAND  THE NETHERLANDS SOUTH AFRICA  HONG KONG  SINGAPORE  CHINA  AUSTRALIA  NEW ZEALAND Declaration and sign off This Carbon Reduction Plan has been completed in accordance with PPN 0621 and associated guidance and reporting standard for Carbon Reduction Plans Emissions have been reported and recorded in accordance with the published reporting standard for Carbon Reduction Plans and the GHG Reporting Protocol corporate standard1 and uses the appropriate Government em ission conversion factors for greenhouse gas company reporting2 Scope 1 and Scope 2 emissions have been reported in accordance with SECR requirements and the required subset of Scope 3 emissions have been reported in accordance with the published report ing standard for Carbon Reduction Plans and the Corporate Value Chain Scope 3 Standard3 This Carbon Reduction Plan has been approved by the Board of Directors Signed on behalf of FDM Group Limited  Rod Flavell Chief Executive Officer July 2023 1httpsghgprotocolorgcorporate standard 2httpswwwgovukgovernmentcollectionsgovernment conversion factors forcompany reporting 3httpsghgprotocolorgstandardsscope 3standard ,https://www.fdmgroup.com/blog/what-is-agile-scrum-methodology/,Project Management,2765,9528
Microservices Architecture, From Wikipedia the free encyclopedia Collection of loosely coupled services used to build computer applications Some of this articles listed sources may not be reliable Please help this article by looking for better more reliable sources Unreliable citations may be challenged or deleted October 2018 Learn how and when to remove this template message In software engineering a microservice architecture is a variant of the serviceoriented architecture structural style It is an architectural pattern that arranges an application as a collection of loosely coupled finegrained services communicating through lightweight protocols One of its goals is that teams can develop and deploy their services independently of others This is achieved by the reduction of several dependencies in the code base allowing developers to evolve their services with limited restrictions from users and for additional complexity to be hidden from users1 As a consequence organizations are able to develop software with fast growth and size as well as use offtheshelf services more easily Communication requirements are reduced These benefits come at a cost to maintaining the decoupling Interfaces need to be designed carefully and treated as a public API One technique that is used is having multiple interfaces on the same service or multiple versions of the same service so as to not disrupt existing users of the code Introductionedit There is no single definition for microservices A consensus view has evolved over time in the industry Some of the defining characteristics that are frequently cited include Services in a microservice architecture are often processes that communicate over a network to fulfill a goal using technologyagnostic protocols such as HTTP234 Services are organized around business capabilities5 Services can be implemented using different programming languages databases hardware and software environments depending on what fits best6 Services are small in size messagingenabled bounded by contexts autonomously developed independently deployable76 decentralized and built and released with automated processes7 A microservice is not a layer within a monolithic application for example the web controller or the backendforfrontend8 Rather it is a selfcontained piece of business functionality with clear interfaces and may through its own internal components implement a layered architecture From a strategic perspective microservice architecture essentially follows the Unix philosophy of Do one thing and do it well9 Martin Fowler describes a microservicesbased architecture as having the following properties2 Lends itself to a continuous delivery software development process10 A change to a small part of the application only requires rebuilding and redeploying only one or a small number of services11 Adheres to principles such as finegrained interfaces to independently deployable services businessdriven development eg domaindriven design12 It is common for microservices architectures to be adopted for cloudnative applications serverless computing and applications using lightweight container deployment According to Fowler because of the large number when compared to monolithic application implementations of services decentralized continuous delivery and DevOps with holistic service monitoring are necessary to effectively develop maintain and operate such applications13 A consequence of and rationale for following this approach is that the individual microservices can be individually scaled In the monolithic approach an application supporting three functions would have to be scaled in its entirety even if only one of these functions had a resource constraint14 With microservices only the microservice supporting the function with resource constraints needs to be scaled out thus providing resource and cost optimization benefits15 Historyedit There are numerous claims as to the origin of the term microservices Whilst vice president of ThoughtWorks in 2004 Fred George began working on prototype architectures based on what he called the Baysean Principles named after Jeff Bay16 As early as 2005 Peter Rodgers introduced the term MicroWebServices during a presentation at the Web Services Edge conference Against conventional thinking and at the height of the SOAP serviceoriented architecture SOA hype curve he argued for RESTservices and on slide 4 of the conference presentation he discusses Software components are MicroWebServices17 He goes on to say MicroServices are composed using Unixlike pipelines the Web meets Unix  true loosecoupling Services can call services multiple language runtimes Complex service assemblies are abstracted behind simple URI interfaces Any service at any granularity can be exposed He described how a welldesigned microservices platform applies the underlying architectural principles of the Web and REST services together with Unixlike scheduling and pipelines to provide radical flexibility and improved simplicity in serviceoriented architectures17 Rodgers work originated in 1999 with the Dexter research project at Hewlett Packard Labs whose aim was to make code less brittle and to make largescale complex software systems robust to change18 Ultimately this path of research led to the development of resourceoriented computing ROC a generalized computation abstraction in which REST is a special subset In 2007 Juval Löwy in his writing19 and speaking2021 called for building systems in which every class was a service Löwy realized this required the use of a technology that can support such granular use of services and he extended Windows Communication Foundation WCF to do just that2223 taking every class and treating it as a service while maintaining the conventional programming model of classes In 2005 Alistair Cockburn wrote about hexagonal architecture which is a software design pattern that is used along with the microservices This pattern makes the design of the microservice possible since it isolates in layers the business logic from the auxiliary services needed in order to deploy and run the microservice completely independent from others A workshop of software architects held near Venice in May 2011 used the term microservice to describe what the participants saw as a common architectural style that many of them had been recently exploring24 In May 2012 the same group decided on microservices as the most appropriate name James Lewis presented some of those ideas as a case study in March 2012 at 33rd Degree in Kraków in Microservices  Java the Unix Way25 as did Fred George26 about the same time Adrian Cockcroft former director for the Cloud Systems at Netflix27 described this approach as finegrained SOA pioneered the style at webscale as did many of the others mentioned in this article  Joe Walnes Dan North Evan Bottcher and Graham Tackley28 Microservices is a specialization of an implementation approach for serviceoriented architectures used to build flexible independently deployable software systems5 The microservices approach is the first realisation of SOA that followed the introduction of DevOps and is becoming more popular for building continuously deployed systems29 In February 2020 the Cloud Microservices Market Research Report predicted that the global microservice architecture market size will increase at a CAGR of 2137 from 2019 to 2026 and reach 31 billion by 202630 Service granularityedit A key step in defining a microservice architecture is figuring out how big an individual microservice has to be There is no consensus or litmus test for this as the right answer depends on the business and organizational context31 For instance Amazon uses a serviceoriented architecture where service often maps 11 with a team of 3 to 10 engineers32 Generally the terminology goes as such services that are dedicated to a single task such as calling a particular backend system or making a particular type of calculation are called atomic services Similarly services that call such atomic services in order to consolidate an output are called composite services It is considered bad practice to make the service too small as then the runtime overhead and the operational complexity can overwhelm the benefits of the approach When things get too finegrained alternative approaches must be considered  such as packaging the function as a library moving the function into other microservices5 If domaindriven design is being employed in modeling the domain for which the system is being built then a microservice could be as small as an aggregate or as large as a bounded Context33 In the granularity of microservices discussion there is a spectrum in one end there are the Anaemic Services which do not have a large number of responsibilities and on the other end the Modular Monolith which are large modules of a system Benefitsedit The benefit of decomposing an application into different smaller services are numerous Modularity This makes the application easier to understand develop test and become more resilient to architecture erosion6 This benefit is often argued in comparison to the complexity of monolithic architectures34 Scalability Since microservices are implemented and deployed independently of each other ie they run within independent processes they can be monitored and scaled independently35 Integration of heterogeneous and legacy systems microservices is considered a viable means for modernizing existing monolithic software application3637 There are experience reports of several companies who have successfully replaced parts of their existing software with microservices or are in the process of doing so38 The process for software modernization of legacy applications is done using an incremental approach39 Distributed development it parallelizes development by enabling small autonomous teams to develop deploy and scale their respective services independently40 It also allows the architecture of an individual service to emerge through continuous refactoring41 Microservicebased architectures facilitate continuous integration continuous delivery and deployment42 Criticism and concernsedit The microservices approach is subject to criticism for a number of issues Services form information barriers43 Interservice calls over a network have a higher cost in terms of network latency and message processing time than inprocess calls within a monolithic service process2 Testing and deployment are more complicated4445 Moving responsibilities between services is more difficult6 It may involve communication between different teams rewriting the functionality in another language or fitting it into a different infrastructure2 However microservices can be deployed independently from the rest of the application while teams working on monoliths need to synchronize to deploy together39 Viewing the size of services as the primary structuring mechanism can lead to too many services when the alternative of internal modularization may lead to a simpler design46 This requires understanding the overall architecture of the applications and interdependencies between components47 Twophased commits are regarded as an antipattern in microservicesbased architectures resulting in a tighter coupling of all the participants within the transaction However the lack of this technology causes awkward dances which have to be implemented by all the transaction participants in order to maintain data consistency48 Development and support of many services are more challenging if they are built with different tools and technologies  this is especially a problem if engineers move between projects frequently49 The protocol typically used with microservices HTTP was designed for publicfacing services and as such is unsuitable for working internal microservices that often must be impeccably reliable50 While not specific to microservices the decomposition methodology often uses functional decomposition which does not handle changes in the requirements while still adding the complexity of services50 The very concept of microservice is misleading since there are only services There is no sound definition of when a service starts or stops being a microservice50 Data aggregation In order to have a full view of a working system it is required to extract data sets from the microservices repositories and aggregate them into a single schema For example to be able to create operational reports that are not possible using a single microservice repository Cognitive loadedit The architecture introduces additional complexity and new problems to deal with such as network latency message format design51 backupavailabilityconsistency BAC52 load balancing and fault tolerance45 All of these problems have to be addressed at scale The complexity of a monolithic application does not disappear if it is reimplemented as a set of microservices Some of the complexity gets translated into operational complexity53 Other places where the complexity manifests itself are increased network traffic and resulting in slower performance Also an application made up of any number of microservices has a larger number of interface points to access its respective ecosystem which increases the architectural complexity54 Various organizing principles such as hypermedia as the engine of application state HATEOAS interface and data model documentation captured via Swagger etc have been applied to reduce the impact of such additional complexity Technologiesedit Computer microservices can be implemented in different programming languages and might use different infrastructures Therefore the most important technology choices are the way microservices communicate with each other synchronous asynchronous UI integration and the protocols used for the communication RESTful HTTP messaging GraphQL  In a traditional system most technology choices like the programming language impact the whole system Therefore the approach to choosing technologies is quite different55 The Eclipse Foundation has published a specification for developing microservices Eclipse MicroProfile5657 Service meshedit See also Service mesh In a service mesh each service instance is paired with an instance of a reverse proxy server called a service proxy sidecar proxy or sidecar The service instance and sidecar proxy share a container and the containers are managed by a container orchestration tool such as Kubernetes Nomad Docker Swarm or DCOS The service proxies are responsible for communication with other service instances and can support capabilities such as service instance discovery load balancing authentication and authorization secure communications and others In a service mesh the service instances and their sidecar proxies are said to make up the data plane which includes not only data management but also request processing and response The service mesh also includes a control plane for managing the interaction between services mediated by their sidecar proxiescitation needed A comparison of platformsedit Implementing a microservice architecture is very difficult There are many concerns see table below that any microservice architecture needs to address Netflix developed a microservice framework to support their internal applications and then opensourced58 many portions of that framework Many of these tools have been popularized via the Spring Framework  they have been reimplemented as Springbased tools under the umbrella of the Spring Cloud59 project The table below shows a comparison of an implementing feature from the Kubernetes ecosystem with an equivalent from the Spring Cloud world60 One noteworthy aspect of the Spring Cloud ecosystem is that they are all Javabased technologies whereas Kubernetes is a polyglot runtime platform Microservices concern Spring Cloud  Netflix OSS Kubernetes Configuration management61 configuration for a microservice application needs to be externalized from the code and be retrievable via a simple service call Spring Config Server Netflix Archaius both support a Gitrepositorybased location for configuration Archaius supports data typing of configuration Kubernetes ConfigMaps exposes the configuration stored in etcd via services Kubernetes Secrets supports the servicebased secure deployment and usage of sensitive configuration information such as passwords certificates etc Service discovery maintain a list of service instances that are available for work within a microservice domain Spring Cloud Eureka allows clients to register to it maintains a heartbeat with registered clients and maps service names to hostnames for clients that lookup services by service name Kubernetes Services provide deploymenttime registration of instances of services that are internally available within the cluster Ingress is a mechanism whereby a service can be exposed to clients outside the cluster Load balancing The key to scaling a distributed system is being able to run more than one instance of a component Load has to be then distributed across those instances via a load balancer Spring Cloud Ribbon provides the ability for service clients to load balance across instances of the service Kubernetes Service provides the ability for the service to be loadbalanced across service instances This is not the equivalent of what Ribbon provides API gateway The granularity of APIs provided by microservices is often different than what a service client needs API Gateways implement facades and provide additional services like proxying and protocol translation and other management functions Spring Cloud Zuul provides configurationbased API facades Kubernetes Service and Ingress resources Istio Ambassador are solutions that provide both northsouth traffic into and out of data center as well as eastwest traffic across data centers or clouds or regions API gateway functions Zuul can also be implemented along with Kubernetes providing configuration at individual service level Security concerns Many security concerns are pushed to the API gateway implementation With distributed microservice applications it makes sense to not reinvent the security wheel and allow for policy definition and implementation in components that are shared by all services Spring Cloud Security addresses many security concerns through Spring Cloud Zuul The Kubernetes ecosystem provides service meshes like Istio which are capable of providing security through their API gateway mechanisms Centralized logging It is important to have a centralized log gathering and analysis infrastructure to manage a plethora of services  many of which are operating in a distributed fashion ELK Stack Elasticsearch Logstash Kibana EFK Stack Elasticsearch Fluentd Kibana Centralized metrics A centralized area where the health and performance of the individual services and overall system can be monitored is essential to proper operations Spring Spectator  Atlas Heapster Prometheus  Grafana Distributed tracing Perprocess logging and metric monitoring have their place but neither can reconstruct the complex paths that transactions take as they propagate across a distributed system Distributed tracing is an essential tool for a microservices platform Spring Cloud Sleuth Hawkular Jaeger Resilience and fault tolerance Distributed systems must be capable of autorouting around failures and be capable of routing requests to the service instance that will provide an optimum response Spring Hystrix Turbine  Ribbon Health check service meshes example Istio62 Autoscaling and selfhealing Distributed systems respond to higher load by scaling horizontally the platform must detect and autorespond to such conditions Furthermore the system needs to detect failures and attempt autorestarts without operator input  Health check selfhealing and autoscaling Packaging deployment and scheduling Largescale systems require robust package management and deployment systems to manage rolling or bluegreen deployments and rollbacks if necessary A scheduler helps determine which particular execution node a new set of services can be deployed to based on current conditions Spring Boot Apache Maven The Spring Cloud system does not have a true scheduler Docker Rkt Kubernetes Scheduler  Deployment Helm63 Job management scheduled computations disconnected from any individual user requests Spring Batch Kubernetes Jobs and Scheduled Jobs Singleton application limit a specific service to run as the only instance of that service within the entire system Spring Cloud Cluster Kubernetes Pods See alsoedit Conways law Crosscutting concern Data mesh a domainoriented data architecture DevOps Fallacies of distributed computing GraphQL gRPC Representational state transfer REST Serviceoriented architecture SOA Microfrontend Unix philosophy Selfcontained system software Serverless computing Weboriented architecture WOA Referencesedit  Microservice architectures more than the sum of their parts IONOS Digitalguide 2 March 2020 Retrieved 20220329  a b c d Martin Fowler Microservices Archived from the original on 14 February 2018  Newman Sam 20150220 Building Microservices OReilly Media ISBN 9781491950357  Wolff Eberhard 20161012 Microservices Flexible Software Architectures AddisonWesley ISBN 9780134602417  a b c Pautasso Cesare 2017 Microservices in Practice Part 1 Reality Check and Service Design IEEE Software 34 1 9198 doi101109MS201724 S2CID 5635705  a b c d Chen Lianping 2018 Microservices Architecting for Continuous Delivery and DevOps The IEEE International Conference on Software Architecture ICSA 2018 IEEE  a b Nadareishvili I Mitra R McLarty M Amundsen M Microservice Architecture Aligning Principles Practices and Culture OReilly 2016  Backends For Frontends Pattern Microsoft Azure Cloud Design Patterns Microsoft  Lucas Krause Microservices Patterns and Applications ASIN B00VJ3NP4A  Ford N Richards M Sadalage P Dehghani Z Software Architecture The Hard Parts Thoughtworks Retrieved 20230120  CICD for microservices architectures Azure Architecture Center Microsoft Retrieved 9 January 2018  Josuttis N 2007 SOA in Practice Sebastopol CA US OReilly ISBN 9780596529550  Martin Fowler 28 August 2014 Microservice Prerequisites Archived from the original on Oct 3 2023  Richardson Chris November 2018 Microservice Patterns Manning Publications 141 Scale cube and microservices ISBN 9781617294549  Mendonca Nabor C Jamshidi Pooyan Garlan David Pahl Claus 20191016 Developing SelfAdaptive Microservice Systems Challenges and Directions PDF IEEE Software 38 2 7079 arXiv191007660 doi101109MS20192955937 S2CID 204744007 Archived PDF from the original on Feb 6 2023  The Grandfather of Microservices Fred George That Tech Show May 11 2021 Archived from the original on Oct 3 2023  a b Rodgers Peter Feb 15 2005 ServiceOriented Development on NetKernel Patterns Processes  Products to Reduce System Complexity CloudComputingExpo SYSCON Media Archived from the original on 20 May 2018 Retrieved 19 August 2015  Russell Perry Rodgers Peter Sellman Royston 2004 Architecture and Design of an XML Application Platform HP Technical Reports p 62 Retrieved 20 August 2015  Löwy Juval 2007 Programming WCF Services 1st ed OReilly Media pp 543553 ISBN 9780596526993  Juval Löwy Every Class a WCF Service Channel9 ARCastTV October 2007  Juval Löwy Every Class As a Service Microsoft TechEd Conference May 2009 SOA206 Archived from the original on 2010  Löwy Juval 2007 Programming WCF Services 1st ed OReilly Media pp 4851 ISBN 9780596526993  Löwy Juval 2010 Programming WCF Services 3rd ed OReilly Media pp 7475 ISBN 9780596805487  Dragoni Nicola Giallorenzo Saverio Lafuente Alberto Lluch Mazzara Manuel Montesi Fabrizio Mustafin Ruslan Safina Larisa 2017 Microservices Yesterday Today and Tomorrow Present and Ulterior Software Engineering pp 195216 arXiv160604036 doi1010079783319674254_12 ISBN 9783319674247 S2CID 14612986  James Lewis Micro services  Java the Unix Way  Fred George 20130320 MicroService Architecture A Personal Journey of Discovery  Farrow Rik 2012 Netflix heads into the clouds PDF  James Lewis and Martin Fowler Microservices  Continuous Deployment Strategies javacodegeekscom 10 December 2014 Retrieved 28 December 2016  Research Verified Market Cloud Microservices Market 2020 Trends Market Share Industry Size Opportunities Analysis and Forecast by 2026  Instant Tech Market News Retrieved 20200218  O Zimmermann DomainSpecific Service Decomposition with Microservice API Patterns Microservices 2019 httpswwwconfmicroservices2019slideskeynotesZimmermanpdf  Amazon SOA mandate 13 October 2011  Vaughn Vernon 2016 DomainDriven Design Distilled AddisonWesley Professional ISBN 9780134434421  Yousif Mazin 2016 Microservices IEEE Cloud Computing 3 5 45 doi101109MCC2016101  Dragoni Nicola Lanese Ivan Larsen Stephan Thordal Mazzara Manuel Mustafin Ruslan Safina Larisa 2017 Microservices How to Make Your Application Scale PDF Perspectives of System Informatics Lecture Notes in Computer Science Vol 10742 pp 95104 arXiv170207149 Bibcode2017arXiv170207149D doi1010079783319743134_8 ISBN 9783319743127 S2CID 1643730  Newman Sam 2015 Building Microservices OReilly ISBN 9781491950357  Wolff Eberhard 2016 Microservices Flexible Software Architecture Addison Wesley ISBN 9780134602417  Knoche Holger Hasselbring Wilhelm 2019 Drivers and Barriers for Microservice Adoption  A Survey among Professionals in Germany Enterprise Modelling and Information Systems Architectures 14 11351135 doi1018417emisa141  a b Taibi Davide Lenarduzzi Valentina Pahl Claus Janes Andrea 2017 Microservices in agile software development a workshopbased study into issues advantages and disadvantages Proceedings of the XP2017 Scientific Workshops doi10114531204593120483 S2CID 28134110  Richardson Chris Microservice architecture pattern microservicesio Retrieved 20170319  Chen Lianping Ali Babar Muhammad 2014 Towards an EvidenceBased Understanding of Emergence of Architecture through Continuous Refactoring in Agile Software Development Proceedings Working IEEEIFIP Conference on Software Architecture 2014 WICSA 2014 The 11th Working IEEEIFIP Conference on Software ArchitectureWICSA 2014 IEEE doi101109WICSA201445  Balalaie Armin Heydarnoori Abbas Jamshidi Pooyan May 2016 Microservices Architecture Enables DevOps Migration to a CloudNative Architecture PDF IEEE Software 33 3 4252 doi101109ms201664 hdl10044140557 ISSN 07407459 S2CID 18802650  Stenberg Jan 11 August 2014 Experiences from Failing with Microservices  Calandra Mariano 7 April 2021 Why unit testing is not enough when it comes to microservices  a b Developing Microservices for PaaS with Spring and Cloud Foundry  Tilkov Stefan 17 November 2014 How small should your microservice be Innoq Retrieved 4 January 2017  Lanza Michele Ducasse Stéphane 2002 Understanding Software Evolution using a Combination of Software Visualization and Software Metrics PDF In Proceedings of LMO 2002 Langages et Modèles à Objets 135149  Richardson Chris November 2018 Microservice Patterns Chapter 4 Managing transactions with sagas Manning Publications ISBN 9781617294549cite book CS1 maint location link   YouTube YouTube  a b c Löwy Juval 2019 Righting Software 1st ed AddisonWesley Professional pp 7375 ISBN 9780136524038  Pautasso Cesare 2017 Microservices in Practice Part 2 Service Integration and Sustainability IEEE Software 34 2 97104 doi101109MS201756 S2CID 30256045  Pautasso Cesare 2018 Consistent Disaster Recovery for Microservices the BAC Theorem IEEE Cloud Computing 5 1 4959 doi101109MCC2018011791714 S2CID 4560021  Fowler Martin Microservice TradeOffs  BRASS Building Resource Adaptive Software Systems US Government DARPA April 7 2015 Access to system components and the interfaces between clients and their applications however are mediated via a number of often unrelated mechanisms including informally documented application programming interfaces APIs idiosyncratic foreign function interfaces complex illunderstood model definitions or ad hoc data formats These mechanisms usually provide only partial and incomplete understanding of the semantics of the components themselves In the presence of such complexity it is not surprising that applications typically bakein many assumptions about the expected behavior of the ecosystem they interact with  Wolff Eberhard 20180415 Microservices  A Practical Guide CreateSpace Independent Publishing Platform ISBN 9781717075901  Swart Stephanie 14 December 2016 Eclipse MicroProfile projectseclipseorg  MicroProfile MicroProfile Retrieved 20210411  Netflix OSS Git Hub  Cloud Spring  Spring Cloud for Microservices Compared to Kubernetes Developers Red hat 20161209  Somashekar Gagan Gandhi Anshul 20210426 Towards Optimal Configuration of Microservices Proceedings of the 1st Workshop on Machine Learning and Systems EuroMLSys 21 Online United Kingdom Association for Computing Machinery pp 714 doi10114534379843458828  Managing microservices with the Istio service mesh Kubernetes May 2017  The Kubernetes Package Manager Helm Further readingedit Special theme issue on microservices IEEE Software 353 MayJune 2018 httpsieeexploreieeeorgxpltocresultjspisnumber8354413 I Nadareishvili et al Microservices Architecture  Aligning Principles Practices and Culture OReilly 2016 ISBN 9781491959794 S Newman Building Microservices  Designing FineGrained Systems OReilly 2015 ISBN 9781491950357 Wijesuriya Viraj Brian 20160829 Microservice Architecture Lecture Notes  University of Colombo School of Computing Sri Lanka Christudas Binildas June 27 2019 Practical Microservices Architectural Patterns EventBased Java Microservices with Spring Boot and Spring Cloud Apress ISBN 9781484245002 Retrieved from httpsenwikipediaorgwindexphptitleMicroservicesoldid1190046216 Categories Architectural pattern computer scienceServiceoriented business computingHidden categories CS1 maint locationArticles with short descriptionShort description is different from WikidataArticles lacking reliable references from October 2018All articles lacking reliable referencesAll articles with unsourced statementsArticles with unsourced statements from July 2022 Some of this articles listed sources may not be reliable Please help this article by looking for better more reliable sources Unreliable citations may be challenged or deleted October 2018 Learn how and when to remove this template message 0 Some of this articles listed sources may not be reliable Please help this article by looking for better more reliable sources Unreliable citations may be challenged or deleted October 2018 Learn how and when to remove this template message Microservices concern Spring Cloud  Netflix OSS Kubernetes 0 Microservices concern Spring Cloud  Netflix OSS Kubernetes 1 Configuration management61 configuration for a microservice application needs to be externalized from the code and be retrievable via a simple service call Spring Config Server Netflix Archaius both support a Gitrepositorybased location for configuration Archaius supports data typing of configuration Kubernetes ConfigMaps exposes the configuration stored in etcd via services Kubernetes Secrets supports the servicebased secure deployment and usage of sensitive configuration information such as passwords certificates etc 2 Service discovery maintain a list of service instances that are available for work within a microservice domain Spring Cloud Eureka allows clients to register to it maintains a heartbeat with registered clients and maps service names to hostnames for clients that lookup services by service name Kubernetes Services provide deploymenttime registration of instances of services that are internally available within the cluster Ingress is a mechanism whereby a service can be exposed to clients outside the cluster 3 Load balancing The key to scaling a distributed system is being able to run more than one instance of a component Load has to be then distributed across those instances via a load balancer Spring Cloud Ribbon provides the ability for service clients to load balance across instances of the service Kubernetes Service provides the ability for the service to be loadbalanced across service instances This is not the equivalent of what Ribbon provides 4 API gateway The granularity of APIs provided by microservices is often different than what a service client needs API Gateways implement facades and provide additional services like proxying and protocol translation and other management functions Spring Cloud Zuul provides configurationbased API facades Kubernetes Service and Ingress resources Istio Ambassador are solutions that provide both northsouth traffic into and out of data center as well as eastwest traffic across data centers or clouds or regions API gateway functions Zuul can also be implemented along with Kubernetes providing configuration at individual service level 5 Security concerns Many security concerns are pushed to the API gateway implementation With distributed microservice applications it makes sense to not reinvent the security wheel and allow for policy definition and implementation in components that are shared by all services Spring Cloud Security addresses many security concerns through Spring Cloud Zuul The Kubernetes ecosystem provides service meshes like Istio which are capable of providing security through their API gateway mechanisms 6 Centralized logging It is important to have a centralized log gathering and analysis infrastructure to manage a plethora of services  many of which are operating in a distributed fashion ELK Stack Elasticsearch Logstash Kibana EFK Stack Elasticsearch Fluentd Kibana 7 Centralized metrics A centralized area where the health and performance of the individual services and overall system can be monitored is essential to proper operations Spring Spectator  Atlas Heapster Prometheus  Grafana 8 Distributed tracing Perprocess logging and metric monitoring have their place but neither can reconstruct the complex paths that transactions take as they propagate across a distributed system Distributed tracing is an essential tool for a microservices platform Spring Cloud Sleuth Hawkular Jaeger 9 Resilience and fault tolerance Distributed systems must be capable of autorouting around failures and be capable of routing requests to the service instance that will provide an optimum response Spring Hystrix Turbine  Ribbon Health check service meshes example Istio62 10 Autoscaling and selfhealing Distributed systems respond to higher load by scaling horizontally the platform must detect and autorespond to such conditions Furthermore the system needs to detect failures and attempt autorestarts without operator input  Health check selfhealing and autoscaling 11 Packaging deployment and scheduling Largescale systems require robust package management and deployment systems to manage rolling or bluegreen deployments and rollbacks if necessary A scheduler helps determine which particular execution node a new set of services can be deployed to based on current conditions Spring Boot Apache Maven The Spring Cloud system does not have a true scheduler Docker Rkt Kubernetes Scheduler  Deployment Helm63 12 Job management scheduled computations disconnected from any individual user requests Spring Batch Kubernetes Jobs and Scheduled Jobs 13 Singleton application limit a specific service to run as the only instance of that service within the entire system Spring Cloud Cluster Kubernetes Pods1 Developing SelfAdaptive Microservice Systems Challenges and Directions Nabor C Mendonc a Pooyan Jamshidi David Garlan and Claus Pahl Abstract A selfadaptive system can dynamically monitor and adapt its behavior to preserve or enhance its quality attributes under uncertain operating conditions This article identiﬁes key challenges for the development of microservice applications as selfadaptive systems using a cloudbased intelligent video surveillance application as a motivating example It also suggests potential new directions for addressing most of the identiﬁed challenges by leveraging existing microservice practices and technologies Index Terms selfadaptive systems microservices DevOps continuous delivery F 1 I NTRODUCTION A selfadaptive system can monitor its behavior and change its conﬁguration or architecture at run time to preserve or enhance its quality attributes eg performance reliability and security under uncertain operating conditions eg varying workloads errors and security threats 1 Despite signiﬁcant progress in developing selfadaptive systems in recent years only a handful of techniques such as auto mated server management cloud elasticity and automated data center management have thus far found their way to industrial applications 2 For example Kubernetes1a modern container orchestration platform that is increasingly being used to deploy and manage microservice applications in the cloud 3 only provides autoscaling ie the ability to automatically change the number of instances of a service and selfhealing ie the ability to automatically restart failed service instances as part of its native selfadaptation capabilities The popularity of microservices in industry has naturally sparked the interest of the research community However most existing research on microservices focuses on general architectural principles and migration guidelines eg 4 Only a few works have addressed the speciﬁc challenges of developing microservice applications as selfadaptive sys tems nevertheless even those works tend to be rather nar row in scope offering only limited forms of adaptation eg selfhealing 5 and runtime placement adaptation 6 We believe the uptake of microservices and their en abling practices and technologies by industry brings a N C Mendon ca is with the Post Graduate Program in Applied Informat ics University of Fortaleza Fortaleza CE Brazil Email naboruniforbr P  Jamshidi is with the Computer Science and Engineering Department University of South Carolina Columbia SC USA Email pjamshidcsescedu D Garlan is with the School of Computer Science Carnegie Mellon University Pittsburgh P A USA Email garlancscmuedu C Pahl is with the Faculty of Computer Science Free University of Bozen Bolzano BozenBolzano Italy Email cpahlunibzit 1 httpskubernetesiounique opportunity to narrow the gap between the state oftheart and the stateofthepractice in selfadaptive sys tems and that both selfadaptive systems and microservice communities have much to gain from each other On the one hand recent progress in selfadaptive sys tems offers a controloriented perspective that leverages a large body of theoretical and practical results to enhance microservice quality attributes using techniques such as planners eg to select the best possible adaptation strategy for each microservice machine learning eg to learn new adaptation strategies from past adaptation results reason ing under uncertainty eg to cope with noisy monitoring data and multiobjective optimization eg to cater to mul tiple possibly conﬂicting microservice requirements 7 On the other hand software characteristics such as independent and frequent deployment the need for a high degree of automation and complex runtime architectures 3 make microservices a fertile ground to foster further research and development on selfadaptive systems In this paper we take a closer look into the interplay between selfadaptive systems and microservices in order to identify key challenges for the development of microservice applications as selfadaptive systems Our contributions are as follows 1 we describe a cloudbased intelligent video surveillance application as an example of a selfadaptive microservice system 2 we identify and illustrate in the context of this example application several challenges for microservice development delivery and operations from multiple selfadaptation perspectives and 3 we discuss potential new directions for addressing most of the key chal lenges identiﬁed for developing selfadaptive microservice systems by leveraging existing microservice practices and technologies 2 M ICROSERVICES Microservices constitute an emerging architectural style that builds on the wellestablished concept of modularization but emphasizes technical boundaries ie different address and execution spaces between software components 3 Each moduleeach microserviceis developed around a single business capability that offers access to its internalarXiv191007660v2 csSE 15 Nov 20192 Fig 1 a Microservice architecture for the edgecloud intelligent video surveillance application and b three continuous delivery pipelines for the applications face detection video processing and face recognition microservices respectively adapted from 8 logic and data through a welldeﬁned network interface Due to their relative simplicity and small size microservices can be released often and adapted to different produc tion environments from cloud data centers to resource constrained devices eg IoTwithout much development effort This has a signiﬁcant impact on improving software agility because each microservice becomes an independent unit of development deployment versioning scaling and management 3 Microservices are considered to be an enabler for emerg ing DevOps practices such as continuous integration CI and continuous delivery CD which aim to signiﬁcantly decrease the time between changing a system and trans ferring that change to the production environment 9 To achieve this level of agility microservices are typically pack aged in lightweight containers eg Docker2 and deployed and managed using automated container orchestration tools eg Kubernetes In particular the use of fully automated CD tools eg Spinnaker3 enables the creation of inde pendent CD pipelines for each microservice Having mul tiple CD pipelines running in parallel allows microservice changes to be rapidly delivered into production since only the affected microservice needs to be built and tested 8 2 httpswwwdockercom 3 httpswwwspinnakerio3 A S ELFADAPTIVE MICROSERVICE SYSTEM We consider an edgecloud intelligent video surveillance application as an example of a selfadaptive microservice system The applications goal is to alert users about the presence and possibly the identiﬁcation of humans in a certain location via realtime analysis of video frames cap tured by one or more security cameras Its architecture inspired by one of Amazons machine learning ML sample solutions4is composed of several business platform  and infrastructure services as shown in Figure 1a Each security camera is deployed along with a ML based face detection edge service1This service is a less accurate yet more energy efﬁcient version of a MLbased face recognition service deployed in the cloud The role of the face detection edge service is to select relevant video frames ie frames with detected human faces to be asynchronously transmitted to a video processing service in the cloud using a cloudprovided streaming service2The streaming service offers a more scalable and reliable solution over the basic HTTP Streaming protocol The video processing service in the cloud analyzes the received video frames3and passes them as invocation parameters to the face recognition 4 httpsawsamazoncomblogsmachinelearning createaserverlesssolutionforvideoframeanalysisandalertingMENDONC  A et al  DEVELOPING SELFADAPTIVE MICROSERVICE SYSTEMS 3 service4in an attempt to recognize any person that might be visible in them If the face recognition service reports a match the video processing service sends out an SMS mes sage informing the application users mobile phones about the match using a notiﬁcation service56The video processing service then saves the analyzed video frames along with any relevant information regarding the video recording eg date camera ID and contents eg names of the recognized persons match accuracy in a storage service7Application users can use a Webbased User Interface Web UI to search for and play back any analyzed video segment stored in the cloud This is done by invoking a video playback edge service deployed somewhere closer to the users physical location8The video playback edge service in turn uses the streaming service to communicate asynchronously with avideo playback service in the cloud9 The video surveillance application also relies on sev eral infrastructure services  such as a discovery service an authentication service a monitoring service and a container orchestration service10To avoid cluttering the depiction of the video surveillance application architecture in Figure 1a omits interactions between business services and infrastruc ture services Following typical microservice practices each service of the video surveillance application is delivered in production using its own independent CD pipeline Figure 1b depicts three possible CD pipelines for the face detection video processing and face recognition services Note how each pipeline goes through different environments from coding to production which represent the multiple development stages eg build testing canary release and ﬁnally full production of each service 9 We envision multiple selfadaptation scenarios for this example application including the following The video processing service may need to dynam ically change its number of deployed instances in response to load variations The face recognition service may need to dynami cally change its container image eg to switch to a less accurate version under extreme load conditions The video playback service may need to dynamically change its quality attributes eg its frame rate in order to cope with latency ﬂuctuations and The CD pipeline for the video playback edge service may need to dynamically adjust that services testing parameters eg to expedite the testing of its self healing capabilities during staging Enacting all of the foregoing different scenarios may bring up a number of challenges for microsevice application developers which we discuss next 4 C HALLENGES We identify the main challenges facing the development of selfadaptive microservice systems from four perspectives design space control loop deployment continuous delivery  and testing 41 Design Space Designing selfadaptive systems involves making design decisions about the environment while it is being observed and about the system itself and then selecting adaptation mechanisms that are thereafter enacted 2 In the context of a microservice application the design space for making self adaptation decisions is even more complex due to the large number of runtime components and their independent and highly dynamic nature 3 Thus a ﬁrst challenge is as follows C1 How to determine monitoring and adaptation mechanisms to face the diversity of microservices qual ity attributes The case of the example video surveillance application illustrates this challenge as the quality requirements and adaptation needs of the ML face recognition service which handles only individual video frames and is invoked syn chronously from within the cloud might be quite differ ent from those of the video playback edge service which handles the entire video segments and is invoked asyn chronously from outside the cloud In particular the former would not have to monitor and adapt its communication parameters eg the request rate at run time in contrast this would be a critical requirement for the latter An additional challenge is the following C2 How to identify and resolve potential conﬂicts between the quality requirements of individual microser vices and those of the overall application when deﬁning their selfadaptive behaviors For instance an important quality attribute of a face recognition service which typically works by comparing ex tracted facial features from a given image with facial images within a database is its recognition accuracy However high accuracy in this kind of ML service inevitably implies high processing and storage costs which might conﬂict with the applications overall cost constraints The following is yet another challenge in this context C3 How to reconcile the adaptation needs of individual microservices and the overall application with the self adaptation capabilities offered by the underlying infras tructure management platform By way of illustration while Kubernetes autoscaling capabilities could be useful to improve the response time of all cloudbased services deployed as part of the video surveillance application current Software Reliability En gineering SRE practices indicate that autoscaling alone might not be enough to make strong guarantees about a services performance especially under high load5In addition Kubernetes does not yet support monitoring and management of service communication characteristics at the application layer ie Layer 7 such as by establishing per service rate limits and bandwidth quotas which could be useful to help manage the performance and communication overhead of the video playback service 5 httpslandinggooglecomsre4 Finally the more recent FunctionasaService FaaS and serverless computing cloud models6in which ﬁnedgrained services are deployed as serverless functions that are trans parently managed and scaled by the cloud platform and charged on a per usage basis poses an additional challenge C4 How to develop and manage selfadaptive mi croservice systems in hybrid deployment environments that are composed of both serverful and serverless ser vices A case in point is encountered because some of the video surveillance services eg video processing could be re implemented and redeployed as serverless services using an FaaS cloud platform such as AWS Lambda7In that case application developers would not only have to reconcile the adaptation requirements of both serverful and serverless services with the selfadaptation capabilities of their respec tive management platforms but also to rethink their entire DevOps and business strategies in order to account for the signiﬁcant technical and economical differences between those two deployment models 10 42 Control Loop Deployment Control loops are crucial elements necessary to realize the runtime adaptation of software systems A typical self adaptation control loop consists of four main activities namely Monitor Analyze Plan and Execute which share a common Knowledge base that are usually referred to as the MAPEK reference model 1 Control loops can be designed and deployed according to different control strategies from a single centralized control component managing the whole system to multiple control components managing different parts of the system and organized in a hierarchi cal or fully decentralized manner 2 In the context of a microservice application where each microservice is inde pendently developed deployed and managed at run time selecting the appropriate control strategies poses additional challenges The following constitutes an initial challenge in this context C5 How to determine the level of distribution visibility  and granularity necessary for deploying a microservice applications control components We see these three deployment dimensions as forming a control loops deployment space for a microservice appli cation The distribution dimension concerns the physical allocation of control loop components to infrastructure re sources The visibility dimension in turn concerns whether the control loop components should be deployed at the application level ie fully visible to developers or at the infrastructure level ie only partially visible to developers Finally the granularity dimension concerns whether control loop components should be deployed as a single monolithic 6 Mike Roberts May 22 2018 Serverless Architecture  Martin Fowlercom Retrieved November 13 2019 from httpsmartinfowler comarticlesserverlesshtml 7 httpsawsamazoncomlambdaservice or decomposed into a collection of independently developed and managed microservices Developing and deploying selfadaptive microservice systems with those three dimensions in mind could help to establish fundamental tradeoffs with respect to multiple quality attributes An example is deploying control loops for each of the video surveillance application services in a fully decentralized fashion which would in turn increase their overall reliability and scalability Nevertheless this strategy would also make it harder to enforce applicationwide adap tation constraints as this would require each control loop to coordinate its actions with the other control loops thereby reducing their autonomy Similarly deploying control loops at the infrastructure level would help to promote a better separation between business and management services at run time thus facilitating their reuse Despite this beneﬁt this strategy would also make control loops much harder to customize for speciﬁc adaptation needs eg managing the expected accuracy of ML services as most control loops deployed at the infrastructure level support only a restricted set of adaptation models and mechanisms 11 Finally deploying control loop components as monolithic services would greatly simplify their packaging and management at run time However this strategy would also force all control components to share the same version and release rate thus severely compromising their continuous improvement to satisfy evolving adaptation needs Another challenge related to control loop deployment is as follows C6 How to reconcile the selected control loop deploy ment strategies with those supported by the underlying infrastructure management platform As an example in Kubernetes selfhealing and autoscal ing controllers are deployed in a mostly centralized manner as part of its master node Therefore if each microservice is to be managed by a fully independent control loop there should be multiple instances of such types of controllers deployed one for each microservice In addition those individual controllers might still have to coordinate their actions at the application level in order to resolve potential requirement conﬂicts as discussed in Section 41 which coordination Kubernetes currently does not support 43 Continuous Delivery We identify three main adaptation scenarios concerning the use of CD practices and tools in the context of a self adaptive microservice system The ﬁrst scenario is the run time adaptation of the CD pipelines themselves In that regard the following is a key challenge C7 How to best determine the appropriate monitoring and adaptation mechanisms that will dynamically adjust the transition events and conditions across the stages of each microservice CD pipeline An exemplar of this challenge is as follows To create a CD pipeline developers typically need to deﬁne the events and conditions under which each stage of the pipeline can be executed This is usually done by manually expressingMENDONC  A et al  DEVELOPING SELFADAPTIVE MICROSERVICE SYSTEMS 5 the trigger events and test requirements of each stage so that the target application can be automatically progressed from one stage to the next In this scenario a selfadaptive pipeline would have to be able to monitor the application behavior at each stage so as to dynamically adjust its trigger events andor test requirements to cope with uncertainties during its execution eg the application repeatedly failing to meet the requirements of one particular stage due to the necessary data or infrastructure resources being unavail able Yet another challenge related to this scenario is as fol lows C8 How to reconcile the adaptation needs of each microservice CD pipeline with the selfadaptation capa bilities offered by the underlying infrastructure and CD management platforms Kubernetes offers a rollout operation that can be used to illustrate this challenge A rollout operation automatically deploys a new service version without having to take the current version down This operation could be useful to implement a canary release pipeline for each of the video surveillance services A canary release pipeline is respon sible for automatically deploying a new service version to production in parallel with the most recent stable version of that service so as to gradually replace instances of the stable service version with instances of the new canary version based on a given set of testing criteria 9 However this solution would still require service developers to manually invoke Kubernetes rollout operation every time theres a new service version to be released Alternatively developers could beneﬁt from a fullﬂedged CD management tool eg Spinnaker to fully automate the execution of that canary release pipeline But even in that case developers would still need to provide the CD management tool with the exact conditions and their trigger events required to deploy the canary release into production The second scenario is the adaptation of the microser vices own adaptation requirements In this scenario a key challenge faced is the following demand C9 How to dynamically adjust the adaptation require ments of each microservice according to the needs of each CD stage As an example to streamline the testing of the autoscal ing capabilities of the video processing service the CD plat form could automatically adjust that services performance requirements during staging so as to trigger its autoscaling features earlier and more often than during normal produc tion Finally the third scenario concerns treating the self adaptation mechanisms of a selfadaptive microservice sys tem as ﬁrstclass DevOps entities In that respect a further challenge is addressing the following issue C10 How to establish an effective strategy for continu ously delivering selfadaptation mechanisms in produc tion in the context of a selfadaptive microservice systemBy way of example each selfadaptation mechanism used by the video surveillance application eg autoscal ing and selfhealing could be independently tested and deployed in its own CD pipeline Such a strategy would allow a more systematic reuse of selfadaptation models and mechanisms across business services albeit at the expense of having a more complex CD process 44 Testing Conducting extensive validation tests with microservices before each deployment is not feasible due to the high frequency of their releases Instead microservice quality assurance is often compensated or even replaced by ﬁne grained monitoring techniques in production environments exposed to real workloads In this way failures can be monitored and quickly corrected by pushing new releases into production 8 The following is a key challenge in this context C11 How to determine testing models and mechanisms to assess the fundamental quality attributes of each microservice and of the overall application from a self adaptation perspective An example of this challenge in the context of the video surveillance application is that developers may need to select different testing mechanisms to assess the self adaptation features of different microservices eg image benchmarking and load generation for testing the autoscal ing features of the face recognition service and fault injection for testing the selfhealing features of the video playback service In addition the need for those testing mechanisms may vary across CD stages and pipelines eg autoscaling tests of the face recognition service may be run only during staging while more critical selfhealing tests of the video playback service may be run all the way to production An additional challenge related to testing is the follow ing C12 How to integrate the systematic testing of microservices including their selfadaptive behaviors within the context of existing CD practices The use of fault injection mechanisms to test a self adaptive systems resiliency in production illustrates this challenge For example the results of fault injection tests created to assess the resiliency of the selfhealing features of the video playback service could be used by the underlying CD platform as one of the criteria for deciding whether the latest version of that service is ready to be promoted from canary release to normal production 5 N EWDIRECTIONS We now suggest promising new directions to address most of the challenges identiﬁed in the previous section 51 New Adaptation Mechanisms Regarding challenges C1 and C3 a practical way of im plementing novel selfadaptation solutions tailored for the6 context of microservice applications would be by extend ing the management API provided by current container orchestration tools like Kubernetes To illustrate one could easily build on the rollout and rollback features provided by Kubernetes to develop a selfadaptive service fallback mech anism that could be customized to meet different adaptation requirements The basic idea is to create multiple fallback versions for each microservice eg a low ﬁdelity version or a high accuracy version and pack them as separate Docker im ages The selfadaptive fallback mechanism could then be conﬁgured to use Kubernetes to automatically update the current image of a given microservice to one of its fallback images under certain system or environment conditions eg update the face recognition service to its high accuracy image whenever the system is underutilized and rollback that service to its original image whenever the load reaches a certain threshold Similarly one could build on the variety of communicationrelated monitoring and management features provided by the use of socalled service mesh tools 3 to create novel connectororiented selfadaptation mechanisms This is the case for example of using the security management features of a service mesh tool like Istio8to provide a selfprotection mechanism that will automatically strengthen the encryption parameters of the communication protocols being used by the video surveillance application services under a security attack without the need to change or restart any service A service mesh could also be useful to dynamically adjust the retry and circuitbreaking parameters 3 used by all clients of an overloaded service so as to reduce the services incoming trafﬁc and thus prevent cascading failures from propagating throughout the system This feature could be particularly useful for missioncritical selfadaptive systems Finally speciﬁcally regarding challenge C2 application developers may rely on recent microservice orchestration languages eg Jolie9 as the means for deﬁning and enact ing applicationaware adaptations While this may provide a possible solution its adoption may be seen as counterin tuitive with respect to some wellestablished microservice principles such as the autonomy of each microservice team to choose the implementation technologies that best ﬁt their needs and expertise 3 52 New Control Loop Deployment Structures From a control loop deployment perspective as discussed in the context of challenges C5 and C6 a microservice systems control components should ideally be deployed in a fully decentralized fashion with each microservice being managed by its own local controller The downside of this solution is that it makes it harder for the local controllers to monitor and manage applicationwide quality attributes Although having a centralized controller dedicated to man aging applicationlevel quality concerns would be a more straightforward solution for this issue its use would create a single point of failure and ultimately could compromise 8 httpsistioio 9 httpswwwjolielangorgthe applications overall availability In practice microser vice developers may choose from a variety of intermediate solutions between those two extremes eg by logically grouping services according to their business andor quality afﬁnity and then having those services being collectively managed by independent yet applicationaware group con trollers organized in a hierarchical or fully decentralized structure Another important issue is the decision about whether microservice developers should have any responsibility in developing and managing control components as sug gested above Having control components explicit in the design and development of a selfadaptive microservice sys tem may contribute to further increase the systems overall complexity In addition this decision could compromise the delivery autonomy of individual services since service de velopers would have to negotiate before every new release in case their code bases share the same control components We advocate the adoption of a middle ground solution having all control components developed tested and re leased as part of the underlying infrastructure management platform yet still exposed to service developers during the later phases of their services CD pipeline 11 53 New Continuous Delivery Strategies The question of how to integrate selfadaptation capabilities with DevOps discussed in the context of challenges C7C9 deserves special attention from selfadaptive microservice system developers Here we discuss two possible CD strate gies and their tradeoffs One ﬁrst strategy is to create a new dedicated CD pipeline to deliver into production all selfadaptation com ponents used by the application Having a dedicated self adaptation pipeline would have the advantage of running it in parallel with the other business pipelines and thus preserve their autonomy On the other hand this solution would prevent business developers from directly improving the selfadaptation components used by their services as this would require negotiating with the developers respon sible for the selfadaptation pipeline Moreover this solution would push critical integration tests to the end of each business pipeline as business developers would not have immediate access to the latest version of their required self adaptation components A second strategy is to have separate business and self adaptation pipelines during the commit and build stages but have the selfadaptation pipeline integrated with the other business pipelines as soon as they enter the testing stage In this case selfadaptation components would still be designed and developed by a separate team but their test ing and deployment would be the responsibility of business developers as part of their business service pipelines This would have the beneﬁt of avoiding delaying integration tests in the business pipelines However as a side effect it could unnecessarily bloat all business pipelines with business developers now being responsible for testing both business and selfadaptation components Those two strategies are but a small sample of the spectrum of CD alternatives developers of selfadaptive microservice systems can explore In that direction extend ing emerging ModelDriven Engineering MDE tools forMENDONC  A et al  DEVELOPING SELFADAPTIVE MICROSERVICE SYSTEMS 7 microservices eg AjiL10 with CD support could be a key enabler to automate the integration of selfadaptation capabilities and DevOps 54 New Testing Approaches A number of recent testing approaches have been proposed speciﬁcally for microservices both by industry eg integra tion testing in production11 and by academia eg trace based error prediction and fault localization 12 A natural new direction here related to challenges C11 and C12 is to systematically integrate those emerging testing approaches within the context of a fully automated selfadaptive CD pipeline In this way the results of both online and ofﬂine tests could be incorporated as part of the set of dynamic events and conditions used by the underlying CD platform to automatically test a given microservice release across multiple pipeline stages Yet another promising direction in this context is apply ingchaos engineering 13 principles to assess the resiliency of a selfadaptive microservice system 14 In that regard one could rely on such a tool as kubemonkey12which can be used to randomly terminate service instances in a Ku bernetes cluster to develop a kind of adversarial control loop  whose main goal is to disturb the selfadaptive behavior of a target microservice system This adversarial control loop could then leverage existing selfadaptation models and techniques to monitor and respond to ie counteract the microservice systems adaptation actions and thereby offer a powerful mechanism to test the selfadaptive systems resiliency in production 55 New Migration Strategies to Microservices In recent years the migration from legacy monolithic ap plications to a microservicebased architecture has gained considerable momentum in both industry 15 and academia 4 However questions such as when and how to switch to the newly migrated microservice system are still challenging One popular migration strategy is apply ing the Strangler Fig Application pattern13in which the functionalities implemented by the monolithic application are gradually replaced by new microservices In that regard an interesting new direction is to use a selfadaptive service mesh to dynamically reroute trafﬁc from the monolith to the new services as they are delivered into production This would facilitate the task of introducing and testing new services during the migration process and also enable a gradual decommission of the legacy infrastructure 6 C ONCLUSION We have looked into a number of practical challenges facing the development and delivery of selfadaptive microservice systems We have also suggested potential ways to address most of those challenges with a focus on current and emerg ing microservice practices and technologies We hope our ideas contribute to promote a better understanding of the 10 httpsgithubcomSeelabFhdoAjiL 11 httpslabsspotifycom20180111testingofmicroservices 12 httpsgithubcomasobtikubemonkey 13 httpsmartinfowlercomblikiStranglerFigApplicationhtmlinterplay between selfadaptive systems and microservices thus providing a timely incentive for researchers practition ers and tool developers to tackle some of the issues raised here as well as others that might arise REFERENCES 1 J O Kephart and D M Chess The vision of autonomic comput ing Computer  vol 36 no 1 pp 4150 2003 2 D Weyns Software Engineering of SelfAdaptive Systems An Organ ised Tour and Future Challenges  Springer 2017 3 P  Jamshidi et al  Microservices The journey so far and challenges ahead IEEE Software  vol 35 no 3 pp 2435 2018 4 A Balalaie A Heydarnoori and P  Jamshidi Microservices archi tecture enables DevOps Migration to a cloudnative architecture IEEE Software  vol 33 no 3 pp 4252 2016 5 S Rajagopalan and H Jamjoom AppBisect Autonomous healing for microservicebased apps in 7th USENIX Workshop on Hot Topics in Cloud Computing HotCloud  2015 6 A R Sampaio Jr et al  Improving microservicebased appli cations with runtime placement adaptation Journal of Internet Services and Applications  vol 10 no 1 pp 130 2019 7 A Filieri et al  Control strategies for selfadaptive software systems ACM Transactions on Autonomous and Adaptive Systems  vol 11 no 4 p 24 2017 8 R Heinrich et al  Performance engineering for microservices Research challenges and directions in Proc of the 8th ACMSPEC on Int Conf Perf Eng Companion  ACM 2017 pp 223226 9 L Bass I Weber and L Zhu DevOps A Software Architects Perspective  AddisonWesley Professional 2015 10 G Adzic and R Chatley Serverless computing Economic and ar chitectural impact in 11th Joint Meeting on Foundations of Software Engineering FSE  ACM 2017 pp 884889 11 N C Mendonc a et al  Generality vs reusability in architecture based selfadaptation The case for selfadaptive microservices in 1st Int Workshop on Architectural Knowledge for SelfAdaptive Systems AKSAS  2018 12 X Zhou et al  Latent error prediction and fault localization for microservice applications by learning from system trace logs in27th ACM Joint Meeting on European Software Engineering Con ference and Symposium on the Foundations of Software Engineering ESECFSE  ACM 2019 pp 683694 13 A Basiri et al  Chaos engineering IEEE Software  vol 33 no 3 pp 3541 2016 14 J C amara et al  Robustnessdriven resilience evaluation of self adaptive software systems IEEE Transactions on Dependable and Secure Computing  vol 14 no 1 pp 5064 2017 15 S Newman Monolith to Microservices Evolutionary Patterns to Transform Your Monolith  OReilly 2019 Nabor C Mendonc a is a professor of applied informatics at the University of Fortaleza Brazil From 2017 to 2018 he was a visiting scholar in the School of Computer Science at Carnegie Mellon University US His research interests include software engineering distributed sys tems selfadaptive systems and cloud comput ing Mendonc a received a PhD in computing from Imperial College London Contact him at naboruniforbr Pooyan Jamshidi is an assistant profes sor at the University of South Carolina US His research interests include software engi neering systems and machine learning with a focus on the areas of machinelearning systems Jamshidi received a PhD from Dublin City University Ireland Contact him at pjamshidcsescedu8 David Garlan is a professor and associate dean in the School of Computer Science at Carnegie Mellon University US His research interests include autonomous and selfadaptive systems software architecture formal meth ods explainablity and cyberphysical systems Garlan received a PhD in computer science from Carnegie Mellon University Contact him at garlancscmuedu Claus Pahl is a professor of computer science at the Free University of BozenBolzano Italy where he heads the Software and Systems En gineering Group His research interests include software engineering in service and cloud com puting speciﬁcally migration architecture speci ﬁcation dynamic quality performance engineer ing and scalability Pahl received a PhD in com puting from the University of Dortmund Contact him at cpahlunibzit 1 Developing SelfAdaptive Microservice Systems Challenges and Directions Nabor C Mendonc a Pooyan Jamshidi David Garlan and Claus Pahl Abstract A selfadaptive system can dynamically monitor and adapt its behavior to preserve or enhance its quality attributes under uncertain operating conditions This article identiﬁes key challenges for the development of microservice applications as selfadaptive systems using a cloudbased intelligent video surveillance application as a motivating example It also suggests potential new directions for addressing most of the identiﬁed challenges by leveraging existing microservice practices and technologies Index Terms selfadaptive systems microservices DevOps continuous delivery F 1 I NTRODUCTION A selfadaptive system can monitor its behavior and change its conﬁguration or architecture at run time to preserve or enhance its quality attributes eg performance reliability and security under uncertain operating conditions eg varying workloads errors and security threats 1 Despite signiﬁcant progress in developing selfadaptive systems in recent years only a handful of techniques such as auto mated server management cloud elasticity and automated data center management have thus far found their way to industrial applications 2 For example Kubernetes1a modern container orchestration platform that is increasingly being used to deploy and manage microservice applications in the cloud 3 only provides autoscaling ie the ability to automatically change the number of instances of a service and selfhealing ie the ability to automatically restart failed service instances as part of its native selfadaptation capabilities The popularity of microservices in industry has naturally sparked the interest of the research community However most existing research on microservices focuses on general architectural principles and migration guidelines eg 4 Only a few works have addressed the speciﬁc challenges of developing microservice applications as selfadaptive sys tems nevertheless even those works tend to be rather nar row in scope offering only limited forms of adaptation eg selfhealing 5 and runtime placement adaptation 6 We believe the uptake of microservices and their en abling practices and technologies by industry brings a N C Mendon ca is with the Post Graduate Program in Applied Informat ics University of Fortaleza Fortaleza CE Brazil Email naboruniforbr P  Jamshidi is with the Computer Science and Engineering Department University of South Carolina Columbia SC USA Email pjamshidcsescedu D Garlan is with the School of Computer Science Carnegie Mellon University Pittsburgh P A USA Email garlancscmuedu C Pahl is with the Faculty of Computer Science Free University of Bozen Bolzano BozenBolzano Italy Email cpahlunibzit 1 httpskubernetesiounique opportunity to narrow the gap between the state oftheart and the stateofthepractice in selfadaptive sys tems and that both selfadaptive systems and microservice communities have much to gain from each other On the one hand recent progress in selfadaptive sys tems offers a controloriented perspective that leverages a large body of theoretical and practical results to enhance microservice quality attributes using techniques such as planners eg to select the best possible adaptation strategy for each microservice machine learning eg to learn new adaptation strategies from past adaptation results reason ing under uncertainty eg to cope with noisy monitoring data and multiobjective optimization eg to cater to mul tiple possibly conﬂicting microservice requirements 7 On the other hand software characteristics such as independent and frequent deployment the need for a high degree of automation and complex runtime architectures 3 make microservices a fertile ground to foster further research and development on selfadaptive systems In this paper we take a closer look into the interplay between selfadaptive systems and microservices in order to identify key challenges for the development of microservice applications as selfadaptive systems Our contributions are as follows 1 we describe a cloudbased intelligent video surveillance application as an example of a selfadaptive microservice system 2 we identify and illustrate in the context of this example application several challenges for microservice development delivery and operations from multiple selfadaptation perspectives and 3 we discuss potential new directions for addressing most of the key chal lenges identiﬁed for developing selfadaptive microservice systems by leveraging existing microservice practices and technologies 2 M ICROSERVICES Microservices constitute an emerging architectural style that builds on the wellestablished concept of modularization but emphasizes technical boundaries ie different address and execution spaces between software components 3 Each moduleeach microserviceis developed around a single business capability that offers access to its internalarXiv191007660v2 csSE 15 Nov 20192 Fig 1 a Microservice architecture for the edgecloud intelligent video surveillance application and b three continuous delivery pipelines for the applications face detection video processing and face recognition microservices respectively adapted from 8 logic and data through a welldeﬁned network interface Due to their relative simplicity and small size microservices can be released often and adapted to different produc tion environments from cloud data centers to resource constrained devices eg IoTwithout much development effort This has a signiﬁcant impact on improving software agility because each microservice becomes an independent unit of development deployment versioning scaling and management 3 Microservices are considered to be an enabler for emerg ing DevOps practices such as continuous integration CI and continuous delivery CD which aim to signiﬁcantly decrease the time between changing a system and trans ferring that change to the production environment 9 To achieve this level of agility microservices are typically pack aged in lightweight containers eg Docker2 and deployed and managed using automated container orchestration tools eg Kubernetes In particular the use of fully automated CD tools eg Spinnaker3 enables the creation of inde pendent CD pipelines for each microservice Having mul tiple CD pipelines running in parallel allows microservice changes to be rapidly delivered into production since only the affected microservice needs to be built and tested 8 2 httpswwwdockercom 3 httpswwwspinnakerio3 A S ELFADAPTIVE MICROSERVICE SYSTEM We consider an edgecloud intelligent video surveillance application as an example of a selfadaptive microservice system The applications goal is to alert users about the presence and possibly the identiﬁcation of humans in a certain location via realtime analysis of video frames cap tured by one or more security cameras Its architecture inspired by one of Amazons machine learning ML sample solutions4is composed of several business platform  and infrastructure services as shown in Figure 1a Each security camera is deployed along with a ML based face detection edge service1This service is a less accurate yet more energy efﬁcient version of a MLbased face recognition service deployed in the cloud The role of the face detection edge service is to select relevant video frames ie frames with detected human faces to be asynchronously transmitted to a video processing service in the cloud using a cloudprovided streaming service2The streaming service offers a more scalable and reliable solution over the basic HTTP Streaming protocol The video processing service in the cloud analyzes the received video frames3and passes them as invocation parameters to the face recognition 4 httpsawsamazoncomblogsmachinelearning createaserverlesssolutionforvideoframeanalysisandalertingMENDONC  A et al  DEVELOPING SELFADAPTIVE MICROSERVICE SYSTEMS 3 service4in an attempt to recognize any person that might be visible in them If the face recognition service reports a match the video processing service sends out an SMS mes sage informing the application users mobile phones about the match using a notiﬁcation service56The video processing service then saves the analyzed video frames along with any relevant information regarding the video recording eg date camera ID and contents eg names of the recognized persons match accuracy in a storage service7Application users can use a Webbased User Interface Web UI to search for and play back any analyzed video segment stored in the cloud This is done by invoking a video playback edge service deployed somewhere closer to the users physical location8The video playback edge service in turn uses the streaming service to communicate asynchronously with avideo playback service in the cloud9 The video surveillance application also relies on sev eral infrastructure services  such as a discovery service an authentication service a monitoring service and a container orchestration service10To avoid cluttering the depiction of the video surveillance application architecture in Figure 1a omits interactions between business services and infrastruc ture services Following typical microservice practices each service of the video surveillance application is delivered in production using its own independent CD pipeline Figure 1b depicts three possible CD pipelines for the face detection video processing and face recognition services Note how each pipeline goes through different environments from coding to production which represent the multiple development stages eg build testing canary release and ﬁnally full production of each service 9 We envision multiple selfadaptation scenarios for this example application including the following The video processing service may need to dynam ically change its number of deployed instances in response to load variations The face recognition service may need to dynami cally change its container image eg to switch to a less accurate version under extreme load conditions The video playback service may need to dynamically change its quality attributes eg its frame rate in order to cope with latency ﬂuctuations and The CD pipeline for the video playback edge service may need to dynamically adjust that services testing parameters eg to expedite the testing of its self healing capabilities during staging Enacting all of the foregoing different scenarios may bring up a number of challenges for microsevice application developers which we discuss next 4 C HALLENGES We identify the main challenges facing the development of selfadaptive microservice systems from four perspectives design space control loop deployment continuous delivery  and testing 41 Design Space Designing selfadaptive systems involves making design decisions about the environment while it is being observed and about the system itself and then selecting adaptation mechanisms that are thereafter enacted 2 In the context of a microservice application the design space for making self adaptation decisions is even more complex due to the large number of runtime components and their independent and highly dynamic nature 3 Thus a ﬁrst challenge is as follows C1 How to determine monitoring and adaptation mechanisms to face the diversity of microservices qual ity attributes The case of the example video surveillance application illustrates this challenge as the quality requirements and adaptation needs of the ML face recognition service which handles only individual video frames and is invoked syn chronously from within the cloud might be quite differ ent from those of the video playback edge service which handles the entire video segments and is invoked asyn chronously from outside the cloud In particular the former would not have to monitor and adapt its communication parameters eg the request rate at run time in contrast this would be a critical requirement for the latter An additional challenge is the following C2 How to identify and resolve potential conﬂicts between the quality requirements of individual microser vices and those of the overall application when deﬁning their selfadaptive behaviors For instance an important quality attribute of a face recognition service which typically works by comparing ex tracted facial features from a given image with facial images within a database is its recognition accuracy However high accuracy in this kind of ML service inevitably implies high processing and storage costs which might conﬂict with the applications overall cost constraints The following is yet another challenge in this context C3 How to reconcile the adaptation needs of individual microservices and the overall application with the self adaptation capabilities offered by the underlying infras tructure management platform By way of illustration while Kubernetes autoscaling capabilities could be useful to improve the response time of all cloudbased services deployed as part of the video surveillance application current Software Reliability En gineering SRE practices indicate that autoscaling alone might not be enough to make strong guarantees about a services performance especially under high load5In addition Kubernetes does not yet support monitoring and management of service communication characteristics at the application layer ie Layer 7 such as by establishing per service rate limits and bandwidth quotas which could be useful to help manage the performance and communication overhead of the video playback service 5 httpslandinggooglecomsre4 Finally the more recent FunctionasaService FaaS and serverless computing cloud models6in which ﬁnedgrained services are deployed as serverless functions that are trans parently managed and scaled by the cloud platform and charged on a per usage basis poses an additional challenge C4 How to develop and manage selfadaptive mi croservice systems in hybrid deployment environments that are composed of both serverful and serverless ser vices A case in point is encountered because some of the video surveillance services eg video processing could be re implemented and redeployed as serverless services using an FaaS cloud platform such as AWS Lambda7In that case application developers would not only have to reconcile the adaptation requirements of both serverful and serverless services with the selfadaptation capabilities of their respec tive management platforms but also to rethink their entire DevOps and business strategies in order to account for the signiﬁcant technical and economical differences between those two deployment models 10 42 Control Loop Deployment Control loops are crucial elements necessary to realize the runtime adaptation of software systems A typical self adaptation control loop consists of four main activities namely Monitor Analyze Plan and Execute which share a common Knowledge base that are usually referred to as the MAPEK reference model 1 Control loops can be designed and deployed according to different control strategies from a single centralized control component managing the whole system to multiple control components managing different parts of the system and organized in a hierarchi cal or fully decentralized manner 2 In the context of a microservice application where each microservice is inde pendently developed deployed and managed at run time selecting the appropriate control strategies poses additional challenges The following constitutes an initial challenge in this context C5 How to determine the level of distribution visibility  and granularity necessary for deploying a microservice applications control components We see these three deployment dimensions as forming a control loops deployment space for a microservice appli cation The distribution dimension concerns the physical allocation of control loop components to infrastructure re sources The visibility dimension in turn concerns whether the control loop components should be deployed at the application level ie fully visible to developers or at the infrastructure level ie only partially visible to developers Finally the granularity dimension concerns whether control loop components should be deployed as a single monolithic 6 Mike Roberts May 22 2018 Serverless Architecture  Martin Fowlercom Retrieved November 13 2019 from httpsmartinfowler comarticlesserverlesshtml 7 httpsawsamazoncomlambdaservice or decomposed into a collection of independently developed and managed microservices Developing and deploying selfadaptive microservice systems with those three dimensions in mind could help to establish fundamental tradeoffs with respect to multiple quality attributes An example is deploying control loops for each of the video surveillance application services in a fully decentralized fashion which would in turn increase their overall reliability and scalability Nevertheless this strategy would also make it harder to enforce applicationwide adap tation constraints as this would require each control loop to coordinate its actions with the other control loops thereby reducing their autonomy Similarly deploying control loops at the infrastructure level would help to promote a better separation between business and management services at run time thus facilitating their reuse Despite this beneﬁt this strategy would also make control loops much harder to customize for speciﬁc adaptation needs eg managing the expected accuracy of ML services as most control loops deployed at the infrastructure level support only a restricted set of adaptation models and mechanisms 11 Finally deploying control loop components as monolithic services would greatly simplify their packaging and management at run time However this strategy would also force all control components to share the same version and release rate thus severely compromising their continuous improvement to satisfy evolving adaptation needs Another challenge related to control loop deployment is as follows C6 How to reconcile the selected control loop deploy ment strategies with those supported by the underlying infrastructure management platform As an example in Kubernetes selfhealing and autoscal ing controllers are deployed in a mostly centralized manner as part of its master node Therefore if each microservice is to be managed by a fully independent control loop there should be multiple instances of such types of controllers deployed one for each microservice In addition those individual controllers might still have to coordinate their actions at the application level in order to resolve potential requirement conﬂicts as discussed in Section 41 which coordination Kubernetes currently does not support 43 Continuous Delivery We identify three main adaptation scenarios concerning the use of CD practices and tools in the context of a self adaptive microservice system The ﬁrst scenario is the run time adaptation of the CD pipelines themselves In that regard the following is a key challenge C7 How to best determine the appropriate monitoring and adaptation mechanisms that will dynamically adjust the transition events and conditions across the stages of each microservice CD pipeline An exemplar of this challenge is as follows To create a CD pipeline developers typically need to deﬁne the events and conditions under which each stage of the pipeline can be executed This is usually done by manually expressingMENDONC  A et al  DEVELOPING SELFADAPTIVE MICROSERVICE SYSTEMS 5 the trigger events and test requirements of each stage so that the target application can be automatically progressed from one stage to the next In this scenario a selfadaptive pipeline would have to be able to monitor the application behavior at each stage so as to dynamically adjust its trigger events andor test requirements to cope with uncertainties during its execution eg the application repeatedly failing to meet the requirements of one particular stage due to the necessary data or infrastructure resources being unavail able Yet another challenge related to this scenario is as fol lows C8 How to reconcile the adaptation needs of each microservice CD pipeline with the selfadaptation capa bilities offered by the underlying infrastructure and CD management platforms Kubernetes offers a rollout operation that can be used to illustrate this challenge A rollout operation automatically deploys a new service version without having to take the current version down This operation could be useful to implement a canary release pipeline for each of the video surveillance services A canary release pipeline is respon sible for automatically deploying a new service version to production in parallel with the most recent stable version of that service so as to gradually replace instances of the stable service version with instances of the new canary version based on a given set of testing criteria 9 However this solution would still require service developers to manually invoke Kubernetes rollout operation every time theres a new service version to be released Alternatively developers could beneﬁt from a fullﬂedged CD management tool eg Spinnaker to fully automate the execution of that canary release pipeline But even in that case developers would still need to provide the CD management tool with the exact conditions and their trigger events required to deploy the canary release into production The second scenario is the adaptation of the microser vices own adaptation requirements In this scenario a key challenge faced is the following demand C9 How to dynamically adjust the adaptation require ments of each microservice according to the needs of each CD stage As an example to streamline the testing of the autoscal ing capabilities of the video processing service the CD plat form could automatically adjust that services performance requirements during staging so as to trigger its autoscaling features earlier and more often than during normal produc tion Finally the third scenario concerns treating the self adaptation mechanisms of a selfadaptive microservice sys tem as ﬁrstclass DevOps entities In that respect a further challenge is addressing the following issue C10 How to establish an effective strategy for continu ously delivering selfadaptation mechanisms in produc tion in the context of a selfadaptive microservice systemBy way of example each selfadaptation mechanism used by the video surveillance application eg autoscal ing and selfhealing could be independently tested and deployed in its own CD pipeline Such a strategy would allow a more systematic reuse of selfadaptation models and mechanisms across business services albeit at the expense of having a more complex CD process 44 Testing Conducting extensive validation tests with microservices before each deployment is not feasible due to the high frequency of their releases Instead microservice quality assurance is often compensated or even replaced by ﬁne grained monitoring techniques in production environments exposed to real workloads In this way failures can be monitored and quickly corrected by pushing new releases into production 8 The following is a key challenge in this context C11 How to determine testing models and mechanisms to assess the fundamental quality attributes of each microservice and of the overall application from a self adaptation perspective An example of this challenge in the context of the video surveillance application is that developers may need to select different testing mechanisms to assess the self adaptation features of different microservices eg image benchmarking and load generation for testing the autoscal ing features of the face recognition service and fault injection for testing the selfhealing features of the video playback service In addition the need for those testing mechanisms may vary across CD stages and pipelines eg autoscaling tests of the face recognition service may be run only during staging while more critical selfhealing tests of the video playback service may be run all the way to production An additional challenge related to testing is the follow ing C12 How to integrate the systematic testing of microservices including their selfadaptive behaviors within the context of existing CD practices The use of fault injection mechanisms to test a self adaptive systems resiliency in production illustrates this challenge For example the results of fault injection tests created to assess the resiliency of the selfhealing features of the video playback service could be used by the underlying CD platform as one of the criteria for deciding whether the latest version of that service is ready to be promoted from canary release to normal production 5 N EWDIRECTIONS We now suggest promising new directions to address most of the challenges identiﬁed in the previous section 51 New Adaptation Mechanisms Regarding challenges C1 and C3 a practical way of im plementing novel selfadaptation solutions tailored for the6 context of microservice applications would be by extend ing the management API provided by current container orchestration tools like Kubernetes To illustrate one could easily build on the rollout and rollback features provided by Kubernetes to develop a selfadaptive service fallback mech anism that could be customized to meet different adaptation requirements The basic idea is to create multiple fallback versions for each microservice eg a low ﬁdelity version or a high accuracy version and pack them as separate Docker im ages The selfadaptive fallback mechanism could then be conﬁgured to use Kubernetes to automatically update the current image of a given microservice to one of its fallback images under certain system or environment conditions eg update the face recognition service to its high accuracy image whenever the system is underutilized and rollback that service to its original image whenever the load reaches a certain threshold Similarly one could build on the variety of communicationrelated monitoring and management features provided by the use of socalled service mesh tools 3 to create novel connectororiented selfadaptation mechanisms This is the case for example of using the security management features of a service mesh tool like Istio8to provide a selfprotection mechanism that will automatically strengthen the encryption parameters of the communication protocols being used by the video surveillance application services under a security attack without the need to change or restart any service A service mesh could also be useful to dynamically adjust the retry and circuitbreaking parameters 3 used by all clients of an overloaded service so as to reduce the services incoming trafﬁc and thus prevent cascading failures from propagating throughout the system This feature could be particularly useful for missioncritical selfadaptive systems Finally speciﬁcally regarding challenge C2 application developers may rely on recent microservice orchestration languages eg Jolie9 as the means for deﬁning and enact ing applicationaware adaptations While this may provide a possible solution its adoption may be seen as counterin tuitive with respect to some wellestablished microservice principles such as the autonomy of each microservice team to choose the implementation technologies that best ﬁt their needs and expertise 3 52 New Control Loop Deployment Structures From a control loop deployment perspective as discussed in the context of challenges C5 and C6 a microservice systems control components should ideally be deployed in a fully decentralized fashion with each microservice being managed by its own local controller The downside of this solution is that it makes it harder for the local controllers to monitor and manage applicationwide quality attributes Although having a centralized controller dedicated to man aging applicationlevel quality concerns would be a more straightforward solution for this issue its use would create a single point of failure and ultimately could compromise 8 httpsistioio 9 httpswwwjolielangorgthe applications overall availability In practice microser vice developers may choose from a variety of intermediate solutions between those two extremes eg by logically grouping services according to their business andor quality afﬁnity and then having those services being collectively managed by independent yet applicationaware group con trollers organized in a hierarchical or fully decentralized structure Another important issue is the decision about whether microservice developers should have any responsibility in developing and managing control components as sug gested above Having control components explicit in the design and development of a selfadaptive microservice sys tem may contribute to further increase the systems overall complexity In addition this decision could compromise the delivery autonomy of individual services since service de velopers would have to negotiate before every new release in case their code bases share the same control components We advocate the adoption of a middle ground solution having all control components developed tested and re leased as part of the underlying infrastructure management platform yet still exposed to service developers during the later phases of their services CD pipeline 11 53 New Continuous Delivery Strategies The question of how to integrate selfadaptation capabilities with DevOps discussed in the context of challenges C7C9 deserves special attention from selfadaptive microservice system developers Here we discuss two possible CD strate gies and their tradeoffs One ﬁrst strategy is to create a new dedicated CD pipeline to deliver into production all selfadaptation com ponents used by the application Having a dedicated self adaptation pipeline would have the advantage of running it in parallel with the other business pipelines and thus preserve their autonomy On the other hand this solution would prevent business developers from directly improving the selfadaptation components used by their services as this would require negotiating with the developers respon sible for the selfadaptation pipeline Moreover this solution would push critical integration tests to the end of each business pipeline as business developers would not have immediate access to the latest version of their required self adaptation components A second strategy is to have separate business and self adaptation pipelines during the commit and build stages but have the selfadaptation pipeline integrated with the other business pipelines as soon as they enter the testing stage In this case selfadaptation components would still be designed and developed by a separate team but their test ing and deployment would be the responsibility of business developers as part of their business service pipelines This would have the beneﬁt of avoiding delaying integration tests in the business pipelines However as a side effect it could unnecessarily bloat all business pipelines with business developers now being responsible for testing both business and selfadaptation components Those two strategies are but a small sample of the spectrum of CD alternatives developers of selfadaptive microservice systems can explore In that direction extend ing emerging ModelDriven Engineering MDE tools forMENDONC  A et al  DEVELOPING SELFADAPTIVE MICROSERVICE SYSTEMS 7 microservices eg AjiL10 with CD support could be a key enabler to automate the integration of selfadaptation capabilities and DevOps 54 New Testing Approaches A number of recent testing approaches have been proposed speciﬁcally for microservices both by industry eg integra tion testing in production11 and by academia eg trace based error prediction and fault localization 12 A natural new direction here related to challenges C11 and C12 is to systematically integrate those emerging testing approaches within the context of a fully automated selfadaptive CD pipeline In this way the results of both online and ofﬂine tests could be incorporated as part of the set of dynamic events and conditions used by the underlying CD platform to automatically test a given microservice release across multiple pipeline stages Yet another promising direction in this context is apply ingchaos engineering 13 principles to assess the resiliency of a selfadaptive microservice system 14 In that regard one could rely on such a tool as kubemonkey12which can be used to randomly terminate service instances in a Ku bernetes cluster to develop a kind of adversarial control loop  whose main goal is to disturb the selfadaptive behavior of a target microservice system This adversarial control loop could then leverage existing selfadaptation models and techniques to monitor and respond to ie counteract the microservice systems adaptation actions and thereby offer a powerful mechanism to test the selfadaptive systems resiliency in production 55 New Migration Strategies to Microservices In recent years the migration from legacy monolithic ap plications to a microservicebased architecture has gained considerable momentum in both industry 15 and academia 4 However questions such as when and how to switch to the newly migrated microservice system are still challenging One popular migration strategy is apply ing the Strangler Fig Application pattern13in which the functionalities implemented by the monolithic application are gradually replaced by new microservices In that regard an interesting new direction is to use a selfadaptive service mesh to dynamically reroute trafﬁc from the monolith to the new services as they are delivered into production This would facilitate the task of introducing and testing new services during the migration process and also enable a gradual decommission of the legacy infrastructure 6 C ONCLUSION We have looked into a number of practical challenges facing the development and delivery of selfadaptive microservice systems We have also suggested potential ways to address most of those challenges with a focus on current and emerg ing microservice practices and technologies We hope our ideas contribute to promote a better understanding of the 10 httpsgithubcomSeelabFhdoAjiL 11 httpslabsspotifycom20180111testingofmicroservices 12 httpsgithubcomasobtikubemonkey 13 httpsmartinfowlercomblikiStranglerFigApplicationhtmlinterplay between selfadaptive systems and microservices thus providing a timely incentive for researchers practition ers and tool developers to tackle some of the issues raised here as well as others that might arise REFERENCES 1 J O Kephart and D M Chess The vision of autonomic comput ing Computer  vol 36 no 1 pp 4150 2003 2 D Weyns Software Engineering of SelfAdaptive Systems An Organ ised Tour and Future Challenges  Springer 2017 3 P  Jamshidi et al  Microservices The journey so far and challenges ahead IEEE Software  vol 35 no 3 pp 2435 2018 4 A Balalaie A Heydarnoori and P  Jamshidi Microservices archi tecture enables DevOps Migration to a cloudnative architecture IEEE Software  vol 33 no 3 pp 4252 2016 5 S Rajagopalan and H Jamjoom AppBisect Autonomous healing for microservicebased apps in 7th USENIX Workshop on Hot Topics in Cloud Computing HotCloud  2015 6 A R Sampaio Jr et al  Improving microservicebased appli cations with runtime placement adaptation Journal of Internet Services and Applications  vol 10 no 1 pp 130 2019 7 A Filieri et al  Control strategies for selfadaptive software systems ACM Transactions on Autonomous and Adaptive Systems  vol 11 no 4 p 24 2017 8 R Heinrich et al  Performance engineering for microservices Research challenges and directions in Proc of the 8th ACMSPEC on Int Conf Perf Eng Companion  ACM 2017 pp 223226 9 L Bass I Weber and L Zhu DevOps A Software Architects Perspective  AddisonWesley Professional 2015 10 G Adzic and R Chatley Serverless computing Economic and ar chitectural impact in 11th Joint Meeting on Foundations of Software Engineering FSE  ACM 2017 pp 884889 11 N C Mendonc a et al  Generality vs reusability in architecture based selfadaptation The case for selfadaptive microservices in 1st Int Workshop on Architectural Knowledge for SelfAdaptive Systems AKSAS  2018 12 X Zhou et al  Latent error prediction and fault localization for microservice applications by learning from system trace logs in27th ACM Joint Meeting on European Software Engineering Con ference and Symposium on the Foundations of Software Engineering ESECFSE  ACM 2019 pp 683694 13 A Basiri et al  Chaos engineering IEEE Software  vol 33 no 3 pp 3541 2016 14 J C amara et al  Robustnessdriven resilience evaluation of self adaptive software systems IEEE Transactions on Dependable and Secure Computing  vol 14 no 1 pp 5064 2017 15 S Newman Monolith to Microservices Evolutionary Patterns to Transform Your Monolith  OReilly 2019 Nabor C Mendonc a is a professor of applied informatics at the University of Fortaleza Brazil From 2017 to 2018 he was a visiting scholar in the School of Computer Science at Carnegie Mellon University US His research interests include software engineering distributed sys tems selfadaptive systems and cloud comput ing Mendonc a received a PhD in computing from Imperial College London Contact him at naboruniforbr Pooyan Jamshidi is an assistant profes sor at the University of South Carolina US His research interests include software engi neering systems and machine learning with a focus on the areas of machinelearning systems Jamshidi received a PhD from Dublin City University Ireland Contact him at pjamshidcsescedu8 David Garlan is a professor and associate dean in the School of Computer Science at Carnegie Mellon University US His research interests include autonomous and selfadaptive systems software architecture formal meth ods explainablity and cyberphysical systems Garlan received a PhD in computer science from Carnegie Mellon University Contact him at garlancscmuedu Claus Pahl is a professor of computer science at the Free University of BozenBolzano Italy where he heads the Software and Systems En gineering Group His research interests include software engineering in service and cloud com puting speciﬁcally migration architecture speci ﬁcation dynamic quality performance engineer ing and scalability Pahl received a PhD in com puting from the University of Dortmund Contact him at cpahlunibzit 44 login VOL 37 NO 1 I first heard about Netflixs remarkable journey into the cloud in Adrian Cock  crofts presentation at HPTS see the reports in this issue  Adrian explained why Netflix was moving to the cloud after having had their own datacenter the cloud was both easier to work with and more reliable  Adrians presentation slides 1 as well as very detailed blog entry 2 do a great job of explaining where Netflix is today and where they plan to go  I suggest that you read both of these resources the slides present an overview and the blog gets into details  What is missing from these resources is a bit of history which Adrian provides here  Rik I am guessing that Netflix started out using a big server in a datacenter pretty much the way other companies had always done and you gradually learned about the advantages of not having your own servers  Could you tell us a little about the past that led you to this point Adrian The history of how we got to the cloud is that our original datacenter systems were based on a few large Oracle servers with a Java front end  The load at that time was dominated by the DVD business  We had a storage data corrup  tion bug in the summer of 2008 which took Netflix down for several days and we also saw that in the future we would need to rebuild our site for higher avail  ability to support the demands of streaming  It was clear that we needed large scale redundant datacenters but we couldnt easily predict how much datacenter capacity we would need for the rapidly growing streaming business and where it should be located  We had also had a fairly painful experience moving from a single datacenter to a pair of small ones leased cages and needed to decide whether to invest heavily in the staff and skills needed to run a large and highgrowthrate datacenter infrastructure or outsource and leverage an external cloud supplier  In parallel we ran a large upgrade of datacenter capacity and an investigation into the feasibility of using cloud  We quickly settled on AWS as the largest cloud and established an executivelevel relationship as a foundation for the business and technical relationship  Through 2009 we explored the cloud platform with several pathfinder projects and noncustomerfacing workloads such as encoding and Hadoopbased log analysis  In early 2010 we brought up the first customerfacing workloads starting with the simplest ones with fewest dependencies and gradually filling in the data sources until almost everything is running in the cloud but with the data resident in both cloud and datacenter  In 2011 we gradually moved the source of truth systems into the cloud with copies in the datacenter as needed  The final stages of that are currently being completed Netflix Heads into the Clouds Interview with Adrian Cockcroft RIK FARROW Adrian Cockcroft is the director of architecture for the Cloud Systems team at Netflix He is focused on availability resilience performance and measurement of the Netflix cloud platform Adrian is also well known as the author of several books while a Distinguished Engineer at Sun Microsystems Sun Performance and Tuning  Resource Management  and Capacity Planning for Web Services  From 2004 to 2007 he was a founding member of eBay Research Labs He graduated with a BSc in Applied Physics from The City University London acockcroftnetflixcom login FEBRUARY 2012 Netflix Heads into the Clouds Interview with Adrian Cockcroft 45Rik I understand that you have built many tools for managing and monitoring your servers and software in the cloud and that you have made them open source  Can you briefly tell us about them Adrian We have built a platform that runs on the AWS cloud but provides abstrac  tions and patterns that are more portable and convenient for the developers at Netflix  I describe this PaaS in a presentation given at QConSF in October slides are at httpwww slideshare netadriancoglobalNetflixplatform  The platform is primarily based on Java running in Tomcat on Linux  We also sup  port the GroovyGrails environment primarily for building internal tools  We use open source components combined with custom code  The Netflix Global PaaS has the following features u Global distribution of traffic processing and data u Localized support for multiple languages and jurisdictions u Support for dynamic and ephemeral cloud resources u Data migration mechanisms from datacenter to cloud and between regions u Continuous backup and secure distributed archive of cloudbased data u Dynamic security key management with multilevel key protection u Finegrained least privilege security based on AWS security groups and IAM u Scalable to many thousands of instances autoscaled with load The components that we are open sourcing at github com include u Curator a distributed coordination framework based on Apache Zookeeper u Priam Tomcatbased automation for simple management of Apache Cassandra on AWS u Astyanax a Java client library for Cassandra that improves on an earlier client called Hector u Honu a high throughput streaming data logging system based on Apache Chukwa Rik In your presentations you mention two tools your developers use Jenkins and Perforce  Could you tell us more about those tools For example why did you choose Perforce over an open source solution Adrian Netflix has been using Perforce as its inhouse source code control system for many years and when we moved to the cloud we didnt change it  We use Jen  kins to run our build system for the cloud  Carl Quinn presented on this at Devoxx 4  Carls team runs Perforce Jenkins Ivy Artifactory and related tools for our cloud developments  Rik Youve made it clear that your move to AWS is as much about reliability as it is about flexibility  Yet even AWS can fail as seen in the April 2011 partitioning event that occurred in Amazons East Region datacenter 3  That event was related to a specific network configuration that exacerbated the initial problem a problem that occurred because the failover hadnt been tested under full load  What do you recommend that other organizations that plan on or have moved to cloud opera  tions do to prepare for such events Adrian We have published a Tech Blog that summarizes what we learned from that outage 5  There is a lot of detail there that answers your question  Rik Whats coming next 46 login VOL 37 NO 1 Adrian We are currently working on the backend infrastructure to support our UK and Ireland launch which leverages the AWS Europe region located in Ireland  Netflix has no employees in Ireland and the flexibility this gives us in contrast to owning our own datacenters is extremely valuable  From a technical perspective the Netflix Global Cloud Platform is being polished hardened and tuned to run more efficiently and we have several additional components we are planning to open source during 2012  Resources 1 Slides for Cockcrofts presentations httpwww slideshare netadrianco  2 Cockcrofts blog entry httptechblog Netflix com201111benchmarking cassandrascalabilityon html  3 Summary of the Amazon EC2 and Amazon RDS Service Disruption in the US East Region httpsaws amazon commessage65648  4 Carl Quinn at Devoxx httpwww devoxx comdisplayDV11CarlQuinn  5 Netflix blog regarding lessons learned from AWS outage httptechblog netflix com201104lessonsnetflixlearnedfromawsoutage html  DOMAIN SPECIFIC SERVICE DECOMPOSITION WITH MICROSERVICE API PATTERNS Prof Dr Olaf Zimmermann ZIO Certified Distinguished ChiefLead IT Architect Institute für Software HSR FHO ozimmermhsrchKeynote International Conference on Microservices 2019 Dortmund Germany February 19 2019 Abstract Service orientation is a key enabler for cloud native application development Microservices have emerged as a state oftheart implementation approach for realizations of the Service Oriented Architecture SOA style promoting modern software engineering and deployment practices such as containerization continuous delivery and DevOps Designing micro services interfaces to be expressive responsive and evolvable is challenging For instance deciding for suited service granularities is a complex task resolving many conflicting forces one size does not fit all Domain  Driven Design DDD can be applied to find initial service boundaries and cuts However service designers seek concrete actionable guidance going beyond high level advice such as turn each bounded context into a microservice  Interface signatures and message representations need particular attention as their structures influence the service quality characteristics This presentation first recapitulates prevalent SOA principles microservices tenets and DDD patterns It then reports on the ongoing compilation of complementary microservices API patterns and proposes a set of pattern based toolsupported API refactorings for service decomposition Finally the presentation highlights related research and development challenges  Olaf Zimmermann 2019Page 2Architecture of this Talk Micropresentations  Page 3  Olaf Zimmermann 2019SOA 101  Microservices TenetsReal World Service Examples Case StudiesService Granularity and Loose Coupling Microservice API Patterns MAPArchitectural Refactoring to MicroservicesService Analysis  Design ModelingMythbusting Patterns Research PbsQsExperience OpinionsLiterature AnalysisLegendIntroduction to Domain Driven DesignSample Project Financial Services Provider  forRetail Banks Supports and partially automates core banking business processes More than 1000 of business services each providing a single operation One database repository logically partitioned  Olaf Zimmermann 2019Page 4 Reference IBM ACM OOPSLA 2004 Exemplary Service Operations in Core Banking Fine business Coarse business Fine technical Hello world of core banking  int getAccountBalance CustomerId Bigdata customer profiling condensed  ActivityClassificationEnum scoreMonthlyInvestmentActivity CustomerId  Month Year Coarse technical Single domain entity but complex payload searchfilter capability  CustomerDTOSet searchCustomers WildcardedCustomerName  CustomerSegment  RegionDeep analytics  Kundengesamtübersicht  BankingProductPortfolioCollection prepareCustomerAnalysisForMeeting CustomerId  Timeframe Business granularity Functional scope domain model coverage Technical granularity Structure of message representations aka Data Transfer Object DTOs  Olaf Zimmermann 2019Page 5Business alignmentagility Independent deployability  Clientserver coupling  Sample Project Order Management Application Telecommunications  Olaf Zimmermann 2019Page 6 Reference IBM ECOWS 2007Exemplary Services in Order Management  Telecomunications  Endpoints play different roles in microservices architectures and their operations fulfill certain responsibilities  Preandpostconditions Conversational state Data consistency vs currentness  Olaf Zimmermann 2019Page 7Impact on scalability and changeability  Computation Function no read no write Event Processor write only Business Activity Processors read write Retrieval Operations read only What is Service Oriented Architecture SOA Page 8  Olaf Zimmermann 2019No single definition SOA is different things to different people A set of services and operations that a business wants to expose to their customers and partners or other portions of the organization Note no scope implied enterprise wide or application An architectural style which requires a service provider  a service requestor consumer and a service contract aka clientserver Note this is where the business alignment becomes real A set of architectural patterns such as service layer with remote facades data transfer objects enterprise service bus service composition choreographyorchestration and service registry promoting principles such as modularity layering and loose coupling to achieve design goals such as reuse and flexibility Note not all patterns have to be used all the time A programming and deployment model realized by standards tools and technologies such as Web services WSDLSOAP RESTful HTTP or asynchronous message queuing AMQP etc Note the such as matters and always hasBusiness Domain Analyst IT Architect Developer Administrator Based on and adapted from IBM SOA Solution Stack IBM developerWorks Napkin Sketch of SOA Realizations Adopted from G  Hohpe  Page 9  Olaf Zimmermann 2019 Our focus today MicroservicesNo longer popular term repurposed for deployment contextOur focus todayDebatable then and now Data Contracts Seven Microservices Tenets byViewpoint  Page 10  Olaf Zimmermann 2019Independent X X  Deployment Scaling Change Polyglot Programming and PersistenceBusiness Alignment eg via DDD IDEAL Cloud Architectures eg12 Factor App Service Monitoring DevOps WayDecentralization  Automation CICDContainerization and Clustering Archi  tecture Analysis Design  Coding Deploy  ment  RuntimeLegend wellknown fairly recent advances Cloud native application architectures areAPIcentric Page 11  Olaf Zimmermann 2019httpwwwcloudcomputingpatternsorg APIAPI APIIDEAL Isolated State DistributionDecomposition Elasticity Automation Loose CouplingCalls toService Operations Page 12  Olaf Zimmermann 2019Payload Header Envelope Header PayloadWrapperPayload Header Payload WrapperEnvelope httpswwwenterpriseintegrationpatternscompatternsmessagingCommandMessagehtml Sample request message note PUTs and POSTs would look different Response message structure  areEIPstyle Messages  some JSON or other MIME typeHow tofind suited granularities andachieve loose coupling  Page 13  Olaf Zimmermann 2019 Context We have decided to go the SOA andor microservices way We use DDD for domain modeling and agile practices for requirements elicitation Problems Industry Academia How to identify an adequate number of API endpoints and operations How to design commanddocument message representation structures so that API clients and API providers are loosel ycoupled and meet their non functional requirements IDEALy  Which patterns principles and practices do you use Do they work Introducing  Microservices API Patterns MAP  Identification Patterns DDD as one practice to find candidate endpoints and operations Evolution Patterns Work in progress EuroPLoP 2019  Olaf Zimmermann 2019Page 14 httpmicroservice apipatternsorg MAP Example Pagination 12 Context An API endpoint and its calls have been identified and specified Problem How can an API provider optimize a response to an API client that should deliver large amounts of data with the same structure Forces Data set size and data access profile user needs especially number of data records required to be available to a consumer Variability of data are all result elements identically structured how often do data definitions change Memory available for a request both on provider and on consumer side Network capabilities server topology intermediaries Security and robustnessreliability concerns Page 15  Olaf Zimmermann 2019 MAP Example Pagination 22 Solution Divide large response data sets into manageable and easy totransmit chunks Send only partial results in the first response message and inform the consumer how additional results can be obtainedretrieved incrementally Process some or all partial responses on the consumer side iteratively as needed agree on a request correlation and intermediatepartial results termination policy on consumer and provider side Variants Cursor based vs offset based Consequences Eg state management required Know Uses Public APIs of social networks Page 16  Olaf Zimmermann 2019 Microservices API Patterns MAP Pattern Index byCategory Page 17  Olaf Zimmermann 2019 httpmicroservice apipatternsorgQuality related decision model published at ICSOC 2018 More problem pattern mappings emerging  MAP Cheat Sheet https microservice apipatternsorgcheatsheet Attribute Driven Design https microservice apipatternsorgpatternsbyforce Recurring Architectural Decisions in Micro Service Design  Olaf Zimmermann 2019Page 18 More Decisions that Recur in Micro Service Design Page 19 httpsmicroservice api patternsorgcheatsheet emerging  Olaf Zimmermann 2019 Open Problem Service IdentificationDesign DDD 4 SOAMSA Page 20 Research Questions Which existing patterns are particularly suited to analyze and design cloud  native applications and to modernize existing systems monolithsmegaliths How can these patterns be combined with Microservices API Patterns MAP and other SOAmicroservices design heuristics to yield a service oriented analysis and design practice Which patterns and practices do you apply What are your experiences  Olaf Zimmermann 2019 Strategic DDD Context Map Relationship Example Insurance scenario  source  https contextmappergithubio Page 21  Olaf Zimmermann 2019D Downstream U Upstream  ACL Anti Corruption Layer OHS Open Host Service Context Mapper A DSL forStrategic DDD Eclipse plugin Based on Xtext ANTLR Sculptor tactic DDD DSL Author  S Kapferer Term project HSR FHO  Olaf Zimmermann 2019Page 22 DDD Applied to Micro Service Design M Ploed is one of the go toguys here find him on Speaker Deck  Applies and extends DDD books by E Evans and V Vernon  Olaf Zimmermann 2019Page 23 Reference JUGS presentation  Berne  Jan 9 2019Implementing Domain Driven Design withRESTful HTTP APIs Mentioned in DDD book by V Vernon and blog posts presentations  No 11 pass through interfaces vs applicationdomain layer Bounded Contexts BCs offered by API provider one API endpoint and IDE project for each teamsystem BC aka microservice  Aggregates supply API resources or responsibilities of microservices Services donate top level home resources in BC endpoint as well The Root Entity the Repository and the Factory in an Aggregate suggest toplevel resources contained entities yield sub resources Repository lookups as paginated queries GET with search parameters Additional rules of thumb own experience literature Master data and transactional data go to different BCsaggregates Creation requests to Factories become POSTs Entity modifiers become PUTs or PATCHes Value Objects appear in the custom mime types representing resources  Olaf Zimmermann 2019Page 24Open Problem  Service Decomposition Page 25 Research Questions How can systems be decomposed into services in forward engineering How do the applied criteria and heuristics differ from software engineering and software architecture classics such as separation of concerns and single responsibility principle Which methods and practices do you use Are they effective and efficient  Olaf Zimmermann 2019 Heuristics that do not suffice IMHO Twopizza rule team size Lines of code in service implementation Size of service implementation in IDE editor Simple if then else rules Eg If your application needs coarse grained services implement a SOA if you require fine ones go the microservices way  I did not make this up  Nontechnical traits such as products not projects Because context matters as M Fowler pointed out at Agile Australia 2018  Olaf Zimmermann 2019Page 26What is wrong with these metrics and best practice recommendations Agility Consistency StateScalability CAS Tradeoffs  Olaf Zimmermann 2019Page 27 ACS Dichotomy Business Agility Scalable State Mgmt  Resource ConsistencyData freshness Ability to respond to change Big data requirements Sharding  partitioning Strict  eventual consistency Audit requirements Incl backupState management Quick access caching Stickiness in cluster Modular MonolithMicroservicesConservative SOA Macroservices Entity relationship model Use cases System characterizations Aggregates DDD Coupling information is extracted from these artifactsService Cutter  Proc  OfESOCC 2016 Springer LNCS Advisor  Prof Dr Olaf Zimmermann CoExaminer  Prof Dr Andreas Rinkel Project Partner Zühlke Engineering AGBachelor Thesis Fall Term 2015 SoftwareLukas Kölbener Michael Gysel A Software Architects Dilemma Step 1 Analyze System Step 2 Calculate Coupling Step 3 Visualize Service Cuts How do I split my system into services Data fields operations and artifacts are nodes Edges are coupled data fields Scoring system calculates edge weights Two different graph clustering algorithms calculate candidate service cuts clusters A clustered colors graphTechnologies Java Maven Spring Core Boot Data Security MVC Hibernate Jersey JHipster  AngularJS BootstrapThe catalog of 16 coupling criteria httpsgithubcomServiceCutter A clustered colors graphPriorities are used to reflect the context Published Language DDD and use case responsibilities are shown Coupling Criteria CC in Service Cutter Ref ESOCC 2016 Eg Semantic Proximity can be observed if Service candidates are accessed within same use case readwrite Service candidates are associated in OOAD domain model Coupling impact note that coupling is a relation not a property Change management eg interface contract DDLs Creation and retirement of instances service instance lifecycle Page 29 Full descriptions in CC card format httpsgithubcomServiceCutterServiceCutterwikiCoupling Criteria  Olaf Zimmermann 2019Open Research Problem  Refactoring toMicroservices Page 30 Research Questions How to migrate a modular monolith to a services based cloud application aka cloud migration brownfield service design Can micro migrationmodernization steps be called out Which techniques and practices do you employ Are you content with them  Olaf Zimmermann 2019 Code Refactoring vs Architectural Refactoring Refactoring are  small behavior preserving transformations  M Fowler 1999 Code refactorings eg extract method Operate on Abstract Syntax Tree AST Based on compiler theory so automation possible eg in Eclipse JavaC Catalog and commentry  httprefactoringcom  Architectural refactorings Resolve one or more architectural smells  have an impact on quality attributes Architectural smell suspicion that architecture is no longer adequate good enough under current requirements and constraints which may differ form original ones Are carriers of reengineering knowledge patterns Can only be partially automated  Olaf Zimmermann 2019Page 31 Architectural Refactoring Name Context viewpoint refinement level  Quality attributes and stories forces    Smell refactoring driver   Architectural decisions to be revisited   Refactoring solution sketchevolution outline    Affected components and connectors if modelled explicitly    Execution tasks in agile planning tool andor full fledged design method   Refactoring toMicroservices API Patterns Template and cloud refactorings First published  SummerSoc 2016 Summary IEEE Software InfoQ Page 32Work in progress   Olaf Zimmermann 2019 Microservices refactorings  Future work forMAP Open Problem  ServiceData Visualization Modeling Page 33 Research Questions What is an intuitive easy tosketch graphical representation for micro services and their endpoints operations and message representations Which notations and tools do you use Do they make communication effective and efficient  Olaf Zimmermann 2019 Visualizing Operations and Message Representations Ports andadapters combined with layering  hexagonioning  Inspired by https herbertogracacom20171116explicit architecture 01 dddhexagonal onion clean cqrshowiputitalltogether  Olaf Zimmermann 2019Page 34PortsAdapters Data Domain LogicRequest message representation Response message representation  Representation LayerMessageServiceLegend Provided interface Required interfaceCustomer DataCustomer Core Microservice Example  Lakeside Mutual Microservices Use patterns to specify Role and responsibility of API call Message representations Documentation and governance  Olaf Zimmermann 2019Page 35Domain Layer Data Layer naInterface Layer Customer ProxyCustomer Self Service Application Customer Endpoint Mutation Checker myLakesideMutual Web FormsMicroservices Summary and Opinions Microservices have many predecessors evolution not revolution Implementation approach and sub style of SOA More emphasis on autonomy and decentralization of decisions of data ownership less vendor driven Automation advances and novel target environments One service size does not fit all Context matters and forces at work Size and granularity are not ends in themselves Goal achieve Independent X but do not forget BAC and CAP and ACS Architecture and architects needed more than ever More options higher consequences of not making adequate decisions Microservices API Patterns Context Mapper Service Cutter Public website now available Pattern language sample implementations supporting tools Service modeling  identification  decomposition  refactoring problems  Olaf Zimmermann 2019Page 36 Microservices Publications Zimmermann O Microservices Tenets Agile Approach to Service Development and Deployment Springer Comp SciRes Dev 2017 httprdcubemJPz Pardon G Pautasso C Zimmermann O Consistent Disaster Recovery for Microservices the Backup Availability Consistency BAC Theorem InIEEE Cloud Computing 51 2018 pp 49 59 Pahl C  Jamshidi  P Zimmermann O Architectural Principles for Cloud Software InACM Trans on Internet Technology TOIT 18 2 2018 pp 171 1723 Furda A  Fidge C  Zimmermann O  Kelly W  Barros A Migrating Enterprise Legacy Source Code to Microservices On Multitenancy Statefulness  and Data Consistency InIEEE Software 35 3 2018 pp 63 72  Olaf Zimmermann 2019Page 37 screen captions are hyperlinks HAL Id hal01636132 httpsinriahalsciencehal01636132 Submitted on 16 Nov 2017 HAL is a multidisciplinary open access archive for the deposit and dissemination of sci entific research documents whether they are pub lished or not The documents may come from teaching and research institutions in F rance or abroad or from public or private research centersLarchive ouverte pluridisciplinaire HAL  est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche publiés ou non émanant des établissements denseignement et de recherche français ou étrangers des laboratoires publics ou privés Microservices How T o Make Y our Application Scale Nicola Dragoni Ivan Lanese Stephan Thordal Larsen Manuel Mazzara Ruslan Mustafin Larisa Safina T o cite this version Nicola Dragoni Ivan Lanese Stephan Thordal Larsen Manuel Mazzara Ruslan Mustafin et al Microservices How T o Make Y our Application Scale AP  Ershov Informatics Conference the PSI Conference Series 11th edition Jun 2017 Moscow Russia hal01636132Microservices How To Make Your Application Scale Nicola Dragoni15 Ivan Lanese2 Stephan Thordal Larsen1 Manuel Mazzara3 Ruslan Musta n3 Larisa Sa na34 1Technical University of Denmark ndradtudk stephanthordalio 2University of BolognaINRIA ivanlanesegmailcom 3Innopolis University Russian Federation flsafina mmazzara rmustafin ginnopolisru 4University of Southern Denmark 5Orebro University Sweden Abstract The microservice architecture is a style inspired by service oriented computing that has recently started gaining popularity and that promises to change the way in which software is perceived conceived and designed In this paper we describe the main features of microservices and highlight how these features improve scalability 1 Introduction History of programming languages and paradigms has been characterized in the last few decades by a progressive shift towards distribution modularization and loose coupling with the purpose of increasing code reuse and robustness 5 This necessity has been dictated by the need of increasing software quality not only in safety and nancialcritical applications but also in more common o theshelf software packages Service oriented architectures SOAs can be seen as a step in this direction where the need for code reuse and robustness was coupled with the need for interoperability between heterogeneous information systems possibly belonging to di erent companies This brought up the idea of a service as a software en tity interacting with other software entities via message passing communications using standard data formats and protocols eg XML SOAP and HTTP and wellde ned interfaces Microservices are a further step along this road emphasizing the use of small services called indeed microservices and moving the service oriented techniques from system integration to system design development and deployment The microservice architecture 9 is built on a few basic principles Bounded Context  First introduced in 11 bounded context means that re lated functionalities are combined into a single business capability and eachNicola Dragoni et al microservice implements one such capability In this way there is a per fect alignment between business capabilities and system structure making it easy eg to know where a functionality is in order to update or x it Size The focus on small size is a crucial novelty of microservices wrt the previous SOAs Idiomatic use of microservice architectures suggests that if a service is too large it should be re ned into two or more services thus preserving granularity and maintaining focus on providing a single business capability only The small size brings major bene ts in terms of service maintainability and extendability a small service can be easily modi ed and if needed rebuilt from scratch with limited resources and in limited time Independency  This concept encourages loose coupling by stating that each microservice in microservice architectures is operationally independent from others and the only form of communication between services is through their published interfaces This is fundamental since this allows one to change x or upgrade a microservice without compromising the system correctness provided that the interfaces are preserved High cohesion is also encouraged since related functionalities should be provided by a unique microservice so that any update related to those functionalities only a ects the correspond ing microservice The shift towards microservices is a sensitive matter these days Several com panies are involved in a major refactoring of their backend systems to accommo date the advantages of the new paradigm 7 Other companies just start their business model developing software following the microservice paradigm since day one We are in the middle of a major change in the view in which software is intended and in the way in which capabilities are organized into components and industrial systems are conceived In the next section we highlight another advantage of microservices scalability for performance fault tolerance or avail ability reasons 2 Scalability Scalability is one of the key features provided by the microservice paradigm In this section we aim at giving an overview on how microservice characteristics naturally contribute to system scalability We emphasize that while frequently scalability is needed for performance reasons to cope with high load scalabil ity can also be used to ensure availability and fault tolerance According to the reason why scalability is needed slightly di erent approaches need to be used as we will emphasize below Distribution Distribution is not an original feature of microservices since eg SOAs are distributed as well However thanks to their small size microser vices take this characteristics to an extreme each business capability including their functionalities and the related data is realized by an independent ser vice which can be deployed on a host possibly di erent from the one of otherMicroservices How To Make Your Application Scale microservices of the same application As rst result this causes a natural dis tribution of the workload that can make the system signi cantly more ecient than a monolith 2 Distribution also makes microservice architectures highly available since the failure of a single microservice does not necessarily result in the failure of other microservices Distribution can also utilize locality and locate services closer to the clients they serve resulting in better geographical scalability 218 Nonuniform scaling Typically when monolithic architectures are exposed to growing load it is dicult to locate which components of the system are actually a ected since the system runs within a single process This means that although only a single component may be experiencing load the whole monolith will need to scale eg by replication or vertical scaling Even if it is known which is the component that is experiencing load it is dicult to scale it in isolation The same reasoning may apply to SOAs services in SOAs may be large frequently hiding a whole monolithic application behind a serviceoriented interface hence they may only scale at a large granularity The same applies when scalability is needed to implement high availability if only some components of a monolith or of a large service are required to be highly available the whole monolithlarge service will have to be highly available Since microservices are implemented and deployed independently of each other ie they run within independent processes they can be monitored and scaled independently as shown by the example below Example A simpli ed illustration showcasing the bene ts of scaling a microser vice architecture compared to a monolithic architecture is given in Figure 1 Both the systems implement componentization of software the monolith utiliz ing regular software components such as libraries and the microservice architec ture utilizing microservices ie Component x corresponds to Service x  In this scenario ComponentService 1 is experiencing a load that requires to replicate it to 3 instances Since the monolith is deployed as a single process one needs to replicate the whole system including all 3 components across three hosts In a microservice architecture one can simply replicate the single service experienc ing load resulting in allocation of much fewer hosts The load balancers are in place in both systems to split the load across replicas However in the monolith the balancer splits only external requests while in the case of the microservice architecture it splits both external requests and internal requests between the di erent microservices thus allowing for a more uniform load balancing This happens in particular when external requests may trigger computations which are heavy in a possibly nonuniform way only balancing external requests may not be enough The reliance on DomainDriven Design 11 and the strive towards high cohe sion means that growing load will typically be delimited to a subset of associated microservices 19 The speci c microservices actually experiencing the growing load can then be scaled eg by relocating them to the more performant hosts or by replicating them across a cluster or on the cloudNicola Dragoni et al Fig 1 Scaling in microservices vs monolithic architecture A similar argument applies to the technology adopted for implementing each microservice the technology used to build a microservice can be chosen in or der for it to perform at best For instance a computationintensive microservice might be implemented in C while a microservice requiring to handle com plex types could be implemented in a language with a sophisticated type system like Haskell This is not possible in a monolithic architecture which is typically bound to a single platform and language Portability Microservices are typically packaged in containers  as provided eg by Docker 15 or similar technologies A container includes the microser vice and all its environment libraries databases     in a unique entity whichMicroservices How To Make Your Application Scale can be easily deployed on any platform supporting the chosen container tech nology ensuring uniform behavior over heterogeneous platforms hosts data centers and cloud providers and isolation wrt other containers eg di erent microservices can use di erent versions of the same library without con icts The portability ensured by containers enables e ortless relocation or replication of a microservice across heterogeneous platforms Microservice architectures are therefore ideal for scaling a system horizontally since the microservices can eas ily be relocated to newly provisioned hosts Elasticity The ability to easily replicate individual microservices coupled with the ability to locate both a single and multiple microservices on a single host also enables microservice architectures to be elastic that is to dynamically scale according to the load Because of this multipleserviceperhost model deploy ing a microservice architecture to a dynamicallysized cluster and in particular on the Cloud allows it to utilize available resources very eciently When the load is high the system can easily be expanded by exploiting additional hosts dynamically allocated to it in the cluster or new virtual machines on the cloud and when resources become redundant because of lower load then those hosts can be deprovisioned and removed from the clustercloud again In the same way the number of service replicas can be increased or shrunk when needed This feature makes microservices a natural technology for the cloud and sug gests that microservice popularity will continue to grow as far as more and more applications are moved to the cloud Availability We have already highlighted some of the ways in which microser vices can help availability but here we summarize the main aspects related to the topic In general high availability is achieved by microservices ability to be replicated and spread across datacenters and geographical distances allowing them to spread load and cope with failing and congested hardware Another relevant aspect concerns system update and evolution while updating a mono lithic application requires to stop it and redeploy it thus causing a possibly long downtime replicability and independence allow microservices to solve the problem First updating a microservice architecture normally involves just one or a few microservices related to the business capability that needs to be xed or improved hence reducing the deployment time Furthermore the old and the new version of the same microservice can run side by side eg the old one completing running requests and the new one taking care of new requests The old one can then be removed when its job is ended Note that containerization avoids interferences between the two versions of the service eg allowing them to rely on di erent versions of the same library This naturally leads to smaller but more frequent updates in the direction of continuous deployment Robustness As for availability also robustness bene ts from using a microser vice approach Indeed one may replicate microservices as described above to ensure fault tolerance Fault tolerance however is also naturally improved beNicola Dragoni et al cause of the usage of containerization and independent processes Indeed a single microservice is completely isolated from other microservices and can only be a ected by them through its de ned interfaces or through the resources it relies on This means that even though some microservices might fail isolation ensures that other microservices and their environments are not a ected Of course this requires microservices to implement some faulttolerant mechanisms that can detect possible failures in microservices they depend on in order to prevent cascading failures One should however pay attention that low level interferences may still hap pen in particular when multiple microservices are deployed on the same host Indeed although their logical environments might be isolated their physical one is not If a single microservice consumes all the resources of a host shared with other microservices those microservices will be a ected Therefore one should be careful when placing microservices together on the same host and take the possible load of each of the microservices into account both before and during operation ensuring that resources are not exhausted by a single microservice No silver bullet The description above should clarify how microservices pro vide a natural way to reach scalability including availability and fault tolerance However this does not come for free having multiple independent entities intro duce some extra administrative overhead in particular for deployment admin istration monitoring and security While there are approaches to mitigate these problems but still far from satisfactory at least concerning security this means that sometimes microservices are not the solution The description above should help to understand the advantages of microservices and deciding whether they are a good technique for the problem at hand We discuss below some concrete cases to further clarify the issue 3 The Language Choice While microservice architectures can be built using a wide range of technologies possibly combined into the same system we think that the use of a dedicated lan guage can simplify the development of microservice systems Our experience is based on the language Jolie the only language we are aware of natively support ing microservice architectures While we refer to 17 for a detailed description of the Jolie language we recall here its features that come handy for our discussion and in particular the ones related to the characteristics of microservices above In Jolie each program is a microservice and its description is composed by a behaviour and some deployment information concerning how it can commu nicate with other microservices In this sense distribution is inherent in the language since each microservice makes its functionalities available at a speci c URL and can be invoked by other microservices Nonuniform scalability can be easily obtained new microservice instances can be run and one can eas ily redirect requests from a single microservice to a load balancer targets of microservice invocations are a rstclass object in Jolie hence they can be easMicroservices How To Make Your Application Scale ily and dynamically changed Primitives for architectural composition such as redirection or aggregation also help in this direction The support that Jolie pro vides to these basic aspects and the fact that it fully supports the microservice paradigm ensure that also the other relevant properties hold Indeed Jolie has no speci c language support for containerization or elasticity and indeed how such a language support can be provided and whether it would be bene cial for the language or not is an active topic of discussion in the Jolie community However Jolie microservices can be easily deployed in Docker 15 containers or on the cloud hence what said above in this respect holds for Jolie microser vices as well We close this section with a note on robustness Jolie provides advanced mechanisms for fault noti cation between di erent microservices 12 These mechanisms allow detailed control on whether faults are propagated from one microservice to the ones interacting with it Indeed non propagating them allows one to avoid cascading errors but careful propagation allows one to restore a correct distributed state for the whole system while preserving the indepen dence of the single microservices Indeed each microservice is responsible for restoring its own state but distributed coordination allows one to ensure global consistency 4 Applications Microservice architecture has an ideal application where scalability minimality and cohesiveness are required Several companies nowadays are moving their monolithic architectures to microservices to reap bene ts of scalability Net ix is one such example  they were one of the pioneers who moved from monolith to microservices 10 Now Net ix underlying microservice architecture enables them to scale e ectively and serve millions of users everyday Portability was used by Net ix not only to make deployment and relocation easier but also to automatise the deployment a deployment tool that knew how to deploy a container could deploy it no matter what was inside it Microservice architecture also allowed Net ix to improve robustness and availability by launching a service called Chaos monkey 3 to continuously test for faults within the system Chaos monkey as the name suggests causes chaos inside the system by shutting down various services randomly and observing how the system would adapt to these failures Despite the fact that Chaos Monkey produces faults on the running system the system still operates within the limited period of time when engineers are able to respond to the possible crash Our research group has investigated another application of the architectural style exploiting the exibility of the Jolie programming language the emerg ing area of smart buildings with an outlook on IoT and smart cities Rooms of a building have been equipped with a number of devices and sensors in or der to capture the fundamental parameters determining wellbeing comfort and livability of humans such as temperature humidity and illumination 22 23 The purpose is to monitor and optimize working conditions and the softwareNicola Dragoni et al infrastructure tightly connected to the hardware makes use of Jolie and mi croservices The system is designed separating the logic into small components Each service is responsible for managing one sensor or one speci c function Some ser vices are written in Java for a simpler interaction with devices and Jolie works as an orchestrator for the entire set of services There are several advantages in this approach First of all reusability  The system supports di erent kinds of sensors but the central logic of data extraction is unchanged even when sen sors are added removed or substituted Second code readability  since services are simple components with a simple logic and a clear naming convention The combination of readability and reusability also leads to reduced bugs Scalabil ityminimality andcohesiveness are necessary due to the need of connecting sensors and actuators removing them adding new ones managing faults and monitoring the dynamic nature of the infrastructure especially when mobile de vices and things are part of the system The elasticity of the context has to be managed partially automatically partially through human intervention from a central control panel therefore demanding the need for service orchestration and work ow management 5 Microservices and Beyond The microservice architecture does not build on vacuum and relates to well established paradigms such as OO and SOA In 9 a comprehensive survey on recent developments of microservice architecture is presented focusing on the evolutionary aspects more than the revolutionary ones The presentation there is intended to help the reader in understanding microservices their origin and their possible future Microservices can be built using a wide range of technologies combined into the same system However we support the idea that a languagebased approach can simplify development 4 Jolie is the only language we are aware of that is natively supporting the paradigm Work ow engines have been around for long 13 and work ow languages capable of describing service orchestration have been released and used in the past for example WSBPEL 20 WSBPEL provides indeed many of the features necessary to describe work ows of services plus communication aspects ports interfaces Dynamic work ow recon gura tion can be expressed too 14 However WSBPEL has been designed for high level orchestration while programming the internal logic of a single microservice requires negrained procedural constructs Our research team has been deeply involved in the microservice community and actively contributed to its broader adoption As an open source project Jolie has already built a community of developers worldwide  both in industry and in academia  taking care of the development continuously improving its usability and therefore broadening the adoption Recent developments and con tributions from our team are extension of the type system 21 development of static type checking 24 addition of more iterative control structures to supportMicroservices How To Make Your Application Scale programming and inline automatic documentation 1 These works geared up the development environment and started the process of transforming it into a full suite that makes the entire concept attractive to developers and marketable to companies The future is certainly not challengefree Security of the paradigm is an issue almost fully untouched 9 Commerciallevel quality packages for development are still far to come despite the acceleration in the interest regarding the matter Fullyveri ed software is an open problem the same way it is for more traditional development models A main open problem is how microservices may integrate with the two main emerging platforms which will likely dominate the near fu ture the cloud and the Internet of Things While microservices seem ideal to run on the cloud thanks to their properties of portability and elasticity running on the Internet of Things still present some diculties In particular many things have low computational capabilities and present higher risks from a security point of view since they are easier to compromise 8 As an example of this sec ond point just consider that botnets such as Mirai 16 are composed by things routers IP cameras digital video recorders     which normally have very low protection eg passwords xed by the manufacturer and never changed 6 Hence integration of microservices and the Internet of Things would make the need for speci c security solutions even more urgent References 1 A Bandura N Kurilenko M Mazzara V Rivera L Sa na and A Tchitchi gin Jolie community on the rise In 2016 IEEE 9th International Conference on ServiceOriented Computing and Applications SOCA  pages 4043 2016 2 A B Bondi Characteristics of scalability and their impact on performance In WOSP  pages 195203 2000 3 A Tseitlin C Bennett Chaos Monkey Released Into The Wild httptechblognet ixcom201207chaosmonkeyreleasedintowildhtml 2012 4 M Mazzara F Montesi C Guidi I Lanese Microservices a languagebased ap proach In Present and Ulterior Software Engineering  Springer 2017 5 E Santana de Almeida A Alvaro D Lucr edio V Cardoso Garcia and S Romero de Lemos Meira Rise project Towards a robust framework for software reuse In IRI pages 4853 2004 6 M De Donno NDragoni A Giaretta and M Mazzara AntibIoTic Protecting IoT Devices Against DDoS Attacks In Proceedings of 5th International Conference in Software Engineering for Defence Applications  2017 7 N Dragoni S Dustdar ST Larsen and M Mazzara Microservices Migration of a mission critical system httpsarxivorgabs170404173 8 N Dragoni A Giaretta and M Mazzara The internet of hackable things In Proceedings of 5th International Conference in Software Engineering for Defence Applications  2017 9 N Dragoni M Mazzara S Giallorenzo F Montesi A Lluch Lafuente R Musta n and L Sa na Microservices yesterday today and tomorrow In Present and Ulterior Software Engineering  Springer Berlin Heidelberg 2017Nicola Dragoni et al 10 M McGarr E Bukoski B Moyles How We Build Code at Net ix httptechblognet ixcom201603howwebuildcodeatnet ixhtml 2016 11 E Evans Domaindriven design tackling complexity in the heart of software  AddisonWesley Professional 2004 12 C Guidi I Lanese F Montesi and G Zavattaro Dynamic error handling in service oriented applications Fundam Inform  95173102 2009 13 F Maurer G Succi H Holz B K otting S Goldmann and B Dellen Soft ware process support over the internet In Proceedings of the 21st international conference on Software engineering  pages 642645 ACM 1999 14 M Mazzara F Abouzaid N Dragoni and A Bhattacharyya Design modelling and analysis of a work ow recon guration In International Workshop on Petri Nets and Software Engineering  pages 1024 2011 15 D Merkel Docker lightweight linux containers for consistent development and deployment Linux Journal  20142392 2014 16 Mirai botnet  wikipedia httpsenwikipediaorgwikiMirai malware 17 F Montesi C Guidi and G Zavattaro ServiceOriented Programming with Jolie InWeb Services Foundations  pages 81107 Springer 2014 18 B Cli ord Neuman Scale in distributed systems In Readings in Distributed Computing Systems  pages 463489 IEEE Computer Society Press 1994 19 S Newman Building Microservices  OReilly Media Inc 2015 20 OASIS Web Services Business Process Execution Language Version 20  2007 httpdocsoasisopenorgwsbpel20OSwsbpelv20OSpdf 21 L Sa na M Mazzara F Montesi and V Rivera Datadriven work ows for microservices genericity in jolie In AINA  2016 22 D Salikhov K Khanda K Gusmanov M Mazzara and N Mavridis Jolie good buildings Internet of things for smart building infrastructure supporting concur rent apps utilizing distributed microservices In CCIT  pages 4853 2016 23 D Salikhov K Khanda K Gusmanov M Mazzara and N Mavridis Microservicebased iot for smart buildings In WAINA  2017 24 A Tchitchigin L Sa na M Mazzara M Elwakil F Montesi and V Rivera Re nement types in jolie In SpringSummer Young Researchers Colloquium on Software Engineering SYRCoSE  2016 Microservices Architecture Enables DevOps An Experience Report on Migration to a CloudNative Architecture Armin Balalaie Abbas Heydarnoori Pooyan Jamshidi Abstract The microservices architecture is one of the rst servicebased architectural styles that has been introduced applied in practice and become popular when the DevOps practices gained momentum in the software industry Migrating monolithic architectures to cloudnative architectures like microservices brings in many bene ts such as exibility to adapt to the technological changes and independent resource management for di erent system components Here we report our experiences and lessons learned during incremental migration and architectural refactoring of a commercial Mobile Backend as a Service to microservices We provide a detailed explanation of how we adopted DevOps and its practices and how these practices facilitated a smooth migration process Furthermore we have taken a step towards devising microservices migration patterns by wrapping our experiences in di erent projects into reusable migration practices 1 Introduction According to Google Trends both DevOps and microservices are recognized as growing concepts and interest ingly with an equal rate after 2014 cf Figure 1 Although DevOps practices can also be used for monoliths but microservices enables an e ective implementation of the DevOps through promoting the importance of small teams 1 Microservices architecture is a cloudnative architecture that aims to realize software sys tems as a package of small services each independently deployable on a potentially di erent platform and technological stack and running in its own process while communicating through lightweight mechanisms like RESTful or RPCbased APIs eg Finagle In this setting each service is a business capability that can utilize various programming languages and data stores and is developed by a small team 2 Migrating monolithic architectures to microservices brings in many bene ts including but not limited to exibility to adapt to the technological changes in order to avoid technology lockin and more importantly reduced timetomarket and better development team structuring around services 3 Here we explain our experiences and lessons learned during incremental migration of the Backtory http wwwbacktorycom  platform a commercial Mobile Backend as a Service MBaaS to microservices in the context of the DevOps practices Microservices helped Backtory in a variety of ways especially in shipping new features more frequently and in providing scalability for the collective set of users coming from di erent mobile application developers Furthermore we report on a number of migration patterns based on our observations in di erent migration projects These patterns can be used by either practitioners who aim to migrate their current monolithic software systems to microservices or system consultants who help organizations to prepare migration plans for adopting the DevOps practices in the migration process towards the microservices To save space the details of these migration patterns are provided in a supplementary technical report 4 1Figure 1 Google Trends report for DevOps and Microservices keywords DevOps and Microservices SIDEBAR DevOps is a set of practices 1 which not only aims to de crease the time between applying a change to a system and the change being transferred to the production environment but also insists on keeping the software quality in terms of both code and the delivery mech anism as one of the key elements in the development process Any techniques that enables the mentioned goal is considered as a DevOps practice 1 5 Continuous Delivery CD 6 is a DevOps practice that enables ondemand deployment of a software to any environment through the automated machinery CD is an essential counterpart for microservices as the number of deployable units increases Yet another critical DevOps practice is the Continuous Monitoring CM 7 which not only provides developers with performancerelated feedbacks but also facilitates detecting any operational anomalies 5 2 The Architectural Concerns for Microservices Migration 21 The Architecture of Backtory Before the Migration Backtory is a commercial MBaaS platform that has been developed in PegahTech Co  httpwww pegahtechir  Backtory provides mobile developers who does not know any serverside programming languages with backend services The original functionality of Backtory was a RDBMS as a Service De velopers could de ne their database schemas in the Backtorys developer dashboard and Backtory would provide them an SDK for their desired target platform eg Android or iOS Afterwards the developers can only code in their desired platforms using their domain objects and the objects would make some service calls on their behalf in order to ful ll their requests Over time new services are being added to Backtory like Chat as a Service Indexing as a Service NoSQL as a Service and so on Backtory is written in Java using the Spring framework The underlying RDBMS is an Oracle 11g Maven is used for fetching dependencies and building the project All of the services were in a Git repository and the modules feature of Maven was used to build di erent services The deployment of services to development machines was done using the Mavens Jetty plugin However the deployment to the production machine was a manual task The architecture of Backtory before the migration to microservices is illustrated in Figure 2a In this gure solid arrows and dashed arrows respectively illustrate the direction of service calls and library dependencies Figure 2a also demonstrates that Backtory consisted of ve major components see Appendix A 222 Why Did We Plan to Migrate Towards the Microservices in the First Place What motivated us to perform a migration to a microservices architecture was an issue raised with a require ment for a Chat as a Service To implement this requirement we chose ejabberd due to its known builtin scalability and its ability to run on clusters To this end we wrote a python script that enabled ejabberd to perform authentications using our Backtory platform The big issue in our service was the ondemand capability This issue made us to perform a series of actions which resulted in raising new motivations for migration to microservices The need for reusability To address the ondemand capability we started to automate the process of setting up a chat service One of these steps was to spin o a database for each user In our system there was a pool of servers each of which had an instance of the Oracle DBMS installed and an instance ofDeveloperServices running During the RDBMS instantiation a server was selected randomly and related users and tablespaces were created in the Oracle server This had several issues since it was just designed to ful ll the RDBMS service needs and it was tightly coupled to the Oracle server Consequently we needed a database reservation system that both of our services could use The need for decentralized data governance Another issue was that every time anyone intended to add some metadata about di erent services they were added to DeveloperData  This was not a good practice since services are independent units that only share their contracts with other parts of the system The need for automated deployment As the number of services was growing another problem was to automate the deployment process and to decouple the build life cycle of each service from others The need for builtin scalability The vision of Backtory is to serve millions of users By increasing the number of services we needed a new approach for handling such kind of scalability because scaling services individually requires major e orts and can be errorprone if not handled properly Therefore our solution was to locate service instances dynamically through the Service Discovery 4 component and balancing the load among them using an internal Load Balancer component 23 The Target Architecture of Backtory After the Migration To realize microservices architecture and to satisfy our new requirements we transformed the Backtorys core architecture to a target architecture by performing some refactorings These changes included introducing microservicesspeci c components and rearchitecting the system In the stateoftheart about microservices 8 9 Domain Driven Design and Bounded Context are introduced as common practices to transform the systems architecture into microservices 10 As we did not have a complex domain we decided to rearchitect the system based on domain entities in the DeveloperData  The nal architecture is depicted in Figure 2g The new technology stack for Backtory was the Spring Boot for embedded application server and fast service initialization the operating systems environment variables for con guration and the Spring Clouds Context and the Con g Server for separating the con guration from the source code as recommended by the CD practices Additionally we chose the Net ix OSS for providing some of the microservicesspeci c components ie Service Discovery 4 and the Spring Cloud Net ix that integrates the Spring framework with the Net ix OSS project We also chose Eureka for Service Discovery 4 Ribbon as Load Balancer Hystrix as Circuit Breaker 11 and Zuul as Edge Server 4 that all are parts of the Net ix OSS project We speci cally chose Ribbon among other load balancers eg HAProxy because of its integration with the Spring framework and other Net ix OSS projects in particular Eureka 3Figure 2 a The architecture of Backtory before the migration b Transforming DeveloperData to a Service c Introducing Con guration Server d Introducing Edge Server e Introducing Dynamic Service Collaboration f Introducing ResourceManager g Target architecture of Backtory after the migration h The nal delivery pipeline i The monitoring and performance feedback infrastructure j DevOps team formation 43 The Migration Process The changes we made throughout the migration process included i architectural refactorings and ii some necessary changes to enable DevOps 31 Architectural Refactoring Migrating the system towards the target architecture was not a onestep procedure and we performed it incrementally without a ecting the endusers We treated the migration steps as architectural changes adding or removing components that consists of two states i before the migration and ii after the migration 311 Preparing the Continuous Integration Pipeline Continuous Integration CI is the rst step towards CD It allows developers to integrate their work with the others early and on a regular basis and helps to prevent future con icts 6 To this end a CI server an asaservice or selfhosted code repository and an artifact repository are needed We chose Jenkins as the CI server selfhosted Gitlab as the code repository and Artifactory as the artifact repository cf Figure 2h Since services can have a number of instances running deploying microservices using virtualization is not coste ective and introduces a heavy computational overhead Furthermore we needed to use the Con guration Management systems in order to create the production and test environments By utilizing containers we could deploy service instances with lower overheads than the virtualization and with a better isolation Another major bene t is the portability since we could deploy anywhere that supports containerization without any changes to our source codes or container images Docker is a tool for the containerization of applications 12 As we were going to use Docker we needed the Docker Registry to be in our pipeline as well To summarize in this step we integrated the Gitlab Jenkins Artifactory and Docker Registry as a CI pipeline As can be seen in Figure 2h the fundamental di erence between this delivery pipeline with a monolithic one is in the existence of independent pipeline delivery for each service thereby each of them can be deployed independently Previously we were using integration tests which needed running the whole set of tests in case of a change in just one service We replaced integration tests with consumerdriven contracts 13 and tests which leaded to independent testing of each service using expectations of their consumers This change minimizes the interteam coordination which despite of a more complex testing strategy enables forming smaller teams as a DevOps practice 312 Transforming DeveloperData to a Service In this step we changed the DeveloperData to use Spring Boot because of its advantages see Section 23 Furthermore as shown in Figure 2b we changed it to expose its functionalities as a RESTful API In this way its dependent services would not be a ected when the internal structure of DeveloperData changes Since they have servicelevel dependency the governance of DeveloperData entities will be done by a single service and DeveloperData would not act as an Integration Database 14 for its dependent services anymore Accordingly we adapted DeveloperServices andContentServices to use DeveloperData as a service and not as a Maven dependency 313 Introducing Continuous Delivery One of the best practices in the CD is to separate the source code the con guration and the environment speci cation so that they can evolve independently 6 In this way we can change the con guration without 5redeploying the source code By leveraging Docker we removed the need for specifying environments since the Docker images produce the same behavior in di erent environments In order to separate the source code and the con guration we ported every service to Spring Boot and changed them to use the Spring Cloud Con guration Server and the Spring Cloud Context for resolving their con guration values cf Figure 2c In this step we also separated services code repositories to have a clearer change history and to separate the build life cycle of each service We also created the Docker le for each service that is a con guration for creating Docker images for that service We then created a CI job per service and ran them to populate our repositories Having the Docker image of each service in our private Docker registry we were able to run the whole system with Docker Compose using only one con guration le Starting from this step we had an automated deployment on a single server 314 Introducing Edge Server As we were going to rearchitect the system and it was supposed to change the internal service architecture we introduced Edge Server 4 to the system to minimize the impact of internal changes on endusers as shown in Figure 2d Accordingly we adapted the DeveloperWebsite  315 Introducing Dynamic Service Collaboration In this step we introduced the Service Discovery 4 Load Balancer and Circuit Breaker 11 to the system as shown in Figure 2e Dependent services should locate each other via the Service Discovery 4 and Load Balancer and the Circuit Breaker 11 will make our system more resilient during the service calls By introducing these components to the system we made our developers more comfortable with these new concepts and it accelerated the rest of the migration process 316 Introducing ResourceManager In this step we introduced the ResourceManager by factoring out the entities that were related to servers ie the AvailableServer  from the DeveloperData and introducing some new features ie MySQL database reservation for satisfying our chat service requirements cf Figure 2f Accordingly we adapted the DeveloperServices to use this service for database reservations 317 Introducing ChatServices and DeveloperInfoServices As the nal step in the architectural refactoring we introduced the following services see the target archi tecture in Figure 2g The DeveloperInfoServices by factoring out developer related entities eg the Developer  from the DeveloperData  The ChatServices for persisting chat service instances metadata and handling chat service instance creations 318 Clusterization In this step we set up a cluster of CoreOS instances with Kubernetes agents installed on them We then deployed our services on this cluster instead of a single server As can be seen in Figure 2h independent testing of services using consumerdriven tests enabled us to also deploy each service independently Hence the occurrence of a change in a service would not result in the redeployment of the whole system anymore 632 Crosscutting Changes 321 Filling the Gap Between the Dev and Ops via Continuous Monitoring In the context of microservices each service can have its own independent monitoring facility owned by the Ops team and thereby enables independent ow of per service performance information to the development Appropriate parametric performance models can be adopted in order to provide a good estimate of the endtoend system performance or to facilitate whatif analyses This helps the Dev team to refactor the architecture in order to remove the performance bottlenecks 5 As shown in Figure 2i the microservices monitoring solution we used consists of both of the client and server containers The server container takes care of the actual monitoring tools In our deployment it contains Kibana for visualization and Elasticsearch for consolidation of the monitoring metrics Through the capabilities of Elasticsearch one can horizontally scale and cluster multiple monitoring components The client container contains the monitoring agents and the facilities to forward the data to the server In this particular instance it contains the Logstash and the collected modules The Logstash connects to the Elasticsearch cluster as the client and stores the processed and transformed metrics data there Note that with this architecture we are able to monitor each microservice independently and react to any anomalies that we can uncover based on the online monitoring data For detecting anomalies we used a statistical model that we trained using the monitoring data in normal situations and then for each new incoming monitoring data point the anomaly detection module calculates a score with the help of principle component analysis to spot outliers 322 Changing Team Structures Traditional software methods encourage horizontal division of project members to functionally separated teams This division normally causes the creation of Dev QA and Ops teams cf Figure 2j This type of separation delays the development life cycle in transition between teams and through various reactions which exist regarding the change frequency in di erent teams Moreover in the microservices setting as each team would be responsible for their own services they cannot bene t from the higher comprehensibility of the code and easier joining of new team members which is caused by the decomposition of the system In contrast DevOps recommends vertical dividing of project members into small crossfunctional teams which also ts microservices well Each team is responsible for a service and consists of people with di erent skills like development and operations skills and they cooperate from the beginning of the project to create more value for the endusers of that particular service through more frequent release of new features to the production and hence remove the transition overheads which were existed in the horizontal team formation Furthermore as each team is focused on a particular service the maintainability and comprehensibility of each services code is much higher and new members can be added to the teams with a lower learning curve During the migration as depicted in Figure 2j we gradually formed small crossfunctional teams for each new service constructed as a result of architectural refactorings Furthermore we formed a core team consisted of representatives of each services team which is responsible for shared capabilities This team has an overall view of the service interactions in the system and are in charge of any critical architectural decision Additionally any interservice refactorings which involves transferring of functionalities between services and updating the corresponding rules in the Edge Server 4 are handled through this team 4 Lessons Learned Migrating an onpremise application to a microservices architecture is a nontrivial task During this migra tion we faced several challenges that we were able to solve In the following we share some of the lessons 7we have learned in this process that we think might be helpful for others who are also trying to migrate to microservices Deployment in the development environment is dicult It is true that the applications code is now in isolated services however to run those services in their machines developers need to deploy the dependent services as well We had this problem since the Introducing Dynamic Service Collaboration step In our case we chose the Docker Compose and put a sample deployment description le in each service so that the dependent services can be easily deployed from our private Docker registry Service contracts are critical Changing so many services that only expose their contracts to each other could be an errorprone task Even a small change in the contracts can break a part of the system or even the system as a whole Service versioning is a solution Nonetheless it could make the deployment procedure of each service even more complex Therefore people usually do not recommend service versioning for microservices Thus techniques like Tolerant Reader 13 are more advisable in order to avoid service versioning Consumerdriven contracts 13 could be a great help in this regard as the team responsible for the service can be con dent that most of their consumers are satis ed with their service Distributed system development needs skilled developers Microservices is a distributed architectural style Furthermore in order for it to be fully functional it needs some supporting services like service discovery load balancer and so on At the early steps of migration we tend to spend a lot of time for describing these concepts and their corresponding tools and libraries to novice developers and still there were many situations that they misuse them Hence to get the most out of microservices those team members are needed who are familiar with these concepts and are comfortable with this type of programming Creating service development templates is important Polyglot persistence and the usage of di erent programming languages are promises of microservices Nevertheless in practice a radical interpretation of these promises could result in a chaos in the system and make it even unmaintainable As a solution from the beginning of architectural refactoring steps we started to create service development templates We have di erent templates for creating a microservice in Java using di erent data stores which includes a simple sample of a correct implementation Recently we are also working on creating templates for NodeJS One simple rule is that each new template should be rst considered by a senior developer for identifying potential challenges Microservices is not a silver bullet Microservices was bene cial for us because we needed that amount of exibility in our system and that we had the Spring Cloud and Net ix OSS that made our migra tion and development a lot easier However as mentioned before by adopting microservices several complexities would be introduced to the system that require a considerable amount of e ort to resolve them 8Figure 3 The process of selecting patterns instantiating and composing a migration plan as well as extending the repository 5 Microservices Migration Patterns After conducting the migration project described so far in this article we decided to make our experiences and best practices more accessible for other similar projects by abstracting them as migration patterns  In this way these practices can be reused to create a migration plan by instantiating and composing the patterns Migrating to cloud and speci cally migrating through cloudnative architectures like microservices is a multidimensional problem and consequently it is a nontrivial task 15 Therefore in the absence of a wellthought methodology it can be transformed to a trialanderror endeavor which may not only waste a lot of time but also lead to a wrong solution Furthermore as factors like the requirements the current situation the skills of team members etc could vary in di erent companies and scenarios a unique and rigid methodology would not suce Thus instead of a one tall methodology we decided to choose a Situational Method Engineering SME  16 approach The rst step towards the SME approach is to prepare a method base or pattern repository consisting of reusable process patterns or method chunks each instantiated from a prede ned metamodel To this end using our previous experience in de ning migration patterns 17 we documented our experience in this project and similar practices in the stateoftheart of microservices see 4 3 httpmicroservices io as method chunks We tried to enrich each step in our migration with the precise de nition of the corresponding situation the problem to be solved and the possible challenges of the proposed solution forming a pattern template see 4 Part of these patterns relates to exactly describing why we need supporting components eg Service Discovery 4 and the prerequisites for their introduction Additionally we provided some solutions and advices for decomposing a monolithic system to constituting services and preparing the current and the target architectures of the system as a roadmap for migration planning Still we provide some hints about the containerization of services and their deployment in a cluster The details of our patterns can be found in 4 However for traceability purposes a mapping between the identi ed patterns and the corresponding sections in this article that describe those patterns can be found in Table 1 As shown in Figure 3 having an initial set of these patterns available a method engineer can construct a concrete method based on his speci c requirements for the migration by applying the construction guidelines For example following the need for polyglotness  one can reach the decomposition patterns Then with respect to her speci c needs she can select a suitable pattern 9Table 1 Patterns and Sections map Identity Pattern Name Section DevOps Impact MP1 Enable the Continuous Integration 311 CI is the rst step towards CD which is a known DevOps practice MP2 Recover the Current Architecture 22 Enables the decomposition of the system to smaller ser vices which leads to smaller teamsMP3 Decompose the Monolith 23 MP4 Decompose the Monolith Based on Data Ownership23 MP5 Change Code Dependency to Ser vice Call312 MP6 Introduce Service Discovery 315Dynamic discovery of services removes the need for man ual wiring thereby advocates more independent deploy ment pipelinesMP7 Introduce Service Discovery Client 315 MP8 Introduce Internal Load Balancer 315 MP9 Introduce External Load Balancer 315 MP10 Introduce Circuit Breaker 315 Failing fast can decrease the coupling between services and thereby contributes to the independency of services deployment MP11 Introduce Con guration Server 313 Separating con guration from code is a CD best practice and CD is a known DevOps practice MP12 Introduce Edge Server 314 Edge Server not only allows Dev to more easily change the internal structure of the system but also permits Ops to better monitor the overall status of each service MP13 Containerize the Services 313 Containers can produce the same environment in both production and development thus reduces the con icts between Dev and Ops MP14 Deploy into a Cluster and Orches trate Containers318 Cluster management tools reduce the diculties around deployment of many instances from di erent services in production thus reduces the resistance of Ops towards Dev changes MP15 Monitor the System and Provide Feedback321 Performance monitoring enables systematic collection of performance data and sharing to enhance decision mak ing For example the Dev team can use such information to refactor the architecture if they nd out there exists a performance anomaly in their system The architectural refactorings as the result of pattern applications cannot occur in an ad hoc manner There exists some invariants that should be satis ed during the architectural transition 18 Keeping the system in a stable state after applying a pattern performing one architectural change at a time and keeping the endusers of the system una ected are the most important invariants which should be taken into account during an architectural change Although a single step itself needs to conform to these invariants the steps and their execution order collectively can violate them and therefore the method engineer should consider this during the migration pattern selection In the migration process of Backtory we have introduced the Edge Server before introducing components related to dynamic collaboration between services for making all of the following changes transparent to endusers If the order of these steps have been changed we could not satisfy some of the mentioned invariants Each of the future migrations can contribute to the repository of patterns as well This can be done via introducing new migration patterns that were lacking before and were used in that particular project This repository will serve as an extensible source for the DevOps community through which they can reuse patterns for migrating towards microservices like the one for architectural patterns at httpmicroservicesio  1051 How the Microservices Migration Patterns Enable DevOps Traditional methods for software development advocate separated Dev and Ops team in which the Dev team provides the Ops team with deployment artifacts and details The problem is that these teams have di erent behaviors regarding the frequency of changes such that the Dev team tends to produce more changes and the Ops team insists on higher stability Furthermore due to the existence of large teams working on monolithic systems any changes needs a lot of coordination Even with the componentization of the system the nal integration needs that amount of coordination and the problem is still present These issues collectively delays the whole development life cycle DevOps together with microservices are tackling the above mentioned issues via providing the necessary equipments for minimizing the coordination amongst the teams responsible for each component and remov ing the barriers for an e ective and reciprocal relationship between the Dev and the Ops teams Indeed in the DevOps setting these teams help each other through continuous valuable feedbacks To elaborate further in Table 1 we brie y describe the impact of our devised patterns on the DevOps and the problems they tackle Appendix A Backtory Components Before the Migration Backtory consisted of the following ve components before the migration CommonLib This is a place for putting shared functionalities like utility classes that are going to be used by the rest of the system DeveloperData This holds the information of developers who are using the Backtory service and their domain model metadata entities that are shared between the DeveloperServices and the ContentServices components DeveloperServices This is where the services related to managing the domain model of developers projects reside in Using these services developers could add new models edit existing ones and so on ContentServices This holds the services that the target SDK is using to perform the CRUD operations on the models objects DeveloperWebsite This is an application written in HTML and JQuery and acts as a dashboard for developers For this purpose it leverages the DeveloperServices component References 1 L Bass I Weber and L Zhu DevOps A Software Architects Perspective  AddisonWesley Profes sional 2015 2 M Fowler and J Lewis Microservices httpmartinfowlercomarticlesmicroserviceshtml  March 2014 Last accessed 3October2015 3 A Balalaie A Heydarnoori and P Jamshidi Migrating to cloudnative architectures using microser vices An experience report in In Proceedings of the 1st International Workshop on Cloud Adoption and Migration  September 2015 114 A Balalaie A Heydarnoori and P Jamshidi Microservices migration patterns Tech Rep TRSUT CEASE201501 Automated Software Engineering Group Sharif University of Technology Tehran Iran October 2015 Available Online at httpasecesharifedupubstechreportsTRSUTCEASE 201501Microservicespdf 5 A Brunnert A van Hoorn F Willnecker A Danciu W Hasselbring C Heger N R Herbst P Jamshidi R Jung J von Kistowski A Koziolek J Kro S Spinner C V ogele J Walter and A Wert Performanceoriented devops A research agenda CoRR  vol abs150804752 2015 6 J Humble and D Farley Continuous delivery Reliable Software Releases through Build Test and Deployment Automation  AddisonWesley Professional 2010 7 A van Hoorn M Rohr W Hasselbring J Waller J Ehlers S Frey and D Kieselhorst Continuous monitoring of software services Design and application of the kieker framework research report Kiel University November 2009 8 S Newman Building Microservices  OReilly Media 2015 9 M Stine Migrating to CloudNative Application Architectures  OReilly Media 2015 10 V Vernon Implementing Domaindriven Design  AddisonWesley Professional 2013 11 M Nygard Release It Design and Deploy ProductionReady Software  Pragmatic Bookshelf 2007 12 C Pahl Containerization and the paas cloud IEEE Cloud Computing  no 3 pp 2431 2015 13 R Daigneau Service Design Patterns Fundamental Design Solutions for SOAPWSDL and RESTful Web Services  AddisonWesley Professional 2011 14 G Hohpe and B Woolf Enterprise Integration Patterns Designing Building and Deploying Messaging Solutions  AddisonWesley Professional 2004 15 P Jamshidi A Ahmad and C Pahl Cloud migration research A systematic review IEEE Trans actions on Cloud Computing  vol 1 pp 142157 July 2013 16 B HendersonSellers J Ralyt P Agerfalk and M Rossi Situational Method Engineering  Springer Verlag Berlin Heidelberg 2014 17 P Jamshidi C Pahl S Chinenyeze and X Liu Cloud migration patterns A multicloud architec tural perspective in Proceedings of the 10th International Workshop on Engineering ServiceOriented Applications  2014 18 A Ahmad P Jamshidi and C Pahl Classi cation and comparison of architecture evolution reuse knowledgea systematic review Journal of Software Evolution and Process  vol 26 no 7 pp 654691 2014 12About the Authors Armin Balalaie is a masters student at the Sharif University of Technology His re search interests include software engineering cloud computing and distributed systems Contact him at arminbalalaiegmailcom  Abbas Heydarnoori is an assistant professor at the Sharif University of Technology Before he was a postdoctoral fellow at the University of Lugano Switzerland Abbas holds a PhD from the University of Waterloo Canada His research interests focus on reverse engineering and reengineering of software systems mining software repositories and recommendation systems in software engineering Contact him at heydarnoori sharifedu  Pooyan Jamshidi is a postdoctoral research associate in the Department of Com puting at Imperial College London UK Pooyan holds a PhD in Computing from Dublin City University Ireland His primary research interest is in the areas of selfadaptive software where he applies statistical machine learning and control theory to enable selforganizing behaviors in distributed systems which are designed to process big data Contact him at pjamshidiimperialacuk  13 ,https://en.wikipedia.org/wiki/Microservices,Back-End Development,4987,29854
API Design and Development, Jump to section Jump to section Topics Understanding APIs What is API design What is API design Published January 8 2019 tminute readCopy URL OverviewAPI design refers to the process of developing application programming interfaces APIs that expose data and application functionality for use by developers and users APIs are important to modern organizations adding new capabilities to everything from their operations and products to their partnership strategies Its no longer a stretch to say that most organizations dont ask whether to engage in API programs but how to do so An effective API program has to build on an organizations overarching corporate strategy and contribute to its objectives Youll know you have the makings of a great strategy when you can answer the following 3 questions in a clear wayWhy do we want to implement APIsWhat concrete outcomes do we want to achieve with these APIsHow do we plan to execute the API program to achieve thatThe whyPeople often misinterpret this question in different ways Firstly rather than focus on the value of the API its helpful to think of the value of the effect of the API Remember its the organizations core business thats valuable not necessarily the API An API is valuable when it becomes a channel that provides new types of access to the existing value an organization deliversAnother common misconception is believing that for an API to be valuable users must be prepared to pay for it This is true only if the API itself is the product In most models this is not the case APIs are usually driving some other metricsales affiliate referrals brand awareness etc The value of the API to users is the result of an API call service request and response rather than the call itselfThe most common business drivers for establishing an API program according to a survey of 152 organizations conducted by the Cutter Consortium and Wipro are to develop new partnerships to increase revenue to exploit new business models to improve time to market and to develop new distribution channels The top technology drivers are to improve application integration improve mobile integration and support the connection to more devices The benefits to the organization need to be strong enough to make the decision to invest in the APIs an obvious choice for the organizationThe whatThe second question should be What concrete outcomes do we want to achieve with these APIs In other words What do the APIs actually do and what impact do they have on the wider business strategyBoth the concepts of the internal view and the external view of an organization can help to define the what of the API The internal view refers to specific valuable assets an organization possesses The more valuable and unique the services and resources offered the more suitable they are for an API programAn organization that has unique data could take advantage of this resource by allowing access to the data via API Unique content data and services can make access to the API extremely valuableWhen deciding what an API should do for a business both internal and external views need to be examined The decision about the what is then usually a combination of the 2 viewsIn concrete terms while the why is unlikely to change often the what may vary significantly based on external factorssuch as markets technical considerations or economic conditions Internal directions about the value of an asset may change which could also affect what should be achieved with an APIThe howThe final question How do we design our API program to achieve what we want is all about implementation and executionTeams must ask themselvesWhat technology is used to build the APIsHow are the APIs designedHow are the APIs maintainedHow are the APIs promoted inside the organization or marketed to the outside worldWhat resources are availableWho should be on the teamHow do we track success against the business goals that have been set What does this mean for your APIsFinding and describing the value of your API is an iterative process The first step is describing jobs your users are trying to get done For exampleAutomatically sending urgent communications to team members in an emergencyBacking up critical files to ensure they are never lostCollecting sample data to detect certain eventsThe next step is identifying particular challenges that affect users before during or after trying to get a job doneEnsuring the reliability of sending with multiple tries detecting failures worrying about many messages being sent rather than just one and integrating with different message delivery systems depending on the location of the userEnsuring the safe delivery of files but also minimizing the amount of transfer bandwidthDealing with massive amounts of data and attempting to correlate it in real timeThe third step is to summarize the potential gains a user could achieveSending other types of notifications which create opportunity rather than warn of threatGetting rid of other storage equipment if reliability meets your needsAutomatically triggering actions based on the eventsWhen examining these pain points think broadly and list things like support documentation or developer portalseverything that a customer could use Next outline how you intend to eliminate or reduce some of the things that may be annoying to API users before during or after trying to complete a jobor issues that prevent them from doing so Then describe how you intend to create gains of any sort for your API usersThrough engaging in this process our 3 examples above might result inA multichannel messaging API with a single call to deliver messages and the ability to retry automatically until arrival is guaranteed eg Twilio PagerDutyA storage synchronization API with optimized calls to efficiently check if new versions should be synchronized eg Bitcasa BoxAn API aggregating several data sources into a configurable stream which could be filtered sampled and easily manipulated eg GNIP DataSiftFinally a useful clarification exercise is to compose several statements that make the fit between the API and the user profile clear If you find it hard to identify such fit statements then the API model needs to be reconsidered Maybe there are API features which need to be added revised refined or eliminated It could also be that your API does offer great value but you are trying to address the wrong type of usersWhen you condense and abstract your fit statements into one overarching statement it becomes your value proposition for your APIs In the case of the messaging API above this might be something likeOur messaging API provides enterprise developers a reliable guaranteed nolatency text messaging functionality for highlycritical business applications The API is also supported by software development kits SDKs covering the most popular programming languages for quick integrationIn some cases you might think This seems like too much work Were just creating an internal API However focussing on value is key even in internal use cases A poorly determined value proposition will lead to difficulty pitching the value of the API to other teams A welldefined value proposition can help ease adoption and make the API program a key contributor to the businessTo help define your own API programs value consider these 5 questionsWho is the user This question should be answered in terms of their relationship to you are they existing customers partners external developers their role are they data scientists mobile developers operations people and their requirements or preferencesWhat user pains are we solving andor what gains are we creating for the user This question should be answered in relationship to the customers business challenges and gains defined by the value proposition and whether or not a critical need is being fulfilled is it a pain point is it a revenue opportunity and what metric is being improved for the user speed revenue cost saving being able to do something newWhich use cases are supported with your API Identify with the help of the value proposition the solutions to your users challenges or opportunities created by the API that are most effective your organization and the user Plan your API to address these use casesHow can the value for the user be expanded over time Plan your value proposition with future changes in mind What are important upcoming milestones relating to internal or external changesWhat value is being created for your organization internally Consider internal benefits and how the API can be of value within the business Make the business model clear from the beginningBeing able to articulate the value of an API is an important milestone in designing your APIbased program However APIs also generate cost and this consideration should be balanced by value While the value may not be measured in monetary terms it must be real for exampleWhat is the existing core business of the organizationHow an API can be used to accelerate or augment this businessIn some cases APIs can lead to entirely new business opportunities outside of the existing business model of an organization Even in these cases APIs generally use existing assets or expertise to create opportunities in new waysIn summary there are 3 reasons why determining the right business model is important for designing effective API programsDetermining the right business model brings the value of the API to the organization into focus which drives the decision regarding longterm commitments to the API program Without that commitment there are rarely resources in place to complete the tasks required for establishing and running an effective API programDetermining the right business model helps to define the functionality of the product which is needed to satisfy third parties and generate businessDetermining the right business model ensures attention is paid to roles and responsibilities within an organization and to who retains which parts of the value generated by the API This also implies defining what users of the API gain from use of the API and how that balances against what the API provider gains Design and implement with the user in mindGood API design has some core principles which may differ in implementation Heres an analogy every car has a steering wheel brake pedals and an accelerator You might find that the hazard lights the trunk release or radio are slightly different from model to model but its rare that an experienced driver cant figure out how to drive a rental carThis level of readytodrive design is what great API teams strive forAPIs which require little or no explanation for the experienced practitioner to begin using themSimplicitySimplicity of API design depends on the context A particular design may be simple for one use case but very complex for another so the granularity of API methods must be balanced It can be useful to think about simplicity on several levels includingData format Support of XML JSON proprietary formats or a combinationMethod structure Methods can be very generic returning a broad set of data or very specific to allow for targeted requests Methods are also usually called in a certain sequence to achieve certain use casesData model The underlying data model can be very similar or very different to what is actually exposed via the API This has an impact on usability as well as maintainabilityAuthentication Different authentication mechanisms have different strengths and weaknesses The most suitable one depends on the contextUsage policies Rights and quotas for developers should be easy to understand and work with FlexibilityMaking an API simple may conflict with making it flexible An API created with only simplicity in mind runs the risk of becoming overly tailored serving only very specific use cases and may not be flexible enough for other use casesTo establish flexibility first find out what the potential space of operations is based on including the underlying systems and data models and defining what subset of these operations is feasible and valuable In order to find the right balance between simplicity and flexibilityTry to expose atomic operations By combining atomic operations the full space can be coveredIdentify the most common and valuable use cases Design a second layer of meta operations that combine several atomic operations to serve these use casesArguably the concept of hypermedia as the engine of application state HATEOAS can further improve flexibility because it allows runtime changes in the API and in client operations HATEOAS does increase flexibility by making versioning and documentation easier however in API design many questions must be considered Critical questions for considerationIn order to think through your API design consider the following 5 questionsHave we designed the API to support our use cases The next step after identifying the main use cases is to design the API so that it supports these use cases Flexibility is important so as not to exclude any use cases that may be less frequent but should still be supported to allow for innovationAre we being RESTful for the sake of it RESTful APIs are quite fashionable but you shouldnt follow this trend just for the sake of fashion There are use cases which are very well suited for it but there are others that favor other architectural styles such as GraphQLDid we expose our data model without thinking about use cases An API should be supported by a layer that abstracts from your actual data model As a general rule dont have an API that goes directly to your databasealthough there may be cases which require thatWhich geographic regions are most important and have we planned our datacenters accordingly API design must also cover nonfunctional elements such as latency and availability Make sure to choose datacenters that are geographically close to where you have most of your usersAre we synchronizing the API design with our other products If the API is not the sole product of your business make sure that the API design is coordinated with the design of the other products It may be that you decide to completely decouple API design from other products Even if this is the case plans to decouple API design from other products needs to be made clear and communicated both internally and externally Obsess about developer experienceA key metric to improve API design for easy adoption is the Time to first hello world TTFHW In other words how long does it take a developer to reach a minimum viable product with your API This is a great way to put yourself in the shoes of a developer who wants to test your API to see what it takes to get something workingWhen you define the start and end of the TTFHW metric we recommend covering as many aspects of the developer engagement process as possible Then optimize it to be as quick and convenient as possibleBeing able to go through the process quickly also builds developer confidence that the API is well organized and things are likely to work as expected Delaying the success moment too long risks losing developersIn addition to TTFHW we recommend another metric Time to first profitable app TTFPA This is trickier because profitable is a matter of definition depending on your API and business strategy Considering this is helpful because it forces you to think about aspects related to API operations as part of the API programThe 2 underlying principles of developer experience areDesign a product or service that provides a clear value to developers and addresses a clear challenge or opportunity This can be monetary value or some other value such as a way to increase reach brand awareness customer base indirect sales reputation for the developer or simply the joy of using great technology that worksThe product needs to be easily accessible This can include having a lightweight registration mechanism or none at all access to testing features great documentation and a lot of free and tidy source codeWe suggest that most API programs should have a developer programregardless of whether you expose your APIs publicly to partners only or internally only The provisions may be more or less elaborate depending on the audienceDeveloper portalThe developer portal is the key element of a developer program this is the core entry point for developers to sign up access and use your APIs Getting access to your API should be simple and easy for developers They should be able to get started quicklyTTFHW is the best metric to measure this You should also consider streamlining the signup processthe simpler and quicker the better A recommended best practice is that developers should be able to invoke your APIs to examine their behavior request and response without any signup at all Also supplementary contentsuch as getting started guides API reference documentation or source codeare great to lessen the learning curveAcceleration via ecosystem partnersAs an API provider you are operating in an ecosystem of partners and vendors These partners often have their own content distribution and communication networks and means We recommend identifying alliances which can be effective in helping to increase the adoption of your API Often such alliances can be found when APIs are complementary and provide value to developers when combinedQuestions to consider to assess your developer experienceHow do we explain the value of the API in the first 5 minutes Develop an elevator pitch about the value proposition of your API that best speaks to developersWhat is our TTFHW and TTFPA and how do we reduce it This is a powerful way to improve the developer friendliness of your API by thinking about the endtoend TTFHW We recommend keeping the TTFHW and TTFPA metrics in mind when considering any elements that are added to the developer experience like portals and every aspect of the API that changesWhat is the onboarding process for developers and is it as easy as possible This needs to be inline with the use cases of your API The level of security naturally needs to be higher for more sensitive APIs or data access which probably needs more formal agreements For everything else it should very simple and straightforward to allow for early developer success TTFHWAre we allowing enough flexibility to make the API attractive for developers Its great if youve found the right value proposition and developers sign up for your API Keep in mind that helping them to be successful will retain and grow their numbersHow do we support developers if they face problems We believe in the selfservice approach which will help you to scale Many developer questions can be covered by good documentation FAQs or forums But selfservice has its limits and for more indepth questions or other complications like invoice problems there should be some type of support mechanism in placeCan our documentation support innovation What support is there for developers who deviate from the normal use cases or wish to do something new Great ideas can come from anywhereLearn more about Red Hat and API managementIconRed_HatDirectionalABlackRGB Keep reading Article What is an API API stands for application programming interfacea set of definitions and protocols to build and integrate application software Read moreIconRed_HatDirectionalABlackRGB Article What does an API gateway do An API gateway is an application programming interface API management tool that sits between a client and a collection of backend services Read moreIconRed_HatDirectionalABlackRGB Article Why Red Hat for APIs Our API solutions focus on reusability IT agility and a management interface that helps you measure monitor and scale Read moreIconRed_HatDirectionalABlackRGB More about APIs Products An infrastructure platform that lets you share distribute control and monetize your application programming interfaces APIs Learn moreIconRed_HatDirectionalABlackRGB Related articles Understanding APIs What is an API What does an API gateway do What is a REST API What is API design What is API management What is API monetization What is GraphQL Why choose Red Hat for API management What is the Kubernetes API REST vs SOAP API security Resources Ebook Open APIs in Financial Services for Dummies Learn more Podcast Command Line Heroes Season 2 Episode 6 The data explosion Listen now Ebook The API owners manual Learn more Keep exploring OVERVIEW Build an open insurance ecosystem with APIs and Red Hat software EBOOK Service mesh or API management ANALYST MATERIAL API management and security Microsoft wre Google Cloud ,https://www.redhat.com/en/topics/api/what-is-api-design,Back-End Development,1097,3344
"Containerization (e.g., Docker)", Containerization Technology Types Advantages Applications and More Ondemand cloudbased infrastructure services have redefined how organizations scale their products and services What does this mean There is no longer a need to overhaul your entire app infrastructure while adding new features or scaling it the way you envision it And as is known the proactive management and monitoring of enterprise IT infrastructure is the need of the hour What if we say there is a possibility to set up a virtualized Operating System OS inside an existing system that imitates its functionality like an entirely new system In simple words what if you could run an OS virtually inside an existing OS It would help you save tons of development time and cost not to mention maintaining the consistency of software code in all developer systems across your application infrastructure Well the answer to all these questions is nothing but containerization technology Let us first take a look at what containers are then the technology behind them and how you can save development costs by efficiently using them Simform is a proficient Containerization  Orchestration Consulting and Implementation company helping businesses implement a container environment and have platform independence effortless operations high productivity and assured security Contact us today to get started What is containerization technology Containerization technology by default comes from the improvements of virtualization It is also commonly described as OSlevel virtualization Confusing is it Lets break it down Containerization is all about packaging the requirements of an application under development in the form of a base image This image can run in an isolated space containers on different systems It is crucial to remember that these containers share the same OS Most IT leaders are intrigued by this technology because it is often used for deploying and running a distributed app without having to use a Virtual Machine VM VMs had the problem of errorprone coding while transferring application infrastructure from one computing environment to another For example most enterprises found it impossible to build apps when one developer shared a development file from a Linux to a Windowsbased OS In 2013 Docker was introduced eliminating the said problem by disrupting the software development processes It allowed Linuxbased codes to run efficiently on Windowsbased systems via Docker Though it was theoretical back then Microsoft was the first to make this possible in 2016 Ever since many websites and leading tech giants such as Shopify Pinterest Riot Games and more have been using containerization technology It has been used widely to take advantage of DevOps What are containers in DevOps What influence do containers have in DevOps As mentioned above containerized files would be in the form of a base image This image can be shared through an organization across developers operations teams and anyone involved in the project This whole schema is an upgraded methodology of DevOps wherein containers help to bring together various teams and the required development and operational files Building on this mythology for integrating and deploying new features into an app faster gave birth to Continuous Integration CI and Continuous Delivery CD The three main factors that influence containers to play a role in DevOps are Dependency Libraries configurations runtime engine program tools etc of an app bundled can be shared with N number of systems using the same OS Increases collaboration Disposability Easy to pull any data and app requirement in a system and discard the entire container from running when the system does not require anything additional Reduces investment Concurrency Containers use CPU power efficiently unlike VMs This has proven to help create autoscale abilities with any architecture model especially while using the cloud Improves automated development Expert Insight For example by using Docker as a container a code written on Linux can be transferred to a Windowsbased system The Linuxbased application will not require any additional system tools libraries runtime native code or settings to run on Windows during development Sometimes even regardless of the infrastructure How convenient is that Types of containers Today there are a couple of choices to choose from regarding container technology Docker is one of the containers that may ring some bells However it would be fatal for your application to misunderstand the types of containers that exist given the growth and expansion containers have had in recent years In 2015 given the rising popularity of this technology Open Container Initiative OCI decided to keep the standards and specifications of container technology minimal to ensure companies have broader choices to pick from the opensourced and wide variety of container engines that exist today Some of the prominent ones are as follows Docker An opensourced containerized platform that combines the source code of an app with the existing OS and its respective libraries and dependencies It lets the said code run on any computing environment LXC An OSbased container that allows an app to run on multiple Linux systems on a virtual level given it has a single Linux kernel that serves as the host OS CRIO It is a Container Runtime Interface CRI for Kubernetes a container cluster management platform It is a CRI to ensure that it follows the OCI compatible runtimes As a result this tool serves as a replacement for Docker with Kubernetes rkt An applicationbased container engine known as Rocket is used for building modern cloudnative apps It uses CoreOS which functions based on the security improvements that earlier versions of Docker were known to have It is best used with necessary technologies or as specific components of a Dockerbased system Advantages of using containerization technology Containerization technology is spreading widely across industries especially within companies dwelling on the services of cloudready apps Yet even if the app is not cloudready or cloudnative here are some benefits of containers that you may reap Reduction in infrastructure cost since many containers can run on a single machine or even a Virtual Machine VM Monolithic or legacy applications could be containerized using microservice architecture making room for future scaling Improves application security since the app will be stored in separate containers on different systems and isolated from the host Containers are not dependent on any particular OS and can run on any OS given the container engine runs on a host OS Containers are lightweight and faster as they prove to be ready for computation under seconds Docker Use Cases A Demonstrative Guide with Realworld Examples Read More Where can you apply containerization technology Be it implementation of DevOps or migration towards the cloud you may wonder what could be the possible use cases of containers Containerization technology can almost help the development of any application that could have been difficult to build on a system natively Some of the important container use cases are mentioned below Application refactoring Containerization technology plays a massive role in helping development and operation teams leverage the liftandshift approaches during the migration of architectures or necessary app requirements CICD support With containers you can create a streamlined development process for building testing and deploying updates or new features frequently at ease In addition it reduces the repetition of running test cases and avoids the creation of continuous clustering of file transfer between different systems Compliment microservices Simplify the development and delivery process when it comes to Microservice apps with containers as they isolate the workload environments Decoupling an architecture with independent work environments can easily be set up Note Read pros cons use cases and more about microservices to learn how to be more agile and expedite time to market Web server dependence Containers do not require to run directly on the host Instead it can run on any machine and the only requirement is to ensure the host OS is the same on all systems Given that within a few command lines a web server can also be set up within a container How to have a scalable CICD pipeline to optimize the software development process Read More How does containerization technology work Let us break down how containers work without complicating it for you Containers create images of codes written on one system and its respective settings dependencies libraries etc These images operate in the form of container engines that can run on any platform Containers focus on isolating the programmed software from different computing environments This makes it possible to run a code consistently or uniformly across other platforms irrespective of its development differences in staging environment and development practices Containerization technology also serves as a host OS However they are not replicas of a parent OS as mentioned above For example take a look at the below image This image shows how containers exactly work Common myths surrounding containerization technology It is essential to squash out some incorrect understanding of containerization before jumping into what they are This section discusses some of the common misinterpretations of container and containerization in DevOps Misconception Fact Containerization and DevOps are different technology services DevOps and containerization are complementary technologies where DevOps can be considered as the foundational parent technology service Containerizing an application provides greater performance and security Containerization technology improves the development process time and helps to reduce overall cost It helps to ensure security only as a part of the monitoring process followed by its complementary DevOps methodologies Containerization does not offer any standalone security services Containers have evolved to embody a complete platform Containers are tools that help the development process with better management especially while adopting DevOps It does not serve as a parent platform like Linux Windows etc Containers are just VMs VMs run on hypervisors In other words VMs use the host systems resources altogether It runs like a complete OS on top of your current OS On the other hand containers use resources of a host system only for what it needs and when it needs it Moreover containers do not always require a host for the supply of OS resources Containerization technology is only for advanced or cloudpowered apps and not legacy applications Containers are technology tools that can wrap any app without refactoring the entire architecture and yet helps to migrate the legacy code into microservices easily Containerization allows any app to pass through the functionalities of a container provided that the app has a code infrastructure that is compatible for running containers How are organizations cutting costs with containerization Although both containers and VMs focus on the same virtualization of a particular computational resource containers are often chosen over a VM Why is that In simple words VMs consume more overhead compared to containerization technology VMs allow a business to run several servers virtually on a single system or more irrespective of the OS In comparison containers are lightweight and virtualize an app with the ability to create instances up and down under seconds That being said let us first dive into the challenges faced with a virtual machine and how containers can instead help cut down development costs Challenges faced before the existence of containers Performance In a VM any developmentrelated resource is often moved from physical hardware to a virtual platform Unfortunately this often results in depletion of resources at a faster rate known as VM saturation and ultimately leads the application to face performance lags Awareness Despite the existence of containers today VM is still widely perceived as new by most IT companies Most developers still misunderstand VM as a tool to virtualize an app VM virtualizes an OS which does not mean it can virtualize the app built in it Such fundamental confusions lead to problems like Build an inappropriate app infrastructure Lose IP addresses while migrating the app between systems Incorrect assignment of the bundled images to the wrong VLAN Storage Virtualizing an OS drive means a file should be converted to a flatfile ie Virtual Machine Disks VMDKs which can take up even more than 100GBs in some cases Moreover VMDKs are not always used by all development systems and such inactive files are expensive storage Not to mention the number of files that would have to be stored How containerization technology helps to overcome challenges While a VM and container both allow organizations to adapt to changing environments rapidly containers offer improved ways to provide new services and build new products quickly Containers function better overcoming the common challenges faced with VMs mentioned above Some of the essential solutions containers offers are Containers allow sharing of a host OS making it lightweight and cheaper in terms of usage for development and deployment The size of a container image is often only in megabytes and not gigabytes compared to the resulting image created with a VM Reduces storage costs Spinning up any function with containers can be accomplished in milliseconds reducing development time Compared to VM one system can host many containers which can be used to transfer development files to a container on another system faster As a result it requires fewer IT resources to run manage and deploy Some of the approaches in which containers specifically help increase the revenue of your product are Capture more market segments with the help of quicker developments methodologies Ability to conduct more research experiment and build prototypes quickly App components can be executed flexibly on the cloud local storage or both These are just the tip of the iceberg and all the above ensures the mentioned solutions help businesses scale successfully As decisionmakers you will have the ability to try something new and if it proves to be fruitful it can be integrated into production processes Not convinced yet Examples of companies that cut costs with containers Containerization technology can benefit a business in terms of both technical and revenue aspects In addition it reduces a considerable amount of costs and risks Lets see reallife examples of how various tech giants leveraged containers to cut expenses through multiple practices 1 Spotify The What With the increase in active users Spotify witnessed more than 200 million monthly subscribers The team adopted microservices and Docker to Containerize the said microservices that ran on a fleet of VMs Build a container orchestration platform which later was called Helios It helped them achieve development velocity and reduce cost in terms of development practices and resources used The How Spotify actively managed workloads clusters the state of instances etc by containerizing their architecture This ultimately softened their expenditures with the following goals Create a Dockerbased orchestration platform to manage all containers used in Spotify and manage all servers Helios provided an HTTP API that interacted with available servers that run the containers used Kubernetes was used to accelerate the development and operations undertaken by Docker 2 Financial Times The What The newspaper giant had to manage large volumes of content on their platform It wanted to reduce a considerable amount of cost spent on AWS server operations The team evolved its tech infrastructure by migrating to containers which reduced the costspent of cloud server management by 80 Some of the approaches they took using Docker as a container are Increased the number of new updates released from 12 to 2200 Stabilized the platform irrespective of the number and size of deployments The How The development team considered the time spent on ensuring the used tech cluster is healthy should be unaffected while attempting to reduce server costs As a result the below is what the team accomplished Built its own container orchestration platform with Kubernetes Containerized the tech stack that consisted of 150 microservices 3 Netflix The What In 2008 Netflix decided to go all outmigrating towards the cloud and hosted most of their services on AWS It started operating based on VMs in AWS Though that helped it create and evolve its architecture with many cloudnative patterns why did it still invest in containerization technology Containers allow Netflix to follow the same patterns employed with VMs flexibly and in a simple manner Compared to VMs this is what Netflix accomplished by using containers Improved endtoend application packaging Built an applicationspecific image smartly for what is only required Simplified the production process by ensuring deployment is applicationcentric For achieving the above Netflix built Titus The How Titus is a containermanagement system Packing smallsized container images onto dense VM and reducing infrastructure footprint Easily schedule service jobs for development tasks with the existing pool of resources Check out how Netflix became a master of DevOps I want to read 4 Pinterest The What Pinterest adopted containers as well It evolved its platform towards containerized technology to manage the increased user workload The team also wanted to reduce the cost of managing countless images shared on the platform and for that they wanted to adopt a new technology that helped to stay smart on investments The team wanted to Add complex services and features to Pinterest at any time without the need for granular control Boost performance improve functional reliability and user experience with Docker The How Following are containerized processes that helped Pinterest to avoid spending through the nose in the long run All servicespecific dependencies were added into what they call service containers This way only one AMI will be transferred between all development systems Built a tool called Telefig that is used to launch and stop containers at will This also helps to manage all dependencies that influence containers Adopted container orchestration methodologies to build a multitenant cluster system for unifying batch tasks Conclusion Future of containerization While there are exceptions virtual machines and containers are two basic tools that help you move your application to a cloudbased environment Several cases will find lift and shift the application into a VM as the simplest solution However thats not always the best solution Containerized environments are pretty dynamic and can change much faster than environments in virtual machines providing valuable agility Meanwhile containerization can empower DevOps teams by allowing them to focus on their most important goals And then microservices can use containerization to deliver smaller singlefunction modules that work in tandem to create more scalable and agile applications Considering all the benefits that containerization provides it is a smart move to use this technology to become the next Spotify Pinterest in short the best in your field Let Simform be your IT partner in devising the perfect container strategy with proper tools and frameworks Get in TouchLeverage the power of DevOps and accelerate your application development osmmronn Comprehensive Guide To Simplify Cloud Migration Learnings from 15 RealWorld Case Stuciee Ssmroem DevOps CICD and Containerization Diagrams that Explain Winning To Misconception Fact 0 Misconception Fact 1 Containerization and DevOps are different technology services DevOps and containerization are complementary technologies where DevOps can be considered as the foundational parent technology service 2 Containerizing an application provides greater performance and security Containerization technology improves the development process time and helps to reduce overall cost It helps to ensure security only as a part of the monitoring process followed by its complementary DevOps methodologies Containerization does not offer any standalone security services 3 Containers have evolved to embody a complete platform Containers are tools that help the development process with better management especially while adopting DevOps It does not serve as a parent platform like Linux Windows etc 4 Containers are just VMs VMs run on hypervisors In other words VMs use the host systems resources altogether It runs like a complete OS on top of your current OS On the other hand containers use resources of a host system only for what it needs and when it needs it Moreover containers do not always require a host for the supply of OS resources 5 Containerization technology is only for advanced or cloudpowered apps and not legacy applications Containers are technology tools that can wrap any app without refactoring the entire architecture and yet helps to migrate the legacy code into microservices easily Containerization allows any app to pass through the functionalities of a container provided that the app has a code infrastructure that is compatible for running containers,https://www.simform.com/blog/containerization-technology/,DevOps,988,3338
Scalability in Web Applications,Acropolium Blog Software development How to Scale a Web Application 9 Best WaysTuesday December 26 2023httpsacropoliumcombloghowtoscalewebappAcropoliumhttpsacropoliumcomimgbaselogosvgHow to Scale a Web Application 9 Best WaysWednesday July 19 2023Sharehttpsacropoliumcomimgarticleshowtoscalewebappimg01jpgKey TakeawaysScaling a web application enables improved performance high availability flexibility and adaptability The core goal is to handle growth and future needsHowever when scaling your app you may face several issues They include database inefficiency server issues code failures lack of automation poor traffic distribution and load problemsScaling your web application is crucial when you experience high loads plan to migrate to the cloud for modernization or seek time and cost savings through prebuilt server solutions Also you may need it to comply with specific regulationsWhen building or modernizing a web application consider every critical factor that impacts its success Scalability is one of the first on the listEven if your product is at the early development lifecycle stage you should be forwardthinking Web apps often experience rapid growth So shortly after the launch requests per minute RPM may significantly increase Your application must be ready to withstand these changes and meet high expectationsIf your web app isnt ready to handle increasing user loads it leads to slow response times poor user experience and increased bounce rates Almost half of website users 47 wont wait more than two seconds for a website to loadIn turn coping with a growing customer flow and an expanded audience will take your business to the next level However efficient web scaling is quite a complex task It requires considerable time money and resource investments Moreover many are unaware of the best web product scaling methods and the challenges they could face in progressFor example 64 of digital leaders use cloud solutions to ensure their software scalability At the same time 94 of them prefer modular architecture Do you want to learn about these and other effective methods to make your web app robust and futureproof Find the answers to this question and even more in this postWe at Acropolium have gained a rich 20year expertise in SaaS development cloud solutions and web application modernization Drawing on our teams experience we will introduce the key challenges efficient solutions and benefits of application scaling Also you will learn from our enterprise construction management biotech SaaS and multitenant accounting automation case studiesUnderstanding the Importance of Scaling a Web ApplicationApplication scaling involves optimizing the apps architecture infrastructure and resources It aims at handling the increased load without compromising performance reliability and user experienceDue to Boston Consulting Group scalability brings companies 3x higher ROI 1520 revenue growth and 1520 cost savingsNow lets overview several most compelling reasons why scaling is crucialForget about performance bottlenecks latency issues and slowdowns Thanks to scaling a web application maintains optimal performance even as the user base and traffic growImplement redundancy and faulttolerant mechanisms such as load balancing and clustering They ensure the application remains accessible even if individual servers or components failDuring peak usage periods scaling websites enables them to handle the temporary surge in traffic without negatively impacting performance Similarly scaling down during lower demand periods optimizes resource utilization and cost efficiencyWith scaling businesses seamlessly introduce new features accommodate increased data storage requirements and support additional user interactionsThe Most Common Problems with the Scalability of Web ApplicationsThe complexity and cost of scaling a web application depend on many factors The potential issues may come from any side So be ready to address them right away Heres a list of the most common challenges to watch out forDatabase inefficiency A robust and resistant database is necessary when scaling a web app The issues may arise because of choosing the wrong database engine Another risk is providing several databases to cope with queries growth The most reliable solution to this problem is using replication and sharding methods Replication ensures that data is handled on multiple databases simultaneously In turn sharding segments data to avoid handling it in one placeServer issues Server overloads are mainly caused by increased RPM and the number of connected users If your server fails it results in poor system performance and quality Turn to vertical or horizontal scaling or combine these methods to strengthen your serverCode failures Clean code and consistent architecture are the essentials of your app scalability Any issues regarding your apps frontend or backend may lead to disaster To prevent it you ensure your tech partners constantly check the code quality test the product and maintain relevant documentationLack of automation Traditional onpremises solutions may cause various mistakes regarding your apps scalability and maintenance Manual errors are nearly inevitable In contrast turning to cloud backend solutions automates many processes Thus depending on your current needs you can scale your web application up or downPoor traffic distribution Inefficient server management often triggers traffic distribution and balance problems Sharing traffic between multiple servers is complex Thats why its worth using several traffic balancers reducing the risks if one failsLoad problems Although high website traffic proves your apps success it also causes particular issues Querying millions of simultaneous visitors is pretty challenging So one of the primary goals of a scalable web application is to build a robust system to handle high traffic In most cases caches are the most effective solution to such issues They reduce database queries and improve the loading speedTo minimize these risks and guarantee a smooth scaling process try DevOps services from a reliable vendor like AcropoliumHow to Successfully Scale Your Web AppSuccessful app scaling is a complex process that concerns most app elements They include databases modern architecture code quality loading speed servers and moreTo choose the right approach prioritize your apps specifics and address the performance issues its experiencing Outdated code unreliable databases and insufficient loading speed require implementing specific scaling methodsHere are the most efficient and popular ways to improve your applications scalabilityCloud ComputingAccording to Statista most respondents 56 claim better scalability as the most significant driver of cloudbased security solutionsFull or partial migration will address many scalability issues It offers secure data storage and overall system performance improvementHowever here comes an important decision to make You should choose the horizontal or vertical scaling approach depending on your current needs and the web apps natureVertical ScalingSuppose your server fails to withstand the growing number of simultaneous clients requests Then sooner or later it will make your web app work slower experience errors or even crash You must increase RPM and CPU to save your audience and keep your scalable web application alive Vertical scaling aims to increase RPM and CPU metrics This method can make immediate changes and save the dayHowever vertical scaling is rather a temporary solution than a futureproof one Adding resources or moving to a more reliable server wont prevent you from multilevel challenges Any server has its limits So you might face a similar problem later on To cope with it you will need drastic architectural changesHorizontal ScalingIf youre looking for a more persistent solution horizontal scaling is often preferable It involves expanding the number of servers to increase reliability and provide extra fallback options in an emergency Moreover multiple servers enable scaling an app without limitsSuch an approach is much cheaper than handling your single hardware on your own Turning to readymade cloud solutions provided by AWS Azure etc offers simplified server maintenance You can automate some processes to eliminate multiple server management complexityWhen choosing the horizontal approach consider autoscaling as an alternative to traditional onpremises solutions It will relieve you of the need to decide when and how to scale your app up or down Instead of timeconsuming manual processes autoscaling implements the necessary horizontal scaling to adjust the servers performanceAnother beneficial option is to use load balancers for efficient traffic distribution Setting several load balancers with access to servers IPs will improve routing traffic between clients and serversDatabase ManagementDatabase management is an integral component of scaling web applications With a horizontal approach your database engine should be efficient enough to handle numerous queries A complex multiserver system requires a separate database smoothly integrated into your web scale architecture You can provide reliable database management using replication or sharding approachesReplication involves a central database and a few additional ones that store the copied data Any request accomplished on the central database will be instantly replicated to the subordinate databases via a network The most significant advantages of database replication are reliability robust recovery and improved read performanceIn turn the sharding method involves data distribution across numerous smaller databases Multiple nodes store pieces of separated data It significantly increases your apps capacity and reduces the burdens caused by a single storage locationTo make your system even more reliable combine replication and sharding solutions This way you split data into segments and replicate each to improve database performanceCache ConfigurationAlong with the growing number of queries the database engine is at risk of overload No matter how powerful your database solution is you should find a way to reduce this pressure for successful web application scalability Caching is the most common and resultdriven way to cope with this challengeThe caching technique allows storing frequently requested data in a temporary memory that constantly updates Therefore the main database can process and operate data faster by immediately redirecting most parts to cachesFor example when users enter the scalable application the request moves to the cache first The database will accept this query only if the cache doesnt contain the particular users information It reduces the main database workload making it more efficientContent Delivery NetworkContent Delivery Network CDN also takes advantage of the cache tires However this solution exists for another purpose It improves your frontend website scalability delivering content faster and with a reduced loading speedCDN serves as a server network distributing content in multiple geographical locations This technology processes the end users requests by the nearest server Its crucial if your web application contains heavy content such as images videos audio files and so on CDN makes routing content processes more streamlined satisfying users and improving your platforms performanceMany service providers including Amazon Web Services CloudFront Cloudflare and more offer reliable CDN solutionsClean CodeIf your code isnt clean and wellfunctioning no advanced solutions make sense when building a scalable app All app development stages including the tech stack product architecture UX design and deployment directly impact your applications scaling capacityThats why providing constant quality checks and multiple QA testing sessions at all web development stages is vital Improve algorithms use appropriate design patterns and ensure you wont end up with spaghetti code instead of large scalable websites or appsArchitecture PatternWhen building a plan on how to scale application pay extra attention to choosing the proper architectural pattern It has a great impact on an applications scalability The preliminary choice depends on the products nature goals market industry demands and moreHere are the most widespread architecture types suitable for scalable web applicationsLayered architecture This pattern consists of multiple data layers Apps with such an architecture are often hard to scale since they dont involve multiple servers and databasesEventdriven architecture This pattern depends on specific events state changes that trigger the data shifts and interactionsMicrokernel plugin architecture Such architecture involves a minimal core operating system you can enrich by adding more functions It ensures a clear distinction between primary and additional featuresMicroservices architecture This architecture consists of multiple modules that dont depend on each other So you can develop deploy and change some aspects of the app without changing the entire scaling applicationSecurity Considerations in ScalingTo scale applications consider several core aspectsImplement strong user authentication rolebased access controls and secure user management practices to ensure proper access controlsApply secure protocols and encryption to protect data at rest and in transitReview and strengthen network security measures It includes configuring firewalls network segmentation and intrusion detection and prevention systemsAdhere to secure coding practices to mitigate common vulnerabilities like input validation output encoding and error handlingPrepare a welldefined incident response plan outlining procedures for promptly detecting analyzing and responding to security incidentsEnsure to perform backups regularly Also test the restoration process to guarantee the ability to recover data and systemsAssess the security posture of thirdparty services or components used in scalingBe aware of applicable compliance requirements and regulations specific to your industry or region Ensure the scaling efforts comply with relevant standards and regulations such as GDPR HIPAA and PCIDSSDoes Your Business Really Need the Scalability of a Web ApplicationAs you see reaching web application scalability is a complex task requiring significant time and resource investments So before starting such a challenging project decide if your product should be scalableFirst determine whether your web app will experience significant user traffic and increased load If your website has a few hundred users and their number isnt likely to grow in the foreseeable future a largescale solution may be an unnecessary waste of time and moneyAlso the decision to scale is hasty for those running startups at early lifecycle stages In such cases your primary goal is to bring your product to the market and verify its capacity After a while your web application will likely hit the target and expand the audience Then you may consider scaling an actual prospect for your companys business growthHowever application scalability is often not a prospect but an immediate needHere is the list of situations where scaling opens up new opportunities for your web platform or solves its current challengesYour system experiences high loadsYour web application is outdated and youre considering migrating to the cloudYou want to save time and cost with the readymade server database and API solutionsThe app must comply with specific regulationsYour need to regulate and balance your websites workload serving endusers around the globe equally wellIf any of these statements are true for you scaling is your best or even the only way outThe following case studies will help you better understand when web application scalability benefits businesses and how to implement such solutions efficientlyAcropoliums Case StudiesAcropolium is a reliable software vendor with rich experience in SaaS development cloud solutions and web app modernization Also we provide DevOps facilitating the necessary processes tools and practices This approach supports the scaling efforts and helps avoid potential issuesOur dedicated team empowers companies to adapt and meet market demands through highly scalable solutions We work with startups small and midsized businesses and enterprises offering options for every need and budgetWe understand the specifics of custom software development even in the most complicated industries These include healthcare retail fintech risk management supply chain and logistics Lets look at some examples of bespoke software solutions for individual projectsEnterprise Construction Management SoftwareIn this project our company needed to provide the client with the optimization of a huge enterprise construction management software We aimed to modernize particular software modules and use new frontend and backend technologies Also we needed to make the product scalable and add more featuresAs a result our developers scaled the system and increased its working speed by 60 We also migrated the core modules to new technologies and provided efficient documentation of all subsystems Finally we modernized the frontend side and optimized the project management systemBiotech Enterprise SaaS DevelopmentWe implemented a biotech enterprise SaaS solution to automate and streamline workflows It reduced administrative expenses and the workforce required for asset auditing certification and quality controlWith improved clienttoclient and clientvendor communication the client experienced a 30 increase in new customers Also we witnessed a remarkable 65 increase in sales and a 75 boost in customer loyalty thanks to the userfriendly dashboard and administrative panelsAccounting Software for Financial BusinessWithin five months we successfully developed a reliable multitenant accounting automation software for small businesses accountants and bookkeepers With our solution users can set up accounts in five clicks It facilitates transactions tracking payments and report generationFollowing the release of our MVP accounting software we achieved a remarkable 30 conversion rate from free demos to paid plans This result indicates strong user interest and satisfactionFinal ThoughtsWith constant innovations and robust technologies businesses have numerous options for scaling web applications The cloudbased approaches are even more costefficient than onpremises ones At the same time the solutions they offer are futureproof and reliable With multiple servers secure databases and scaling automation you can find the most effective way to build a powerful and durable systemLooking for an experienced tech partner to choose the right way to scale up application We at Acropolium could be a perfect match Our team members are experts in finding scalable solutions We managed numerous projects regarding process automation and full system modernization Our products are easy to scale on cloud architecture depending on your business growthSo if you have any questions or ideas concerning your web apps scalability feel free to drop us a line and try our expert IT outsourcing on a subscription basis Lets start the journey to your apps largescale future togetherSources of informationForbescom  Website User Experience StatisticsBCG  Keys to Scaling Digital Ability and Valuewritten byPavlo ZheldakChief Delivery Officer AcropoliumI am responsible for successful project delivery and achieving highquality outcomes for our clients As a member of Acropolium for over 10 years I strongly advocate for a processoriented approach and our ISO certification obtained two years ago is a testament to the unwavering quality we upholdLooking for experienced software engineerssee our portfolio17 min readLets start a new project togetherLeave us your details and explore the full potential of our future collaborationestimate project or just write an email FAQHow to make a web application scalableWhat factors should be considered in scalability planningWhat is the difference between horizontal scaling and vertical scalingHow can I ensure high availability and disaster recovery while scaling my web applicationHow to make a web application scalableHow to make a web application scalableTo build a scaling app employ a distributed architecture adopt load balancers and implement caching mechanisms This way youll handle increased traffic Also you can use horizontal scaling and a distributed database or caching layers to ensure fast and reliable access to dataWhat factors should be considered in scalability planningWhat factors should be considered in scalability planningWhen planning to scale app consider the following factors projected growth in user base or workload performance system requirements scalability limitations of the chosen technology stack and the ability to add or remove resources dynamically to meet changing demandsWhat is the difference between horizontal scaling and vertical scalingWhat is the difference between horizontal scaling and vertical scalingHorizontal app scaling involves adding more instances or nodes to distribute the workload across multiple machines In contrast vertical scaling means increasing a single machines resources like CPU memory or storage to handle higher workloadsHow can I ensure high availability and disaster recovery while scaling my web applicationHow can I ensure high availability and disaster recovery while scaling my web applicationTo scale websites and ensure high availability and disaster recovery consider the following load balancing across multiple servers redundant and distributed data storage automated backups replication or synchronization mechanisms and distributed infrastructure to handle potential failuresArticles you may also likeHow to Scale a Software Product in 2023Software development 04242022 17 min readCustom Software Development Project Estimation GuideSoftware development 12092022 16 min readHow to Reduce Software Development Costs Without Losing QualitySoftware development 10202021 17 min readCustom Software vs Off the Shelf Which to Choose in 2023Software development 05302023 13 min readHow Much Does It Cost to Build a Website in 2022Software development 12092022 17 min readGuide on Event Management Software Solutions Development Features and App TypesSoftware development 01252023 13 min readEmailinfoacropoliumcomPhone number 420 388 880 038AddressOtakarova 136445 České Budějovice 37001 Czech RepublicIndustriesTransportation  LogisticsHospitalityHealthcareOil  GasBuilding  ConstructionRisk ManagementAutomotiveFintechRetailMarketing  EventsExpertiseAI  MLBig DataCloud SolutionsFrontend DevelopmentChatBot Systems for EnterpriseVideo StreamingPaymentsBlockchainDocument GenerationSaaSDevOpsInternet of ThingsSoftware ModernizationBaas DevelopmentHow we workAboutProcessAwards  RecognitionCareersFAQContactsServicesSubscriptionCustom Software DevelopmentWeb App DevelopmentMobile App DevelopmentDedicated TeamSoftware EngineeringSoftware ConsultingPortfolioInsightsHow Much Does It Cost To Build A Saas App BreakdownBig Data in Logistics Key Benefits  5 Real Use CasesChatbots in Logistics  Transportation Benefits  Use CasesHow to Build  Scale a MultiTenant SaaS Application Best PracticesHow to Develop a GPS Tracking Software for Realtime Vehicle TrackingGuide to Hotel Property Management System development2003  2023 Acropolium All rights reserved Property of Acropolium SitemapPrivacy  Cookie PolicyTerms  ConditionsWe use cookies on our website to enhance your experience If you want to see the complete overview of the cookies used please see our privacy policy Read moreChange Settings Accept allStrictly necessary cookiesThese cookies are essential for your use of different parts of our website and its features Without them services that you want to get cant be providedGDPR General Data rotation Regulation Visitor preferencesThese cookies help us personalize the Acropolium website and provide you with relevant content by remembering your preferences and settingsICO Information Commissioners Office Analytics cookiesThese cookies allow us to measure your use of the website so that we can improve it later They collect information in a way that does not directly identify anyone Ir I _ lSYSTEM тF INTERNATIONAL CERTIFICATION Date of initial certification lssue date Certification cycle Valid through  The certificote is subject to reissuonce for т уиw Head of the Certification body 05052021  Й042023  3 years until 04052024f f cEFlTlFlGATE of Quality Management system Certificate Ns  SlC MS040 lSO90 0L2282 The Ceftification Body RosUkfelt hиrиЮч ceftifies that the Qualiш Management System of Бхrтфтliыm spol s lт Otakarova lИ6445 öиskö Гudöjтыiхи 3 И7001 Czech Republic Registry code 281И8970 хтухиrуiуgт softtruaredevelopmentт хтуsultlуg in softtruare developmentт тthиr activities iу the field of iуfтrmгtiту technoIogy and хтmфыtиr systems complies with the requirements of the international standard ISO 9OO1i2O15 Quality management systems Requirements l NTERNATIONAL STANDARD Жffiшof тууытl surveillonce oudit П Shcherbyna lSo90012282 I  l l Ióst cert notification letter ýlccKl4лodated ó022i 0219и Ukеine нiиы 7 Yunosti str off 33 Tel ý096559434 к806753Gк802httpu krcertcomua httpsicglobalcomгISo 9тт1 issued Slc Global lnc Йд WlGsДПN D suite 4 NoRTH ГБY ПNФБRlП ТlБ 1ЧИ хANADAW  Ёr FфglJ tr  ц г ýЫfr t 4 ôЖsуЖЩ r L_  _гýw ,https://acropolium.com/blog/how-to-scale-web-app/,Back-End Development,1433,3623
Content Delivery Networks (CDNs), What is a content delivery network CDN A content delivery network is a network of servers that is geographically dispersed to enable faster web performance by locating copies of web content closer to users or facilitating delivery of dynamic content eg live video feeds Each CDN server is located on what is called the network edgecloser to users than the host server which is where the website originates For this reason CDN servers are often called edge servers Each server stores or caches copies of a subset of the web contentHTML files images audio video applicationsfrom the host server By reducing the distance between this content and users the content delivery network helps the website publisher provide faster performance reduce loading time for its users and control its own bandwidth consumption and costs Organizations typically purchase CDN services from CDN providers which maintain their own server networks In the video What Is a Content Delivery Network IBM chief architect Ryan Sumner goes through a scenario where a CDN helps make the website and page load time faster for globally distributed users For a closer look at cloud computing and edge networks read the blog posts Cloud at the Edge and Rounding out the Edges Benefits of a content delivery network CDNs provide faster load times reduced bandwidth consumption and many other benefits for web publishers Better connectivity and scalability for web publishers A content delivery network provides site users with faster content load times For web publishers that equates to more page views traffic spikes improved customer engagement and less site abandonment Reduced bandwidth consumption Web hosts charge organizations for data transferred from the origin server By storing copies of content closer to the users a CDN enables fewer data transfers from the origin server reducing an organizations bandwidth consumption and costs Reduced latency Latency refers to the delay between the time data is requested from a system and when the system actually starts sending it in response A greater distance between a user requesting web content and the server delivering it can result in greater latency Because content delivery network servers store web content caches closer to your users they can reduce latency and improve performance Better response to traffic spikes A successful marketing campaign a limitedtime offer a video gone viralthese types of events can create a sudden anticipated or unanticipated increase in content demand Content delivery networks use load balancing to distribute this demand across servers to prevent overloading any single server Load balancing also helps keep the spike or surge in demand from impacting website performance Outsourced infrastructure support By relying on a CDN an organization does not have to spend time human capital or money building out and maintaining its own geographically distributed server network Enhanced security Content delivery networks employ analytics and automation tools that can uncover distributed denial of service DDoS attacks maninthemiddle attacks firewall issues and others Greater user satisfaction Slow load times and issues with media playback and application responsiveness are among the chief reasons that users abandon andor avoid websites Working with a content delivery network can prevent or reduce some of these performance issues making it more likely that content consumers will be satisfied with their site interactions Improved content delivery Not only do CDNs deliver content faster but they also improve the quality of the delivered content Video replay video calls and live video streaming can be hindered by slow transmission which may result in jitter Buffering poor image and sound quality and incomplete transmissions also affect the delivery of video and audio content Content delivery networks help by shortening the distance between the content and the user and by load balancing traffic to prevent overwhelming routers or servers Speedier ecommerce Ecommerce consumers have high expectations for online shopping experiencesthey expect fast product image load times quick payment method approvals and easy transactions on any mobile or desktop device Content delivery networks help B2C and B2B retailers deliver ecommerce content and apps quickly during peak traffic periods How CDNs work As previously noted a CDN works by helping a web publisher deliver faster higherquality performance for users through content distribution from servers that are closer to them than the websites origin server For example suppose your website is based in the United Kingdom UK If someone from the United States US accesses your site the CDN serves that user from an edge server in the US closer to the user instead of from your UKbased origin server for the web page The result is faster content loading and web application performance as well as improved user experience More than half of all web traffic is served over content delivery networks and that percentage continues to grow as businesses expand their global reach and offer more varied content types CDNs also distribute traffic loads so that no single server is overloaded with traffic requests Gaming companies cloud application creators livestreaming ondemand media and other media services ecommerce sites with a global reachas digital consumption needs grow content owners rely on CDNs to better serve their users CDN services A CDN primarily offers improved web content delivery but CDN providers offer additional services that complement serving up content Security services CDNs can provide DDOS protection to data centers and websites In a DDoS attack the attackers try to overwhelm a domains DNS servers with more traffic than the can manage with the objective of disrupting or degrading service CDNs use analytics and automation to monitor for these attacks and respond by limiting request rates the number of information requests an HTTP can make in a specified time period In an man in the middle MITM attack the attacker tries to intercept or alter the communication between the origin server CDN servers and website users MITM attacks can occur at a number of places in a network but CDNs help mitigate MITM attacks by adopting Secure Sockets Layer SSL and Transport Layer Security TLS protocols to secure communications between the CDN and the website origin server as well as between the CDN and the ISP Private CDNs If you work with a content delivery network youll most likely share network functionality with other CDN customers However some CDNs now offer private CDNs which provide the customer with their own dedicated CDN resources A private CDN might appeal to an organization that has strict security needs or specific geographic requirements or that simply wants its own dedicated edge servers that are highly available and wont suffer any latency issues Analytics Content delivery networks may offer realtime analytics for monitoring website traffic and gathering metrics about visitors to a site The objective is to track user behavior With that information website and web application creators can optimize content for users improve site service and target marketing efforts to specific user personas CDN pricing Every content delivery network provider maintains its own pricing structure Most charge a monthly fee based on gigabytes of data transferred from the edge servers to users Rates vary based on the destination the region where cached content is hosted and accessed by users Providers also have different policies for storage some charge storage fees while others do not Major CDN providers post pricing on their websites For most providers the pergigabyte rate decreases as the total gigabytes of data transferred increase Leading CDN providers also charge their customers only for the bandwidth used each month so that billing reflects actual use of the service Several providers even offer free levels of service What is included in that free level of service varies widely by provider Free and paid levels of service come with specific service level agreements SLAs Leading CDN providers tend to offer 999 percent of uptime to customers Before choosing a CDN provider understand its pricing structure and SLAs Since most providers charge based on actual bandwidth used estimate usage before choosing a service to gain a general idea of what monthly costs will be There are CDN pricing calculators online that help you compare pricing among top providers based on bandwidth estimates and bandwidth use by geographical region CDN for websites Not every website publisher needs a CDN A local school districts website for example may not need a CDN because most users will access the site from a nearby location But if you have a mediarich website a geographically dispersed group of users or missioncritical content that requires fast delivery a CDN may be your best option CDN providers and hosting The proliferation of content delivery network providers has been spurred by an increase in content types and devices used to access that content Top providers include the following Akamai MaxCDN Incapsula Rackspace Cloudflare When choosing a CDN provider consider the size and distribution of its network how well its server locations called points of presence or PoPs map to the locations of your site users customer support availability pricing and service level agreements SLAs Also consider whether the provider offers any additional services that would be helpful to your organization such as added security and analytics services Content delivery network hosting describes the networked servers of a CDN provider that host selected web content from a website While website hosting typically refers to only one server CDN hosting includes many servers networked together CDN hosting augments website hosting by caching content in network servers that are geographically closer to website users This differs from a web server which hosts your full site on the origin server CDN hosting can therefore deliver content to users faster than the websites origin server Open source CDNs Not every organization can justify the cost of working with a content delivery network Open source CDNs provide a less costly although more time and laborintensive option With open source CDNs you can link to libraries of content such as CSS or JavaScript frameworks Open source CDNs host elements of website infrastructure on CDN servers Website content managers can access that content for free Open source CDNs do not host your websites original content However they can improve content delivery by moving common web structural elements used by your site closer to your users Storage For website operators with robust content storage needs content delivery network providers offer storage clusters that integrate with their network of edge servers Website operators may want this storage capability if they serve large static files such as videos or installation files By storing these files closer to the user CDN storage delivers better service and faster downloads These storage options also relieve the traffic burden on the origin server by decreasing load requests and routing those requests to CDN edge servers instead Learn more about how you can leverage cloud object storage across all IBM CDN offerings CDN tutorials If youre ready to learn more about using content delivery networks try one of these tutorials In the tutorial Accelerate Delivery of Static Files Using a CDN youll practice how to upload files to a Cloud Object Storage bucket and then make content globally available with a CDN Similarly you can easily manage your data stored in IBM Cloud Object Storage via CISs Resolve Override with COS capability Related solutions IBM Content Delivery Network Avoid network traffic jams and decrease latency by keeping your data closer to your users with Akamais content delivery network on IBM Cloud Explore the IBM Content Delivery Network IBM Cloud Internet Services Get DDoS protection global load balancing and a suite of security reliability and performance capabilities Explore IBM Cloud Internet Services Resources What is load balancing Load balancing lets you evenly distribute network traffic to prevent failure caused by overloading a particular resource Learn more What is a DDoS attack DDoS attacks flood websites with malicious traffic making applications and other services unavailable to legitimate users Learn more Take the next step Your users expect fast load times for your web apps But content delivery can be slow and inconsistent IBM Content Delivery Network provides content caching on the Akamai network so content is delivered at record speed Serve noncacheable dynamic content with optimized performance and automatically scale your service with payasyougo pricing Explore IBM Content Delivery Network ,https://www.ibm.com/topics/content-delivery-networks,Infrastructure,697,2028
SSL Certificates and HTTPS,What is an SSL certificate An SSL certificate is a digital certificate that authenticates a websites identity and enables an encrypted connection SSL stands for Secure Sockets Layer a security protocol that creates an encrypted link between a web server and a web browser Companies and organizations need to add SSL certificates to their websites to secure online transactions and keep customer information private and secure In short SSL keeps internet connections secure and prevents criminals from reading or modifying information transferred between two systems When you see a padlock icon next to the URL in the address bar that means SSL protects the website you are visiting Since its inception about 25 years ago there have been several versions of SSL protocol all of which at some point ran into security troubles A revamped and renamed version followed  TLS Transport Layer Security which is still in use today However the initials SSL stuck so the new version of the protocol is still usually called by the old name How do SSL certificates work SSL works by ensuring that any data transferred between users and websites or between two systems remains impossible to read It uses encryption algorithms to scramble data in transit which prevents hackers from reading it as it is sent over the connection This data includes potentially sensitive information such as names addresses credit card numbers or other financial details The process works like this A browser or server attempts to connect to a website ie a web server secured with SSL The browser or server requests that the web server identifies itself The web server sends the browser or server a copy of its SSL certificate in response The browser or server checks to see whether it trusts the SSL certificate If it does it signals this to the webserver The web server then returns a digitally signed acknowledgment to start an SSL encrypted session Encrypted data is shared between the browser or server and the webserver This process is sometimes referred to as an SSL handshake While it sounds like a lengthy process it takes place in milliseconds When a website is secured by an SSL certificate the acronym HTTPS which stands for HyperText Transfer Protocol Secure appears in the URL Without an SSL certificate only the letters HTTP  ie without the S for Secure  will appear A padlock icon will also display in the URL address bar This signals trust and provides reassurance to those visiting the website To view an SSL certificates details you can click on the padlock symbol located within the browser bar Details typically included within SSL certificates include The domain name that the certificate was issued for Which person organization or device it was issued to Which Certificate Authority issued it The Certificate Authoritys digital signature Associated subdomains Issue date of the certificate The expiry date of the certificate The public key the private key is not revealed Why you need an SSL certificate Websites need SSL certificates to keep user data secure verify ownership of the website prevent attackers from creating a fake version of the site and convey trust to users If a website is asking users to sign in enter personal details such as their credit card numbers or view confidential information such as health benefits or financial information then it is essential to keep the data confidential SSL certificates help keep online interactions private and assure users that the website is authentic and safe to share private information with More relevant to businesses is the fact that an SSL certificate is required for an HTTPS web address HTTPS is the secure form of HTTP which means that HTTPS websites have their traffic encrypted by SSL Most browsers tag HTTP sites  those without SSL certificates  as not secure This sends a clear signal to users that the site may not be trustworthy  incentivizing businesses who have not done so to migrate to HTTPS An SSL certificate helps to secure information such as Login credentials Credit card transactions or bank account information Personally identifiable information  such as full name address date of birth or telephone number Legal documents and contracts Medical records Proprietary information Types of SSL certificate There are different types of SSL certificates with different validation levels The six main types are Extended Validation certificates EV SSL Organization Validated certificates OV SSL Domain Validated certificates DV SSL Wildcard SSL certificates MultiDomain SSL certificates MDC Unified Communications Certificates UCC Extended Validation certificates EV SSL This is the highestranking and most expensive type of SSL certificate It tends to be used for high profile websites which collect data and involve online payments When installed this SSL certificate displays the padlock HTTPS name of the business and the country on the browser address bar Displaying the website owners information in the address bar helps distinguish the site from malicious sites To set up an EV SSL certificate the website owner must go through a standardized identity verification process to confirm they are authorized legally to the exclusive rights to the domain Organization Validated certificates OV SSL This version of SSL certificate has a similar assurance similar level to the EV SSL certificate since to obtain one the website owner needs to complete a substantial validation process This type of certificate also displays the website owners information in the address bar to distinguish from malicious sites OV SSL certificates tend to be the second most expensive after EV SSLs and their primary purpose is to encrypt the users sensitive information during transactions Commercial or publicfacing websites must install an OV SSL certificate to ensure that any customer information shared remains confidential Domain Validated certificates DV SSL The validation process to obtain this SSL certificate type is minimal and as a result Domain Validation SSL certificates provide lower assurance and minimal encryption They tend to be used for blogs or informational websites  ie which do not involve data collection or online payments This SSL certificate type is one of the least expensive and quickest to obtain The validation process only requires website owners to prove domain ownership by responding to an email or phone call The browser address bar only displays HTTPS and a padlock with no business name displayed Wildcard SSL certificates Wildcard SSL certificates allow you to secure a base domain and unlimited subdomains on a single certificate If you have multiple subdomains to secure then a Wildcard SSL certificate purchase is much less expensive than buying individual SSL certificates for each of them Wildcard SSL certificates have an asterisk  as part of the common name where the asterisk represents any valid subdomains that have the same base domain For example a single Wildcard certificate for website can be used to secure paymentsyourdomaincom loginyourdomaincom mailyourdomaincom downloadyourdomaincom anythingyourdomaincom MultiDomain SSL Certificate MDC A MultiDomain certificate can be used to secure many domains andor subdomain names This includes the combination of completely unique domains and subdomains with different TLDs TopLevel Domains except for localinternal ones For example wwwexamplecom exampleorg mailthisdomainnet exampleanythingcomau checkoutexamplecom secureexampleorg MultiDomain certificates do not support subdomains by default If you need to secure both wwwexamplecom and examplecom with one MultiDomain certificate then both hostnames should be specified when obtaining the certificate Unified Communications Certificate UCC Unified Communications Certificates UCC are also considered MultiDomain SSL certificates UCCs were initially designed to secure Microsoft Exchange and Live Communications servers Today any website owner can use these certificates to allow multiple domain names to be secured on a single certificate UCC Certificates are organizationally validated and display a padlock on a browser UCCs can be used as EV SSL certificates to give website visitors the highest assurance through the green address bar It is essential to be familiar with the different types of SSL certificates to obtain the right type of certificate for your website How to obtain an SSL certificate SSL certificates can be obtained directly from a Certificate Authority CA Certificate Authorities  sometimes also referred to as Certification Authorities  issue millions of SSL certificates each year They play a critical role in how the internet operates and how transparent trusted interactions can occur online The cost of an SSL certificate can range from free to hundreds of dollars depending on the level of security you require Once you decide on the type of certificate you require you can then look for Certificate Issuers which offer SSLs at the level you require Obtaining your SSL involves the following steps Prepare by getting your server set up and ensuring your WHOIS record is updated and matches what you are submitting to the Certificate Authority it needs to show the correct company name and address etc Generating a Certificate Signing Request CSR on your server This is an action your hosting company can assist with Submitting this to the Certificate Authority to validate your domain and company details Installing the certificate they provide once the process is complete Once obtained you need to configure the certificate on your web host or on your own servers if you host the website yourself How quickly you receive your certificate depends on what type of certificate you get and which certificate provider you procure it from Each level of validation takes a different length of time to complete A simple Domain Validation SSL certificate can be issued within minutes of being ordered whereas Extended Validation can take as long as a full week Can an SSL certificate be used on multiple servers It is possible to use one SSL certificate for multiple domains on the same server Depending on the vendor you can also use one SSL certificate on multiple servers This is because of MultiDomain SSL certificates which we discussed above As the name implies MultiDomain SSL Certificates work with multiple domains The number is left up to the specific issuing Certificate Authority A MultiDomain SSL Certificate is different from a Single Domain SSL Certificate which  again as the name implies  is designed to secure a single domain To make matters confusing you may hear MultiDomain SSL Certificates also referred to as SAN certificates SAN stands for Subject Alternative Name Every multidomain certificate has additional fields ie SANs which you can use to list additional domains that you want to cover under one certificate Unified Communications Certificates UCCs and Wildcard SSL Certificates also allow for multidomains and in the latter case an unlimited number of subdomains What happens when an SSL certificate expires SSL certificates do expire they dont last forever The Certificate AuthorityBrowser Forum which serves as the de facto regulatory body for the SSL industry states that SSL certificates should have a lifespan of no more than 27 months This essentially means two years plus you can carry over up to three months if you renew with time remaining on your previous SSL certificate SSL certificates expire because as with any form of authentication information needs to be periodically revalidated to check it is still accurate Things change on the internet as companies and also websites are bought and sold As they change hands the information relevant to SSL certificates also changes The purpose of the expiry period is to ensure that the information used to authenticate servers and organizations is as uptodate and accurate as possible Previously SSL certificates could be issued for as long as five years which was subsequently reduced to three and most recently to two years plus a potential extra three months In 2020 Google Apple and Mozilla announced they would enforce oneyear SSL certificates despite this proposal being voted down by the Certificate Authority Browser Forum This took effect from September 2020 It is possible that in the future the length of validity will reduce still further When an SSL certificate expires it makes the site in question unreachable When a users browser arrives at a website it checks the SSL certificates validity within milliseconds as part of the SSL handshake If the SSL certificate has expired visitors will receive a message to the effect of  This site is not secure Potential risk ahead While users do have the option to proceed it is not advisable to do so given the cybersecurity risks involved including the possibility of malware This will significantly impact bounce rates for website owners as users rapidly click off the homepage and go elsewhere Keeping on top of when SSL certificates expire presents a challenge for larger businesses While smaller and mediumsized businesses SMEs may have one or only a few certificates to manage enterpriselevel organizations that potentially transact across markets  with numerous websites and networks  will have many more At this level allowing an SSL certificate to expire is usually the result of oversight rather than incompetence The best way for larger businesses to stay on top of when their SSL certificates expire is by using a certificate management platform There are various products on the market which you can find using an online search These allow enterprises to see and manage digital certificates across their entire infrastructure If you do use one of these platforms it is important to log in regularly so you can be aware of when renewals are due If you allow a certificate to expire the certificate becomes invalid and you will no longer be able to run secure transactions on your website The Certification Authority CA will prompt you to renew your SSL certificate before the expiration date Whichever Certificate Authority or SSL service you use to obtain your SSL certificates from will send you expiration notifications at set intervals usually starting at 90 days out Try to ensure that these reminders are being sent to an email distribution list  rather than a single individual who may have left the company or moved to another role by the time the reminder is sent Think about which stakeholders in your company are on this distribution list to ensure the right people see the reminders at the right time How to tell if a site has an SSL certificate The easiest way to see if a site has an SSL certificate is by looking at the address bar in your browser If the URL begins with HTTPS instead of HTTP that means the site is secured using an SSL certificate Secure sites show a closed padlock emblem which you can click on to see security details  the most trustworthy sites will have green padlocks or address bars Browsers also show warning signs when a connection is not secure  such as a red padlock a padlock which is not closed a line going through the websites address or a warning triangle on top of the padlock emblem How to ensure your online session is safe Only submit your personal data and online payment details to websites with EV or OV certificates DV certificates are not suitable for eCommerce websites You can tell if a site has an EV or OV certificate by looking at the address bar For an EV SSL the organizations name will be visible in the address bar itself For an OV SSL you can see the organizations names details by clicking on the padlock icon For a DV SSL only the padlock icon is visible Read the websites privacy policy This enables you to see how your data will be used Legitimate companies will be transparent about how they collect your data and what they do with it Look out for trust signals or indicators on websites As well as SSL certificates these include reputable logos or badges which show the website meets specific security standards Other signs that can help you determine if a site is real or not include checking for a physical address and telephone number checking their returns or refunds policy and making sure prices are believable and not too good to be true Stay alert to phishing scams Sometimes cyber attackers create websites that mimic existing websites to trick people into purchasing something or logging in to their phishing site It is possible for a phishing site to obtain an SSL certificate and therefore encrypt all the traffic that flows between you and it A growing proportion of phishing scams occur on HTTPS sites  deceiving users who feel reassured by the padlock icons presence To avoid these kinds of attacks Always examine the domain of the site you are on and ensure it is spelled correctly The URL of a fake site might differ by only one character  eg amaz0ncom instead of amazoncom If in doubt type the domain directly into your browser to make sure you are connecting to the website you intend to visit Never enter logins passwords banking credentials or any other personal information on the site unless you are sure of its authenticity Always consider what a particular site is offering whether it looks suspicious and whether you really need to register on it Make sure your devices are well protected Kaspersky Internet Security checks URLs against an extensive database of phishing sites and it detects scams regardless of how safe the resource looks Cybersecurity risks continue to evolve but understanding the types of SSL certificates to look out for and how to distinguish a safe site from a potentially dangerous one will help internet users avoid scams and protect their personal data from cybercriminals Related articles Tips on how to prevent ransomware attacks How to run a virus scan the right way What is a security breach How to protect your privacy against hackers What is an SSL certificate  Definition and ExplanationKasperskyFeatured ArticlesCrypto Wallet Hardware Hardware Wallet vs Cold WalletsWhat is security awareness trainingWhat is ransomware as a serviceTor Browser What is it and is it safeWhat is a Dictionary Attack LJ  Kaspersky Premium Were more than just antivirus Ultimate privacy with Unlimited VPN Password Manager  Documents Vault Learn More CABrowser Forum Baseline Requirements for the Issuance and Management of Publicly Trusted Certificates CABrowser Forum  Version 160 June 22 2018 cabforumorg Copyright 201 8 CABrowser Forum This work is licensed under the Creative Commons Attribution 40 International license Baseline Requirements v 1 60 ii TABLE OF CONTENTS 1 Introduction      1 11 Overview      1 12 Document name and Identification    1 121 Revisions     2 122 Relevant Dates     4 13 PKI Participants     4 131 Certification Authorities     4 132 Registration Au thorities     4 133 Subscribers     5 134 Relying Parties     5 135 Other Participants     5 14 Certificate Usage     5 141 Appropriate Certificate Uses    5 142 Prohibited Certificate Uses    5 15 Policy administration     6 151 Organization administering the doc ument    6 152 Contact person     6 153 Person determining CPS suitability for the policy   6 154 CPS approval procedures    6 16 Definitions and acronyms     6 161 Definitions     6 162 Acronyms     12 163 References     12 164 Conventions     13 2 PUBLICATION AND REPOSITORY RESPONSIBILITIES   13 21 Repositories     13 22 Publi cation of information     13 23 Time or frequency of publication    14 24 Access controls on repositories    14 3 IDENTIFICATION AND AUTHENTICATION    14 31 Naming      14 311 Types of names     14 312 Need for names to be meaningful    14 313 Anonymity or pseudonymity of subscribers    14 314 Rules for interpreting various name forms    14 315 Uniqueness of names     14 316 Recognition aut hentication and role of trademarks   14 32 Initial identity validation     15 321 Method to Prove Possession of Private Key    15 322 Authentication of Organization and Domain Identity   15 323 Authentication of Individual Identity    21 324 Nonverified Subscriber Information    21 325 Validation of Authority     21 326 Criteria for Interoperation or Certification    21 33 Identification and authentication for re key requests   22 331 Identifi cation and Authentication for Routine Re key   22 332 Identification and Authentication for Re key After Revocation   22 34 Identification and authentication for revocation request   22 4 CERTIFICATE LIFE CYCLE OPERATIONAL REQUIREMENTS   22 41 Certificate Application     22 411 Who Can Submit a Certificate Application    22 412 Enrollment Process and Responsibilities    22 42 Certificate application processing    22 421 Performing Identification and Authentication Functions   22 422 Approval or Rejection of Certificate Applications   23 423 Time to Process Certificate Applications    23 43 Certificate issuance     24 431 CA Actions during Certificate Issuance    24 432 Notification of Certificate Issuance    24 Baseline Requirements v 1 60 iii 44 Certificate acceptance     24 441 Conduct constituting certificate acceptance    24 442 Publication of the certificate by the CA    24 443 Notification of certificate issuance by the CA to other entities   24 45 Key pair and certificate usage     24 451 Subscriber private key and certificate usage    24 452 Relying party public key and certificate usage   24 46 Certificate renewal     24 461 Circumstance for certificate renewal    24 462 Who may request renewal    24 463 Processing certificate renewal requests    24 464 Notification of new certificate issuance to subscriber   24 465 Conduct constituting acceptance of a renewal certificate   25 466 Publication of the renewal certificate by the CA   25 467 Notification of certificate issuance by the CA to other entities   25 47 Certificate re key     25 471 Circumstance for certificate re key    25 472 Who may request c ertification of a new public key   25 473 Processing certificate re keying requests    25 474 Notification of new certificate i ssuance to subscriber   25 475 Conduct constituting acceptance of a re keyed certificate   25 476 Publication of the re keyed certificate by the CA   25 477 Notification of certificate issuance by the CA to other entities   25 48 Certificate modificatio n     25 481 Circumstance for certificate modification    25 482 Who may request certificate modification    25 483 Processing certificate modification requests    25 484 Notification of new certificate issuance to subscriber   25 485 Conduct constituting acceptance of modified certificate   26 486 Publication of the modified certificate by the CA   26 487 Notification of certificate issuance by the CA to other entities   26 49 Certificate revocation and suspension    26 491 Circumstances for Revocation    26 492 Who Can Request Revocation    27 493 Procedure for Revo cation Request    27 494 Revocation Request Grace Period    27 495 Time within which CA Must Process the Revocation Request   28 496 Revocation Checking Requirement for Relying Parties   28 497 CRL Issuance Frequency    28 498 Maximum Latency for CRLs    28 499 Online RevocationStatus Checking Availability   28 491 0 Online Revocation Checking Requirements    28 4911 Other Forms of Revocation Advertisements Available   29 4912 Special Req uirements Related to Key Compromise   29 4913 Circumstances for Suspension    29 4914 Who Can Request Suspension    29 4915 Procedure for Suspension Request    29 4916 Limits on Suspension Period    29 410 Certificate status services     29 4101 Operational Characteristics    29 4102 Service Availability     29 4103 Optional Features     30 411 End of subscription     30 412 Key escrow a nd recovery     30 4121 Key escrow and recovery policy and practices   30 4122 Session key encapsulation and recovery policy and practices   30 5 MANAGEMENT OPERATIONAL and Physical CONTROLS   30 51 Physical security Controls     31 511 Site location and construction    31 512 Physical access     31 513 Power and air co nditioning    31 514 Water exposures     31 Baseline Requirements v 1 60 iv 515 Fire prevention and protection    31 516 Media storage     31 517 Waste disposal     31 518 Offsite backup     31 52 Procedural controls     31 521 Trusted Roles     31 522 Number of Individuals Required per Task    31 523 Identification and Authentication for Trusted Roles   31 524 Roles Requiring Separation of Duties    31 53 Personnel controls     31 531 Qualifications Experience and Clearance Requirements   32 532 Background Check Procedures    32 533 Training Requirements and Procedures    32 534 Retraining Frequency and Requirements    32 535 Job Rotation Frequency and Sequence    32 536 Sanctions for Unauthorized Actions    32 537 Independent Contractor Controls    32 538 Documentation Supplied to Personnel    32 54 Audit logging procedures     32 541 Types of Events Recorded    32 542 Frequency for Processing and Archiving Audit Logs   33 543 Retention Period for Audit Logs    33 544 Protection of Audit Log     33 545 Audit Log Backup Procedures    33 546 Audit Log Accumulation System internal vs external   33 547 Notification to Event Causing Subject    33 548 Vulnerability Assessments    33 55 Records archival     34 551 Types of Records Archived    34 552 Retention Period for Archive    34 553 Protection o f Archive     34 554 Archive Backup Procedures    34 555 Requirements for Time stamping of Records    34 556 Archive Collection System internal or external   34 557 Procedures to Obtain and Verify Archive Information   34 56 Key changeover     34 57 Compromise and disaster recovery    34 571 Incident and Compromise Han dling Procedures   34 572 Recovery Procedures if Computing Resources Software andor Data Are Corrupted  35 573 Recovery Pr ocedures After Key Compromise   35 574 Business Continuity Capabilities after a Disaster   35 58 CA or RA termination     35 6 TECHNICAL SECURITY CONTROLS    35 61 Key pair generation and installation    35 611 Key Pair Generation     35 612 Private Key Delivery to Subscriber    36 613 Public Key Delivery to Certificate Is suer    36 614 CA Public Key Delivery to Relying Parties    36 615 Key Sizes     36 616 Public Key Parameters Generation and Quality Checking   37 617 Key Usage Purposes     38 62 Private Key Pr otection and Cryptographic Module Engineering Controls   38 621 Cryptographic Module Standards and Controls   38 622 Private K ey n out of m Multi person Control    38 623 Private Key Escrow     38 624 Private Key Backup     38 625 Private Key Archival     38 626 Private Key Transfer into or from a Cryptographic Module   38 627 Private Key Storage on Cryptographic Module   38 628 Activating Private Keys     39 629 Deactivating Private Keys    39 6210 Destroying Private Keys    39 Baseline Requirements v 1 60 v 6211 Cryptographic Module Capabilities    39 63 Other aspects of key pair management    39 631 Public Key Archival     39 632 Certificate Operational Period s and Key Pair Usage Periods   39 64 Activation data     39 641 Activation data generation and installation    39 642 Activation data protection    39 643 Other aspects of activation data    39 65 Computer security controls     39 651 Specific Computer Security Technical Requirements   39 652 Computer Security Rating    39 66 Life cycle technical controls     39 661 System development controls    40 662 Security management controls    40 663 Life cycle security controls    40 67 Network security controls     40 68 Time stamping     40 7 CeRTIFICATE CRL AND OCSP PROFILES    40 71 Certificate profile     40 711 Version Numbers     40 712 Certificate Content and Extensions Application of RFC 5280   40 713 Algorithm Object Identifiers    43 714 Name Forms     43 715 Nam e Constraints     46 716 Certificate Policy Object Identifier    47 717 Usage of Policy Constraints Extension    48 718 Policy Qualifiers Syntax and Semantics    48 719 Processing Semantics for the Critical Certificate Policies Extension  48 72 CRL profile     48 721 Version numbers     48 722 CRL and CRL entry extensi ons   48 73 OCSP profile     48 731 Version numbers     48 732 OCSP extensions     48 8 COMPLIANCE AUDIT AND OTHER ASSESSMENTS    49 81 Frequency or circumstances of assessment    49 82 Identityqualifications of assessor    49 83 Assessors relationship to assessed entity    50 84 Topics covered by assessment    50 85 Actions taken as a result of deficiency    50 86 Communication of result s     50 87 SelfAudits     51 9 OTHER BUSINESS AND LEGAL MATTERS    51 91 Fees      51 911 Certificate issuance or renewal fees    51 912 Certificate access fees     51 913 Revocation or status information access fees   51 914 Fees for other services     51 915 Refund policy     51 92 Financial responsibility     51 921 Insurance coverage     51 922 Other assets     51 923 Insurance or warranty coverage for end entities   51 93 Confidentiality of business i nformation    51 931 Scope of confidential information    51 932 Information not within the scope of confidential information   52 933 Responsibility to protect confidential information   52 94 Privacy of personal information    52 941 Privacy plan     52 942 Information treated as private    52 943 Information not dee med private    52 944 Responsibility to protect private information    52 Baseline Requirements v 1 60 vi 945 Notice and consent to use private information   52 946 Disclosure pursuant to judicial or administrative process   52 947 Other information disclosure circumstances    52 95 Intellectual property rights     52 96 Representations and warranties    52 961 CA Representations and Warranties    52 962 RA Representations and Warranties    53 963 Subscriber Representations an d Warranties    53 964 Relying Party Representations and Warranties   54 965 Representations and Warranties of Other Participan ts   54 97 Disclaimers of warranties     54 98 Limitations of liability     54 99 Indemnities     54 991 Indemnification by CAs     54 992 Indemnification by Subscribers    55 993 Indemnification by Relying Parties    55 910 Term and termination     55 9101 Term     55 9102 Termination     55 9103 Effect of termination and survival    55 911 Individual notices and communications with participants   55 912 Amendments     55 9121 Procedure for amendment    55 9122 Notification mechanism and period    55 9123 Circumstances under which OID must be changed   55 913 Dispute resolution provisions     55 914 Governing law     55 915 Compliance with applica ble law    55 916 Miscellaneous provisions     55 9161 Entire Agreement     55 9162 Assignment     55 9163 Severability     55 9164 Enforcement     56 9165 Force Majeure     56 917 Other provisions     56 Forum Guideline Baseline Requirements v 1 60 1 1 INTRODUCTION 11 OVERVIEW This document describe s an integrated set of technologies protocols i dentity proofing lifecycle management and auditing requirements that are necessary but not sufficient for the issuance and management of Publicly Trusted Certificates Certificates that are trusted by virtue of the fact that their corresponding Root Ce rtificate is distributed in widely availa ble application software The r equirements are not mandatory for Certification Authorities unless and until they become adopted and enforced by relying  party Application Software Suppliers Notice to Readers The CP for the Issuance and Management of Publicly Trusted Certificates describe a subset of the requirements that a Certification Authority must meet in order to issue Publicly Trusted Certificates  This document serves two purposes to specify Baseline Re quirements and to provide guidance and requirements for what a CA should include in its CPS Except where expl icitly stated otherwise these R equirements apply only to relevant events that occur on or after the Effective Date These R equirements do not a ddress all of the issues relevant to the issuance and management of Publicly  Trusted Certificates In accordance with RFC 3647 and to facilitate a comparison of other certificate policies and CPSs eg for policy mapping  this document includes all sect ions of the RFC 3647 framework  However rather than beginning with a no stipulation comment in all empty sections  the CABrowser Forum is leaving such sections initially blank until a decision of no stipulation is made  The CABrowser Forum may upd ate the se Requirements from time to time in order to address both existing and emerging threats to online security In particular it is expected that a future version will contain more formal and comprehensive audit requirements for delegated functions These R equirements only address Certificates intended to be used for authenticating servers accessible through the Internet Similar requirements for code signing SMIME time stamping VoIP IM Web services etc may be covered in future versions These Requirements do not address the issuance or management of Certificates by enterprises that operate their own Public Key Infrastructure for internal purposes only and for which the Root Certificate is not distributed by any Application Software Suppl ier These Requirements are applicable to all Certification Authorities within a chain of trust They are to be flowed down from the Root Certification Authority through successive Subordinate Certification Authorities 12 DOCUMENT NAME AND IDENTIFICATION This certificate policy CP contains the requirements for the issuance and management of publicly trusted SSL certificates as adopted by the CABrowser Forum The following Certificate Policy identifiers are reserved for use by CAs as an optional means of asserting compliance with this document OID arc 22314012 as follows joint isoitut2 international organizations23 ca browser forum140 certificate policies1 baseline  requirements2 domain validated1  223140121 joint isoitut2 international organizations23 ca browser forum140 certificate policies1 baseline  requirements2 organization validated2  223140122  and jointisoitut2 internationalorganizations23 cabrowserforum140 certificatepolicies1 base line requirements2 individual validated3 223140123  Forum Guideline Baseline Requirements v 1 60 2 121 Revisions Ver Ballot Description Adopted Effective 100 62 Version 10 of the Baseline Requirements Adopted 22Nov 11 01Jul12 101 71 Revised Auditor Qualifications 08May 12 01Jan13 102 75 Non critical Name Constraints allowed as exception to RFC 5280 08Jun12 08Jun12 103 78 Revised DomainIP Address Validation High Risk Requests and Data Sources 22Jun12 22Jun12 104 80 OCSP responses for non issued certificate s 02Aug 12 01Feb13 01Aug 13  83 Network and Certificate System Security Requirements adopted 03Aug 13 01Jan13 105 88 Userassigned country code of XX allowed 12Sep12 12Sep12 110  Published as Version 11 with no changes from 105 14Sep12 14Sep12 111 93 Reasons for Revocation and Public Key Parameter checking 07Nov 12 07Nov 12 01Jan13 112 96 Wildcard certificates and new gTLDs 20Feb13 20Feb13 01Sep13 113 97 Prevention of Unknown Certificate Contents 21Feb13 21Feb13 114 99 Add DSA Keys BR v114 3May 2013 3May 2013 115 102 Revision to subject domainComponent language in section 923 31May 2013 31May 2013 116 105 Technical Constraints for Subordinate Certificate Authorities 29July2013 29July2013 117 112 Replace Definition of Internal Server Name with Internal Name 3April 2014 3April 2014 118 120 Affiliate Authority to Verify Domain 5June 2014 5June 2014 119 129 Clarification of PSL mentioned in Section 1113 4Aug 2014 4Aug 2014 120 125 CAA Records 14Oct2014 15Apr2015 121 118 SHA 1 Sunset 16Oct2014 16Jan2015 1Jan2016 1Jan2017 122 134 Application of RFC 5280 to Pre certificates 16Oct2014 16Oct2014 123 135 ETSI Auditor Qualifications 16Oct2014 16Oct2014 124 144 Validation Rules for onion Names 18Feb2015 18Feb2015 125 148 Issuer Field Correction 2April 2015 2April 2015 130 146 Convert Baseline Requirements to RFC 3647 Framework 16Apr2015 16Apr2015 131 151 Addition o f Optional OIDs for Indicating Level of Validation 28Sep2015 28Sep2015 132 156 Amend Sections 1 and 2 of Baseline Requirements 3Dec2015 3Dec2016 133 160 Amend Section 4 of Baseline Requirements 4Feb2016 4Feb2016 134 162 Sunset of Excep tions 15Mar 2016 15Mar 2016 135 168 Baseline Requirements Corrections Revised 10May 2016 10May 2016 Forum Guideline Baseline Requirements v 1 60 3 136 171 Updating ETSI Standards in CABF documents 1July2016 1July2016 137 164 Certificate Serial Number Entropy 8July2016 30Sep2016 138 169 Revised Validation Requirements 5Aug 2016 1Mar 2017 139 174 Reform of Requirements Relating to Conflicts with Local Law 29Aug 2016 27Nov 2016 140 173 Removal of requirement to cease use of public key due to incorrect info 28July2016 11Sep2016 141 175 Addition of givenName and surname 7Sept 2016 7Sep2016 142 181 Removal of some validation methods listed in section 3224 7Jan2017 7Jan2017 143 187 Make CAA Checking Mandatory 8Mar 2017 8Sep2017 144 193 825 day C ertificate Lifetimes 17Mar 2017 1Mar 2018 145 189 Amend Section 617 of Baseline Requirements 14Apr2017 14May 2017 146 195 CAA Fixup 17Apr2017 18May 2017 147 196 Define Audit Period 17Apr2017 18May 2017 148 199 Require commonName in Root and Intermediate Certificates 9May 2017 8June 2017 149 204 Forbid DTPs from doing DomainIP Ownership 11July2017 11Aug 2017 150 212 Canonical ise formal name of the Baseline Requirements 1Sept 2017 1Oct2017 151 197 Effective Date of Ballot 193 Provisions 1May 2017 2June 2017 152 190 Add Validation Methods with Minor Corrections 19Sept 2017 19Oct2017 153 214 CAA Discovery CNAME Errata 27Sept 2017 27Oct2017 154 215 Fix Ballot 190 Errata 4Oct2017 5Nov 2017 155 217 Sunset RFC 2527 21Dec2017 20Jan2018 156 218 Remove validation methods 1 and 5 5Feb2018 9Mar 2018 157 220 Minor Cleanups Spring 2018 30Mar 2018 29Apr2018 158 219 Clarify handling of CAA Record Sets with no issueissuewild propert y tag 10Apr2018 10May 2018 159 223 Update BR Section 84 for CA audit criteria 15May 2018 14June 2018 160 224 WhoIs and RDAP 22May 2018 22June 2018  Effective Date and Additionally Relevant Compliance Date s Forum Guideline Baseline Requirements v 1 60 4 122 Relevant Dates Compliance Sections Summary Description See Full Text for Detail s 2013 0101 616 For RSA public keys CAs SHALL confirm that the value of the public exponent is an odd number equal to 3 or more 2013 0101 4910 CAs SHALL support an OCSP capability using the GET method 2013 0101 5 CAs SHALL comply with the Ne twork and Certificate System Security Requirements 2013 0801 4910 OCSP Responders SHALL NOT respond Good for Unissued Certificates 2013 0901 3226 CAs SHALL revoke any certificate where wildcard character occurs in the first label position imme diately to the left of a registry controlled label or public suffix 2013 1231 615 CAs SHALL confirm that the RSA Public Key is at least 2048 bits or that one of the following ECC curves is used P 256 P 384 or P 521 A Root CA Certificate issue d prior to 31 Dec 2010 with an RSA key size less than 2048 bits MAY still serve as a trust anchor 2015 0116 713 CAs SHOULD NOT issue Subscriber Certificates utilizing the SHA 1 algorithm with an Expiry Date greater than 1 January 2017  2015 0401 632 CAs SHALL NOT issue certificates with validity periods longer than 39 months  except under certain circumstances  2015 0415 22 A CAs CPS must state whether it reviews CAA Records and if so its policy or practice on processing CAA records for Full y Qualified Domain Names 2015 1101 71421 Issuance of Certificates with Reserved IP Address or Internal Name prohibited 2016 0101 713 CAs MUST NOT issue any new Subscriber certificates or Subordinate CA certificates using the SHA 1 hash algorit hm 2016 0630 617 CAs MUST NOT issue Subscriber Certificates directly from Root CAs 2016 0630 632 CAs MUST NOT issue Subscriber Certificates with validity periods longer than 39 months regardless of circumstance 2016 0930 71 CAs SHALL generat e Certificate serial numbers greater than zero 0 containing at least 64 bits of output from a CSPRNG 2016 1001 71421 All Certificates with Reserved IP Address or Internal Name must be revoked 2016 1203 1 and 2 Ballot 156 amendments to sections 1 52 23 and 24 are applicable 2017 0101 713 CAs MUST NOT issue OCSP responder certificates using SHA 1 inferred 2017 0301 3224 CAs MUST follow revised validation requirements in section 3224 2017 0908 3228 CAs MUST check and pr ocess CAA records 2018 0301 421 and 632 Certificates issued MUST have a Validity Period no greater than 825 days and reuse of validation information limited to 825 days 2018 0531 22 CP and CPS must follow RFC 3647 format 2018 0801 32241 and 5 CAs must stop using domain validation methods BR 32241 and 32245 stop reusing validation data from those methods 13 PKI PARTICIPANTS The CABrowser Forum is a voluntary organization of Certification Authorities and suppliers of Internet browser and other relying party software applications 131 Certification Authorit ies Certification Authority CA is defined in Section 16 Current CA Members of the CABrowser Forum are listed here httpscabforu morgmembers  132 Registration Authorit ies Forum Guideline Baseline Requirements v 1 60 5 With the exception of sections 3224 and 3225 the CA MAY delegate the performance of all or any part of Section 32 requirements to a Delegated Third Party provided that the process as a whole fulfills all of the requirements of Section 32 Before the CA authorizes a Delegated Third Party to perform a delegated function the CA SHALL contractually require the Delegated Third Party to 1 Meet the qualification requirements of Section 531  when applicabl e to the delegated function 2 Retain documentation in accordance with Section 552  3 Abide b y the other provisions of these R equirements that are applicable to the delegated function and 4 Comply with a the CAs Certificate PolicyCertification Practice Statement or b the Delegated Third Partys practice statement that the CA has verified complies with these Requirements The CA MAY designate an Enterprise RA to verify certificate requests from the Enterprise RAs own organization The CA SHA LL NOT accept certificate requests authorized by an Enterprise RA unless the following requirements are satisfied 1 The CA SHALL confirm that the requested Fully Qualified Domain Names are within the Enterprise RAs verified Domain Namespace 2 If th e certificate request includes a Subject name of a type other than a Fully Qualified Domain Name the CA SHALL confirm that the name is either that of the delegated enterprise or an Affiliate of the delegated enterprise or that the delegated enterprise i s an agent of the named Subject For example the CA SHALL NOT issue a Certificate containing the Subject name XYZ Co on the authority of Enterprise RA ABC Co unless the two companies are affiliated see Section 32 or ABC Co is the agent of XY Z Co This requirement applies regardless of whether the accompanying requested Subject FQDN falls within the Domain Namespace of ABC Cos Registered Domain Name The CA SHALL impose these limitations as a contractual requirement on the Enterprise RA a nd monitor compliance by the Enterprise RA 133 Subscribers As defined in Section 161 134 Relying Parties Relying Party  and Application Software Supplier  are defined in Section 16 1 Current Members of t he CABrowser Forum who are Application Software Suppl iers are listed here httpscabforumorgmembers  135 Other Participants Other groups that have participat ed in the development of these Requirements include the AICPACICA WebTrust for Certification Authoritie s task force and ETSI ESI Participation by such groups does not imply their endorsement recommendation or approval of the final product 14 CERTIFICATE USAGE 141 Appropriate Certificate U ses The primary goal of these Requirements is to enable efficient and se cure electronic communication  while addressing user concerns about the trustworthiness of Certificates Th ese Requirements also serve to inform users and help them to make informed decisions when relying on Certificates 142 Prohibited Certificate Uses Forum Guideline Baseline Requirements v 1 60 6 15 POLIC Y ADMINISTRATION The Baseline Requirements for the Issuance and Management of Publicly Trusted Certificates present criteria established by the CABrowser Forum for use by Certification Authorities when issuing maintaining and revoking publicly trusted Certificates This document may be revised from time to time as appropriate in accordance with procedures adopted by the CABrowser Forum Because one of th e primary beneficiaries of this document is the end user the Forum openly invites anyone to mak e recommendations and suggestions by email to the CABrowser Forum at questionscabforumorg  The Forum members value all input regardless of source and will seriously consider all such input 151 Organization Administering the Document No stipulation 152 Contact Person Contact information for the CABrowser Forum is available here httpscabforumorgleadership In this section of a CAs CPS the CA shall provide a link to a web page or an email address for co ntacting the person or persons responsible for operation of the CA 153 Person Determining CPS suitability for the policy No stipulation 154 CPS approval procedures No stipulation 16 DEFINITIONS AND ACRO NYMS 161 Definitions Affiliate A corporation partnership j oint venture or other entity controlling controlled by or under common control with another entity  or an agency department political subdivision or any entity operating under the direct control of a Government Entity  Applicant The natural person or Legal Entity that applies for or seeks renewal of a Certificate Once the Certificate issues the Applicant is referred to as the Subscriber For Certificates issued to devices the Applicant is the entity that controls or operates the device named in the Certificate even if the device is sending the actual certificate request Applicant Representative A natural person or human sponsor who is either the Applicant employed by the Applicant or an authorized agent who has express authority to repr esent the Applicant i who signs and submits or approves a certificate request on behalf of the Applicant andor ii who signs and submits a Subscriber Agreement on behalf of the Applicant andor iii who acknowledges the Terms of Use on behalf of the Applicant when the Applicant is an Affiliate of the CA or is the CA  Application Software Supplier A supplier of Internet browser software or other relying party application software that displays or uses Certificates and incorporates Root Certifica tes Attestation Letter A letter attesting that Subject Information is correct written by an accountant lawyer government official or other reliable third party customarily relied upon for such information  Forum Guideline Baseline Requirements v 1 60 7 Audit Period In a period oftime audit the period between the first day start and the last day of operations end covered by the auditors in their engagement This is not the same as the period of time when the auditors are on site at the CA The coverage rules and maximum length of audit periods are defined in section 81 Audit Report A report from a Qualified Auditor stating the Qualified Auditors opinion on whether an entitys processes and controls comply with the mandatory provisions of these Requirements Authorization Domain N ame The Domain Name used to obtain authorization for certificate issuance for a given FQDN The CA may use the FQDN returned from a DNS CNAME lookup as the FQDN for the purposes of domain validation If the FQDN contains a wildcard character then the CA MUST remove all wildcard labels from the left most portion of requested FQDN The CA may prune zero or more labels from left to right until encountering a Base Domain Name and may use any one of the intermediate values for the purpose of domain validation Authorized Port s One of the following ports 80 http 443 http 25 smtp 22 ssh Base Domain Name The portion of an applied for FQDN that is the first domain name node left of a registry  controlled or public suffix plus the registry controlled or public suffix eg examplecouk or examplecom For FQDNs where the right most domain name node is a gTLD having ICANN Specification 13 in its registry agreement the gTLD itself may be used as the Base Domain Name  CAA From RFC 6844  httptoolsietforghtmlrfc6844  The Certification Authority Authorization CAA DNS Resource Record allows a DNS domain name holder to specify the Certification Authorities CAs authorized to issue certifica tes for that domain Publication of CAA Resource Records allows a public Certification Authority to implement additional controls to reduce the risk of unintended certificate mis  issue Certificate An electronic document that uses a digital signature t o bind a public key and an identity Certificate Data Certificate request s and data related thereto whether obtained from the Applicant or otherwise in the CAs possession or control or to which the CA has access Certificat e Management Process Processes  practices and procedures associated with the use of keys software and hardware by which the CA verifies Certificate Data issues Certificates maintains a Repository and revokes Certificates Certificate Policy A set of rules that indicates the applicability of a named Certificate to a particular community andor PKI implementation with common security requirements Certificate Problem Report Complaint of suspected Key Compromise Certificate misuse or other types of fraud compromise m isuse or inappropriate conduct related to Certificates Certificate Revocation List A regularly updated time stamped list of revoked Certificates that is created and digitally signed by the CA that issued the Certificates Certification Authority An organization that is responsible for the creation issuance revocation and management of Certificates The term applies equally to both Roots CAs and Subordinate CAs Certification Practice Statement One of several documents forming the governance framework in which Certificates are created issued managed and used Control Control and its correlative meanings controlled by and under common control with means possession directly or indirectly of the power to 1 direct the manageme nt personnel finances or plans of such entity 2 control the election of a majority of the directors  or 3 vote that portion of voting shares Forum Guideline Baseline Requirements v 1 60 8 required for control under the law of the entitys Jurisdiction of Incorporation or Registration but in no case less than 10 Country Either a member of the United Nations OR a geographic region recognized as a Sovereign State by at least two UN member nations Cross Certificate A certificate that is used to establish a trust relationship between two Root CAs  CSPRNG A random number generator intended for use in cryptographic system Delegated Third Party A natural person or Legal Entity that is not the CA  and whose activities are not within the scope of the appropriate CA audits  but is authori zed by the CA to assist in the Certificate Management Process by performing or fulfilling one or more of the CA requirements found herein Domain Authorization Document  Documentation provided by or a CAs documentation of a communication with a Domai n Name Registrar the Domain Name Registrant or the person or entity listed in WHOIS as the Domain Name Registrant including any private anonymous or proxy registration service attesting to the authority of an Applicant to request a Certificate for a specific Domain Namespace Domain Contact The Domain Name Registrant technical contact or administrative contract or the equivalent under a ccTLD as listed in the WHOIS record of the Base Domain Name or in a DNS SOA record  or as obtained through dir ect contact with the Domain Name Registrar  Domain Name The label assigned to a node in the Domain Name System Domain Namespace The set of all possible Domain Names that are subordinate to a single node in the Domain Name System Domain Name Regis trant Sometimes referred to as the owner of a Domain Name but more properly the persons or entityies registered with a Domain Name Registrar as having the right to control how a Domain Name is used such as the natural person or Legal Entity that is listed as the Registrant by WHOIS or the Domain Name Registrar Domain Name Registrar A person or entity that registers Domain Names under the auspices of or by agreement with i the Internet Corporation for Assigned Names and Numbers ICANN ii a national Domain Name authorityregistry or iii a Network Information Center including their affiliates contractors delegates successors or assigns Effective Date 1 July 2012 Enterprise RA An employee or agent of an organization u naffiliated with the CA who authorizes issuance of Certificates to that organization Expiry Date The Not After date in a Certificate that defines the end of a Certificates validity period Fully Qualified Domain Name A Domain Name that includes the labels of all superior nodes in the Internet Domain Name System Government Entity A government operated legal entity agency department ministry branch or similar element of the government of a country or political subdivision within such coun try such as a state province city county etc High Risk Certificate Request A Request that the CA flags for additional scrutiny by reference to internal criteria and databases maintained by the CA which may include names at higher risk for phishi ng or other fraudulent usage names contained in previously rejected certificate requests or revoked Certificates names Forum Guideline Baseline Requirements v 1 60 9 listed on the Miller Smiles phishing list or the Google Safe Browsing list or names that the CA identifies using its own risk mitigati on criteria Internal Name A string of characters not an IP address in a Common Name or Subject Alternative Name field of a Certificate that cannot be verified as globally unique within the public DNS at the time of certificate issuance because it d oes not end with a Top Level Domain registered in IANAs Root Zone Database Issuing CA In relation to a particular Certificate the CA that issued the Certificate This could be either a Root CA or a Subordinate CA Key Compromise A Private Key is s aid to be compromised if its value has been disclosed to an unauthorized person an unauthorized person has had access to it or there exists a practical technique by which an unauthorized person may discover its value A Private Key is also considered co mpromised if methods have been developed that can easily calculate it based on the Public Key such as a Debian weak key see httpwikidebianorgSSLkeys or if there is clear evidence that the specific method used to generate the Private Key was flawed  Key Generation Script  A documented plan of procedures for the generation of a CA Key Pair  Key Pair The Private Key and its associated Public Key Legal Entity An associa tion  corporation  partnership  proprietorship  trust  government entity or other entity with legal standing in a co untrys legal system Object Identifier A unique alphanumeric or numeric identifier registered under the International Organization for Standardizations applicable standard for a specific object or object cl ass OCSP Responder An online server operated under the authority of the CA and connected to its Repository for processing Certificate status requests See also Online Certificate Status Protocol Online Certificate Status Protocol An online Certif icate checking protocol that enables relying party application software to determine the status of an identified Certificate See also OCSP Responder Parent Company A company that Controls a Subsidiary Company Private Key The key of a Key Pair tha t is kept secret by the holder of the Key Pair and that is used to create Digital Signatures andor to decrypt electronic records or files that were encrypted with the corresponding Public Key Public Key  The key of a Key Pair that may be publicly disc losed by the holder of the corresponding Private Key and that is used by a Relying Party to verify Digital Signatures created with the holders corresponding Private Key andor to encrypt messages so that they can be decrypted only with the holders corres ponding Private Key  Public Key Infrastructure  A set of hardware software people procedures rules policies and obligations used to facilitate the trustworthy creation issuance management and use of Certificates and keys based on Public Key Cryp tography Publicly Trusted Certificate A Certificate that is trusted by virtue of the fact that its corresponding Root Certificate is distributed as a trust anchor in widely available application software Qualified Auditor A natural person or Legal Entity that meets the requirements of Section 82 Random Value A value specified by a CA to the Applicant that exhibits at least 112 bits of entropy Forum Guideline Baseline Requirements v 1 60 10 Registered Domain Name A Domain Name that has been registered with a Domain Name Registrar Regist ration Authority RA Any Legal E ntity that is responsible for identification and authentication of subjects of Certificate s but is not a CA and hence does not sign or issue Certificate s An RA may assist in the certificate application process or revoc ation process or both When  RA is used as an adjective to describe a role or function it does not necessarily imply a separate body but can be part of the CA  Reliable Data Source An identification document or source of data used to verify Subject I dentity Information that is generally recognized among commercial enterprises and governments as reliable and which was created by a third party for a purpose other than the Applicant obtaining a Certificate Reliable Method of Communication A method of communication such as a postalcourier delivery address telephone number  or email address that was verified using a source other than the Applicant Representative Relying Party  Any natural person or Legal Entity that relies on a Valid Certificat e An Application Software Supplier is not considered a Relying Party when software distributed by such Supplier merely displays information relating to a Certificate Repository  An online database containing publicly disclosed PKI governance documen ts such as Certificate Policies and Certification Practice Statements and Certificate status information either in the form of a CRL or an OCSP response Request Token A value derived in a method specified by the CA which binds this demonstration of control to the certificate request The Request Token SHALL incorporate the key used in the certificate request A Request Token MAY include a timestamp to indicate when it was created A Request Token MAY include other information to ensure its uniquen ess A Request Token that includes a timestamp SHALL remain valid for no more than 30 days from the time of creation A Request Token that includes a timestamp SHALL be treated as invalid if its timestamp is in the future A Request Token that does not include a timestamp is valid for a single use and the CA SHALL NOT re use it for a subsequent validation The binding SHALL use a digital signature algorithm or a cryptographic hash algorithm at least as strong as that to be used in signing the certificat e request Required Website Content Either a Random Value or a Request Token together with additional information that uniquely identifies the Subscriber as specified by the CA Requirements  The Baseline Requirements found in th is document Reserved IP Address  An IPv4 or IPv6 address that the IANA has marked as reserved httpwwwianaorgassignmentsipv4 address spaceipv4 address spacexml httpwwwianaorgassignmentsipv6 address spaceipv6 address spacexml Root CA  The top level Certification Authority whose Root Certificate is distributed by Application Software Suppliers and that issues Subordinate CA Certificates Forum Guideline Baseline Requirements v 1 60 11 Root Certificate  The self signed Certificate issued by the Root CA to identify itself and to facilitate verification of Certificates issued to its Subordinate CAs Sovereign State A state or co untry that administers its own government and is not dependent upon or subject to another power Subject  The natural person device system unit or Legal Entity identified in a Certificate as the Subject The Subject is either the Subscriber or a device under the control and operation of the Subscriber Subject Identity Information Information that identifies the Certificate Subject  Subject Identity Information does not include a domain name listed in the subjectAltName extension or the Subje ct commonName field Subordinate CA  A Certification Authority whose Certificate is signed by the Root CA or another Subordinate CA Subscriber  A natural person or Legal Entity to whom a Certificate is issued and who is legally bound by a Subscriber Agreement or Terms of Use Subscriber Agreement  An agreement between the CA and the ApplicantSubscriber that specifies the rights and responsibilities of the parties Subsidiary Company A company that is controlled by a Parent Company Technically Constrained Subordinate CA Certificate A Subordinate CA certificate which uses a combination of Extended Key Usage settings and Name Constraint settings to limit the scope within which the Subordinate CA Certificate may issue Subscriber or additional Subo rdinate CA Certificates Terms of Use Provisions regarding the safekeeping and acceptable uses of a Certificate issued in accordance with these Requirements when the ApplicantSubscriber is an Affiliate of the CA or is the CA  Test Certificate A Certi ficate with a maximum validity period of 30 days and which  i includes a critical extension with the specified Test Certificate CABF OID 22314021  or ii is issued under a CA where there are no certificate pathschains to a root certificate subjec t to these Requirements Trustworthy System  Computer hardware software and procedures that are reasonably secure from intrusion and misuse provide a reasonable level of availability reliability and correct operation are reasonably suited to perfo rming their intended functions and enforce the applicable security policy Unregistered Domain Name A Domain Name that is not a Registered Domain Name Valid Certificate  A Certificate that passes the validation procedure specified in RFC 5280 Vali dation Specialists  Someone who performs the information verification duties specified by these Requirements Validity Period  The period of time measured from the date when the Certificate is issued until the Expiry Date WHOIS Information retrieved directly from the Domain Name Registrar or registry operator via the protocol defined in RFC 3912 the Registry Data Access Protocol defined in RFC 7482 or an HTTPS website Wildcard Certificate A Cer tificate containing an asterisk  in the left most position of any of the Subject Fully Qualified Domain Names contained in the Certificate Forum Guideline Baseline Requirements v 1 60 12 Wildcard Domain Name  A Domain Name consisting of a single asterisk character followed by a single full stop ch aracter  followed by a Fully Qualified Domain Name 162 Acronyms AICPA American Institute of Certified Public Accountants CA Certification Authority CAA Certification Authority Authorization ccTLD Country Code Top Level Domain CICA Canadian Institute of Chartered Accountants CP Certificate Policy CPS Certification Practice Statement CRL Certificate Revocation List DBA Doing Business As DNS Domain Name System FIPS US Government Federal Information Processing Standard FQDN Fully Qualified Domain Name IM Instant Messaging IANA Internet Assigned Numbers Authority ICANN Internet Corporation for Assigned Names and Numbers ISO International Organization for Standardization NIST US Government National Institute of Standards and Technology OCSP Online Certi ficate Status Protocol OID Object Identifier PKI Public Key Infrastructure RA Registration Authority SMIME Secure MIME Multipurpose Internet Mail Extensions SSL Secure Sockets Layer TLD Top Level Domain TLS Transport Layer Security VOIP Voice Over In ternet Protocol 163 References ETSI EN 3 19 403 Electronic Signatures and Infrastructures ESI Trust Service Provider Conformity Assessment  Requirements for conformity assessment bodies assessing Trust Service Providers  ETSI EN 319 411 1 Electronic Sign atures and Infrastructures ESI Policy and security requirements for Trust Service Providers issuing certificates Part 1 General requirements ETSI TS 102 042 Electronic Signatures and Infrastructures ESI Policy requirements for certification auth orities issuing public key certificates FIPS 140 2 Federal Information Processing Standards Publication  Security Requirements For Cryptographic Modules Information Technology Laboratory National Institute of Standards and Technology May 25 2001 ISO 211882006 Public key infrastructure for financial services  Practices and policy framework Network and Certificate System Security Requirements v10 112013 NIST SP 800 89 Recommendation for Obtaining Assurances for Digital Signature Appli cations httpcsrcnistgovpublicationsnistpubs800 89SP 800 89_November2006pdf  RFC2119 Request for Comments 2119 Key words for use in RFCs to Indicate Requirement Levels Bradner March 1997 Forum Guideline Baseline Requirements v 1 60 13 RFC2527 Request for Comments 2527 Internet X509 Public Key Infrastructure Certificate Policy and Certification Practices Framework Chokhani et al March 1999 RFC3647 Request for Comments 3647 Internet X509 Public Key Infrastructure Certificate Policy and Certification Practices Framework C hokhani et al November 2003 RFC3912 Request for Comments 3912 WHOIS Protocol Specification Daigle September 2004 RFC4366 Request for Comments 4366 Transport Layer Security TLS Extensions Blake Wilson et al April 2006 RFC5019 Request for Comments 5019 The Lightweight Online Certificate Status Protocol OCSP Profile for HighVolume Environments A Deacon  et al September 2007  RFC5280 Request for Comments 5280 Internet X509 Public Key Infrastructure Certificate and Certificate Revocation List CRL Profile Cooper et al May 2008 RFC6844 Request for Comments 684 4 DNS Certification Authority Authorization CAA Resource Record Hallam Baker Stradling January 2013 RFC6960 Request for Comments 6960 X509 Internet Public Key Infrastructure Online Certificate Status Protocol  OCSP Santesson Myers Ankney M alpani Galperin Adams June 2013 RFC7482 Requ est for Comments 7482 Registration Data Access Protocol  RDAP  Query Format Newton et al March 2015 WebTrust for Certification Authorities  SSL Baseline with Network Security Version 20 available at httpwwwwebtrustorghomepage documentsitem 79806pdf  X509 Recommendation ITU T X509 102012  ISOIEC 959 482014 E Information technology  Open Systems Interconnection  The Directory Public key and attribute certificate frameworks 164 Conventions The key words MUST MUST NOT REQUIRED SHALL SHALL NOT SHOULD SHOULD NOT RECOMMENDED MA Y and OPTIONAL in these Requirements shall be interpreted in accordance with RFC 2119 2 PUBLICATION AND REPO SITORY RESPONSIBILIT IES The CA SHALL develop implement enforce and annually update a Certificate Policy andor Certification Practice Statemen t that describes in detail how the CA implements the latest version of these Requirements 21 REPOSITORIES The CA SHALL make revocation information for Subordinate Certificates and Subscriber Certificates available in accordance with this Policy 22 PUBLICATION OF INFORMATION The CA SHALL publicly disclose its Certificate Policy andor Certification Practice Statement through an appropriate and readily accessible online means that is available on a 24x7 basis The CA SHALL publicly disclose its CA business pra ctices to the extent required by the CAs selected audit scheme see Section 81 Forum Guideline Baseline Requirements v 1 60 14 Effective as of 31 May 2018 the Certificate Policy andor Certification Practice Statement MUST be structured in accordance with RFC 3647 Prior to 31 May 2018 the Certif icate Policy andor Certification Practice Statement MUST be structured in accordance with either RFC 2527 or RFC 3647 The Certificate Policy andor Certification Practice Statement MUST include all material required by RFC 3647 or if structured as such RFC 2527 Effective as of 8 September 2017  section 42 of a CAs Certificate Policy andor Certification Practice Statement section 41 for CAs still conforming to RFC 2527 SHALL state the CAs policy or practic e on processing CAA Records for F ully Qu alified Domain Names  that policy shall be consistent with these Requirements It shall clearly specify the set of Issuer Domain Names that the CA recognises in CAA issue or issuewild records as permitting it to issue  The CA SHALL log all actions take n if any consistent with its processing practice The CA SHALL publicly give effect to these Requirements and represent that it will adhere to the latest published version The CA MAY fulfill this requirement by incorporating these Requirements direct ly into its Certificate Policy andor Certification Practice Statements or by incorporating them by reference using a clause such as the following which MUST include a link to the official version of these Requirements Name of CA conforms to the curr ent version of the Baseline Requirements for the Issuance and Management of Publicly Trusted Certificates published at httpwwwcabforumorg In the event of any inconsistency between this document and those Requirements those Requirements take precede nce over this document The CA SHALL host test Web pages that allow Application Software Suppliers to test their software with Subscriber Certificates that chain up to each publicly trusted Root Certificate At a minimum the CA SHALL host separate Web p ages using Subscriber Certificates that are i valid ii revoked and iii expired 23 TIME OR FREQUENCY OF PUBLICATION The CA SHALL develop implement enforce and annually update a Certificate Policy andor Certification Practice Statement that describ es in detail how the CA implements the latest version of these Requirements 24 ACCESS CONTROLS ON R EPOSITORIES The CA shall make its Repository public ly available in a read only manner 3 IDENTIFICATION AND A UTHENTICATION 31 NAMING 311 Types of names 312 Need for names to be meaningful 313 Anonymity or pseudonymity of subscribers 314 Rules for interpreting various name forms 315 Uniqueness of names 316 Recognition authentication and role of trademarks Forum Guideline Baseline Requirements v 1 60 15 32 INITIAL IDENTITY VAL IDATION 321 Met hod to P rove Possession of Private Key 322 Authenticati on of Organization and Domain Identity If the Applicant requests a Certificate that will contain Subject Identity Information comprised only of the countryName field then the CA SHALL verify the country associated with the Subject using a verification process meeting the requirements of Section 3223 and that is described in the CAs Certificate Policy and or Certification Practice Statement If the Applicant requests a Certificate that will contain the countryName field and other Subject Identity Infor mation then the CA SHALL verify the identity of the Applicant  and the authenticity of the Applicant Representative s certificate request using a verification process meeting the requirements of this Section 3221 and that is described in the CAs Certi ficate Policy and or Certification Practice Statement The CA SHALL inspect any document relied upon under this Section for alteration or falsification 3221 Identity If the Subject Identity Information is to include the name or address of an organization t he CA SHALL verify the identity and address of the organization and that the address is the Applicants address of existence or operation The CA SHALL verify the identity and address of the Applicant using documentation provided by  or through communicat ion with  at least one of the following  1 A government agency in the jurisdiction of the Applicants legal creation existence or recognition 2 A third party database that is periodically updated and considered a Reliable Data Source  3 A site visit by the CA or a third party who is acting as an agent for the CA or 4 An Attestation Letter The CA MAY use the same documentation or communication described in 1 through 4 above to verify both the Applicants identity and address Alternatively the CA MAY veri fy the address of the Applicant but not the identity of the Applicant using a utility bill bank statement credit card statement government issued tax document or other form of identification that the CA determines to be reliable  3222 DBATradename If the Subject Identity Information is to include a DBA or tradename  the CA SHALL verify the Applicants right to use the DBAtrade name using at least one of the following  1 Documentation provided by or communication with a government agency in the jurisdictio n of the Applicants legal creation existence or recognition 2 A Reliable Data Source  3 Communication with a government agency responsible for the management of such DBAs or tradenames  4 An Attestation Letter accompanied by documentary support  or 5 A util ity bill bank statement credit card statement government issued tax document or other form of identification that the CA determines to be reliable 3223 Verification of Country If the subject countryName field is present the n the CA SHALL verify the coun try associated with the Subject using one of the following a the IP Address range assignment by country for either i the web sites IP Forum Guideline Baseline Requirements v 1 60 16 address as indicated by the DNS record for the web site or ii the Applicants IP address b the ccTLD of the requested Domain Name c information provided by the Domain Name Registrar or d a method identified in Section 3221  The CA SHOULD implement a process to screen proxy servers in order to prevent reliance upon IP addresses assigned in countries other than where the Applicant is actually located 3224 Validation of Domain Authorization or Control This section defines the permitted processes and procedures for validating the Applicants ownership or control of the domain The CA SHALL confirm that prior to issuance  the CA has validated each Fully Qualified Domain Name FQDN listed in the Certificate using at least one of the methods listed below  Completed validations of Applicant authority may be valid for the issuance of multiple Certificates over time In all cases the validation must have been initiated within the time period specified in the relevant requirement such as Section 421 of this document prior to Certificate issuance For purposes of domain validation the term Applicant includes the A pplicants Parent Company Subsidiary Company or Affiliate CAs SHALL maintain a record of which domain validation method including relevant BR version number they used to validate every domain Note FQDNs may be listed in Subscriber Certificates using dNSNames in the subjectAltName extension or in Subordinate CA Certificates via dNSNames in permittedSubtrees within the Name Constraints extension 32241 Validating the Applicant as a Domain Contact Confirming the Applicants control over the FQDN by validating the Applicant is the Domain Contact directly with the Domain Name Registrar This method may only be used if 1 The CA authenticates the Applicants identity under BR Section 3221 and the authority of the Applicant Representative under BR S ection 325 OR 2 The CA authenticates the Applicants identity under EV Guidelines Section 112 and the agency of the Certificate Approver under EV Guidelines Section 118 OR 3 The CA is also the Domain Name Registrar or an Affiliate of the Registrar  of the Base Domain Name Note Once the FQDN has been validated using this method the CA MAY also issue Certificates for other FQDNs that end with all the labels of the validated FQDN This method is suitable for validating Wildcard Domain Names For certificates issued on or after August 1 2018 this method SHALL NOT be used for validation and completed validations using this method SHALL NOT be used for the issuance of certificates 32242 Email Fax SMS or Postal Mail to Domain Contact Confi rming the Applicants control over the FQDN by sending a Random Value via email fax SMS or postal mail and then receiving a confirming response utilizing the Random Value The Random Value MUST be sent to an email address faxSMS number or postal mail address identified as a Domain Contact Each email fax SMS or postal mail MAY confirm control of multiple Authorization Domain Names The CA MAY send the email fax SMS or postal mail identified under this section to more than one recipient provided that every recipient is identified by the Domain Name Registrar as representing the Domain Name Registrant for every FQDN being verified using the email fax SMS or postal mail The Random Value SHALL be unique in each email fax SMS or postal mail The CA MAY resend the email fax SMS or postal mail in its entirety including re use of the Random Value provided that the communications entire contents and recipients remain unchanged The Random Value SHALL remain valid for use in a confirming resp onse for no more than 30 days from its creation The CPS MAY specify a shorter validity period for Random Values in which case the CA MUST follow its CPS Forum Guideline Baseline Requirements v 1 60 17 Note Once the FQDN has been validated using this method the CA MAY also issue Certificates for oth er FQDNs that end with all the labels of the validated FQDN This method is suitable for validating Wildcard Domain Names 32243 Phone Contact with Domain Contact Confirming the Applicants control over the FQDN by calling the Domain Name Registrant s phone number and obtaining a response confirming the Applicants request for validation of the FQDN The CA MUST place the call to a phone number identified by the Domain Name Registrar as the Domain Contact Each phone call SHALL be made to a single num ber and MAY confirm control of multiple FQDNs provided that the phone number is identified by the Domain Registrar as a valid contact method for every Base Domain Name being verified using the phone call Note Once the FQDN has been validated using this method the CA MAY also issue Certificates for other FQDNs that end with all the labels of the validated FQDN This method is suitable for validating Wildcard Domain Names 32244 Constructed Email to Domain Contact Confirm the Applicants control o ver the FQDN by i sending an email to one or more addresses created by using admin administrator webmaster hostmaster or postmaster as the local part followed by the at  sign  followed by an Authorization Domain Name ii including a Random Value in the email and iii receiving a confirming response utilizing the Random Value Each email MAY confirm control of multiple FQDNs provided the Authorization Domain Name used in the email is an Authorization Domain Name for each FQDN being confirmed The Random Value SHALL be unique in each email The email MAY be re sent in its entirety including the re use of the Random Value provided that its entire contents and recipient SHALL remain unchanged The Random Value SHALL remain valid for u se in a confirming response for no more than 30 days from its creation The CPS MAY specify a shorter validity period for Random Values Note Once the FQDN has been validated using this method the CA MAY also issue Certificates for other FQDNs that end with all the labels of the validated FQDN This method is suitable for validating Wildcard Domain Names 32245 Domain Authorization Document Confirming the Applicants control over the FQDN by relying upon the attestation to the authority of the Appl icant to request a Certificate contained in a Domain Authorization Document The Domain Authorization Document MUST substantiate that the communication came from the Domain Contact The CA MUST verify that the Domain Authorization Document was either i d ated on or after the date of the domain validation request or ii that the WHOIS data has not materially changed since a previously provided Domain Authorization Document for the Domain Name Space For certificates issued on or after August 1 2018 this method SHALL NOT be used for validation and completed validations using this method SHALL NOT be used for the issuance of certificates 32246 Agreed Upon Change to Website Confirming the Applicants control over the FQDN by confirming one of the foll owing under the well  knownpki validation directory or another path registered with IANA for the purpose of Domain Validation on the Authorization Domain Name that is accessible by the CA via HTTPHTTPS over an Authorized Port Forum Guideline Baseline Requirements v 1 60 18 1 The presence of Requir ed Website Content contained in the content of a file  The entire Required Website Content MUST NOT appear in the request used to retrieve the file or web page or 2 The presence of the Request Token or Random Value contained in the content of a file where t he Request Token or Random Value MUST NOT appear in the request If a Random Value is used the CA SHALL provide a Random Value unique to the certificate request and SHALL not use the Random Value after the longer of i 30 days or ii if the Applicant s ubmitted the Certificate request the timeframe permitted for reuse of validated information relevant to the Certificate such as in Section 421 of these Guidelines or Section 11143 of the EV Guidelines Note Examples of Request Tokens include but a re not limited to i a hash of the public key ii a hash of the Subject Public Key Info X509 and iii a hash of a PKCS10 CSR A Request Token may also be concatenated with a timestamp or other data If a CA wanted to always use a hash of a PKCS1 0 CSR as a Request Token and did not want to incorporate a timestamp and did want to allow certificate key re use then the applicant might use the challenge password in the creation of a CSR with OpenSSL to ensure uniqueness even if the subject and key are identical between subsequent requests This simplistic shell command produces a Request Token which has a timestamp and a hash of a CSR Eg echo date u YmdHM sha256sum r2csr  sed s g The script outputs 201602251811c9c863405fe7675a3988 b97664ea6baf442019e4e52fa335f406f7c5f26cf14f The CA should define in its CPS or in a document referenced from the CPS the format of Request Tokens it accepts Note Once the FQDN has been validated using this method the CA MAY also issue Certificates fo r other FQDNs that end with all the labels of the validated FQDN This method is suitable for validating Wildcard Domain Names 32247 DNS Change Confirming the Applicants control over the FQDN by confirming the presence of a Random Value or Request Token for either in a DNS CNAME TXT or CAA record for either 1 an Authorization Domain Name or 2 an Authorization Domain Name that is prefixed with a label that begins with an underscore character If a Random Value is used the CA SHALL provide a Rando m Value unique to the Certificate request and SHALL not use the Random Value after i 30 days or ii if the Applicant submitted the Certificate request the timeframe permitted for reuse of validated information relevant to the Certificate such as in Se ction 331 of these Guidelines or Section 11143 of the EV Guidelines Note Once the FQDN has been validated using this method the CA MAY also issue Certificates for other FQDNs that end with all the labels of the validated FQDN This method is suita ble for validating Wildcard Domain Names 32248 IP Address Confirming the Applicants control over the FQDN by confirming that the Applicant controls an IP address returned from a DNS lookup for A or AAAA records for the FQDN in accordance with section 3225 Note Note Once the FQDN has been validated using this method the CA MAY NOT also issue Certificates for other FQDNs that end with all the labels of the validated FQDN unless the CA performs a separate validation for that FQDN using an authoriz ed method This method is NOT suitable for validating Wildcard Domain Names 32249 Test Certificate Confirming the Applicants control over the FQDN by confirming the presence of a non expired Test Certificate issued by the CA on the Authorization Dom ain Name and which is accessible by the CA via TLS over an Authorized Port for the purpose of issuing a Certificate with the same Public Key as in the Test Certificate Forum Guideline Baseline Requirements v 1 60 19 Note Once the FQDN has been validated using this method the CA MAY also issue Certifi cates for other FQDNs that end with all the labels of the validated FQDN This method is suitable for validating Wildcard Domain Names 322410 TLS Using a Random Number Confirming the Applicants control over the FQDN by confirming the presence of a Random Value within a Certificate on the Authorization Domain Name which is accessible by the CA via TLS over an Authorized Port 322411 Any Other Method This method has been retired and MUST NOT be used 322412 Validating Applicant as a Domain Co ntact Confirming the Applicants control over the FQDN by validating the Applicant is the Domain Contact This method may only be used if the CA is also the Domain Name Registrar or an Affiliate of the Registrar of the Base Domain Name Note Once the FQ DN has been validated using this method the CA MAY also issue Certificates for other FQDNs that end with all the labels of the validated FQDN This method is suitable for validating Wildcard Domain Names 3225 Authentication for an IP Address For each IP Addre ss listed in a Certificate the CA SHALL confirm that as of the date the Certificate was issued the Applicant has control over the IP Address by 1 Having the Applicant demonstrate practical control over the IP Address by making an agreed upon change to information found on an online Web page identified by a uniform resource identifier containing the IP Address 2 Obtaining documentation of IP address assignment from the Internet Assigned Numbers Authority IANA or a Regional Internet Registry RIP E APNIC ARIN AfriNIC LACNIC 3 Performing a reverse IP address lookup and then verifying control over the resulting Domain Name under Section 3224  or 4 Using any other method of confirmation provided that the CA maintains documented evidenc e that the method of confirmation establishes that the Applicant has control over the IP Address to at least the same level of assurance as the methods previously described Note IPAddresses may be listed in Subscriber Certificates using IPAddress in the subjectAltName extension or in Subordinate CA Certificates via IPAddress in permittedSubtrees within the Name Constraints extension 3226 Wildcard Domain Validation Before issuing a certificate with a wildcard character  in a CN or subjectAltName of type DNS ID the CA MUST establish and follow a documented procedure pubsuffix that determines if the wildcard character occurs in the first label position to the left of a registry controlled label or public suffix eg com couk see RFC 6454 Se ction 82 for further explanation If a wildcard would fall within the label immediately to the left of a registry controlled or public suffix CAs MUST refuse issuance unless the applicant proves its rightful control of the entire Domain Namespace e g CAs MUST NOT issue couk or local but MAY issue examplecom to Example Co Prior to September 1 2013 each CA MUST revoke any valid certificate that does not comply with this section of the Requirements pubsuffix Determination of wha t is registry controlled versus the registerable portion of a Country Code Top Level Domain Namespace is not standardized at the time of writing and is not a property of the DNS Forum Guideline Baseline Requirements v 1 60 20 itself Current best practice is to consult a public suffix list such as httppublicsuffixorg PSL and to retrieve a fresh copy regularly If using the PSL a CA SHOULD consult the ICANN DOMAINS section only not the PRIVATE DOMAINS section The PSL is updated regularly to conta in new gTLDs delegated by ICANN which are listed in the ICANN DOMAINS section A CA is not prohibited from issuing a Wildcard Certificate to the Registrant of an entire gTLD provided that control of the entire namespace is demonstrated in an appropriat e way  3227 Data Source Accuracy Prior to using any data source as a Reliable Data Source the CA SHALL evaluate the source for its reliability accuracy and resistance to alteration or falsification The CA SHOULD consider the following during its evaluati on 1 The age of the information provided 2 The frequency of updates to the information source 3 The data provider and purpose of the data collection 4 The public accessibility of the data availability and 5 The relative difficulty in falsifying o r altering the data Databases maintained by the CA its owner or its affiliated companies do not qualify as a Reliable Data Source if the primary purpose of the database is to collect information for the purpose of fulfilling the validation requirements under this Section 32 3228 CAA Records This section is effective as of 8 September 2017 As part of the issuance process the CA MUST check for CAA record s and follow the processing instructions found for each dNSName in the subjectAltName extension of t he certificate to be issued as specified in RFC 6844 as amended by Errata 5065 Appendix A  If the CA issues they MUST do so within the TTL of the CAA record or 8 hours whichever is greater This stipulation does not prevent the CA from checking CAA records at any other time When processing CAA records CAs MUST process the issue issuewild and iodef property tags as specified in RFC 6844  although they are not required to act on the contents of the iodef property tag  Additional property tags MAY be supported but MUST NOT conflict with or supersede the mandatory property tags set out in this document CAs MUST respect the critical flag and not issue a certificate if they encounter an unrecognized property with this flag set CAs MAY treat a non empty CAA Resource Record Set that does not contain any issue property tags and also does not contain any issuewild property tags when performing CAA processing for a Wildcard Domain Name as permission to issue provided that no records in the CAA Resourc e Record Set otherwise prohibit issuance  RFC 6844 requires that CAs MUST NOT issue a certificate unless either 1 the certificate request is consistent with the applicable CAA Resource Record set or 2 an exception specified in the relevant Certificat e Policy or Certification Practices Statement applies For issuances conforming to these Baseline Requirements CAs MUST NOT rely on any exceptions specified in their CP or CPS unless they are one of the following  CAA checking is optional for certific ates for which a Certificate Transparency pre certificate was created and logged in at least two public logs and for which CAA was checked Forum Guideline Baseline Requirements v 1 60 21  CAA checking is optional for certificates issued by a Technically Constrained Subordinate CA Certificate as set o ut in Baseline Requirements section 715 where the lack of CAA checking is an explicit contractual provision in the contract with the Applicant  CAA checking is optional if the CA or an Affiliate of the CA is the DNS Operator as defined in RFC 7719 o f the domains DNS CAs are permitted to treat a record lookup failure as permission to issue if  the failure is outside the CAs infrastructure  the lookup has been retried at least once and  the domains zone does not have a DNSSEC validation c hain to the ICANN root CAs MUST document potential issuances that were prevented by a CAA record in sufficient detail to provide feedback to the CAB Forum on the circumstances and SHOULD dispatch reports of such issuance requests to the contacts stipu lated in the CAA iodef records if present CAs are not expected to support URL schemes in the iodef record other than mailto or https 323 Authentication of Individual I dentity If an Applicant subject to this Section 323 is a natural person  then the CA SHALL verify the Applicants name  Applicants address  and the authenticity of the certificate request The CA SHALL verify the Applicants name using a legible copy which discernibly shows the Applicants face of at least one currently valid governm entissued photo ID passport drivers license military ID national ID or equivalent document type  The CA SHALL inspect the copy for any indication of alteration or falsification The CA SHALL verify the Applicants address using a form of identifi cation that the CA determines to be reliable  such as a government ID utility bill or bank or credit card statement The CA MAY rely on the same government issued ID that was used to verify the Applicants name The CA SHALL verify the certificate req uest with the Applicant using a Reliable Method of Communication 324 Non verified Subscriber Information 325 Validation of Authority If the Applicant for a Certificate containing Subject Identity Information is an organization t he CA SHALL use a Reliable Metho d of Communication to verify the authenticity of the Applicant Representatives certificate request The CA MAY use the sources list ed in section 322 1 to verify the Reliable Method of Communication Provided that the CA uses a Reliable Method of Comm unication the CA MAY establish the authenticity of the certificate request directly with the Applicant Representative or with an authoritative source within the Applicants organization  such as the Applicants main business offices corporate offices hu man resource offices information technol ogy offices or other department that the CA deems appropriate  In addition the CA SHALL establish a process that allows an Applicant to specify the individuals who may request Certificates If an Applicant spe cifies in writing the individuals who may request a Certificate then the CA SHALL NOT accept any certificate request s that are outside this specification  The CA SHALL provide an Applicant with a list of its authorized certificate requesters upon the Applicants verified written request 326 Criteria for Interoperation or Certification The CA SHALL disclose all Cross Certificates that identify the CA as the Subject provided that the CA arranged for or accepted the establishment of the trust relationship i e the Cross Certificate at issue Forum Guideline Baseline Requirements v 1 60 22 33 IDENTIFICATION AND A UTHENTICATION FOR RE KEY REQUESTS 331 Identification and Authentication for Routine Rekey 332 Identification and Authentication for Rekey After Revocation 34 IDENTIFICATION AND A UTHENTICATION FOR RE VOCATION REQUEST 4 CERTIFICATE LIFE CYC LE OPERATIONAL REQUI REMENTS 41 CERTIFICATE APPLICAT ION 411 Who Can Submit a Certificate Application In accordance with Section 552  the CA SHALL maintain an internal database of all previously revoked Certificates and previously re jected certificate requests due to suspected phishing or other fraudulent usage or concerns The CA SHALL use this information to identify subsequent suspicious certificate requests 412 Enrollment Process and Responsibilities Prior to the issuance of a Certi ficate the CA SHALL obtain the following documentation from the Applicant 1 A certificate request which may be electronic and 2 An executed Subscriber Agreement or Terms of Use which may be electronic The CA SHOULD obtain any additional documentation th e CA determines necessary to meet these Requirements Prior to the issuance of a Certificate the CA SHALL obtain from the Applicant a certificate request in a form prescribed by the CA and that complies with these Requirements One certificate request M AY suffice for multiple Certificates to be issued to the same Applicant subject to the aging and updating requirement in Section 331  provided that each Certificate is supported by a valid current certificate request signed by the appropriate Applicant Representative on behalf of the Applicant The certificate request MAY be made submitted andor signed electronically The certificate request MUST contain a request from or on behalf of the Applicant for the issuance of a Certificate and a certific ation by or on behalf of the Applicant that all of the information contained therein is correct 42 CERTIFICATE APPLICAT ION PROCESSING 421 Performing Identification and Authentication Functions The certificate request MAY include all factual information about t he Applicant to be included in the Certificate and such additional information as is necessary for the CA to obtain from the Applicant in order to comply with these Requirements and the CAs Certificate Policy andor Certification Practice Statement In cases where the certificate request does not contain all the necessary information about the Applicant the CA SHALL obtain the remaining information from the Applicant or having obtained it from a reliable independent third party data source confirm i t with the Applicant The CA SHALL establish and follow a documented procedure for verifying all data requested for inclusion in the Certificate by the Applicant Forum Guideline Baseline Requirements v 1 60 23 Applicant information MUST include but not be limited to at least one Fully Qualified Dom ain Name or IP address to be included in the Certificates SubjectAltName extension Section 632 limits the validity period of Subscriber Certificates The CA MAY use the documents and data provided in Section 32 to verify certificate information or may reuse previous validations themselves provided that  1 Prior to March 1 2018 the CA obtained the data or document from a source specified under Section 32 or completed the validation itself no more than 39 months prior to issuing the Certificate a nd 2 On or after March 1 2018 the CA obtained the data or document from a source specified under Section 32 or completed the validation itself no more than 825 days prior to issuing the Certificate In no case may a prior validation be reused if any dat a or document used in the prior validation was obtained more than the maximum time permitted for reuse of the data or document prior to issuing the Certificate After the change to any validation method specified in the Baseline Requirements or EV Guideli nes a CA may continue to reuse validation data or documents collected prior to the change or the validation itself for the period stated in this BR 421 unless otherwise specifically provided in a ballot Validations completed using methods specified in Section 32241 or Section 32245 SHALL NOT be re used on or after August 1 2018 The CA SHALL develop maintain and implement documented procedures that identify and require additional verification activity for High Risk Certificate Requests pr ior to the Certificates approval as reasonably necessary to ensure that such requests are properly verified under these Requirements If a Delegated Third Party fulfills any of the CAs obligations under this section  the CA SHALL verify that the proces s used by the Delegated Third Party to identify and further verify High Risk Certificate Requests provides at least the same level of assurance as the CAs own processes  422 Approval or Rejection of Certificate Applications CAs SHOULD NOT issue Certificates c ontaining a new gTLD under consideration by ICANN Prior to issuing a Certificate containing an Internal Name with a gTLD that ICANN has announced as under consideration to make operational the CA MUST provide a warning to the applicant that the gTLD may soon become resolvable and that at that time the CA will revoke the Certificate unless the applicant promptly registers the Domain Name When a gTLD is delegated by inclusion in the IANA Root Zone Database the Internal Name becomes a Domain Name and at such time a Certificate with such gTLD which may have complied with these Requirements at the time it was issued will be in a violation of these Requirements unless the CA has verified the Subscribers rights in the Domain Name The provisions below a re intended to prevent such violation from happening Within 30 days after ICANN has approved a new gTLD for operation as evidenced by publication of a contract with the gTLD operator on wwwICANNorg each CA MUST 1 compare the new gTLD against the CAs records of valid certificates and 2 cease issuing Certificates containing a Domain Name that includes the new gTLD until after the CA has first verified the Subscribers control over or exclusive right to use the Domain Name in accordance with Secti on 3224  Within 120 days after the publication of a contract for a new gTLD is published on wwwicannorg CAs MUST revoke each Certificate containing a Domain Name that includes the new gTLD unless the Subscriber is either the Domain Name Registrant or can demonstrate control over the Domain Name 423 Time to Process Certificate Applications No stipulation Forum Guideline Baseline Requirements v 1 60 24 43 CERTIFICATE ISSUANCE 431 CA Actions during Certificate Issuance Certificate issuance by the Root CA SHALL require an individual authorized by the CA ie  the CA system operator system officer or PKI administrator to deliberately issue a direct command in order for the Root CA to perform a certificate signing operation 432 Notification of Certificate Issuance No stipulation 44 CERTIFICATE ACCEPTAN CE 441 Conduc t constituting certificate acceptance No stipulation 442 Publication of the certificate by the CA No stipulation 443 Notification of certificate issuance by the CA to other entities No stipulation 45 KEY PAIR AND CERTIFI CATE USAGE 451 Subscriber private key and cer tificate usage See Sec tion 963 provisions 2 and 4 452 Relying party public key and certificate usage No stipulation 46 CERTIFICATE RENEWAL 461 Circumstance for certificate renewal No stipulation 462 Who may request renewal No stipulation 463 Processing certificate renewal requests No stipulation 464 Notification of new certificate issuance to subscriber Forum Guideline Baseline Requirements v 1 60 25 No stipulation 465 Conduct constituting acceptance of a renewal certificate No stipulation 466 Publication of the renewal certificate by the CA No stipulation 467 Notification of certificate issuance by the CA to other entities No stipulation 47 CERTIFICATE RE KEY 471 Circumstance for certificate re key No stipulation 472 Who may request certification of a new public key No stipulation 473 Processing certificate re keying requests No stipul ation 474 Notification of new certificate issuance to subscriber No stipulation 475 Conduct constituting acceptance of a re keyed certificate No stipulation 476 Publication of the re keyed certificate by the CA No stipulation 477 Notification of certificate issuance b y the CA to other entities No stipulation 48 CERTIFICATE MODIFICA TION 481 Circumstance for certificate modification No stipulation 482 Who may request certificate modification No stipulation 483 Processing certificate modification requests No stipulation 484 Notification of new certificate issuance to subscriber No stipulation Forum Guideline Baseline Requirements v 1 60 26 485 Conduct constituting acceptance of modified certificate No stipulation 486 Publication of the modified certificate by the CA No stipulation 487 Notification of certificate issuance by the CA to other ent ities No stipulation 49 CERTIFICATE REVOCATI ON AND SUSPENSION 491 Circumstances for Revocation 4911 Reasons for Revoking a Subscriber Certificate The CA SHALL revoke a Certificate within 24 hours if one or more of the following occurs 1 The Subscriber requests in writing that the CA revoke the Certificate 2 The Subscriber notifies the CA that the original certificate request was not authorized and does not retroactively grant authorization 3 The CA obtains evidence that the Subscribers Private Key correspondi ng to the Public Key in the Certificate suffered a Key Compromise or no longer complies with the requirements of Sections 615 and 616  4 The CA obtains evidence that the Certificate was misused 5 The CA is made aware that a Subscriber has violated one or more of its material obligations under the Subscriber Agreement or Terms of Use 6 The CA is made aware of any circumstance indicating that use of a Fully Qualified Domain Name or IP address in the Certificate is no longer legally permitted eg a court or arbitrator has revoked a Domain Name Registrants right to use the Domain Name a relevant licensing or services agreement between the Domain Name Registrant and the Applicant has terminated or the Domain Name Registrant has failed to renew the Domain Name 7 The CA is made aware that a Wildcard Certificate has been used to authenticate a fraudulently misleading subordinate Fully Qualified Domain Name 8 The CA is made aware of a material change in the information contained in the Certificate 9 The CA is made aware that the Certificate was not issued in accordance with these Requirements or the CAs Certificate Policy or Certification Practice Statement 10 The CA determines that any of the information appearing in the Certificate is inaccur ate or misleading 11 The CA ceases operations for any reason and has not made arrangements for another CA to provide revocation support for the Certificate 12 The CAs right to issue Certificates under these Requirements expires or is revoked or termin ated unless the CA has made arrangements to continue maintaining the CRLOCSP Repository 13 The CA is made aware of a possible compromise of the Private Key of the Subordinate CA used for issuing the Certificate 14 Revocation is required by the CAs C ertificate Policy andor Certification Practice Statement or 15 The technical content or format of the Certificate presents an unacceptable risk to Application Software Suppliers or Relying Parties eg the CABrowser Forum might determine that a deprec ated Forum Guideline Baseline Requirements v 1 60 27 cryptographicsignature algorithm or key size presents an unacceptable risk and that such Certificates should be revoked and replaced by CAs within a given period of time 4912 Reasons for Revoking a Subordinate CA Certificate The Issuing CA SHALL revoke a Subordinate CA Certificate within seven 7 days if one or more of the following occurs 1 The Subordinate CA requests revocation in writing 2 The Subordinate CA notifies the Issuing CA that the original certificate request was not authorized and doe s not retroactively grant authorization 3 The Issuing CA obtains evidence that the Subordinate CAs Private Key corresponding to the Public Key in the Certificate suffered a Key Compromise or no longer complies with the requirements of Sections 615 and 616  4 The Issuing CA obtains evidence that the Certificate was misused 5 The Issuing CA is made aware that the Certificate was not issued in accordance with or that Subordinate CA has not complied with this document or the applicable Certificate Pol icy or Certification Practice Statement 6 The Issuing CA determines that any of the information appearing in the Certificate is inaccurate or misleading 7 The Issuing CA or Subordinate CA ceases operations for any reason and has not made arrangements f or another CA to provide revocation support for the Certificate 8 The Issuing CAs or Subordinate CAs right to issue Certificates under these Requirements expires or is revoked or terminated unless the Issuing CA has made arrangements to continue maint aining the CRLOCSP Repository 9 Revocation is required by the Issuing CAs Certificate Policy andor Certification Practice Statement or 10 The technical content or format of the Certificate presents an unacceptable risk to Application Software Suppli ers or Relying Parties eg the CABrowser Forum might determine that a deprecated cryptographicsignature algorithm or key size presents an unacceptable risk and that such Certificates should be revoked and replaced by CAs within a given period of time 492 Who Can Request Revocation The Subscriber RA or Issuing CA can initiate revocation Additionally Subscribers Relying Parties Application Software Suppliers and other third parties may submit Certificate Problem Reports informing the issuing CA of re asonable cause to revoke the certificate 493 Procedure for Revocation Request The CA SHALL provide a process for Subscribers to request revocation of their own Certificates The process MUST be described in the CAs Certificate Policy or Certification Practic e Statement The CA SHALL maintain a continuous 24x7 ability to accept and respond to revocation requests and related inquiries The CA SHALL provide Subscribers Relying Parties Application Software Suppliers and other third parties with clear instruct ions for reporting suspected Private Key Compromise Certificate misuse or other types of fraud compromise misuse inappropriate conduct or any other matter related to Certificates The CA SHALL publicly disclose the instructions through a readily acce ssible online means 494 Revocation Request Grace Period No stipulation Forum Guideline Baseline Requirements v 1 60 28 495 Time within which CA Must Process the Revocation Request The CA SHALL begin investigation of a Certificate Problem Report within twenty four hours of receipt and decide whether revocatio n or other appropriate action is warranted based on at least the following criteria 1 The nature of the alleged problem 2 The number of Certificate Problem Reports received about a particular Certificate or Subscriber 3 The entity making the complain t for example a complaint from a law enforcement official that a Web site is engaged in illegal activities should carry more weight than a complaint from a consumer alleging that she didnt receive the goods she ordered and 4 Relevant legislation 496 Rev ocation Checking Requirement for Relying Parties No stipulation Note Following certificate issuance a certificate may be revoked for reasons stated in Section 491 Therefore relying parties should check the revocation status of all certificates th at contain a CDP or OCSP pointer 497 CRL I ssuance Frequency For the status of Subscriber Certificates If the CA publishes a CRL then the CA SHALL update and reissue CRLs at least once every seven days and the value of the nextUpdate field MUST NOT be mor e than ten days beyond the value of the thisUpdate field  For the status of Subordinate CA Certificates The CA SHALL update and reissue CRLs at least i once every twelve months and ii within 24 hours after revoking a Subordinate CA Certificate and the value of the nextUpdate field MUST NOT be more than twelve months beyond the value of the thisUpdate field  498 Maximum Latency for CRLs No stipulation 499 Online Revocation Status Checking Availability OCSP responses MUST conform to RFC6960 andor RFC5019 OCSP responses MUST either 1 Be signed by the CA that issued the Certificates whose revocation status is being checked or 2 Be signed by an OCSP Responder whose Certificate is signed by the CA that issued the Certificate whose revocation status is bein g checked In the latter case the OCSP signing Certificate MUST contain an extension of type id pkixocspnocheck as defined by RFC6960  4910 Online Revocation Checking Requirements Effective 1 January 2013 the CA SHALL support an OCSP capability using th e GET method for Certificates issued in accordance with these Requirements For the status of Subscriber Certificates The CA SHALL update information provided via an Online Certificate Status Protocol at least every four days OCSP responses from this se rvice MUST have a maximum expiration time of ten days For the status of Subordinate CA Certificates Forum Guideline Baseline Requirements v 1 60 29 The CA SHALL update information provided via an Online Certificate Status Protocol at least i every twelve months and ii within 24 hours after revoki ng a Subordinate CA Certificate If the OCSP responder receives a request for status of a certificate that has not been issued then the responder SHOULD NOT respond with a good status The CA SHOULD monitor the responder for such requests as part of its security response procedures Effective 1 August 2013 OCSP responders for CAs which are not Technically Constrained in line with Section 715 MUST NOT respond with a good status for such certificates 4911 Other Forms of Revocation Advertisements Availab le If the Subscriber Certificate is for a high traffic FQDN the CA MAY rely on stapling in accordance with RFC4366 to distribute its OCSP responses In this case the CA SHALL ensure that the Subscriber staples the OCSP response for the Certificate in its TLS handshake The CA SHALL enforce this requirement on the Subscriber either contractually through the Subscriber Agreement or Terms of Use or by technical review measures implement ed by the CA 4912 Special Requirements Related to K ey Compromise See Section 491 4913 Circumstances for Suspension The Repository MUST NOT include entries that indicate that a Certificate is suspended 4914 Who Can Request Suspension Not applicable 4915 Procedure for Suspension Request Not applicable 4916 Limits on Suspension Period Not applicable 410 CERTIFICATE STATUS S ERVICES 4101 Operational Characteristics Revocation entries on a CRL or OCSP Response MUST NOT be removed until after the Expiry Date of the revoked Certificate 4102 Service Availability The CA SHALL operate and maintain its CRL and OCSP capability with resources sufficient to provide a response time of ten seconds or less under normal operating conditions The CA SHALL maintain an online 24x7 Repository that application software can use to automatically check the current status of all unexpired Certificates issued by the CA Forum Guideline Baseline Requirements v 1 60 30 The CA SHALL maintain a continuous 24x7 ability to respond internally to a high priority Certificate Problem Report and where appropriate forward such a complaint to law enforcement authorities andor revok e a Certificate that is the subject of such a complaint 4103 Optional Features No stipulation 411 END OF SUBSCRIPTION No stipulation 412 KEY ESCROW AND RECOV ERY 4121 Key escrow and recovery policy and practices No stipulation 4122 Session key encapsulation and recovery pol icy and practices Not applicable 5 MANAGEMENT OPERATIO NAL  AND PHYSICAL CONTROLS The CABrowser Forums Network and Certificate System Security Requirements are incorporated by reference as if fully set forth herein  The CA SHALL develop implement and m aintain a comprehensive security program designed to 1 Protect the confidentiality integrity and availability of Certificate Data and Certificate Management Processes 2 Protect against anticipated threats or hazards to the confidentiality integrity  and availability of the Certificate Data and Certificate Management Processes 3 Protect against unauthorized or unlawful access use disclosure alteration or destruction of any Certificate Data or Certificate Management Processes 4 Protect against accidental loss or destruction of or damage to any Certificate Data or Certificate Management Processes and 5 Comply with all other security requirements applicable to the CA by law The Certificate Management Process MUST include 1 physical secur ity and environmental controls 2 system integrity controls including configuration management integrity maintenance of trusted code and malware detectionprevention 3 network security and firewall management including port restrictions and IP addre ss filtering 4 user management separate trusted role assignments education awareness and training and 5 logical access controls activity logging and inactivity time outs to provide individual accountability The CAs security program MUST includ e an annual Risk Assessment that Forum Guideline Baseline Requirements v 1 60 31 1 Identifies foreseeable internal and external threats that could result in unauthorized access disclosure misuse alteration or destruction of any Certificate Data or Certificate Management Processes 2 Assesses the likelihood and potential damage of these threats taking into consideration the sensitivity of the Certificate Data and Certificate Management Processes and 3 Assesses the sufficiency of the policies procedures information systems technology and oth er arrangements that the CA has in place to counter such threats Based on the Risk Assessment the CA SHALL develop implement and maintain a security plan consisting of security procedures measures and products designed to achieve the objectives set forth above and to manage and control the risks identified during the Risk Assessment commensurate with the sensitivity of the Certificate Data and Certificate Management Processes The security plan MUST include administrative organizational technical and physical safeguards appropriate to the sensitivity of the Certificate Data and Certificate Management Processes The security plan MUST also take into account then available technology and the cost of implementing the specific measures and SHALL impl ement a reasonable level of security appropriate to the harm that might result from a breach of security and the nature of the data to be protected 51 PHYSICAL SECURITY CONTROLS 511 Site location and construction 512 Physical access 513 Power and air conditioning 514 Water exposures 515 Fire prevention and protection 516 Media storage 517 Waste disposal 518 Offsite backup 52 PROCEDURAL CONTROLS 521 Trusted Roles 522 Number of Individuals Required per Task The CA Private Key SHALL be backed up stored and recovered only by personnel in trusted rol es using at least dual control in a physically secured environment 523 Identification and Authentication for Trusted Roles 524 Roles Requiring Separation of Duties 53 PERSONNEL CONTROLS Forum Guideline Baseline Requirements v 1 60 32 531 Qualifications Experience and Clearance Requirements Prior to the engagemen t of any person in the Certificate Management Process whether as an employee agent or an independent contractor of the CA the CA SHALL verify the identity and trustworthiness of such person 532 Background Check Procedures 533 Training Requirements and Proced ures The CA SHALL provide all personnel performing information verification duties with skills training that covers basic Public Key Infrastructure knowledge authentication and vetting policies and procedures including the CAs Certificate Policy andor Certification Practice Statement common threats to the information verification process including phishing and other social engineering tactics and these Requirements  The CA SHALL maintain records of such training and ensure that personnel entrusted with Validation Specialist duties maintain a skill level that enables them to perform such duties satisfactorily The CA SHALL document that each Validation Specialist possesses the skills required by a task before allowing the Validation Specialist to p erform that task The CA SHALL require all Validation Specialists to pass an examination provided by the CA on the information verification requirements outlined in these Requirements 534 Retraining Frequency and R equirements All personnel in Trusted Roles SHALL maintain skill levels consistent with the CAs training and performance programs 535 Job Rotation Frequency and Sequence 536 Sanctions for Unauthorized Actions 537 Independent Contractor Controls The CA SHALL verify that the Delegated Third Partys personnel in volved in the issuance of a Certificate meet the training and skills requirements of Section 533 and the document retention and event logging requirements of Section 541  538 Documentation Supplied to Personnel 54 AUDIT LOGGING PROCED URES 541 Types of Events Recorded The CA and each Delegated Third Party SHALL record details of the actions taken to process a certificate request and to issue a Certificate including all information generated and documentation received in connection with the certificate request th e time and date and the personnel involved The CA SHALL make these records available to its Qualified Auditor as proof of the CAs compliance with these Requirements The CA SHALL record at least the following events 1 CA key lifecycle management eve nts including a Key generation backup storage recovery archival and destruction and Forum Guideline Baseline Requirements v 1 60 33 b Cryptographic device lifecycle management events 2 CA and Subscriber Certificate lifecycle management events including a Certificate requests renew al and re key requests and revocation b All verification activities stipulated in these Requirements and the CAs Certification Practice Statement c Date time phone number used persons spoken to and end results of verification telephone calls  d Acceptance and rejection of certificate requests e Issuance of Certificates and f Generation of Certificate Revocation Lists and OCSP entries 3 Security events including a Successful and unsuccessful PKI system access attempts b PKI and security system actions performed c Security profile changes d System crashes hardware failures and other anomalies e Firewall and router activities and f Entries to and exits from the CA facility Log entries MUST include the f ollowing elements 1 Date and time of entry 2 Identity of the person making the journal entry and 3 Description of the entry 542 Frequency for Processing and Archiving Audit Logs 543 Retention Period for Audit Logs The CA SHALL retain any audit logs gener ated for at least seven years The CA SHALL make these audit logs available to its Qualified Auditor upon request 544 Protection of Audit Log 545 Audit Log Backup Procedures 546 Audit Log Accumulation System internal vs external 547 Notification to Event Causing Subje ct 548 Vulnerability Assessments Additionally the CAs security program MUST include an annual Risk Assessment that 1 Identifies foreseeable internal and external threats that could result in unauthorized access disclosure misuse alteration or destruct ion of any Certificate Data or Certificate Management Processes 2 Assesses the likelihood and potential damage of these threats taking into consideration the sensitivity of the Certificate Data and Certificate Management Processes and 3 Assesses the s ufficiency of the policies procedures information systems technology and other arrangements that the CA has in place to counter such threats Forum Guideline Baseline Requirements v 1 60 34 55 RECORDS ARCHIVAL 551 Types of Records Archived 552 Retention Period for Archive The CA SHALL retain all documentation relating to certificate requests and the verification thereof and all Certificates and revocation thereof for at least seven years after any Certificate based on that documentation ceases to be valid 553 Protection of Archive 554 Archive Backup Procedures 555 Requi rements for Time stamping of Records 556 Archive Collection System internal or external 557 Procedures to Obtain and Verify Archive Information 56 KEY CHANGEOVER 57 COMPROMISE AND DISAS TER RECOVERY 571 Incident and Compromise Handling Procedures CA organizations shall have an Incident Response Plan and a Disaster Recovery Plan The CA SHALL document a business continuity and disaster recovery procedures designed to notify and reasonably protect Application Software Suppliers Subscribers and Relying Parties in the eve nt of a disaster security compromise or business failure The CA is not required to publicly disclose its business continuity plans but SHALL make its business continuity plan and security plans available to the CAs auditors upon request The CA SHALL a nnually test review and update these procedures The business continuity plan MUST include 1 The conditions for activating the plan 2 Emergency procedures 3 Fallback procedures 4 Resumption procedures 5 A maintenance schedule for the plan 6 Awareness and education requirements 7 The responsibilities of the individuals 8 Recovery time objective RTO 9 Regular testing of contingency plans 10 The CAs plan to maintain or restore the CAs business operations in a timely manner following interruption to or failure of critical business processes Forum Guideline Baseline Requirements v 1 60 35 11 A requirement to store critical cryptographic materials ie secure cryptographic device and activation materials at an alternate location 12 What constitutes an acceptable system outage a nd recovery time 13 How frequently backup copies of essential business information and software are taken 14 The distance of recovery facilities to the CAs main site and 15 Procedures for securing its facility to the extent possible during the period of time following a disaster and prior to restoring a secure environment either at the original or a remote site 572 Recovery Procedures if C omputing Resources Software andor Data Are Corrupted 573 Recovery Procedures After Key Compromise 574 Business Continu ity Capabilities after a Disaster 58 CA OR RA TERMINATION 6 TECHNICAL SECURITY C ONTROLS 61 KEY PAIR GENERATION AND INSTALLATION 611 Key Pair Generation 6111 CA Key Pair Generation For Root CA Key Pairs created after the Effective Date that are either i used as Root CA Key Pairs or ii Key Pairs generated for a subordinate CA that is not the operator of the Root CA or an Affiliate of the Root CA the CA SHALL 1 prepare and follow a Key Generation Script 2 have a Qualified Auditor witness the Root CA Key Pair genera tion process or record a video of the entire Root CA Key Pair generation process and 3 have a Qualified Auditor issue a report opining that the CA followed its key ceremony during its Key and Certificate generation process and the controls used to ensure the integrity and confidentiality of the Key Pair For other CA Key Pairs created after the Effective Date that are for the operator of the Root CA or an Affiliate of the Root CA the CA SHOULD 1 prepare and follow a Key Generation Script and 2 have a Qualified Auditor witness the Root CA Key Pair generation process or record a video of the entire Root CA Key Pair generation process In all cases the CA SHALL 1 generate the keys in a physically secured environment as described in the CAs Certifi cate Policy andor Certification Practice Statement Forum Guideline Baseline Requirements v 1 60 36 2 generate the CA keys using personnel in trusted roles under the principles of multiple person control and split knowledge 3 generate the CA keys within cryptographic modules meeting the applicable t echnical and business requirements as disclosed in the CAs Certificate Policy andor Certification Practice Statement 4 log its CA key generation activities and 5 maintain effective controls to provide reasonable assurance that the Private Key was gen erated and protected in conformance with the procedures described in its Certificate Policy andor Certification Practice Statement and if applicable its Key Generation Script 6112 RA Key Pair Generation 6113 Subscriber Key Pair Generation The CA SHALL reject a certificate request if the requested Public Key does not meet the requirements set forth in Sections 615 and 616 or if it has a known weak Private Key such as a Debian weak key see httpwiki debianorgSSLkeys  612 Private Key Delivery to Subscriber Parties other than the Subscriber SHALL NOT archive the Subscriber Private Key without authorization by the Subscriber  If the CA or any of its designated R As generated the Private Key on behalf of the S ubscriber then the CA SHALL encrypt the P rivate Key for transport to the Subscriber If the CA or any of its designated R As become aware that a Subscribers Private Key has been communicated to an unauthorized person or an organization not affiliated with the Subscriber then the CA SHALL revoke all cert ificates that include the Public Key corresponding to the communicated Private Key 613 Public Key Delivery to Certificate Issuer 614 CA P ublic Key Delivery to Relying Parties 615 Key Sizes Certificates MUST meet the following requirements for algorithm type and key size 1 Root CA Certificates Validity period beginning on or before 31 Dec 2010 Validity period beginning after 31 Dec 2010 Digest algorithm MD5 NOT RECOMMENDED SHA 1 SHA 256 SHA 384 or SHA  512 SHA 1 SHA 256 SHA 384 or SHA  512 Minimum RSA modulus size bits 2048 2048 ECC curve NIST P 256 P 384 or P 521 NIST P 256 P 384 or P 521 Minimum DSA modulus and divisor L 2048 N 224 or L 2048 N 256 L 2048 N 224 or L 2048 N 256 Forum Guideline Baseline Requirements v 1 60 37 size bits  2 Subordinate CA Certific ates Validity period beginning on or before 31 Dec 2010 and ending on or before 31 Dec 2013 Validity period beginning after 31 Dec 2010 or ending after 31 Dec 2013 Digest algorithm SHA 1 SHA 256 SHA 384 or SHA  512 SHA 1 SHA 256 SHA 384 or SHA  512 Minimum RSA modulus size bits 1024 2048 ECC curve NIST P 256 P 384 or P 521 NIST P 256 P 384 or P 521 Minimum DSA modulus and divisor size bits  L 2048 N 224 or L 2048 N 256 L 2048 N 224 Or L 2048 N 256 3 Subscriber Certific ates Validity period ending on or before 31 Dec 2013 Validity period ending after 31 Dec 2013 Digest algorithm SHA1 SHA 256 SHA 384 or SHA  512 SHA1 SHA 256 SHA 384 or SHA  512 Minimum RSA modulus size bits 1024 2048 ECC curve NIST P 256 P 384 or P 521 NIST P 256 P 384 or P 521 Minimum DSA modulus and divisor size bits L 2048 N 224 or L 2048 N 256 L 2048 N 224 or L 2048 N 256  SHA 1 MAY be used with RSA keys in accordance with the criteria defined in Section 713  A Root CA Certificate issued prior to 31 Dec 2010 with an RSA key size less than 2048 bits MAY still serve as a trust anchor for Subscriber Certificates issued in accordance with these Requirements L and N the bit lengths of modulus p and divisor q respectively are described in the Digital Signature Standard FIPS 186 4 httpnvlpubs nistgovnistpubsFIPSNISTFIPS186 4pdf  616 Public Key Parameters Generation and Quality Checking RSA The CA SHALL confirm that the value of the public expone nt is an odd number equal to 3 or more Additionally the public exponent SHOULD be in the range between 2161 and 22561 The modulus SHOULD also have the following characteristics an odd number not the power of a prime and have no factors smaller than 752 Source Section 533 NIST SP 800 89 DSA Although FIPS 800 57 says that domain parameters may be made available at some accessible site compliant DSA certificates MUST include all domain parameters This is to insure maximum interoperability among relying party software The CA MUST confirm that the value of the public key has the unique correct representation and range in the field and that the key has the correct order in the subgroup Source Section 531 NIST SP 800 89 Forum Guideline Baseline Requirements v 1 60 38 ECC The CA SH OULD confirm the validity of all keys using either the ECC Full Public Key Validation Routine or the ECC Partial Public Key Validation Routine Source Sections 56232 and 56233 respectively of NIST SP 56A Revision 2  617 Key U sage Purposes Privat e Keys corresponding to Root Certificates MUST NOT be used to sign Certificates except in the following cases 1 Self signed Certificates to represent the Root CA itself 2 Certificates for Subordinate CAs and Cross Certificates 3 Certificates for infr astructure purposes administrative role certificates internal CA operational device certificates  and 4 Certificates for OCSP Response verification  62 PRIVATE KEY PROTECTI ON AND CRYPTOGRAPHIC MODULE ENGINEERING CONTROLS The CA SHALL implement physical and logical safeguards to prevent unauthorized certificate issuance Protection of the CA Private Key outside the validated system or device specified above MUST consist of physical security encryption or a combination of both implemented in a manner th at prevents disclosure of the CA Private Key The CA SHALL encrypt its Private Key with an algorithm and key length that according to the state of the art are capable of withstanding cryptanalytic attacks for the residual life of the encrypted key or ke y part 621 Cryptographic Module Standards and Controls 622 Private K ey n out of m Multiperson Control 623 Private Key Escrow 624 Private Key Backup See Section 522 625 Private Key Archival Parties other than the Subordinate CA SHALL NOT archive the Subordinate CA Pr ivate Keys without authorization by the Subordinate CA  626 Private Key Transfer into or from a Cryptographic Module If the Issuing CA generated the Private Key on behalf of the Subordinate CA then the Issuing CA SHALL encrypt the Private Key for transport to the Subordinate CA If the Issuing CA becomes aware that a Subordinate CAs Private Key has been communicated to an unauthorized person or an organization not affiliated with the Subordinate CA then the Issuing CA SHALL revoke all certificates that inc lude the Public Key corresponding to the communicated Private Key 627 Private Key Storage on Cryptographic Module Forum Guideline Baseline Requirements v 1 60 39 The CA SHALL protect its Private Key in a system or device that has been validated as meeting at least FIPS 140 level 3 or an appropriate Common Criteria Protection Profile or Security Target EAL 4 or higher which includes requirements to protect the Private Key and other assets against known threats 628 Activating Private Keys 629 Deactivating Private Keys 6210 Destroying Private Keys 6211 Cryptographic Module Capabilities 63 OTHER ASPECTS OF KEY PAIR MANAGEMENT 631 Public Key Archival 632 Certificate Operational Periods and Key Pair Usage Periods Subscriber Certificates issued after 1 March 2018 MUST have a Validity Period no greater than 825 days  Subscriber Certificates issued after 1 July 201 6 but prior to 1 March 2018 MUST have a Validity Period no greater than 39 months 64 ACTIVATION DATA 641 Activation data generation and installation 642 Activation data protection 643 Other aspects of activation data 65 COMPUTER SECURITY CONTROLS 651 Specific Computer Security Technical Requirements The CA SHALL enforce multi factor authentication for all accounts capable of directly causing certificate issuance 652 Computer Security Rating 66 LIFE CYCLE TECHNICAL CONTROLS Forum Guideline Baseline Requirements v 1 60 40 661 System development con trols 662 Security management controls 663 Life cycle security controls 67 NETWORK SECURITY CON TROLS 68 TIME STAMPING 7 CERTIFICATE CRL AND OCSP PROFILES 71 CERTIFICATE PROFILE The CA SHALL meet the technical requirements set forth in Section 22  Publication of Infor mation  Section 615  Key Sizes and Section 616  Public Key Parameters Generation and Quality Checking  Effective September 30 2016 CAs SHALL generate non sequential Certificate serial numbers greater than zero 0 containing at least 64 bits of o utput from a CSPRNG  711 Version Numbers Certificates MUST be of type X509 v3 712 Certificate Content and Extensions  Application of RFC 5280 This section specifies the additional requirements for Certificate content and extensions for Certificates generated after the Effective Date 7121 Root CA Certificate a basicConstraints This extension MUST appear as a critical extension The cA field MUST be set true The pathLenConstraint field SHOULD NOT be present b keyUsage This extension MUST be present and MUST be mar ked critical Bit positions for keyCertSign and cRLSign MUST be set If the Root CA Private K ey is used for signing OCSP responses then the digitalSignature bit MUST be set c certificatePolicies This extension SHOULD NOT be present d extendedK eyUsage This extension MUST NOT be presen t Forum Guideline Baseline Requirements v 1 60 41 7122 Subordinate CA Certificate a certificatePolicies This extension MUST be present and SHOULD NOT be marked critical certificatePoliciespolicyIdentifier Required The following fields MAY be present if the Subordinate CA is not an Affiliate of the entity that controls the Root CA certificatePoliciespolicyQualifierspolicyQualifierId Optional  idqt 1 RFC 5280 certificatePoliciespolicyQualifiersqualifiercPSuri Optional  HTTP URL for the Root CAs Certificate P olicies Certification Practice Statement Relying Party Agreement or other pointer to online policy information provided by the CA b cRLDistributionPoint s This extension MUST be present and MUST NOT be marked critical It MUST contain the HTTP URL of the CAs CRL service c authorityInformationAccess With the exception of stapling which is noted below this extension MUST be present It MUST NOT be marked critical and it MUST contain the HTTP URL of the Issuing CAs OCSP responder accessMethod  136 1557481 It SHOULD also contain the HTTP URL of the Issuing CAs certificate accessMethod  1361557482 The HTTP URL of the Issuing CAs OCSP responder MAY be omitted provided that the Subscriber staples the OCSP response for the Cer tificate in its TLS handshakes RFC4366 d basicConstraints This extension MUST be present and MUST be marked critical The cA field MUST be set true The pathLenConstraint field MAY be present e keyUsage This extension MUST be present and MUST be marked critical Bit positions for keyCertSign and cRLSign MUST be set If the Subordinate CA Private K ey is used for signing OCSP responses then the digitalSignature bit MUST be set  f nameConstraints optional If present this extension SHOULD be marked cr itical  Non critical Name Constraints are an exception to RFC 5280 42110 however they MAY be used until the Name Constraints extension is supported by Application Software Suppliers whose software is used by a substantial portion of Relying Par ties worldwide g extkeyUsage optional Forum Guideline Baseline Requirements v 1 60 42 For Subordinate CA Certificates to be Technically constrained in line with section 715  then either the value idkpserverAuth RFC5280 or id kpclientAuth RFC5280 or both values MUST be present Other values MAY be present If present this extension SHOULD be marked non critical  Generally Extended Key Usage will only appear within end entity certificates as highlighted in RFC 5280 42112 however Subordinate CAs MAY include the extension to furt her protect relying parties until the use of the extension is consistent between Application Software Suppliers whose software is used by a substantial portion of Relying Parties worldwide 7123 Subscriber Certificate a certificatePolicies This extension MUST be present and SHOULD NOT be marked critical certificatePoliciespolicyIdentifier Required  A Policy Identifier defined by the issuing CA that indicates a Certificate Policy asserting the issuing CAs adherence to and compliance with these Requirements  The following extensions MAY be present certificatePoliciespolicyQualifierspolicyQualifierId Recommended  idqt 1 RFC 5280 certificatePoliciespolicyQualifiersqualifiercPSuri Optional  HTTP URL for the Subordinate CAs Certification Pract ice Statement Relying Party Agreement or other pointer to online information provided by the CA b cRLDistributionPoint s This extension MAY be present If present it MUST NOT be marked critical and it MUST contain the HTTP URL of the CAs CRL service c authorityInformationAccess With the exception of stapling which is noted below this extension MUST be present It MUST NOT be marked critical and it MUST contain the HTTP URL of the Issuing CAs OCSP responder accessMethod  1361557481 It SHOULD also contain the HTTP URL of the Issuing CAs certificate accessMethod  1361557482  The HTTP URL of the Issuing CAs OCSP responder MAY be omitted provided that the Subscriber staples OCSP responses for the Certificate in its TLS handshakes RFC4366 d basicConstraints optional The cA field MUST NOT be true  e keyUsage optional Forum Guideline Baseline Requirements v 1 60 43 If present bit positions for keyCertSign and cRLSign MUST NOT be set f extKeyUsage required Either the value id kpserverAuth RFC5280 or id kpclientAuth RFC5280 or both values MUST be present idkpemailProtection RFC5280 MAY be present Other values SHOULD NOT be present 7124 All Certificates All other fields and extensions MUST be set in accordance with RFC 5280 The CA SHALL NOT issue a Certificate that contains a keyUsage flag extendedKeyUsage value Certificate extension or other data not specified in section 7121 7122 or 7123 unless the CA is aware of a reason for including the data in the Certificate CAs SHALL NOT issue a Certificate with a Extensions that do not apply in the context of the public Internet such as an extendedKeyUsage value for a service that is only valid in the context of a privately managed network unless i such value falls within an OID arc for which the Applicant demonstrates ownership or ii the Applicant can otherwise demonstrate the right to assert the data in a public context or b semantics that if included will mislead a Relying Party about the certificate information verified by the CA such as i ncluding extendedKeyUsage value for a smart card where the CA is not able to verify that the corresponding Private Key is confined to such hardware due to remote issuance 7125 Application of RFC 5280 For purposes of clarification a Precertificate as descri bed in RFC 6962  Certificate Transparency shall not be considered to be a certificate subject to the requirements of RFC 5280  Internet X509 Public Key Infrastructure Certificate and Certificate Revocation List CRL Profile under these Baseline Requ irements 713 Algorithm Object Identifiers Effective 1 January 2016 CAs MUST NOT issue any new Subscriber certificates or Subordinate CA certificates using the SHA 1 hash algorithm CAs MAY continue to sign certificates to verify OCSP responses using SHA1 until 1 January 2017 This Section 713 does not apply to Root CA or CA cross certificates CAs MAY continue to use their existing SHA 1 Root Certificates SHA 2 Subscriber certificates SHOULD NOT chain up to a SHA 1 Subordinate CA Certificate Effective 1 6 January 2015 CAs SHOULD NOT issue Subscriber Certificates utilizing the SHA 1 algorithm with an Expiry Date greater than 1 January 2017 because Application Software Providers are in the process of deprecating andor removing the SHA 1 algorithm from the ir software and they have communicated that CAs and Subscribers using such certificates do so at their own risk 714 Name Forms 7141 Issuer Information The content of the Certificate Issuer Distinguished Name field MUST match the Subject DN of the Issuing CA to support Name chaining as specified in RFC 5280 section 4124 7142 Subject Information  Subscriber Certificates By issuing the Certificate the CA represents that it followed the procedure set forth in its Certificate Policy andor Certification Practice St atement to verify that as of the Certificates issuance date all of the Subject Forum Guideline Baseline Requirements v 1 60 44 Information was accurate CAs SHALL NOT include a Domain Name or IP Address in a Subject attribute except as specified in Section 3224 or Section 3225 71421 Subject Alterna tive Name Extension Certificate F ield extensionssubjectAltName RequiredOptional Required Contents  This extension MUST contain at least one entry Each entry MUST be either a dNSName containing the Fully Qualified Domain Name or an iPAddress contain ing the IP address of a server The CA MUST confirm that the Applicant control s the Fully Qualified Domain Name or IP address or has been granted the right to use it by the Domain Name Registrant or IP address assignee as appropriate  Wildcard FQDNs are permitted As of the Effective Date of these Requirements prior to the issuance of a Certificate with a subjectAlternativeName extension or Subject commonName field containing a Reserved IP Address or Internal Name the CA SHALL notify the Applicant that the use of such Certificates has been deprecated by the CA  Browser Forum and that the practice will be eliminated by October 2016 Also as of the Effective Date the CA SHALL NOT issue a certificate with an Expiry Date later than 1 November 2015 with a subjectAlternativeName extension or Subject commonName field containing a Reserved IP Address or Internal Name Effective 1 October 2016 CAs SHALL revoke all unexpired Certificates whose subjectAlternativeName extension or Subject commonName field conta ins a Reserved IP Address or Internal Name  71422 Subject Distinguished Name Field s a Certificate Field  subjectcommonName OID 2543 RequiredOptional Deprecated Discouraged but not prohibited Contents If present this field MUST contain a single I P address or Fully Qualified Domain Name that is one of the values contained in the Certificates subjectAltName extension see Section 71421  b Certificate Field subject organizationName OID 25410 Optional  Contents If present the subjectorgan izationName field MUST contain either the Subjects name or DBA as verified under Section 3222  The CA may include information in this field that differs slightly from the verified name  such as common variations or abbreviations  provided that the CA d ocuments the difference and any abbreviations used are locally accepted abbreviations eg if the official record shows Company Name Incorporated the CA MAY use Company Name Inc or Company Name  Because Subject name attributes for individuals e g givenName 25442 and surname 2544 are not broadly supported by application software the CA MAY use the subjectorganizationName field to convey a natural person Subjects name or DBA  c Certificate Field  subjectgivenName 2544 2 and subj ectsurname 2544  Optional Contents If present the subjectgivenName field and subjectsurname field MUST contain an natural person Subjects name as verified under Section 323 A Certificate containing a subjectgivenName field or subjectsurna me field MUST contain the 223140123 Certificate Policy OID d Certificate Field  Number and street subjectstreetAddress OID 2549 Optional if the subjectorganizationName field   subject givenName field or subjectsurname field are present  Prohibited if the subjectorganizationName field  subjectgivenName and subjectsurname field are absent Contents If present the subjectstreetAddress field MUST contain the Subjects street address information as verified under Section 3221  Forum Guideline Baseline Requirements v 1 60 45 e Certificate Field  subjectlocalityName OID 2547 Required if the subjectorganizationName field  subjectgivenName field or subjectsurname field are present and the subjectstateOrProvinceName field is absent Optional if the subjectstateOrProvinc eName field and the subjectorganizationName field subjectgivenName field or subjectsurname field are present Prohibited if the subjectorganizationName field  subjectgivenName and subjectsurname field are absent Contents If present the subject localityName field MUST contain the Subjects locality information as verified under Section 3221  If the subjectcountryName field specifies the ISO 3166 1 user assigned code of XX in accordance with Section 714 22g the localityName field MAY co ntain the Subjects locality andor state or province information as verified under Section 3221  f Certificate Field  subjectstateOrProvinceName OID 2548 Required if the subjectorganizationName field  subjectgivenName field or subjectsurname field are present and subjectlocalityName field is absent Optional if the subjectlocalityName field and the subjectorganizationName field and subjectgivenName field  or subjectsurname field are present Prohibited if the subjectorganizationName field  subjectgivenName field  or subjectsurname field are absent Contents If present the subjectstateOrProvinceName field MUST contain the Subjects state or province information as verified under Section 3221 If the subjectcountryName field specifies the ISO 3166 1 user assigned code of XX in accordance with Section 7142 2g  the subjectstateOrProvinceName field MAY contain the full name of the Subjects country information as verified under Section 3221  g Certificate Field  subjectp ostalCode OID 25417 Optional if the subjectorganizationName  subjectgivenName field or subjectsurname fields are present Prohibited if the subjectorganizationName field  subjectgivenName field or subjectsurname field are absent Contents  If present the subjectpostalCode field MUST contain the Subjects zip or postal information as verified under Section 3221 h Certificate Field subjectcountryName OID 2546  Required if the subjectorganizationName field  subjectgivenName o r subjectsurname field are present Optional if the subjectorganizationName field  subjectgivenName field and subjectsurname field are absent Contents If the subjectorganizationName field is present the subjectcountryName MUST contain the two letter ISO 3166 1 country code associated with the location of the Subject verified under Section 3221  If the subjectorganizationName field is absent the subjectcountryName field MAY contain the two letter ISO 3166 1 country code associated with the Subject as verified in accordance with Section 3223  If a Country is not represented by an official ISO 3166 1 country code the CA MAY specify the ISO 3166 1 user assigned code of XX indicating that an official ISO 3166 1 alp ha2 code has not been assi gned i Certificate Field subjectorganizationalUnitName Optional The CA SHALL implement a process that prevents an OU attribute from including a name DBA tradename trademark address location or other text that refers to a specific natural person or Legal Entity unless the CA has verified this information in accordance with Section 32 and the Certificate also contains subjectorganizationName  subjectgivenName subjectsurname  subjectlocalityName and subjectcountryName attributes also ver ified in accordance with Section 3221 Forum Guideline Baseline Requirements v 1 60 46 j Other Subject Attributes All other optional attributes when present within the subject field MUST contain information that has been verified by the CA Optional attributes MUST NOT contain metadata such as   and   ie space characters andor any other indication that the value is absent incomplete or not applicable 7143 Subject Information  Root Certificates and Subordinate CA Certificates By issuing a Subordinate CA Certificate the CA represents that it followed the procedure set forth in its Certificate Policy andor Certification Practice Statement to verify that as of the Certificates issuance date all of the Subject Information was accurate 71431 Subject Distinguished Name Fields a Certific ate Field subjectcommonName OID 2543 RequiredOptional Required Contents This field MUST be present and the contents SHOULD be an identifier for the certificate such that the certifica tes Name is unique across all certificates issued by the issui ng certificate b Certificate Field subjectorganizationName OID 25410 RequiredOptional Required Contents This field MUST be present and the contents MUST contain either the Subject CAs name or DBA as verified under Section 3222 The CA may include information in this field that differs slightly from the verified name such as commo n variations or abbreviations provided that the CA documents the difference and any abbreviations used are locally accepted abbreviations eg if the official record shows Company Name Incorporated the CA MAY use Company Name Inc or Company Name c Certificate Field subjectcountryName OID 2546 RequiredOptional Required Contents This field MUST contain t he twoletter ISO 31661 country code for the country in which the CAs place of business is located 715 Name Constraints For a Subordinate CA Certificate to be considered Technically Constrained the certificate MUST include an Extended Key Usage EKU exte nsion specifying all extended key usages that the Subordinate CA Certificate is authorized to issue certificates for The anyExtendedKeyUsage KeyPurposeId MUST NOT appear within this extension If the Subordinate CA Certificate includes the id kpserverA uth extended key usage then the Subordinate CA Certificate MUST include the Name Constraints X509v3 extension with constraints on dNSName iPAddress and DirectoryName as follows  a For each dNSName in permittedSubtrees the CA MUST confirm that the A pplicant has registered the dNSName or has been authorized by the domain registrant to act on the registrants behalf in line with the verification practices of section 3224  b For each iPAddress range in permittedSubtrees the CA MUST confirm that th e Applicant has been assigned the iPAddress range or has been authorized by the assigner to act on the assignees behalf c For each DirectoryName in permittedSubtrees the CA MUST confirm the Applicants andor Subsidiarys Organizational name and locati on such that end entity certificates issued from the subordinate CA Certificate will be in compliancy with section 7124 and 7125  Forum Guideline Baseline Requirements v 1 60 47 If the Subordinate CA Certificate is not allowed to issue certificates with an iPAddress then the Subordinate CA Cert ificate MUST specify the entire IPv4 and IPv6 address ranges in excludedSubtrees The Subordinate CA Certificate MUST include within excludedSubtrees an iPAddress GeneralName of 8 zero octets covering the IPv4 address range of 00000 The Subordinate CA Certificate MUST also include within excludedSubtrees an iPAddress GeneralName of 32 zero octets covering the IPv6 address range of 00 Otherwise the Subordinate CA Certificate MUST include at least one iPAddress in permittedSubtrees A decoded example for issuance to the domain and sub domains of examplecom by organization   Example LLC Boston Massachusetts US would be  X509v3 Name Constraints Permitted DNSexamplecom DirName CUS STMA LBoston OExample LLC Excluded IP00000000 IP0000000000000000 If the Subordinate CA is not allowed to issue certificates with dNSNames then the Subordinate CA Certificate MUST include a zero length dNSName in excludedSubtrees Otherwise the Subordinate CA Certifica te MUST include at least one dNSName in permittedSubtrees  716 Certificate Policy Object Identifier 7161 Reserved Certificate Policy Identifiers This section describes the content requirements for the Root CA Subordinate CA and Subscriber Certificates as they r elate to the identification of Certificate Policy The following Certificate Policy identifiers are reserved for use by CAs as an optional means of asserting compliance with these Requirements as follows joint isoitut2 international organizations 23 ca browser forum140 certificate policies1 baseline requirements2 domain validated1  223140121 if the Certificate complies with these Requirements but lacks Subject Identity Information that is verified in accordance with Section 3221 or Section 323  If the Certificate asserts the policy identifier of 223140121 then it MUST NOT include organizationN ame givenName surname  streetAddress localityName stateOrProvinceName or postalCode in the Subject field joint isoitut2 international organizations23 ca browser forum140 certificate policies1 baseline requirements2 organization validated2  223140122 if the Certificate complies with these Requirements and includes Subject Identity Information that is veri fied in accordance with Section 3221  jointisoitut2 internationalorganizations23 cabrowserforum140 certificatepolicies1 baselinerequirements2 individual validated3 223140123 if the Certificate complies with these Requireme nts and includes Subject Identity Information that is verified in accordance with Section 323 If the Certificate asserts the policy identifier of 22314012 2 then it MUST also include organization Name localityName to the extent such field is requ ired under Section 71422  stateOrProvinceName  to the extent such field is required under Section 71422  and countryName in the Subject field If the Certificate asserts the policy identifier of 223140123 then it MUST also include i eit her organizationName or givenName and surname ii localityName to the extent such field is required under Section 71422 iii Forum Guideline Baseline Requirements v 1 60 48 stateOrProvinceName to the extent required under Section 71422 and iv countryName in the Subject field 7162 Root CA Certificates A Root CA Certificate SHOULD NOT contain the certificatePolicies extension 7163 Subordinate CA Certificates A Certificate issued after the Effective Date to a Subordinate CA that is not an Affiliate of the Issuing CA 1 MUST include one or more expl icit policy identifiers that indicates the Subordinate CAs adherence to and compliance with these Requirements ie either the CABrowser Forum reserved identifiers or identifiers defined by the CA in its Certificate Policy andor Certification Practice Statement and 2 MUST NOT contain the anyPolicy identifier 2529320 A Certificate issued after the Effective Date to a Subordinate CA that is an affiliate of the Issuing CA 1 MAY include the CABrowser Forum reserved identifiers or an identifier defin ed by the CA in its Certificate Policy andor Certification Practice Statement to indicate the Subordinate CAs compliance with these Requirements and 2 MAY contain the anyPolicy identifier 2529320 in place of an explicit policy identifier A Subordi nate CA SHALL represent  in its Certificate Policy and or Certification Practice Statement  that all Certificates containing a policy identifier indicating compliance with these Requirements are issued and managed in accordance with these Requirements 7164 Subscriber Certificates A Certificate issued to a Subscriber MUST contain one or more policy identifiers defined by the Issuing CA in the Certificates certificatePolicies extension that indicates adherence to and compliance with these Requirements CAs complying with these Requirements MAY also assert one of the reserved policy OIDs in such Certificates The issuing CA SHALL document in its Certificate Policy or Certification Practice Statement that the Certificates it issues containing the specified po licy identifiers are managed in accordance with these Requirements 717 Usage of Policy Constraints Extension 718 Policy Qualifiers Syntax and Semantics 719 Processing Semantics for the Critical Certificate Policies Extension 72 CRL PROFILE 721 Version numbers 722 CRL and CR L entry extensions 73 OCSP PROFILE 731 Version numbers 732 OCSP extensions Forum Guideline Baseline Requirements v 1 60 49 8 COMPLIANCE AUDIT AND OTHER ASSESSMENTS The CA SHALL at all times 1 Issue Certificates and operate its PKI in accordance with all law applicable to its business and the Certificates it issues in every jurisdiction in which it operates 2 Comply with these Requirements 3 Comply with the audit requirements set forth in this section  and 4 Be licensed as a CA in each jurisdiction where it operates if licensing is required by the law of such jurisdicti on for the issuance of Certificates Implementers Note Version 11 6 of the SSL Baseline Requirements was published on July 29 2013  Version 20 of WebTrusts Principles and Criteria for Certifi cation Authorities  SSL Baseline with Network Security and ETSI s Electronic Signatures and Infrastructures ESI 102 042 incorporate version 11 6 of these Baseline Requirements and version 10 of the Network and Certificate System Security Requirements The CABrowser Forum continues to improve the Basel ine Requirements while WebTrust and ETSI also continue to update their audit criteria We encourage all CAs to conform to each revision herein on the date specified without awaiting a corresponding update to an applicable audit criterion In the event of a conflict between an existing audit criterion and a guideline revision we will communicate with the audit community and attempt to resolve any uncertainty and we will respond to implementation questions directed to questionscabforumorg Our coordinat ion with compliance auditors will continue as we develop guideline revision cycles that harmonize with the revision cycles for audit criteria the compliance auditing periods and cycles of CAs and the CA Browser Forums guideline implementation dates 81 FREQUENCY OR CIRCUMSTA NCES OF ASSESSMENT Certificates that are capable of being used to issue new certificates MUST either be Technically Constrained in line with section 715 and audited in line with section 87 only or Unconstrained and fully audited in line with all remaining requirements from this section A Certificate is deemed as capable of being used to issue new certificates if it contains an X509v3 basicConstraints extension with the cA boolean set to true and is therefore by definition a Root C A Certificate or a Subordinate CA Certificate The period during which the CA issues Certificates SHALL be divided into an unbroken sequence of audit periods An audit period MUST NOT exceed one year in duration If the CA has a currently valid Audit Rep ort indicating compliance with an audit scheme listed in Section 81 then no pre issuance readiness assessment is necessary If the CA does not have a currently valid Audit Report indicating compliance with one of the audit schemes listed in Section 81 then before issuing Publicly Trusted Certificates the CA SHALL successfully complete a point intime readiness assessment performed in accordance with applicable standards under one of the audit schemes listed in Section 81 The point intime readiness assessment SHALL be completed no earlier than twelve 12 months prior to issuing Publicly Trusted Certificates and SHALL be followed by a complete audit under such scheme within ninety 90 days of issuing the first Publicly Trusted Certificate 82 IDENTITY QUALIFICATIONS OF A SSESSOR The CAs audit SHALL be performed by a Qualified Auditor A Qualified Auditor means a natural person Legal Entity or group of natural persons or Legal Entities that collectively possess the following qualifications and skills 1 Independence from the subject of the audit 2 The ability to conduct an audit that addresses the criteria specified in an Eligible Audit Scheme see Section 81 Forum Guideline Baseline Requirements v 1 60 50 3 Employs individuals who have proficiency in examining Public Key Infrastructure techn ology information security tools and techniques information technology and security auditing and the third party attestation function 4 For audits conducted in accordance with any one of the ETSI standards accredited in accordance with ISO 17065 app lying the requiremen ts specified in ETSI EN 319 403  5 For audits conducted in accordance with the WebTrust standard licensed by WebTrust 6 Bound by law government regulation or professional code of ethics and 7 Except in the case of an Internal G overnment Auditing Agency maintains Professional LiabilityErrors  Omissions insurance with policy limits of at least one million US dollars in coverage 83 ASSESSORS RELATIONS HIP TO ASSESSED ENTI TY 84 TOPICS COVERED BY AS SESSMENT The CA SHALL undergo an au dit in accordance with one of the following schemes 1 WebTrust for CAs v20 or newer AND WebTrust for CAs SSL Baseline with Network Security v22 or newer  2 ETSI EN 319 411 1 which includes normative references to ETSI EN 319 401 the latest version o f the referenced ETSI documents should be applied  or 3 If a Government CA is required by its Certificate Policy to use a different internal audit scheme it MAY use such scheme provided that the audit either a encompasses all requirements of one of th e above schemes or b consists of comparable criteria that are available for public review Whichever scheme is chosen it MUST incorporate periodic monitoring andor accountability procedures to ensure that its audits continue to be conducted in accorda nce with the requirements of the scheme The audit MUST be conducted by a Qualified Auditor as specified in Section 82 For Delegated Third Parties which are not Enterprise RAs  then the CA SHALL obtain an audit report issued under the auditing stan dards that underlie the accepted audit schemes found in Section 81 that provides an opinion whether the Delegated Third Partys performance complies with either the Delegated Third Partys practice statement or the CAs Certificate Policy andor Certific ation Practice Statement If the opinion is that the Delegated Third Party does not comply then the CA SHALL not allow the Delegated Third Party to continue performing delegated functions The audit period for the Delegated Third Party SHALL NOT exceed o ne year ideally aligned with the CAs audit However if the CA or Delegated Third Party is under the operation control or supervision of a Government Entity and the audit scheme is completed over multiple years then the annual audit MUST cover at lea st the core controls that are required to be audited annually by such scheme plus that portion of all non core controls that are allowed to be conducted less frequently but in no case may any non core control be audited less often than once every three years 85 ACTIONS TAKEN AS A R ESULT OF DEFICIENCY 86 COMMUNICATION OF RES ULTS The Audit Report SHALL state explicitly that it covers the relevant systems and processes used in the issuance of all Certificates that assert one or more of the policy identifiers liste d in Section 7161  The CA SHALL make the Audit Report publicly available The CA is not required to make publicly available any general audit findings that Forum Guideline Baseline Requirements v 1 60 51 do not impact the overall audit opinion For both government and commercial CAs the CA SHOULD ma ke its Audit Report publicly available no later than three months after the end of the audit period In the event of a delay greater than three months and if so requested by an Application Software Supplier the CA SHALL provide an explanatory letter sign ed by the Qualified Auditor 87 SELF AUDITS During the period in which the CA issues Certificates the CA SHALL monitor adherence to its Certificate Policy Certification Practice Statement and these Requirements and strictly control its service quality by pe rforming self audits on at least a quarterly basis against a randomly selected sample of the greater of one certificate or at least three percent of the Certificates issued by it during the period commencing immediately after the previous self audit sample was taken Except for Delegated Third Parties that undergo an annual audit that meets the criteria specified in Section 81 the CA SHALL strictly control the service quality of Certificates issued or containing information verified by a Delegated Third P arty by having a Validation Specialist employed by the CA perform ongoing quarterly audits against a randomly selected sample of at least the greater of one certificate or three percent of the Certificates verified by the Delegated Third Party in the perio d beginning immediately after the last sample was taken The CA SHALL review each Delegated Third Partys practices and procedures to ensure that the Delegated Third Party is in compliance with these Requirements and the relevant Certificate Policy andor Certification Practice Statement The CA SHALL internally audit each Delegated Third Partys compliance with these Requirements on an annual basis During the period in which a Technically Constrained Subordinate CA issues Certificates the CA which sign ed the Subordinate CA SHALL monitor adherence to the CAs Certificate Policy and the Subordinate CAs Certification Practice Statement On at least a quarterly basis against a randomly selected sample of the greater of one certificate or at least three pe rcent of the Certificates issued by the Subordinate CA during the period commencing immediately after the previous audit sample was taken the CA shall ensure all applicable CP are met 9 OTHER BUSINESS AND L EGAL MATTERS 91 FEES 911 Certificate issuance or renewal fees 912 Certificate access fees 913 Revocation or status information access fees 914 Fees for other services 915 Refund policy 92 FINANCIAL RESPONSIBI LITY 921 Insurance coverage 922 Other assets 923 Insurance or warranty coverage for end entities 93 CONFIDENTIALITY OF B USINESS INFORMATIO N 931 Scope of confidential information Forum Guideline Baseline Requirements v 1 60 52 932 Information not within the scope of confidential information 933 Responsibility to protect confidential information 94 PRIVACY OF PERSONAL INFORMATION 941 Privacy plan 942 Information treated as private 943 Information not deemed private 944 Responsibility to protect private information 945 Notice and consent to use private information 946 Disclosure pursuant to judicial or administrative process 947 Other information disclosure circumstances 95 INTELLECTUAL PROPERT Y RIGHTS 96 REPRESENTATIONS AND WARRANTIES 961 CA Representations and Warranties By issuing a Certificate the CA makes the certificate warranties listed herein to the following Certificate Beneficiaries  1 The Subscriber that is a party to the Subscriber Agreement or Terms of Use for the Certificate 2 All Ap plication Software Suppliers with whom the Root CA has entered into a contract for inclusion of its Root Certificate in software distributed by such Application Software Supplier and 3 All Relying Parties who reasonably rely on a Valid Certificate The CA r epresents and warrants to the Certificate Beneficiaries that during the period when the Certificate is valid the CA has complied with these Requirements and its Certificate Policy andor Certification Practice Statement in issuing and managing the Certif icate The Certificate Warranties specifically include but are not limited to the following 1 Right to Use Domain Name or IP Address  That at the time of issuance the CA i implemented a procedure for verifying that the Applicant either had the right to use or had control of the Domain Names and IP addresses listed in the Certificates subject field and subjectAltName extension or only in the case of Domain Names was delegated such right or control by someone who had such right to use or cont rol ii followed the procedure when issuing the Certificate and iii accurately described the procedure in the CAs Certificate Policy andor Certification Practice Statement 2 Authorization for Certificate That at the time of issuance the CA i i mplemented a procedure for verifying that the Subject authorized the issuance of the Certificate and that the Applicant Representative is authorized to request the Certificate on behalf of the Subject  ii followed the procedure when issuing the Certifica te and iii accurately described the procedure in the CAs Certificate Policy andor Certification Practice Statement 3 Accuracy of Information That at the time of issuance the CA i implemented a procedure for verifying the accuracy of all of the in formation contained in the Certificate with the exception of the subjectorganizationalUnitName attribute ii followed the procedure when issuing the Certificate Forum Guideline Baseline Requirements v 1 60 53 and iii accurately described the procedure in the CAs Certificate Policy andor Certif ication Practice Statement 4 No Misleading Information That at the time of issuance the CA i implemented a procedure for reducing the likelihood that the information contained in the Certificates subjectorganizationalUnitName attribute would be misl eading ii followed the procedure when issuing the Certificate and iii accurately described the procedure in the CAs Certificate Policy andor Certification Practice Statement 5 Identity of Applicant That if the Certificate contains Subject Identit y Information the CA i implemented a procedure to verify the identity of the Applicant in accordance with Sections 32 and 112  ii followed the procedure when issuing the Certificate  and iii accurately described the procedure in the CAs Certifica te Policy andor Certification Practice Statement 6 Subscriber Agreement That  if the CA and Subscriber are not Affiliated the Subscriber and CA are parties to a legally valid and enforceable Subscriber Agreement that satisfies these Requirements or if the CA and Subscriber are the same entity or are Affiliated the Applicant Representative acknowledged the Terms of Use 7 Status That the CA maintain s a 24 x 7 publicly accessible Repository with current information regarding the status valid or revoked  of all unexpired Certificates and 8 Revocation That the CA will revoke the Certificate for any of the reasons specified in these Requirements The Root CA SHALL be responsible for the performance and warranties of the Subordinate CA for the Subordinate CAs compliance with these Requirements and for all liabilities and indemnification obligations of the Subordinate CA under these Requirements as if the Root CA were the Subordinate CA issuing the Certificates 962 RA Representations and Warranties 963 Subscribe r Representations and Warranties The CA SHALL require as part of the Subscriber Agreement or Terms of Use that the Applicant make the commitments and warranties in this section for the benefit of the CA and the Certificate Beneficiaries Prior to the iss uance of a Certificate the CA SHALL obtain for the express benefit of the CA and the Certificate Beneficiaries either 1 The Applicants agreement to the Subscriber Agreement with the CA or 2 The Applicants acknowledgement of the Terms of Use The CA SHALL implement a process to ensure that each Subscriber Agreement or Terms of Use is legally enforceable against the Applicant In either case the Agreement MUST apply to the Certificate to be issued pursuant to the certificate request The CA MAY use a n electronic or click through Agreement provided that the CA has determined that such agreements are legally enforceable A separate Agreement MAY be used for each certificate request or a single Agreement MAY be used to cover multiple future certifica te requests and the resulting Certificates so long as each Certificate that the CA issues to the Applicant is clearly covered by that Subscriber Agreement or Terms of Use The Subscriber Agreement or Terms of Use MUST contain provisions imposing on the A pplicant itself or made by the Applicant on behalf of its principal or agent under a subcontractor or hosting service relationship the following obligations and warranties 1 Accuracy of Information An obligation and warranty to provide accurate and comp lete information at all times to the CA both in the certificate request and as otherwise requested by the CA in connection with the issuance of the Certificates to be supplied by the CA 2 Protection of Private Key An obligation and warranty by the Appl icant to take all reasonable measures to assure control of keep confidential and properly protect at all times the Private Key Forum Guideline Baseline Requirements v 1 60 54 that corresponds to the Public Key to be included in the requested Certificates and any associated activation data or device  eg password or token 3 Acceptance of Certificate An obligation and warranty that the Subscriber will review and verify the Certificate contents for accuracy 4 Use of Certificate An obligation and warranty to install the Certificate only on servers that are accessible at the subjectAltNames listed in the Certificate and to use the Certificate solely in compliance with all applicable laws and solely in accordance with the Subscriber Agreement or Terms of Use 5 Reporting and Revocation An obligati on and warranty to  a promptly request revocation of the Certificate and cease using it and its associated Private Key if there is any actual or suspected misuse or compromise of the Subscribers Private Key associated with the Public Key included in t he Certificate  and b promptly request revocation of the Certificate and cease using it if any information in the Certificate is or becomes incorrect or inaccurate 6 Termination of Use of Certificate An obligation and warranty to promptly cease all u se of the Private Key corresponding to the Public Key included in the Certificate upon revocation of that Certificate for reasons of Key Compromise 7 Responsiveness An obligation to respond to the CAs instructions concerning Key Compromise or Certificate misuse within a specified time period 8 Acknowledgment and Acceptance An acknowledgment and acceptance that the CA is entitled to revoke the certificate immediately if the Applicant were to violate the terms of the Subscriber Agreement or Terms of Use or if the CA discovers that the Certificate is being used to enable criminal activities such as phishing attacks fraud or the distribution of malware 964 Relying Party Representations and Warranties 965 Representations and Warranties of Other Participants 97 DISCLA IMERS OF WARRANTIES 98 LIMITATIONS OF LIABI LITY For delegated tasks the CA and any Delegated Third Party MAY allocate liability between themselves contractually as they determine but the CA SHALL remain fully responsible for the performance of all parties i n accordance with these Requirements as if the tasks had not been delegated If the CA has issued and managed the Certificate in compliance with these Requirements and its Certificate Policy andor Certification Practice Statement the CA MAY disclaim li ability to the Certificate Beneficiaries or any other third parties for any losses suffered as a result of use or reliance on such Certificate beyond those specified in the CAs Certificate Policy andor Certification Practice Statement If the CA has not issued or managed the Certificate in compliance with these Requirements and its Certificate Policy andor Certification Practice Statement the CA MAY seek to limit its liability to the Subscriber and to Relying Parties regardless of the cause of action o r legal theory involved for any and all claims losses or damages suffered as a result of the use or reliance on such Certificate by any appropriate means that the CA desires If the CA chooses to limit its liability for Certificates that are not issued o r managed in compliance with these Requirements or its Certificate Policy andor Certification Practice Statement then the CA SHALL include the limitations on liability in the CAs Certificate Policy andor Certification Practice Statement 99 INDEMNITIES 991 Indemnification by CAs Notwithstanding any limitations on its liability to Subscribers and Relying Parties the CA understands and acknowledges that the Application Software Suppliers who have a Root Certificate distribution agreement in place Forum Guideline Baseline Requirements v 1 60 55 with the Root CA do not assume any obligation or potential liability of the CA under these Requirements or that otherwise might exist because of the issuance or maintenance of Certificates or reliance thereon by Relying Parties or others Thus except in the case where the CA is a government entity the CA SHALL defend indemnify and hold harmless each Application Software Supplier for any and all claims damages and losses suffered by such Application Software Supplier related to a Certificate issued by the CA regard less of the cause of action or legal theory involved This does not apply however to any claim damages or loss suffered by such Application Software Supplier related to a Certificate issued by the CA where such claim damage or loss was directly cause d by such Application Software Suppliers software displaying as not trustworthy a Certificate that is still valid or displaying as trustworthy 1 a Certificate that has expired or 2 a Certificate that has been revoked but only in cases where the re vocation status is currently available from the CA online and the application software either failed to check such status or ignored an indication of revoked status 992 Indemnification by Subscribers 993 Indemnification by Relying Parties 910 TERM AND TERMINATION 9101 Term 9102 Termination 9103 Effect of termination and survival 911 INDIVIDUAL NOTICES A ND COMMUNICATIONS WI TH PARTICIPANTS 912 AMENDMENTS 9121 Procedure for amendment 9122 Notification mechanism and period 9123 Circumstances under which OID must be changed 913 DISPUTE RESOLUTION P ROVISIONS 914 GOVE RNING LAW 915 COMPLIANCE WITH APPL ICABLE LAW 916 MISCELLANEOUS PROVIS IONS 9161 Entire Agreement 9162 Assignment 9163 Severability In the event of a conflict between these Requirements and a law regulation or government order hereinafter Law of any jurisdiction in which a CA operates or issues certificates a CA MAY modify any conflicting requirement to the minimum extent necessary to make the requirement valid and legal in the jurisdiction This applies only to operations or certificate issuances that are subject to that Law  In such event the CA SHALL immediately and prior to issuing a certificate under the modified requirement include in Section 9163 of the CAs CPS a detailed reference to the Law requiring a modification of these Requirements under this section and t he specific modification to these Requirements implemented by the CA The CA MUST also prior to issuing a certificate under the modified requirement  notify the CABrowser Forum of the relevant information newly added to its CPS by sending a message to q uestionscabforumorg and receiving confirmation that it has been posted to the Public Mailing List and is indexed in the Public Mail Archives available at httpscabforumorgpipermailpublic or such other email addresses and links as the Forum Guideline Baseline Requirements v 1 60 56 Forum may des ignate so that the CABrowser Forum may consider possible revisions to these Requirements accordingly Any modification to CA practice enabled under this section MUST be discontinued if and when the Law no longer applies or these Requirements are modif ied to make it possible to comply with both them and the Law simultaneously An appropriate change in practice modification to the CAs CPS and a notice to the CABrowser Forum as outlined above MUST be made within 90 days 9164 Enforcement attorneys fees and waiver of rights 9165 Force Majeure 917 OTHER PROVISIONS Forum Guideline Baseline Requirements v 1 60 57 APPENDIX A  RFC 6844 Errata 5065 The following errata report has been held for document update for RFC6844 DNS Certification Authority Authorization CAA Resource Record   You may review the report below and at httpwwwrfc editororgerrataeid5065  Status Held for Document Update Type Technical Reported by  Phillip Hallam Baker  philliphcomodocom  Date Reported 2017 0710 Held by EKR IESG Section 4 Original Text  Let CAAX be the record set returned in response to performing a CAA record q uery on the label X PX be the DNS label immediately above X in the DNS hierarchy and AX be the target of a CNAME or DNAME alias record specified at the label X o If CAAX is not empty RX  CAA X otherwise o If AX is not null and R AX is not empty then RX  RAX otherwise o If X is not a top level domain then RX  RPX otherwise o RX is empty Corrected Text  Let CAAX be the record set returned in response to performing a CAA record qu ery on the label X PX be the DNS label immediately above X in the DNS hierarchy and AX be the target of a CNAME or DNAME alias record chain specified at the label X o If CAAX is not empty RX  CAA X otherwise o If AX is not null and CAAAX is not empty then RX  CAAAX otherwise o If X is not a top level domain then RX  RPX otherwise o RX is empty Thus when a search at node X ret urns a CNAME record the CA will follow the CNAME record chain to its target If the target label contains a CAA record it is returned Otherwise the CA continues the search at the parent of node X Note that the search does not include the parent of a target of a CNAME record except when the CNAME points back to its own path To prevent resource exhaustion attacks CAs SHOULD limit the length of CNAME chains that are accepted However CAs MUST process CNAME chains that contain 8 or fewer CNAME records ,https://www.kaspersky.com/resource-center/definitions/what-is-a-ssl-certificate,Security,4440,29159
Domain Name System (DNS) Management," Hostinger Nov 29 2023 Maisha R 8min Read How to Use Hostingers DNS Zone Editor in 2024 Copy link Copied DNS stands for Domain Name System which is a standard protocol that translates domain names into IP addresses With it the web browser can communicate with the server and load the websites content on the users screen The DNS Zone Editor is a part of the hPanel that enables shared cloud and WordPress hosting clients to modify their domains DNS records These are files that contain the information about your domain including which IP addresses it points to If you use Hostinger services there will be occasions where using the DNS Zone Editor will be necessary This article will explain all there is to know about this feature and how to navigate it correctly Download Guide To Using Hostinger How a DNS WorksWhat Are NameserversExploring Hostingers DNS Zone EditorWhat Is an A Record What Is a CNAME RecordWhat Is an MX RecordWhat Is a TXT RecordWhat Is an AAAA RecordWhat Is an NS RecordWhat Is an SRV RecordWhat Is a CAA RecordResetting Your DNS Zone to Default Settings How a DNS Works Before we begin heres a brief explanation of how DNS works A user enters the websites URL on the browsers address bar The web browser sends a query for the domain names translation to the DNS nameservers Afterward the DNS nameservers will retrieve the corresponding IP address from its DNS records The web browser fetches the website content from the IP address and loads it on the users screen Some cases may require you to modify a domain names DNS records One example would be when you want to switch web hosts or point the domain name to a different IP address Thats where the DNS Zone Editor comes into play Note that any changes made to the DNS records wont take effect immediately Depending on which type of record you modify the process may take up to 24 hours What Are Nameservers Nameservers store all of the DNS records of a domain name and use them to find the domains associated IP address Theyre also responsible for directing traffic to the website the domain belongs to When a user registers a domain name the host will provide them with at least two nameserver values One will serve as a backup if the other one goes down Heres what Hostingers nameservers look like ns1dnsparkingcomns2dnsparkingcom If you want to modify a domains DNS records its DNS settings should include the websites hosting providers nameserver values As such to use the hPanels DNS Zone Editor ensure that your domain is pointing to Hostinger Pro Tip The domain must be pointing to Hostinger nameservers Otherwise the DNS zone will not be managed from the Hostinger side In other words the DNS Zone Editor will not have any effect Ultimately if the user misses this step none of the rest of the article will make any sense If you purchase a domain name from our services it will use our nameserver values by default Hostinger clients can verify this by opening hPanel  Domains and clicking on their current domain The nameservers will appear in the Domain Information table Those who bought a domain name from a different provider should go to their registrars settings and change the existing nameservers with the ones above Doing so will point the domain to your new hosting account directing visitors to the site youre hosting with Hostinger Exploring Hostingers DNS Zone Editor Hostingers clients can open the DNS Zone Editor by going to the hPanel  Hosting Account  Advanced Should the DNS Zone Editor be inaccessible check if your domain name already connects to your hosting plan and uses the correct nameservers Heres what your DNS Zone Editor page should look like If you only purchase a domain name at Hostinger click on Domains on the top menu and select the domain youre using On the left sidebar choose DNS  Nameservers and then navigate to the DNS records tab There will be several DNS records you can edit add and remove For illustration purposes we will use the domain name loremipsumcom What Is an A Record An A record is the most basic type of DNS record as it simply points a domain or subdomain to an IP address Note that A records only point to IPv4 addresses By default there are two listings in the DNS Zone Editor One is for the domain using the ftp subdomain while the other is for the naked domain signified by the  symbol Using the loremipsumcom example these records will point both ftploremipsumcom and loremipsumcom to the IP address of 000000000 If you want to point the domain or its subdomains to an additional IP address simply add a new A record in the Manage DNS Records section like so Below are the fields you need to fill in Type  the type of DNS record you want to create Name  use  if you want the domain name to point to another IP address You can also insert a subdomain name Points to  enter the IP address that your domain or subdomain points to TTL  short for time to live this field specifies how long the DNS resolver should save the query for this domain as cache Most hosting providers usually set it to 14400 seconds or 4 hours After filling in the required information hit Add Record to create the entry What Is a CNAME Record Short for Canonical Name the CNAME record is for making one particular domain or subdomain an alias for another domain Lets say you have a website using the loremipsumcom domain However its common for people to enter www before the domain on their browser so you want the URL wwwloremipsumcom to point to your site as well The CNAME record makes that possible Note that when you add a new CNAME record you will insert the main domain name in the Target field as opposed to entering its IP address as illustrated below If you change the IP address of the main domain in the A record the CNAME records aliases will follow suit What Is an MX Record Also known as Mail Exchanger the MX record specifies the mail server responsible for receiving emails sent to your domain Hostinger clients will automatically use our MX records which are mx1hostingercommx2hostingercom Heres what they look like on the DNS Zone Editor If you want to use a thirdparty email hosting service remove these MX records and add new ones using their mail servers Aside from Name and TTL there are other two fields you must enter during this process Mail server  the address of the server that will receive the emails Priority  which mail server address to use first when collecting the emails The lowest number represents the highest priority Important You can only use one email provider per one domain name at a time so ensure you only have one MX record for the domain name If the user is using different email providers for the main domain and subdomain make sure to use the name section in the DNS zone appropriately Here is an example of what an MX record looks like using one of Google Workspaces mail servers Expert Tip If your domain is pointing elsewhere as indicated by the NS records your DNS zone management will be moved to the provider you pointed the domain to and should be managed from there Darius G Chief Customer Officer What Is a TXT Record A TXT record is a DNS entry containing text information about a domain that is readable to external parties Common examples of TXT records are Sender Policy Framework SPF and DomainKeys Identified Mail DKIM Website owners generally use both to secure email exchanges from spoofing or phishing attempts Google Apps also uses TXT records for domain verification purposes The SPF TXT record works by specifying the IP addresses or hostnames that have permission to send messages on behalf of a domain Meanwhile the DKIM TXT record includes cryptographic signatures to the email to verify that the message comes from a trustworthy source Hostingers DNS Zone Editor already has an SPF TXT record created by default It uses the vspf1 tag within the TXT value as shown in this screenshot The steps to add a new TXT record are the same as other entries Use  for the domain or insert the subdomains name in the Name field depending on what the information is for For the DKIM record enter the selector name along with _domainkey Instead of Points to a TXT value field will appear where youll need to fill in the information you want to specify in the record Below is what the fields should look like when adding a new DKIM TXT record Important Keep in mind that a domain name can have multiple TXT records for verification but should only have one SPF and one DKIM record but there are some ways to include more than that What Is an AAAA Record The AAAA record is similar to the A record we previously covered The difference is it will point your domain to an IPv6 address instead of an IPv4 By default this record is left blank in Hostingers DNS Zone editor since most internet service providers ISP and internet routers do not have IPv6 support yet What Is an NS Record In the DNS Zone Editor the NS records contain the nameserver values Hostinger has provided You should edit them only when you want to transfer your website to a different web host Expert Tip Keep in mind that NS records should always stay pointed to values ns1dnsparkingcom and ns2dnsparkingcom Even if you want to switch hosts this section of the DNS Zone Editor is not the best place to edit the NS records If you need to change hosts you should change the nameservers from the registrar which can be checked from the WHOIS domain lookup Leslie M Senior Customer Success Specialist What Is an SRV Record The SRV record specifies the server location of the service to establish a connection with them Its intended for protocols like VoIP and XMPP both of which facilitate user communication via the internet Just like the AAAA record this entry is empty by default The required information for this record is similar to others Name  the service protocol and domain name using the format _service_protocolexamplecom Weight  if multiple SRV records have the same priority this value will determine which one to contact first The higher the number the higher the priority Port  a number used by the service Target  the address of the destination server Priority  the priority of a server The system will prioritize records with lower numbers What Is a CAA Record Short for Certification Authority Authorization this DNS record defines the certificate authority CA that can issue SSL certificates for a domain Its purpose is to prevent unauthorized and malicious parties from granting fake certifications If you have multiple subdomains theres no need to create separate CAA records for each one One entry set for the root domain will automatically apply to all of the subdomains Hostinger includes the following CAA records by default Besides Name and TTL insert the following fields to add a new CAA record Flag  an unsigned integer from 0 to 255 The default flag is 0 Tag  choose between issue issuewild and iodef Issue will authorize a single CA to grant any type of certificate Issuewild allows the CA to only use a wildcard certificate Iodef is to specify the contact information the CA can report to if there are any CAArelated issues CA domain  the domain name of the certificate authority Heres an example that shows what you may enter if you want to add a CAA record for Sectigo Resetting Your DNS Zone to Default Settings Sometimes an error may occur after editing the DNS zone One way to fix it is by restoring the default settings Scroll down to the bottom and press the Reset DNS Records button Conclusion To recap the DNS Zone Editor allows only shared cloud and WordPress hosting clients to edit their domains DNS records The following are the types of DNS records that you can modify A record  specifies which IPv4 addresses the domain name points to CNAME record  assigns domains or subdomains that can serve as aliases for a websites main domain MX record  defines the mail servers responsible for receiving emails sent to your domain name TXT record  adds text information that is readable to external parties usually for security and verification purposes AAA record  similar to the A record but points to IPv6 addresses NS record  lists the nameserver values the domain name uses SRV record  specifies the server location of a service that should connect with the domain Its typically used for such internet protocols as VoIP and XMPP CAA record  defines which certificate authorities can issue SSL certificates to a domain name Feel free to use this guide anytime you need to use the DNS Zone Editor Keep in mind that if an error occurs after editing the data you can always restore the DNS records to their default settings The author Maisha R Maisha is a proponent of highquality actionable content When shes not writing for Hostinger Tutorials and Blog she immerses herself in the English thesaurus Her love for personal development essays drives her to help her fellow writers succeed in the world of content marketing More from Maisha R    a a  https   aN nN Ds a O nsldnsparkingcom ns2dnsparkingcom O ey a 20 S  Handle high traffic and load pages fast Buy Web Hosting  Domain Information Status Email verification status Expires at Secret key  Nameservers  Active  verified 20240124 015959 see  nsldnsparkingcom ns2dnsparkingcom Change   Advanced DNS Zone Editor PHP Configuration Cron Jobs SSH Access PHP Info Cache Manager DNS Zone Editor ff  Hosting  examplecom  Advanced  DNS Zone Editor  DNs updates might take up to 24 hours to propagate Once DNS records are changed keep in mind that it takes up to 24 hours for the changes to take effect Manage DNS records These records define how your domain behaves Common uses include pointing your domain at web servers or configuring email delivery for your domain Type Name  A   Points to 14400 Add Record Q Search Type  Name  Content  TTL  CNAME www  examplecom 14400 Delete Edit CNAME autodiscover oO autodiscovermailhostingercom 300 Delete Edit A ftp  123456 7890 14400 Delete Edit HOSTINGER  Back to domains domaintid s paaresheisuiccsas ns2dnsparkingcom B Ns  Nameservers  Contact information FB Give feedback 4soo ing provider Reset DNS records This feature resets all existing DNS records of domaintld to default Reset DNS records A https__ , 10 Load Balancing Techniques Mastering the Art of Distributed ComputingGurpreet SinghFollow15 min readSep 9ListenShareFrom straightforward methods like Random Allocation to more complex techniques like ResourceBased or Application Layer Content Switching choosing the right strategy can significantly impact both user experience and operational costs Similarly while not a loadbalancing method Rate Limiting serves as a complementary mechanism to protect resources and ensure fair usage Whether youre designing a smallscale application or a global hightraffic service understanding these loadbalancing techniques is key to building resilient efficient and userfriendly systemssource nginxRound RobinRound Robin is one of the simplest algorithms used in load balancing In this method incoming requests are distributed in a circular order across all the available servers in a server pool The first request goes to the first server the second request goes to the second server and so on When it reaches the last server in the pool the Round Robin algorithm starts over at the first server This way each server gets an equal opportunity to serve requestsTradeoffsSimplicity The Round Robin algorithm is straightforward to implement This makes it a good choice for basic load distribution where sophisticated capabilities are not requiredFairness Because it distributes requests equally each server gets a fair share of the load This is beneficial when all servers have similar capabilitiesLow Overhead The algorithm is not resourceintensive in terms of computation and memory which makes it a good choice for systems where these resources are limitedPredictability It offers predictable behavior making it easier to diagnose issues related to load balancing since the request distribution is uniformQuick Response Time for Lightweight Requests For scenarios where all requests are nearly identical in terms of the resources they consume Round Robin can offer fast response timesDrawbacksUnaware of Server Load The Round Robin algorithm doesnt take into account the current load on each server If one server is slower or is already handling more requests Round Robin will still send new requests to it which can lead to performance issuesNot SessionAware In a stateful application where user sessions are important Round Robin can break the application logic because it does not ensure session persistence For example if a user logs in on Server A and the next request goes to Server B the user might be logged out if sessions are not shared between the serversInefficient Resource Utilization If servers have different capabilities eg different CPU RAM Round Robin will not exploit these differences efficientlyExampleSuppose we have 3 servers Server A Server B and Server C In a Round Robin load balancing setup the first request will go to Server A the second to Server B the third to Server C and the fourth back to Server A This pattern repeats indefinitelyRequest 1  Server ARequest 2  Server BRequest 3  Server CRequest 4  Server ARequest 5  Server BAnd so onfrom itertools import cycleservers  Server A Server B Server Crobin  cycleservers Simulating 5 requestsfor i in range5 printfRequest i1 is sent to nextrobinLeast ConnectionsThe Least Connections algorithm is a more advanced load balancing technique compared to Round Robin In this method the load balancer maintains a record of the number of active connections for each server in the pool Incoming requests are routed to the server with the least number of active connections at that momentTradeoffsMore Intelligent Routing Unlike Round Robin Least Connections takes into account the current server load at least in terms of active connections making it more adaptive to varying workloadsBetter for Varying Request Complexity This method works better when requests consume different amounts of resources as it aims to distribute the load more evenly based on active connections which is often a better measure of load than a simple roundrobin queueGood for Longlived Connections In environments where connections are longlived eg WebSockets streaming services Least Connections can offer a more balanced distribution of connections over timeImproves Over Time The more it runs the better it is at load distribution as it continually adapts to the current state of the server poolDrawbacksUnaware of Task Complexity While the Least Connections method considers the number of active connections it doesnt account for the computational complexity of the tasks each server is handling A server could have fewer but more resourceintensive tasks and yet still receive new requestsHigher Overhead Maintaining a realtime count of active connections for each server incurs more computational overhead compared to simpler algorithms like Round RobinPotential for Suboptimal Utilization If servers are of varying capacities the least capable server may receive the same number of requests as the most capable server which could result in suboptimal resource utilizationInitial Imbalance In some setups when all servers have zero or the same number of connections the first few requests could all go to the same server creating a temporary imbalanceExampleSuppose there are 3 servers Server A Server B and Server C with the following numbers of active connectionsServer A 5 active connectionsServer B 2 active connectionsServer C 4 active connectionsserver_connections  Server A 5 Server B 2 Server C 4def find_least_connectionsserver_connections return minserver_connections keyserver_connectionsget Simulating 1 requestserver  find_least_connectionsserver_connectionsprintfRequest is sent to serverserver_connectionsserver  1A new request arrives The load balancer will route this request to Server B because it has the fewest active connections 2Weighted Round Robin or Weighted Least ConnectionsBoth Weighted Round Robin and Weighted Least Connections are extensions of the basic Round Robin and Least Connections algorithms respectively In these weighted methods each server is assigned a weight based on its capacity or some other criteria Servers with higher weights will receive a proportionally larger number of requestsTradeoffsBetter Resource Utilization These weighted methods allow for more intelligent distribution of requests especially in a heterogeneous environment where servers have different capacitiesAdaptability Both methods can be more adaptable to realworld scenarios where all servers are not equally capable or where different types of requests consume different amounts of resourcesFairness and Priority The weight assignment can also be used to prioritize certain servers over others providing more control over the traffic distributionScalability These weighted methods can be more effective as you scale your environment When you add a new more powerful server you can simply assign it a higher weight instead of reconfiguring the entire systemHybrid Scenarios Weighted methods can be useful in hybrid or cloud scenarios where you might have a mix of onpremises and cloud servers with varying capabilitiesDrawbacksComplexity The added layer of weights increases the complexity of managing and configuring the load balancerManual Tuning Deciding the appropriate weights for each server often requires manual tuning and a deep understanding of the workload characteristics and server capabilitiesResource Monitoring For Weighted Least Connections the load balancer has to not only keep track of active connections but also needs to consider the weights in realtime increasing the computational overheadInefficiency in Weight Allocation If weights are not set properly it can lead to inefficient use of resources For example assigning a toohigh weight to a lowcapacity server can overwhelm itWeighted Round Robin ExampleSuppose you have 3 servers with the following weightsServer A Weight 1Server B Weight 2Server C Weight 3servers  Server A3  Server B2  Server C1robin  cycleservers Simulating 6 requestsfor i in range6 printfRequest i1 is sent to nextrobinThe sequence of routing requests would look something like this A B B C C C A B B C C C  and so onWeighted Least Connections ExampleImagine you have the same 3 servers with the same weights but differing numbers of active connectionsServer A 3active connections Weight 3Server B 2active connections Weight 2Server C 0active connections Weight 1server_weights  Server A 3 Server B 2 Server C 1server_connections  Server A 3 Server B 2 Server C 0def find_weighted_least_connectionsserver_connections server_weights return minserver_connections keylambda x server_connectionsx  server_weightsx Simulating 1 requestserver  find_weighted_least_connectionsserver_connections server_weightsprintfRequest is sent to serverserver_connectionsserver  1When a new request arrives the load balancer might compute a ratio of active connections to weight In this case Server A would have a ratio of 21  2 Server B would have 42  2 and Server C would have 93  3 The new request would go to either Server A or Server B as they have the lowest ratioHashingHashing is a technique used to map data to a fixedsize array typically called a hash table A hash function processes the input data to produce an output called a hash code which is then used to index into the hash table Hashing is commonly used for efficient data retrieval data indexing data deduplication and various other applicationsMethodsDivisionremainder method This is one of the simplest methods where the key k is divided by a prime number p and the remainder is taken as the index ℎkk mod pMultiplicative hash function In this method the key is multiplied by a constant A 0  A  1 the fractional part is retained and then multiplied by m the table size hk  m  k  A mod 1Universal hashing This method randomly selects a hash function from a carefully designed class of functions This minimizes the chance of a collisionCryptographic hash functions These are hash functions designed to be secure against certain attacks Examples include SHA256 and MD5 although MD5 is considered weak nowTradeoffsSpeed vs Space A larger hash table reduces collisions but uses more memory Conversely a smaller table uses less memory but is more prone to collisions which would then require additional time for resolutionSimple vs Complex Functions Simple hash functions are generally faster but may produce more collisions Complex or cryptographic functions reduce the risk of collision or reverse engineering but are computationally more expensiveDrawbacksCollision Two different keys might produce the same hash value which is called a collision Hash tables typically have mechanisms to handle this such as chaining or open addressing but it adds complexityNoninvertible Hashing is a oneway function Once data is hashed you cant retrieve the original data from the hash codeLimited Security Regular hash functions are not secure meaning that someone could potentially guess the key based on the hash value especially if the set of keys is smallSpaceTime Tradeoff Hash tables need extra memory for storage to reduce the chance of collision If the table size is small the chance of collision is higher which reduces efficiencyNonOrdered Hash tables do not store keys in any particular order which is a drawback if you need to perform range queries or sorted operationsExampleConsider a simple example where we want to create a hash table to store student grades based on student IDs Using a simple divisionremainder hash function with table size 10hash_table  None  10def hash_functionkey return key  10 Insert grades for student IDs 23 45 and 12hash_tablehash_function23  Ahash_tablehash_function45  Bhash_tablehash_function12  C Retrieve grade for student ID 23grade  hash_tablehash_function23printfGrade for student ID 23 is gradeHere we use a simple hash function to quickly index into an array and storeretrieve grades This example doesnt handle collisions which would need to be managed in a full implementationRandom AllocationRandom Allocation is a loadbalancing strategy where incoming requests are distributed randomly across available servers Unlike algorithms like Round Robin or Least Connections Random Allocation doesnt follow a predefined pattern or consider any server metrics it simply picks a server at random each time a request comes inTradeoffsSimplicity vs Efficiency One of the main advantages of Random Allocation is its simplicity both in terms of understanding and implementation However this comes at the cost of potentially suboptimal load distributionUniformity Over Time In the long run with a large enough number of requests Random Allocation can provide a reasonably uniform distribution of load However in the short term it can be quite imbalancedNo Need for Tracking Unlike Least Connections or other more sophisticated algorithms Random Allocation doesnt require keeping track of the current state of each server which might be beneficial in some very specific cases where you cant or dont want to maintain such informationDrawbacksUnpredictable Load Since the allocation is random it could happen that some servers get more requests than others leading to an imbalanced loadNo Consideration for Server Capacity The algorithm doesnt account for the performance or current load of individual servers which could result in poor performance if a less capable or alreadyoverloaded server is chosenNot Ideal for Sticky Sessions In scenarios where a users multiple requests need to go to the same server to maintain state random allocation is not suitableExampleSuppose you have 3 servers Server A Server B and Server CHeres a Python example simulating Random Allocation for 5 requestsimport randomservers  Server A Server B Server C Simulating 5 requestsfor i in range5 server  randomchoiceservers printfRequest i  1 is sent to serverGeoLocation Based Load BalancingGeoLocation Based Load Balancing is a technique used to distribute incoming network or application traffic based on the geographic locations of the client and the server This method helps in minimizing latency as a users requests are generally routed to the closest or most appropriate data centerTradeoffsLatency vs Complexity While GeoLocation based load balancing can significantly reduce latency it comes with the cost of increased complexity in the implementation and maintenanceAccuracy vs Overhead The more accurate your geolocation information the better your routing decisions will be but obtaining and maintaining that level of accuracy can be difficult and resourceintensiveLocal Optimizations vs Global Load While focusing on geolocation can optimize for local latency conditions it might not always provide the most balanced load across all servers globally For example servers in less frequented locations might be underutilizedCost vs Performance Geographic dispersion of data centers increases resilience and enhances user experience by lowering latency but comes with increased costs for setup and maintenanceDrawbacksGeoIP Inaccuracy The geographical location determined through IP addresses may not always be accurate This can result in suboptimal routingHandling Mobile Users Users may move between geographical locations which can complicate the load balancing decisions and may require frequent updatesRegulatory and Data Sovereignty Issues Data storage and transfer are subject to legal constraints which might not align well with geographically optimized load balancingComplexity Implementing and maintaining a geolocation based system can be more complex and costly compared to simpler methods like Round Robin or Random AllocationExampleConsider a scenario where a company has data centers in New York London and Tokyo A user from Paris connects to their service A simplified exampleuser_location  Parisdata_centers  New York US London UK Tokyo JPdef find_closest_data_centeruser_location data_centers if user_location in UK France Germany return London elif user_location in US Canada return New York else return Tokyoclosest_data_center  find_closest_data_centeruser_location data_centersprintfThe closest data center for a user from user_location is in closest_data_centerIn this example the users request would be routed to the London data centerApplication Layer Content SwitchingApplication Layer Content Switching is a sophisticated form of load balancing that distributes incoming requests based on content type application state or other applicationlayer data This method is highly flexible and can route traffic based on a variety of factors such as URL paths cookies HTTP headers or even custom application logicTradeoffsFlexibility vs Complexity Application Layer Content Switching provides the most flexible routing options but at the cost of increased complexityOptimization vs Generality This method allows for specialized servers that can be highly optimized for specific tasks eg serving static content processing dynamic queries However this specialization can lead to underutilization of resources if not managed carefullyCentralization vs Decentralization Having a centralized router can simplify configuration but can also become a bottleneck or single point of failureAdvanced Features vs Cost This type of load balancing often requires more advanced and therefore more expensive hardware or software load balancersDrawbacksComplexity The routing logic can become complex to manage especially as you scale or as application requirements changeMaintenance Overhead Additional complexity in configuration and routing logic can lead to higher operational overheadIncreased Latency The extra processing time required to inspect applicationlayer data can introduce additional latency although this is generally minimalPotential for Errors As the complexity of routing rules increases the potential for misconfiguration or bugs also risesExampleConsider a web application that serves both static content like images CSS JS files and dynamic content like user profiles A simple Pythonlike pseudocode might look likedef route_requestrequest if requestpathstartswithstatic return send_to_serverStaticContentServer elif requestpathstartswithuser return send_to_serverUserProfileServer else return send_to_serverGeneralPurposeServerdef send_to_serverserver_type  Code to send the request to the specified server type passIn this example if a request is for a URL path that starts with static it gets routed to a specialized server that only serves static content If the URL path starts with user it goes to a server optimized for user profile dataResourceBased Load BalancingResourceBased Load Balancing is a strategy that considers the resources CPU load memory usage network IO etc available on each server before distributing incoming requests This approach aims to ensure that each servers workload corresponds to its resource availability leading to better performance and utilizationTradeoffsEfficiency vs Complexity Resourcebased methods are excellent for optimizing server utilization but at the cost of more complex monitoring and decisionmaking systemsRealTime Adaptability vs Latency This method adapts well to realtime changes in server resource utilization but may incur a latency cost for collecting those realtime metricsResource Type vs Balance Focusing on one type of resource eg CPU load might overlook other types of resources eg memory disk IO potentially leading to imbalances in other aspects of system performanceCost vs Performance Achieving realtime highly accurate resourcebased load balancing often requires specialized software or hardware which can be more expensiveDrawbacksComplex Monitoring This approach requires an indepth realtime understanding of the resource usage of each server which may be complicated to implement and maintainPotential Latency Collecting resource metrics could introduce additional latency especially if the metrics need to be gathered frequently or if the reporting mechanism is slowData Freshness If the resource data is not updated in realtime the load balancer might make decisions based on stale data leading to suboptimal load distributionResource Overheads Implementing such a strategy may consume extra resources for the monitoring and decisionmaking processesExampleLets consider three servers with different CPU loadsServer A 20 CPU loadServer B 50 CPU loadServer C 80 CPU loadIn Pythonlike pseudocode you might have something likeserver_cpu_load  Server A 20 Server B 50 Server C 80def find_least_loaded_serverserver_cpu_load return minserver_cpu_load keyserver_cpu_loadget Simulate a single requestleast_loaded_server  find_least_loaded_serverserver_cpu_loadprintfSend request to least_loaded_serverIn this example the request would go to Server A as it currently has the lowest CPU loadRate LimitingRate Limiting is a technique used to control the amount of incoming requests to a server within a given time frame It is often used to protect resources prevent abuse and ensure fair usage While not strictly a loadbalancing strategy rate limiting often works in conjunction with load balancers to manage traffic and maintain the quality of serviceTradeoffsProtection vs Accessibility Rate limiting is effective in protecting your service from abuse but may limit accessibility for legitimate highusage clientsGranularity vs Overheads The more granular your rate limits eg peruser perendpoint etc the better you can control the traffic However this comes at the cost of increased complexity and resource usage for trackingFixed vs Dynamic Rates A fixed rate limit is easier to implement but may not adapt well to varying server capabilities Dynamic rate limits that adjust based on current server load can be more efficient but are also more complex to implementShortTerm Fairness vs LongTerm Fairness Rate limiting ensures shortterm fairness by evenly distributing the allowed requests over a short period However it might not account for longterm fairness where a user who has been inactive for a while may want to make a burst of legitimate requestsDrawbacksUser Experience Legitimate users may get slowed down or temporarily blocked impacting user experienceComplexity Implementing an effective ratelimiting algorithm can be complex especially in distributed architecturesResource Utilization Tracking rate limit counts and times can consume additional server resourcesFalse Positives Sometimes multiple users may share an IP address eg users on the same WiFi network and rate limiting based on IP can wrongly limit these usersExampleImagine an API service that allows 100 requests per minute per user If a user exceeds this rate further requests from that user within the same minute are either queued delayed or rejectedHeres a simple Pythonlike pseudocode using a dictionary to track request countsfrom time import timerate_limits    Dictionary to hold rate limit information for each userdef handle_requestuser_id current_time  time if user_id not in rate_limits rate_limitsuser_id  count 1 timestamp current_time else elapsed_time  current_time  rate_limitsuser_idtimestamp if elapsed_time  60  60 seconds  1 minute if rate_limitsuser_idcount  100 rate_limitsuser_idcount  1 else return Rate limit exceeded else rate_limitsuser_id  count 1 timestamp current_time return Request processed Simulating a series of API requestsfor i in range105 printhandle_requestuser_1ConclusionLoad balancing strategies are crucial for ensuring efficient resource utilization maximizing throughput reducing latency and achieving fault tolerance in distributed systems Each strategy comes with its unique set of advantages drawbacks and tradeoffs requiring careful consideration to match your specific needs From straightforward methods like Random Allocation to more complex techniques like ResourceBased or Application Layer Content Switching choosing the right strategy can significantly impact both user experience and operational costs Similarly while not a loadbalancing method Rate Limiting serves as a complementary mechanism to protect resources and ensure fair usage Whether youre designing a smallscale application or a global hightraffic service understanding these loadbalancing techniques is key to building resilient efficient and userfriendly systemsIf you found this article helpful please dont forget to hit the Follow  and Clap  buttons to help me write more articles like thisThank You Thank you for Reading   see you in the next blog Feel free to connect with me LinkedIn httpswwwlinkedincomingurpreetsinghpalClick on the following link to read all great stories on Medium httpsmediumcomgurpreetsingh_89Get an email whenever I publish a new storyhttpsmediumcomgurpreetsingh_89subscribeThe end  ","https://www.hostinger.com/tutorials/how-to-use-hostinger-dns-zone-editor?ppc_campaign=google_search_generic_hosting_all&bidkw=defaultkeyword&lo=1011082&gad_source=1&gclid=CjwKCAiAs6-sBhBmEiwA1Nl8s18e-8Tr9PoBdYv7DWeNhLr-lrcaWFBdXym6Ql7KX_5KHCi7lo37DRoCiegQAvD_BwE, https://medium.com/@gurpreet.singh_89/10-load-balancing-techniques-mastering-the-art-of-distributed-computing-cea946ac5cdb",Infrastructure,1872,6012
Load Balancing Techniques,10 Load Balancing Techniques Mastering the Art of Distributed ComputingGurpreet SinghFollow15 min readSep 9ListenShareFrom straightforward methods like Random Allocation to more complex techniques like ResourceBased or Application Layer Content Switching choosing the right strategy can significantly impact both user experience and operational costs Similarly while not a loadbalancing method Rate Limiting serves as a complementary mechanism to protect resources and ensure fair usage Whether youre designing a smallscale application or a global hightraffic service understanding these loadbalancing techniques is key to building resilient efficient and userfriendly systemssource nginxRound RobinRound Robin is one of the simplest algorithms used in load balancing In this method incoming requests are distributed in a circular order across all the available servers in a server pool The first request goes to the first server the second request goes to the second server and so on When it reaches the last server in the pool the Round Robin algorithm starts over at the first server This way each server gets an equal opportunity to serve requestsTradeoffsSimplicity The Round Robin algorithm is straightforward to implement This makes it a good choice for basic load distribution where sophisticated capabilities are not requiredFairness Because it distributes requests equally each server gets a fair share of the load This is beneficial when all servers have similar capabilitiesLow Overhead The algorithm is not resourceintensive in terms of computation and memory which makes it a good choice for systems where these resources are limitedPredictability It offers predictable behavior making it easier to diagnose issues related to load balancing since the request distribution is uniformQuick Response Time for Lightweight Requests For scenarios where all requests are nearly identical in terms of the resources they consume Round Robin can offer fast response timesDrawbacksUnaware of Server Load The Round Robin algorithm doesnt take into account the current load on each server If one server is slower or is already handling more requests Round Robin will still send new requests to it which can lead to performance issuesNot SessionAware In a stateful application where user sessions are important Round Robin can break the application logic because it does not ensure session persistence For example if a user logs in on Server A and the next request goes to Server B the user might be logged out if sessions are not shared between the serversInefficient Resource Utilization If servers have different capabilities eg different CPU RAM Round Robin will not exploit these differences efficientlyExampleSuppose we have 3 servers Server A Server B and Server C In a Round Robin load balancing setup the first request will go to Server A the second to Server B the third to Server C and the fourth back to Server A This pattern repeats indefinitelyRequest 1  Server ARequest 2  Server BRequest 3  Server CRequest 4  Server ARequest 5  Server BAnd so onfrom itertools import cycleservers  Server A Server B Server Crobin  cycleservers Simulating 5 requestsfor i in range5 printfRequest i1 is sent to nextrobinLeast ConnectionsThe Least Connections algorithm is a more advanced load balancing technique compared to Round Robin In this method the load balancer maintains a record of the number of active connections for each server in the pool Incoming requests are routed to the server with the least number of active connections at that momentTradeoffsMore Intelligent Routing Unlike Round Robin Least Connections takes into account the current server load at least in terms of active connections making it more adaptive to varying workloadsBetter for Varying Request Complexity This method works better when requests consume different amounts of resources as it aims to distribute the load more evenly based on active connections which is often a better measure of load than a simple roundrobin queueGood for Longlived Connections In environments where connections are longlived eg WebSockets streaming services Least Connections can offer a more balanced distribution of connections over timeImproves Over Time The more it runs the better it is at load distribution as it continually adapts to the current state of the server poolDrawbacksUnaware of Task Complexity While the Least Connections method considers the number of active connections it doesnt account for the computational complexity of the tasks each server is handling A server could have fewer but more resourceintensive tasks and yet still receive new requestsHigher Overhead Maintaining a realtime count of active connections for each server incurs more computational overhead compared to simpler algorithms like Round RobinPotential for Suboptimal Utilization If servers are of varying capacities the least capable server may receive the same number of requests as the most capable server which could result in suboptimal resource utilizationInitial Imbalance In some setups when all servers have zero or the same number of connections the first few requests could all go to the same server creating a temporary imbalanceExampleSuppose there are 3 servers Server A Server B and Server C with the following numbers of active connectionsServer A 5 active connectionsServer B 2 active connectionsServer C 4 active connectionsserver_connections  Server A 5 Server B 2 Server C 4def find_least_connectionsserver_connections return minserver_connections keyserver_connectionsget Simulating 1 requestserver  find_least_connectionsserver_connectionsprintfRequest is sent to serverserver_connectionsserver  1A new request arrives The load balancer will route this request to Server B because it has the fewest active connections 2Weighted Round Robin or Weighted Least ConnectionsBoth Weighted Round Robin and Weighted Least Connections are extensions of the basic Round Robin and Least Connections algorithms respectively In these weighted methods each server is assigned a weight based on its capacity or some other criteria Servers with higher weights will receive a proportionally larger number of requestsTradeoffsBetter Resource Utilization These weighted methods allow for more intelligent distribution of requests especially in a heterogeneous environment where servers have different capacitiesAdaptability Both methods can be more adaptable to realworld scenarios where all servers are not equally capable or where different types of requests consume different amounts of resourcesFairness and Priority The weight assignment can also be used to prioritize certain servers over others providing more control over the traffic distributionScalability These weighted methods can be more effective as you scale your environment When you add a new more powerful server you can simply assign it a higher weight instead of reconfiguring the entire systemHybrid Scenarios Weighted methods can be useful in hybrid or cloud scenarios where you might have a mix of onpremises and cloud servers with varying capabilitiesDrawbacksComplexity The added layer of weights increases the complexity of managing and configuring the load balancerManual Tuning Deciding the appropriate weights for each server often requires manual tuning and a deep understanding of the workload characteristics and server capabilitiesResource Monitoring For Weighted Least Connections the load balancer has to not only keep track of active connections but also needs to consider the weights in realtime increasing the computational overheadInefficiency in Weight Allocation If weights are not set properly it can lead to inefficient use of resources For example assigning a toohigh weight to a lowcapacity server can overwhelm itWeighted Round Robin ExampleSuppose you have 3 servers with the following weightsServer A Weight 1Server B Weight 2Server C Weight 3servers  Server A3  Server B2  Server C1robin  cycleservers Simulating 6 requestsfor i in range6 printfRequest i1 is sent to nextrobinThe sequence of routing requests would look something like this A B B C C C A B B C C C  and so onWeighted Least Connections ExampleImagine you have the same 3 servers with the same weights but differing numbers of active connectionsServer A 3active connections Weight 3Server B 2active connections Weight 2Server C 0active connections Weight 1server_weights  Server A 3 Server B 2 Server C 1server_connections  Server A 3 Server B 2 Server C 0def find_weighted_least_connectionsserver_connections server_weights return minserver_connections keylambda x server_connectionsx  server_weightsx Simulating 1 requestserver  find_weighted_least_connectionsserver_connections server_weightsprintfRequest is sent to serverserver_connectionsserver  1When a new request arrives the load balancer might compute a ratio of active connections to weight In this case Server A would have a ratio of 21  2 Server B would have 42  2 and Server C would have 93  3 The new request would go to either Server A or Server B as they have the lowest ratioHashingHashing is a technique used to map data to a fixedsize array typically called a hash table A hash function processes the input data to produce an output called a hash code which is then used to index into the hash table Hashing is commonly used for efficient data retrieval data indexing data deduplication and various other applicationsMethodsDivisionremainder method This is one of the simplest methods where the key k is divided by a prime number p and the remainder is taken as the index ℎkk mod pMultiplicative hash function In this method the key is multiplied by a constant A 0  A  1 the fractional part is retained and then multiplied by m the table size hk  m  k  A mod 1Universal hashing This method randomly selects a hash function from a carefully designed class of functions This minimizes the chance of a collisionCryptographic hash functions These are hash functions designed to be secure against certain attacks Examples include SHA256 and MD5 although MD5 is considered weak nowTradeoffsSpeed vs Space A larger hash table reduces collisions but uses more memory Conversely a smaller table uses less memory but is more prone to collisions which would then require additional time for resolutionSimple vs Complex Functions Simple hash functions are generally faster but may produce more collisions Complex or cryptographic functions reduce the risk of collision or reverse engineering but are computationally more expensiveDrawbacksCollision Two different keys might produce the same hash value which is called a collision Hash tables typically have mechanisms to handle this such as chaining or open addressing but it adds complexityNoninvertible Hashing is a oneway function Once data is hashed you cant retrieve the original data from the hash codeLimited Security Regular hash functions are not secure meaning that someone could potentially guess the key based on the hash value especially if the set of keys is smallSpaceTime Tradeoff Hash tables need extra memory for storage to reduce the chance of collision If the table size is small the chance of collision is higher which reduces efficiencyNonOrdered Hash tables do not store keys in any particular order which is a drawback if you need to perform range queries or sorted operationsExampleConsider a simple example where we want to create a hash table to store student grades based on student IDs Using a simple divisionremainder hash function with table size 10hash_table  None  10def hash_functionkey return key  10 Insert grades for student IDs 23 45 and 12hash_tablehash_function23  Ahash_tablehash_function45  Bhash_tablehash_function12  C Retrieve grade for student ID 23grade  hash_tablehash_function23printfGrade for student ID 23 is gradeHere we use a simple hash function to quickly index into an array and storeretrieve grades This example doesnt handle collisions which would need to be managed in a full implementationRandom AllocationRandom Allocation is a loadbalancing strategy where incoming requests are distributed randomly across available servers Unlike algorithms like Round Robin or Least Connections Random Allocation doesnt follow a predefined pattern or consider any server metrics it simply picks a server at random each time a request comes inTradeoffsSimplicity vs Efficiency One of the main advantages of Random Allocation is its simplicity both in terms of understanding and implementation However this comes at the cost of potentially suboptimal load distributionUniformity Over Time In the long run with a large enough number of requests Random Allocation can provide a reasonably uniform distribution of load However in the short term it can be quite imbalancedNo Need for Tracking Unlike Least Connections or other more sophisticated algorithms Random Allocation doesnt require keeping track of the current state of each server which might be beneficial in some very specific cases where you cant or dont want to maintain such informationDrawbacksUnpredictable Load Since the allocation is random it could happen that some servers get more requests than others leading to an imbalanced loadNo Consideration for Server Capacity The algorithm doesnt account for the performance or current load of individual servers which could result in poor performance if a less capable or alreadyoverloaded server is chosenNot Ideal for Sticky Sessions In scenarios where a users multiple requests need to go to the same server to maintain state random allocation is not suitableExampleSuppose you have 3 servers Server A Server B and Server CHeres a Python example simulating Random Allocation for 5 requestsimport randomservers  Server A Server B Server C Simulating 5 requestsfor i in range5 server  randomchoiceservers printfRequest i  1 is sent to serverGeoLocation Based Load BalancingGeoLocation Based Load Balancing is a technique used to distribute incoming network or application traffic based on the geographic locations of the client and the server This method helps in minimizing latency as a users requests are generally routed to the closest or most appropriate data centerTradeoffsLatency vs Complexity While GeoLocation based load balancing can significantly reduce latency it comes with the cost of increased complexity in the implementation and maintenanceAccuracy vs Overhead The more accurate your geolocation information the better your routing decisions will be but obtaining and maintaining that level of accuracy can be difficult and resourceintensiveLocal Optimizations vs Global Load While focusing on geolocation can optimize for local latency conditions it might not always provide the most balanced load across all servers globally For example servers in less frequented locations might be underutilizedCost vs Performance Geographic dispersion of data centers increases resilience and enhances user experience by lowering latency but comes with increased costs for setup and maintenanceDrawbacksGeoIP Inaccuracy The geographical location determined through IP addresses may not always be accurate This can result in suboptimal routingHandling Mobile Users Users may move between geographical locations which can complicate the load balancing decisions and may require frequent updatesRegulatory and Data Sovereignty Issues Data storage and transfer are subject to legal constraints which might not align well with geographically optimized load balancingComplexity Implementing and maintaining a geolocation based system can be more complex and costly compared to simpler methods like Round Robin or Random AllocationExampleConsider a scenario where a company has data centers in New York London and Tokyo A user from Paris connects to their service A simplified exampleuser_location  Parisdata_centers  New York US London UK Tokyo JPdef find_closest_data_centeruser_location data_centers if user_location in UK France Germany return London elif user_location in US Canada return New York else return Tokyoclosest_data_center  find_closest_data_centeruser_location data_centersprintfThe closest data center for a user from user_location is in closest_data_centerIn this example the users request would be routed to the London data centerApplication Layer Content SwitchingApplication Layer Content Switching is a sophisticated form of load balancing that distributes incoming requests based on content type application state or other applicationlayer data This method is highly flexible and can route traffic based on a variety of factors such as URL paths cookies HTTP headers or even custom application logicTradeoffsFlexibility vs Complexity Application Layer Content Switching provides the most flexible routing options but at the cost of increased complexityOptimization vs Generality This method allows for specialized servers that can be highly optimized for specific tasks eg serving static content processing dynamic queries However this specialization can lead to underutilization of resources if not managed carefullyCentralization vs Decentralization Having a centralized router can simplify configuration but can also become a bottleneck or single point of failureAdvanced Features vs Cost This type of load balancing often requires more advanced and therefore more expensive hardware or software load balancersDrawbacksComplexity The routing logic can become complex to manage especially as you scale or as application requirements changeMaintenance Overhead Additional complexity in configuration and routing logic can lead to higher operational overheadIncreased Latency The extra processing time required to inspect applicationlayer data can introduce additional latency although this is generally minimalPotential for Errors As the complexity of routing rules increases the potential for misconfiguration or bugs also risesExampleConsider a web application that serves both static content like images CSS JS files and dynamic content like user profiles A simple Pythonlike pseudocode might look likedef route_requestrequest if requestpathstartswithstatic return send_to_serverStaticContentServer elif requestpathstartswithuser return send_to_serverUserProfileServer else return send_to_serverGeneralPurposeServerdef send_to_serverserver_type  Code to send the request to the specified server type passIn this example if a request is for a URL path that starts with static it gets routed to a specialized server that only serves static content If the URL path starts with user it goes to a server optimized for user profile dataResourceBased Load BalancingResourceBased Load Balancing is a strategy that considers the resources CPU load memory usage network IO etc available on each server before distributing incoming requests This approach aims to ensure that each servers workload corresponds to its resource availability leading to better performance and utilizationTradeoffsEfficiency vs Complexity Resourcebased methods are excellent for optimizing server utilization but at the cost of more complex monitoring and decisionmaking systemsRealTime Adaptability vs Latency This method adapts well to realtime changes in server resource utilization but may incur a latency cost for collecting those realtime metricsResource Type vs Balance Focusing on one type of resource eg CPU load might overlook other types of resources eg memory disk IO potentially leading to imbalances in other aspects of system performanceCost vs Performance Achieving realtime highly accurate resourcebased load balancing often requires specialized software or hardware which can be more expensiveDrawbacksComplex Monitoring This approach requires an indepth realtime understanding of the resource usage of each server which may be complicated to implement and maintainPotential Latency Collecting resource metrics could introduce additional latency especially if the metrics need to be gathered frequently or if the reporting mechanism is slowData Freshness If the resource data is not updated in realtime the load balancer might make decisions based on stale data leading to suboptimal load distributionResource Overheads Implementing such a strategy may consume extra resources for the monitoring and decisionmaking processesExampleLets consider three servers with different CPU loadsServer A 20 CPU loadServer B 50 CPU loadServer C 80 CPU loadIn Pythonlike pseudocode you might have something likeserver_cpu_load  Server A 20 Server B 50 Server C 80def find_least_loaded_serverserver_cpu_load return minserver_cpu_load keyserver_cpu_loadget Simulate a single requestleast_loaded_server  find_least_loaded_serverserver_cpu_loadprintfSend request to least_loaded_serverIn this example the request would go to Server A as it currently has the lowest CPU loadRate LimitingRate Limiting is a technique used to control the amount of incoming requests to a server within a given time frame It is often used to protect resources prevent abuse and ensure fair usage While not strictly a loadbalancing strategy rate limiting often works in conjunction with load balancers to manage traffic and maintain the quality of serviceTradeoffsProtection vs Accessibility Rate limiting is effective in protecting your service from abuse but may limit accessibility for legitimate highusage clientsGranularity vs Overheads The more granular your rate limits eg peruser perendpoint etc the better you can control the traffic However this comes at the cost of increased complexity and resource usage for trackingFixed vs Dynamic Rates A fixed rate limit is easier to implement but may not adapt well to varying server capabilities Dynamic rate limits that adjust based on current server load can be more efficient but are also more complex to implementShortTerm Fairness vs LongTerm Fairness Rate limiting ensures shortterm fairness by evenly distributing the allowed requests over a short period However it might not account for longterm fairness where a user who has been inactive for a while may want to make a burst of legitimate requestsDrawbacksUser Experience Legitimate users may get slowed down or temporarily blocked impacting user experienceComplexity Implementing an effective ratelimiting algorithm can be complex especially in distributed architecturesResource Utilization Tracking rate limit counts and times can consume additional server resourcesFalse Positives Sometimes multiple users may share an IP address eg users on the same WiFi network and rate limiting based on IP can wrongly limit these usersExampleImagine an API service that allows 100 requests per minute per user If a user exceeds this rate further requests from that user within the same minute are either queued delayed or rejectedHeres a simple Pythonlike pseudocode using a dictionary to track request countsfrom time import timerate_limits    Dictionary to hold rate limit information for each userdef handle_requestuser_id current_time  time if user_id not in rate_limits rate_limitsuser_id  count 1 timestamp current_time else elapsed_time  current_time  rate_limitsuser_idtimestamp if elapsed_time  60  60 seconds  1 minute if rate_limitsuser_idcount  100 rate_limitsuser_idcount  1 else return Rate limit exceeded else rate_limitsuser_id  count 1 timestamp current_time return Request processed Simulating a series of API requestsfor i in range105 printhandle_requestuser_1ConclusionLoad balancing strategies are crucial for ensuring efficient resource utilization maximizing throughput reducing latency and achieving fault tolerance in distributed systems Each strategy comes with its unique set of advantages drawbacks and tradeoffs requiring careful consideration to match your specific needs From straightforward methods like Random Allocation to more complex techniques like ResourceBased or Application Layer Content Switching choosing the right strategy can significantly impact both user experience and operational costs Similarly while not a loadbalancing method Rate Limiting serves as a complementary mechanism to protect resources and ensure fair usage Whether youre designing a smallscale application or a global hightraffic service understanding these loadbalancing techniques is key to building resilient efficient and userfriendly systemsIf you found this article helpful please dont forget to hit the Follow  and Clap  buttons to help me write more articles like thisThank You Thank you for Reading   see you in the next blog Feel free to connect with me LinkedIn httpswwwlinkedincomingurpreetsinghpalClick on the following link to read all great stories on Medium httpsmediumcomgurpreetsingh_89Get an email whenever I publish a new storyhttpsmediumcomgurpreetsingh_89subscribeThe end  ,https://medium.com/@gurpreet.singh_89/10-load-balancing-techniques-mastering-the-art-of-distributed-computing-cea946ac5cdb,Infrastructure,1133,3550
Web Caching Strategies,Best Caching strategies  Progressive Web App PWALibin V BabuFollowPublished inAnimall Engineering5 min readJan 19 20211ListenShareThe main challenge Ive faced while building a web app was the page loading speed The best way to speed up a page is to load the assets from the cache and thus avoid network calls This is really important when your users are on a slow network This time Ive decided to jump on to service workers and make full use of its caching strategiesPopular caching strategies areCache first Network fallbackThe network first Cache fallbackStale while revalidateNetwork onlyCache onlyIll briefly explain what these strategies are and where we can apply theseCache first Network fallbackThe service worker will loads the local cached assets HTML CSS images fonts etc if possible bypassing the network If cached content is not available the service worker returns a response from the web instead and caches the network response This strategy can be used when dealing with remote resources that are very unlikely to change such as static imagesThe network first Cache fallbackIn this strategy the service worker will check the network first for a response and if successful returns current data to the page If the network request fails then the service worker returns the cached entry instead Use this when data must be as fresh as possible such as a realtime API response but you still want to display something as a fallback when the network is unavailableStale while revalidateThe stalewhilerevalidate pattern allows you to respond to the request as quickly as possible with a cached response if available falling back to the network request if its not cached The network request is then used to update the cache This is a fairly common strategy where having the most uptodate resource is not vital to the applicationNetwork onlyIn this the service worker will only check the network There is no going to the cache for data If the network fails then the request fails This can be used when only fresh data can be displayed on your siteCache onlyThe data is cached during the install event so that you can depend on the information being there This can be useful if you have your own precaching stepWhile you can implement these strategies yourself manually using workBox is recommended for service worker caching Workbox is a set of libraries that can power a productionready service worker for your Progressive Web AppThe approach Ive taken at Animall are1 Precache the home page assets when the user lands on the onboarding page through the install event With this once the user completes the onboarding all the static assets needed to load the home page are already available in the cacheselfaddEventListenerinstall async function event  eventwaitUntilcachesopenassetsthenfunction cache  return cacheaddAllfilesToCache filesToCache in the above code is an array of files to be cached at the install event2 Networkonly strategy to handle all navigationsvar networkOnly  new NetworkOnlyvar navigationHandler  async function navigationHandlerparams  try  return await networkOnlyhandleparams  catch error  return cachesmatchFALLBACK_HTML_URL  cacheName offline   Register this strategy to handle all navigationsvar navigationRoute  new workboxroutingNavigationRoutenavigationHandlerregisterRoutenavigationRouteThis ensures that the pages are loaded from the network only and fall back to an offline page if the internet is not available3 Stale While Revalidate strategy for CSS and js assetsregisterRoutefunction_ref2  var request  _ref2request return requestdestination  style  requestdestination  script new StaleWhileRevalidate cacheName assets plugins new CacheableResponsePlugin statuses 200 All the CSSjs assets are loaded from the cache and returns to the user immediately Same time it will check for any updates also from the network as well If the file is updated in the network the service worker will update the cache So next time when the user loads the same page he will get the updated version4 Cache First for the imagesregisterRoutefunction_ref  var request  _refrequest return requestdestination  image new CacheFirst cacheName images plugins new CacheableResponsePlugin statuses 200  new ExpirationPlugin maxEntries 50 maxAgeSeconds 60  60  24  30  30 Days purgeOnQuotaError true The images we use are usually not updated on the server frequently So Ive used the cache first strategy for loading the static images with few options as well Since the images can bloat your cache disk quickly we have put a maximum image limit in the cache with maxEntries Use purgeOnQuotaError along with this to make sure that the cache is cleared when the quota exceeds Also Ive applied maxAgeSeconds to expire the image cacheIf you are excited about solving similar problems Animall is looking for people like you to build the next billion users platform Animall is a top tier VC funded startup building an online platform to empower millions of dairy farmers ushering in the next digital white revolution You can find the opportunities here or shoot an email to missionanimallin as  ,https://medium.com/animall-engineering/best-caching-strategies-progressive-web-app-pwa-c610d65b2009,Infrastructure,349,782
Payment Gateway Integration,Whether you are an eCommerce platform owner or just maintaining your online presence you want to offer your customers a safe quick and easytouse payment system The chosen payment solution has to satisfy both the needs of your customers and your business So it has to be protected from fraud support a variety of payment methods be convenient to use and compatible with your platformTo accept electronic payments and be able to process credit or debit cards a merchant uses a payment gateway Choosing the right payment gateway determines the currencies you can accept the transaction fee how fast money gets in your merchant account and the payment methods youll offerAccording to Invespcrocom over 23 percent of customers abandon their shopping carts because of a complex checkout 11 percent system or too much information required to complete it 12 percent These statistics confirm that choosing the right payment solution provider is as important as other aspects of a good eCommerce website But in order to choose a payment solution first we need to understand what is a payment gateway and how it works What is a payment gateway A payment gateway is a service that authorizes and processes payments in online and brickandmortar stores A gateway serves as a portal to facilitate transaction flow between customers and merchants It uses security protocols and encryption to pass the transaction data safely The data is transferred from websitesapplicationmobile devices to payment processorsbanks and backPayment gateways can execute the following transaction typesAuthorization  a type of transaction used to check if a customer has enough funds to pay It doesnt include the actual money transfer Instead during authorization a merchant ensures that a cardholder is capable of paying for an ordered item An authorization transaction is used for orders that take time to shipmanufactureCapture  the actual processing of a previously authorized payment resulting in funds being sent to the merchants accountSale  a combination of authorization and capture transactions A cardholder is first authorized Then funds may or may not be captured Its a regular payment for immediate purchases like a subscription purchase or eticketsRefund  the result of a canceled order for which a merchant will have to apply a refund payment processing to return the moneyVoid  similar to refund but can be done if funds were not yet captured Payment processing flow The infrastructure of online payment processing is a little bit more complicated than you might imagine For the customer its represented by a small window or a separate website where they have to pass through the checkout But actually processing involves several financial institutions or tools verifying the transaction data on both ends allowing the customer to complete the purchase in a few secondsWhen a customer checks out  passing the card number expiration date and CVV  a payment gateway has to perform several tasks which take about 34 seconds Customer A customer presses a Purchase button and fills in the necessary fields to pass the transaction data The data is encrypted and sent to the merchants web server via an SSL connection Merchant and payment gateway After the transaction data is received a merchant passes it to the payment gateway via another encrypted SSL channel If any of data is stored by a payment gateway it is settled in a specific type of secured storage Usually gateways dont store actual credit card numbers but rather save tokens Payment processor The information goes to payment processors These are the companies that provide payment processing services as thirdparty players Payment processors are connected both with a merchants account and a payment gateway transferring data back and forth At that stage a payment processor is passing the transaction to a card network Visa Mastercard American Express etc VisaMastercardAmerican ExpressDiscover The role of a card network is to verify the transaction data and pass it to the issuer bank the bank that produced the cardholders creditdebit card Issuer bank The issuer bank also accepts or denies the authorization request In response a bank sends a code back to the payment processor which contains the transaction status or error details Payment gateway Transaction status is returned to the payment gateway then passed to the website Customer and issuing bank A customer receives a message with the transaction status accepted or denied via a payment system interface Issuer bank Within a couple of days generally the next day the funds are transferred to the merchants account The transaction is performed by the issuing bank to the acquiring bank Payment processing scheme Now we are moving closer to payment gateways in their variety To integrate a payment system into your website you will have to follow multiple steps Payment gateway integration Generally there are four main methods to integrate a payment gateway All of them differ by two major factors whether you must be in compliance with any financial regulation PCI DSS and the degree of user experience concerning the checkout and payment procedure So lets discover what the options are here and which integration methods suit your needs What is PCI DSS compliance and when do you need it In case you just need a payment gateway solution and dont plan to store or process credit card data you may skip this section because all the processing and regulatory burden will be carried out by your gateway or payment service providerBut in case youre going to deal with sensitive financial data youll need to comply with some industry regulations Payment Card Industry Data Security Standard PCI DSS is a necessary element for processing card payments This security standard was created in 2004 by the four biggest card associations Visa MasterCard American Express and DiscoverTo become PCI compliant you will have to complete 5 steps Define your compliance level There are four levels of compliance that are determined by the number of safe transactions your business has finished Transactions count if they were done via MasterCard Visa American Express or Discover cards and there was a certain number of successful transactions Study the PCI SelfAssessment Questionnaire SAQ SAQ is a set of requirements and subrequirements The latest version has 12 requirements Complete the Attestation of Compliance AOC AOC is a kind of exam you take after reading the requirements There are 9 types of AOC for different businesses The one required for retailers is called AOC SAQ D  Merchants Conduct an External Vulnerability Scan by the Approved Scanning Vendor ASV The list of ASVs can be found here Submit your documents to the acquirer bank and card associations The documents include the ASV scan report and your filledin SAQ and AOC Given this information were going to look at the existing integration options and explain the pros and cons of each Well also focus on whether you must comply with PCI DSS in each case as we explain what integration methods suit different types of businesses Hosted gateway A hosted payment gateway acts as a third party So it requires your customers to leave your website to complete a purchase Basically thats the case when a customer is redirected to a payment gateway web page to type in their credit card number When the transaction data is sent the customer is redirected back to the merchants page Here they finalize the checkout where transaction approval is shown Hosted payment gateway work scheme The pros of a hosted payment gateway are that all payment processing is taken by the service provider Client card data is also stored by the vendor So using a hosted gateway requires no PCI compliance and offers pretty easy integrationThe cons are that there is a lack of control over a hosted gateway Customers may not trust thirdparty payment systems Besides that redirecting them away from your website lowers conversion rate and doesnt help your branding eitherHow to integrate Integration guides are generally open on the vendors websites and the connection happens through an API For example PayPal Checkout suggests integration in the form of a Smart Payment Button Basically its a piece of HTML code that implements a PayPal button on your checkout page It invokes the PayPal REST API calls to validate collect and send payment information through a gateway whenever a user triggers the buttonBest fit for small or local businesses that are more comfortable using an external payment processor Direct Post method Direct Post is an integration method that allows a customer to shop without leaving your website as you dont have to obtain PCI compliance Direct Post assumes that the transactions data will be posted to the payment gateway after a customer clicks a purchase button The data instantly gets to the gateway and processor without being stored on your own serverThe pros of this method are equal to an integrated payment gateway You get the customization options and branding capabilities without PCI DSS compliance The user performs all the necessary action on one pageThe con is that a Direct Post method isnt completely secureHow to integrate A vendor would set up the API connection between your shopping cart and its payment gateway to post the card dataBest fit for can be used by businesses of all sizes Nonhosted integrated method An integrated payment gateway basically means there are no third parties involved at the payment checkout stage of Companies using integrated gateways obtain PCI DSS compliance which means theyre in charge of storing securing and conducting initial verification for each transaction This is done by installing a payment gateway solution available on the merchants websiteIn some cases companies can use a white label payment gateway as a nonhosted solution This is basically a prebuilt gateway that can be customized and branded as your own Here are some wellknown white label solutions designed for merchants PayXpert Akurateco Hips PayPipes MasterCard An integrated gateway can be a dedicated source of revenue as merchants that obtain all the necessary compliance become payment service providers themselves This means your business can process payments for other merchants for a fee But besides the regulatory aspect being a payment gateway provider brings a technological burden because you need an infrastructure to safely store transaction data credit card tokens etcThe pros are that you have full control over the transactions at your website You can customize your payment system as you wish and tailor it to your business needs In case of a whitelabel solution the payment gateway is your branded technologyThe cons generally are all about maintaining the infrastructure of your payment system and the related expenses To use an integrated gateway you have to be PCI compliant first of all because you will have to store all clients credit card data on your own servers Also integrating the gateway can be tricky if you want to add custom functionalityHow to integrate Nonhosted payment gateways are integrated via APIs to your server Consequently it will require an engineering team to perform the integration Most vendors have welldocumented integration guides API references or developer portalsBest fit for for medium and large businesses that rely heavily on branding and user experience Choosing a payment gateway provider Now you can choose a payment solution for your business considering all factors your business specifics and your customers Here are some things to consider prior to deciding on a provider Study the pricing Payment processing is complex as it includes several financial institutions or organizations Like any service a payment gateway requires a fee for using thirdparty tools to process and authorize the transaction Every party that participates in payment verificationauthorization or processing charges fees Transactions commonly are billed according to the amount location across a certain country or international and type of a product physical or digitalEvery payment solution provider has its own terms of use and fees Usually you will have the following fee types gateway setup fee monthly gateway fee merchant account setup and a fee for each transaction processed Read all the pricing documentation to avoid hidden fees or additional expenses Check transaction limits for a given provider While fees and installation charges are inevitable there is one thing that may determine whether you can work with a certain provider Gateway providers set transaction limits as a minimum and maximum amount Both values are of interest for merchants and their business as you want to use a single gateway for all the available productsSo lets take for example Stripe as one of the biggest players Their transaction limit minimum is 050 and 99999999 is their maximum The maximum amount will probably suit the majority of businesses that dont trade bonds or real estate online But if your business is selling say stock music tracks for a price as low as 010 this may affect your choice even though making a 010 purchase is extremely rareThe second thing you should pay attention to is daily or monthly transaction limits These occur pretty rarely but also play a huge role for gateway provider choice Examine merchant account options A merchant account is an agreement between a merchant and an acquiring bank by which a merchant allows a bank to process their transactions Additionally a merchant agrees to follow the operational regulations of credit card processing established by credit card companiesA merchant account can be opened through banks or payment gateway providers that offer merchant accounts as a part of a service This includes payment processors If you already have a merchant account consider what that provider offers Otherwise its better to choose a provider that offers a merchant account from the start Make sure the gateway supports necessary payment methods and credit cards As of 2019 the most popular payment methods remain credit cards varying from 82 to 69 percent of all shoppers in different regions according to Statista Second place is occupied by various electronic payment methods like PayPal Union Pay and Alipay ranging between 51 and 80 percent of all shoppersIn terms of credit cards as a major payment method you have to make sure a payment gateway accepts all the required credit card networksAnother aspect is multicurrency support If your business is international you want your customers to be able to pay no matter what currency they use Popular gateway providers offer multicurrency support processing with or without an additional fee If you are going to use a hosted payment system there are also localized checkouts available Consider mobile payments While mobile payments are acquiring money from the credit card accounts accepting Apple Pay or Google Pay means supporting a different payment method In short mobile payments have their own tokenization process and come as a separate method in all payment gateway servicesDepending on the country youre running your business in mobile wallets may or may not be available But the three major applications Apple Pay Google Pay and Samsung Pay currently support all four main credit card networks and operate in hundreds of countries So you have to scan the providers page and find the corresponding information on whether the gateway supports mobile wallets and which onesKeep in mind that there are also different transaction limits set for a given time period for example PayPal Ensure your product type is permitted by the provider Generally there are two types of products considered by providers digital and physicalSome of the payment solution providers offer their services both for physical and digital products But its not rare for only one type of product to be available in use of a certain system So before subscribing to a provider make sure it permits your type of a product Popular payment gateway providers The horde of gateway providers is overwhelming so weve picked some of the biggest most reliable options Table of payment gateway providers features Stripe Stripe is an eCommerce tailoredpayment solution Stripe accepts all major payment methods including mobile payment providers such as Apple Pay WeChat Pay Alipay and Android PayThe service is fully loaded with its comprehensive documentation international support and monitoring system It has a simplified PCI compliance procedure with 135 supported currencies and allows for integrating with other thirdparty platformsPricing Stripe charges no setup fees The standard package charges 29 percent  030 per transaction Additionally there is a fee for international card processing 1 percent But Stripe also offers a customized solution and pricing package for large businesses The chargeback amount is a fixed 15 PayPal PayPal is one of the most widely accepted electronic payment methods in the world PayPal offers scalable solutions for businesses of different sizes Through its gateway PayPal offers processing of all the major credit and debit cards and PayPal payments themselves with various other methods It also has multiple services which include PayPal Payments Pro PayPal Express Checkout and BraintreePayPal is often integrated as a hosted payment solution PayPal Payments Pro is an upgrade you may obtain if you want an integrated checkout right on your website PayPal Express Checkout is the easiest option as it simply adds a PayPal button to your website Braintree is a separate payment solution but it is a PayPal division The main advantage of using Braintree is that it bills international transactions without an additional feePricing PayPals pricing model is complex and includes different calculations for micropayments their platform usage and international transactions Domestic transactions are billed at 29 percent  030 per transaction Outside the US transactions are 39 percent  a fee based on the currency used There is no monthly fee for the standard PayPal but Payments Pro charges 30 monthly for a subscription The chargeback amount is 20 and for Braintree with equal pricing for transactions it is 15 No setup fees are included Amazon Pay Amazon Pay is an eCommerce giant with its platform designed for online retailers Amazon Pay is integrated via API offering a semiintegrated payment solution Its available across devices with a focus on mobile use Amazon service also supports all the major payment methods and credit cardsPricing Domestic transactions are billed at 29 percent  030 per transaction International is 39 percent The refund amount is 20  taxes if applicable No setup or monthly fees Authorizenet Authorizenet is designed for small and mediumsized businesses Their service also provides all the major payment method support including PayPal payments and Apple Pay Authorizenet protects users from fraudulent transactions via its Advanced Fraud Detection Suite They also support integration with mobile applicationsPricing 29 percent  030 per transaction There is a 25 monthly fee for a gateway and 49 for merchant account setup You may sign up for a payment gateway if you already have a merchant account 2Checkout 2Checkout provides customizable options for businesses of different sizes as well as integrated payment solutions Its biggest advantage is its scalability with packages for different product types 2Checkout supports all the major payment methods 87 currencies and 15 languages localizationsPricing 2Checkout includes 3 packages with different fees There are no setup monthly or recurring payments The 2Sell fee is 35 percent  035 per transaction 2Monetize is a package tailored to digital product sellers and its pricing is 60 percent  060 per transaction Custom payment gateway There are a lot of payment gateway providers that offer a full shopping experience to your customers and various integration methods But if you are a large enterprise you might be interested in building your own payment solution to break free of vendor restrictions How to build a custom gateway Creating a custom payment gateway requires several stepsPayment gateway provider registration Register as a payment gateway provider with a credit card company or several through your acquiring bank Contracting with banks Contract banks that will act as payment processors to handle the actual processing for you Multiple banks can give you different transaction fees for international transfers or different rates for currency exchange API development Develop an API for your gateway and write robust documentation as required within PCI DSS compliance Tokenization solution Any institution that stores credit card information does it in the form of tokens This is a security measure when we replace sensitive data with tokens as it reduces the chance of fraud Tokens contain transaction data and cardholder information without exposing it to the third parties PCI DSS certification Become PCI DSS compliant by implementing all the necessary security measures and integrating merchant fraud protection mechanisms on your website Choose additional payment methods If you need additional methods like PayPal Bitcoin or mobile wallets eg Apple Pay youll need to integrate them separately with their APIs Management tools development Develop a merchant administration web application or simply an admin panel to allow your staff to control merchant operations You may also use opensource payment gateway solutions It is possible to use an opensource payment gateway like OmniPay PayU or Active Merchant software that will lower the costs of the engineering But it will again restrict you in customization optionsDeveloping an independent custom gateway and payment processing infrastructure requires serious expenses that are billed in a range from 150000 to 800000 That price includes engineering maintenance PCI DSS compliance certification SSL certification writing API documentation and administration expenses Besides the financial issues it also requires the time to launch a fully working system and implement it into your productHowever a custom payment solution can bring a number of benefitsLower transaction fees Establishing your gateway you avoid a gateway provider as a freeforming factor which lowers transaction feesCustomization A large enterprise business may be firmly restricted by what vendors offer Even if you find a vendor with low transaction fees and a great number of payment methods there are always restrictions Developing a custom payment solution allows you to implement any feature you want whether those are recurring payments or multicurrency transactionsOffer payment gateway as a product With your own custom payment solution you will be able to offer it to other merchants and agentsBeing a longtime investment developing a custom payment gateway is quite reasonable for a company with a large yearly revenue For companies handling fewer than 20 thousand transactions per year a customer payment solution is unnecessary But for merchants conducting over 12 million transactions the savings quickly mount upOptimizing your gateway and saving costs on transaction fees are reasonable factors to consider Pitfalls you should be aware of are security issues which are usually carried by the gateway providers But obtaining PCI compliance and using fraud management will help you to get customer confidence Conclusion So whether you are choosing a payment gatewayprocessor provider or planning to build your own payment portal it is always a much more profitable solution for an online merchant unless you are a nonprofit website Websites using an inbuilt payment system are more trusted by customers And if you are looking for a way to improve client confidence integrate a payment solution that will inspire trust support multiple payment methods and be protected from fraudulent actionsHOW PAYMENT PROCESSING WORKS Purchase Data sent to the gateway  Merchant Payment  Payment Chetty  Checkout  gateway  processor Response sent back tothe cardholder Respective card Funds settlement in the companies verity merchants account transaction data Orange arrow indicates card data verification flow Green arrow indicates the response from banks anda credit card associations returnedtoa cardholder Blue arrow indicates funds settlement inthe acquiring bank altexsoft sohware rhe HOSTED PAYMENT GATEWAY Checkout on the website Gateway provider altexsoft rerBd engineering Features Payment methods Gateway features Monthly fee Fee per transaction Setupfee Chargeback International transactions Supported creditdebit cards Availability in countries PAYMENT GATEWAY PROVIDERS Stripe AliPay Android Pay Apple Pay Bitcoin ACH WeChat EPS PcIDDS compliance AVS SSL CCV Virtual Terminal No 29030 ACHBitcoin processing 08 No 15 39030 Visa MasterCard American Express Discover AMEX PayPal PayPal Venmo Android Pay Apple Pay Bitcoin PcIDDS compliance AVS SSL CCV Virtual Terminal 30 Payments Pro 29030 No 20 39fee based ona currency Vi MasterCard American Express Discover JCB Diners AMEX 202 Amazon Pay Amazon Pay PCIDDS compliance AVS SSLCCV No 29030 No 20 taxes 39030 Visa MasterCard American Express Discover JCB Diners NYCE STAR China Union EuroCard 78 Authorizenet Apple Pay PayPal E check Visa Checkout PciDDS compliance AVS SSL CCV Virtual Terminal 25 Gateway fe 29030 49 25 Visa MasterCard American Express Discover JCB 20 2Checkout Wire ACH PayPal WebMoney Payoneer WeChat PciDDS compliance AVS SSL ccv No 35035 NO Visa MasterCard American Express Discover JCB 200 altexsoft sofware rd engineering Payment Card Industry PCI Data Security Standard SelfAssessment Questionnaire Instructions and Guidelines Version 321 June 2018 PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page i Document Changes Date Version Description October 1 2008 12 To align content with new PCI DSS v12 and to implement minor changes noted since original v11 October 28 2010 20 To align content with new PCI DSS v20 and clarify SAQ environment types and eligibility criteria Addition of SAQ C VT for Webbased Virtual Terminal merchants June 2012 21 Addition of SAQ P2PE HW for merchants who process cardholder data only via hardware payment terminals incl uded in a validated and PCI SSClisted PCI Point toPoint Encryption P2PE solution This document is for use with PCI DSS version 20 April 2015 31 To align content with PCI DSS v3 1 including addition of SAQs A EP and B IP and clarify eligibility criteria for existing SAQs  May 2016 32 Updated to align with PCI DSS v32 and clarify eligibility criteria for existing SAQs  June 2018 321 Minor u pdate s to align with PCI DSS v3 21 PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page ii Table of Contents Document Changes      i About this Document      1 PCI DSS Self Assessment How it All Fits Together    2 SAQ Overview      3 Why PCI DSS is Important     4 Understanding the difference between compliance and security   5 General Tips and Strategies for PCI DSS Compliance    5 Selecting the SAQ and Attestation that Best Apply to Your Organization   8 SAQ A  Card notpresent Merchants All Cardholder Data Functions Fully Outsourced  10 SAQ A EP  Partially Outsourced E Commerce Merchants Using a Third Party Website for Payment Processing      11 SAQ B  Merchants with Only Imprint Machines or Only Standalone Dial Out Terminals No Electronic Cardholder Data Storage     12 SAQ B IP  Merchants with Standalone IP Connected PTS Point ofInteraction POI terminals No Electronic Cardholder Data Storage    13 SAQ C VT  Merchants with Web Based Virtual Terminals No Electronic Cardholder Data Storage  14 SAQ C  Merchants with Payment Application Systems Connected to the Internet No Electronic Cardholder Data Storage     15 SAQ P2PE  Merchants using Only Hardware Payment Terminals in a PCI SSC listed P2PE Solution No Electronic Cardholder Data Storage    16 SAQ D for Merchants  All Other SAQ Eligible Merchants    17 SAQ D for Service Providers  SAQ Eligible Service Providers   17 Which SAQ Best Applies to My Environment    18 PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 1 About this Document This document was developed to help merchants and service providers understand the P ayment Card Industry Data Security Standard  PCI DSS Self Assessment Questionnaire s SAQ s In order to understand why PCI DSS is important to your organization what strategies your organization can use to facilitate PCI DSS compliance validation and whether your organizat ion is eligible to complete one of the shorter SAQ s we recommend that you review this Instructions and Guidelines document in its entirety PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 2 PCI DSS SelfAssessment How it All Fits Together The PCI DSS and supporting documents represent a common set of i ndustry tools to help ensure the safe handling of cardholder data The standard itself provides an actionable framework for developing a robust security process including preventing detecting  and reacting to security incidents To reduce the risk of comp romise and mitigate the impact if it does occur it is important for all entities that store process or transmit cardholder data to be compliant  The chart below outlines the tools in place to help organizations with PCI DSS compliance and self assessment These and other related documents can be found at wwwpcisecuritystandardsorg   Note Information Supplements provide supplemental information and guidance only a nd do not replace or supersede any requirements in PCI DSS  PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 3 SAQ Overview The PCI DSS Self Assessment Questionnaire s SAQ s are validation tool s intended to assist merchants and service providers in self evaluating their compliance with the PCI DSS  There are multiple versions of the PCI DSS SAQ s to meet various scenarios This document has been developed to help your organization determine which SAQs best applies to your environment  The PCI DSS SAQ is a validation tool for merchants and service provide rs not required by their respective acquirer s or payment brand s to submit a PCI DSS Report on Compliance ROC  Please consult your acquirer or payment brand for details regarding PCI DSS validation requirements Each PCI DSS SAQ consists of the followi ng components 1 Questions correlating to the PCI DSS requirements as appropriate for different environments  See Selecting the SAQ and Attestation that Best Apply to Your Organization in this document This section also includes a column for Expected Testing which is based on the testing procedures in PCI DSS 2 Attestation of Compliance The Attestation includes your declaration of eligibility for completing the applicable SAQ and the subsequent result s of a PCI DSS self assessment  PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 4 Why PCI DSS is Important The founding members of the PCI Security Standards Council American Express Discover JCB Master card and Visa continually monitor occurrences of account data compromise These compromises cover the full spectrum of organizations from very small to very large merchants and service providers A security breach and subsequent compromise of payment card data has far reaching consequences for affected organizations including 1 Regulatory notificatio n requirements 2 Loss of reputation 3 Loss of customers 4 Potential financial liabilities for example regulatory and other fees and fines and 5 Litigation  Forensic analysis of compromise s has shown that common security weaknesses  which are addressed by PCI DSS controls  are often exploited because the PCI DSS controls either were not in place or were poorly implemented when the compromise occurred  PCI DSS was designed and includes detailed requirements for exactly this reason to minimize the chance of compromise and the effects if a compromise does occur  Examples of common PCI DSS control failures includ e but are not limited to  Storage of sensitive authentication data SAD  such as track data  after authorization Requirement 32 Many compromised entities were unaware that their systems were storing this data  Inadequate access controls due to improperly installed point ofsale POS systems allowing malicious users in via paths intended for POS vendors Requirements 71 72 82  and 83   Default system settings and passwords not changed when the system was installed Requirement 21   Unnecessary and insecure services not removed or secured when the system was installed Requirement s 222 and 22 3  Poorly coded web applications resultin g in SQL injection and other vulnerabilities which allow access to the database storing cardholder data directly from the website Requirement 65   Missing and outdated security patches Requirement 6 2  Lack of logging Requirement 10   Lack of monitor ing via log reviews intrusion detectionprevention quarterly vulnerability scans and change detection mechanism s Requirements 106 112 114 and 115   Poor scoping decisions for example excluding part of the network from PCI DSS scope due to inadequate network segmentation that was not verified to be effective Requirement 1134  This results in the cardholder data environment being unknowingly exposed to weaknesses in other parts of the network that have not been secured according to PCI DSS for example from unsecured wireless access points and vulnerabilities introduced via employee e mail and web browsing Requirements 12 13 and 14  PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 5 Understanding the difference between compliance and security Its important to recognize the differen ce between being compliant and being secure Being compliant with PCI DSS at one point in time does not prevent things from changing in your environment which if the proper controls are not implemented could impact your security You should therefore ensu re that PCI DSS controls continue to be implemented properly as part of business asusual BAU activities and as defined by your overall security strategy This will enable you to monitor the effectiveness of your organizations security controls on an on going basis and maintain your PCI DSS compliant environment between PCI DSS assessments Examples of how PCI DSS should be incorporated into BAU activities are provided in the  Best Practices for Implementing PCI DSS into Business asUsual Processes section in the PCI DSS Additionally the PCI DSS security requirements are intended for the protection of payment card data and your organization may have other sensitive data and assets that need protecting which could be outside of the scope of PCI DSS The refore while PCI DSS compliance if properly maintained can certainly contribute to overall security it should not be viewed as a replacement for a robust organization wide security program General Tips and Strategies for PCI DSS Compliance Following are some general tips and strategies for beginning your PCI DSS compliance efforts Th ese tips may help you eliminate storage of cardholder data you do not need isolate the data you do need to defined and controlled centralized areas and may allow you to limit the scope of your PCI DSS compliance validation effort  For example by eliminating cardholder data that you do nt need andor isolating th e data that you do need to defined and controlled areas you can remove systems and networks that dont store process  or transmit cardholder data and that dont connect to systems that dofrom the scope of your self assessment 1 Sensitive Authentication Data includes the full track contents o f the magnetic stripe or equivalent data on a chip card v erification codes and values PIN s and PIN blocks Make sure you never store this data after authorization 2 Ask your POS vendor about the security of your system with the following suggested questions a Have default settings and passwords been changed on the systems and databases that are part of the POS system b Do you access my POS system remotely If so have you implemented appropriate controls to prevent others from accessing my POS system  such as using secure remote access methods and not using common or default passwords How often do you access my POS device remotely and why Who is authorized to access my POS remotely c Have all unnecessary and insecure services been removed from the sy stems and databases that are part of the POS system d Is my POS software validated to the Payment Application Data Security Standard PADSS Refer to PCI SSCs list of Validated Payment Applications  e Does my POS software store sensitive authentication data such as track data or PIN blocks If so this storage is prohibited  how quickly can you help me remove it f Does my POS software store primary account numbers PANs If so this storage must be protected  how is the POS protecting this data g Will you document the list of files written by the application with a summary of each files content s to verify that the above mentioned prohibited data is not stored PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 6 h Does my POS software enforce complex and unique passwords for all user access i Can you confirm that you do not use common or default passwords for access to my system and other merchant systems you support j Have all the systems and databases that are part of the POS system been patched with all applicable security updates k Is the logging ca pability turned on for the systems and databases that are part of the POS system l If prior versions of my POS software stored sensitive authentication data has this feature been removed during current updates to the POS software Was a secure wipe utility used to remove this data 3 Cardholder data if you dont need it dont store it a Payment brand rules allow for the storage of primary a ccount number PAN expiration date cardholder name and service code b Take inventory of all the reasons and places you store this data If the data doesnt serve a legitimate business purpose consider eliminating it  c Think about whether the storage of that data and the business process it supports are worth the following i The risk of having the data compromised ii The additional PCI DSS controls that must be applied to protect that data iii The ongoing maintenance efforts to remain PCI DSS compliant over time 4 Cardholder data if you do need it consolidate and isolate it You can limit the scope of a PCI DSS assessment by consolidating data storage in a defined environment and isolating the data through the use of proper network segmentation  For example if your employees browse the Internet and receive e mail on the same machine or network segment as cardholder data consider segmenting isolating the cardholder data onto its own machine or network segment for example  via routers or firewalls If you can isolate the cardholder data effectively you may be able to focus your PCI DSS efforts on just the isolated part rather than including all your machines 5 Compensating Controls Compensating controls may be considered for most PCI DSS requirements when an organization cannot meet the technical specification of a requirement but has sufficiently mitigated the associa ted risk through alternative controls If your organization does not have the exact control specified in PCI DSS but has other controls in place that satisfy the PCI DSS definition of compensating controls see Compensating Controls in PCI DSS Appendi x B and also in the PCI DSS and PA DSS Glossary of Terms Abbreviations and Acronyms  your organization should do the following a Follow the procedures for compensating controls as outlined in PCI DSS Appendi x B b For all requirements that were met with the assistance of a compensating control respond to the SAQ question by checking the YES with CCW  column  PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 7 c Document each compensating control by completing a Compensating Controls Worksheet in Appendix B of the SAQ A Compensating Contr ols Worksheet must be completed for each requirement that is met with a compensating control  d Submit all completed Compensating Controls Worksheets  along with your completed SAQ andor Attestation of Compliance  according to instructions from your acquirer or payment brand 6 Professional Assistance and Training a If you would like to engage a security professional for help with your self assessment  we encourage you to consider contacting a Qualified Security Assessor QSA QSAs have been trained by PCI SSC to conduct PCI DSS assessments and are listed on the PCI SSC website b The PCI SSC website is a primary source for additional resources including  The PCI DSS Glossary of Terms Abbreviations and Acronyms  Frequently Asked Questions FAQ s  Webinars  Information Supplements and Guidelines  SAQ forms and Attestations of Compliance c PCI SSC also provides a number of training programs to help build awareness for an organization s personnel Example s include PCI Awareness the PCI Professional PCIP program and the Internal Security Assessor ISA program  Please refer to wwwpcisecuritystandardsorg for more information d Payment related training programs and resources may also be available f rom the payment brands andor your merchant acquirer  Note Information Supplements complement the PCI DSS and identify additional considerations and recommendations for meeting PCI DSS requirements they do not change eliminate  or supersede the PCI DSS or any of its requirements PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 8 Selecting the SAQ and Attestation that Best Apply to Your Organization All merchants and service providers are required to comply with the PCI DSS as applicable to their environment s at all times  There are a number of SAQ types  shown briefly in the table below and described in more detail in the following pages  Use the table to help determine which SAQ applies to your organization and then review the detailed descriptions to ensure you meet all the requirements for that SAQ Note for all SAQs except SAQ D  These SAQs include questions that apply to a specific type of merchant environment as defined in the related SAQ eligibility criteria If there are PCI DSS requirements applicable to your envi ronment that are not covered in a given SAQ it may be an indication that this SAQ is not suitable for your environment Additionally you must comply with all applicable PCI DSS requirements in order to be PCI DSS compliant SAQ Description A Card notpresent merchants e commerce or mailtelephone order that have fully outsourced all cardholder data functions to PCI DSS compliant third party service providers with no electronic storage processing or transmission of any cardholder data on the merchants systems or premises Not applicable to face toface channels AEP Ecommerce m erchants who outsource all payment processing to PCI DSS validated third parties  and who have a websites that doesnt directly receive cardholder data but th at can impact the security of the payment transaction No electronic storage process ing or transmi ssion of cardholder data on merchants systems or premises Applicable only to e commerce channels B Merchants using only  Imprint machines with no electronic cardholder data storage andor  Standalone dial out terminals with no electronic cardholder data storage Not applicable to e commerce channels BIP Merchants using only standalone PTS approved payment terminals with an IP connection to the payment processor with no electronic cardholder data storage  Not applicable to e commerce channels  CVT Merchants who manually enter a single transaction at a time via a keyboard into an Internet based virtual payment terminal solution that is provided and hosted by a PCI DSS validated third party service provider N o electronic cardholder data storage  Not applicable to ecommerce channels  C Merchants with payment application systems connected to the Internet no electronic cardholder data storage  Not applicable to e commerce channels  PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 9 SAQ Description P2PE Merchants using only hardware payment terminals included in and managed via a validated PCI SSC listed Point toPoint Encryption  P2PE  solution with no electronic cardholder data storage Not applicable to e commerce channels  D SAQ D for Merchants All merchants not included in descriptions for the above SAQ types SAQ D for Service Providers All service providers defined by a payment brand as eligible to complete an SAQ  PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 10 SAQ A  Card notpresent Merchants  All Cardholder Data Functions Fully Outsourced SAQ A has been developed to address requirements applicable to merchants whose cardholder data functions are completely outsourced to validated third parties where the merchant retains only pa per reports or r eceipts with cardholder data  SAQ A merchants may be either e commerce or mailtelephone  order merchants card notpresent  and d o not store  process or transmit any cardholder data in electronic format on their systems or premises  SAQ A merchants will confirm that they meet the following eligibility criteria for this payment channel  Your company accepts only card notpresent e commerce or mailtelephone order transactions  All processing of cardholder data is entirely outsourced to PCI DSS valid ated third party service providers  Your company does not electronically store process or transmit any cardholder data on your systems or premises but relies entirely on a third partys to handle all these functions  Your company has confirmed that all third partys handling storage processing andor transmission of cardholder data are PCI DSS compliant and  Any cardholder data your company retains is on paper for example printed reports or receipts  and these documents are not received electronic ally Additionally for e commerce channels  All elements of all payment pages delivered to the consumers browser originate only and directly from a PCI DSS validated thirdparty service providers This SAQ is not applicable to face toface channels For a graphical guide to choosing your SAQ type please see Which SAQ Best Applies to My Environment  on page 18 PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 11 SAQ A EP  Partially Outsourced ECommerce Merchants Using a Third Party Website for Payment Processing SAQ A EP has been developed to address requirements applicable to e commerce merchants with a websites that does not itself receive cardholder data but which does affect the security of the payment transaction andor the integrity of the page that accepts the consumers cardholder data SAQ A EP merchants are e commerce merchants who partially outsource their e commerce payment channel to PCI DSS validated third parties and do not electronically store  process  or transmit any cardholder data on their systems or premises  SAQ AEP merchants will confirm that they meet the following eligibility criteria for this payment channel   Your company accepts only e commerce transactions  All processing of cardholder data  with the exception of the payment page is entirely outsourced to a PCI DSS validated third party payment processor  Your e commerce website does not receive cardholder data but controls how consumers or their cardholder data are redirected to a PCI DSS validated third party payment processor  If merchant website is hosted by a third party provider the provider is validated to all applicable PCI DSS requirements eg including PCI DSS Appendix A if the provider is a shared hosting provider  Each element of the payment page s delivered to the consumers browser originat es from either the merchants website or a PCI DSS compliant service providers  Your company does not electronically store process or transmit any cardholder data on your systems or premises but relies entirely on a third partys to handle all these functions  Your company has confirmed that all third partys handling storage processing andor transmission of cardholder data are PCI DSS compliant and  Any cardholder data your company retains is on paper for example printed reports or receipts  and these documents are not received electronically This SAQ is applicable only to e commerce channels Note For the purposes of SAQ A EP PCI DSS requirements that refer to the cardholder data environment are applicable to the merchant websites This is because the merchant website directly impacts how the payment card data is transmitted even though the website itself does not receive cardholder data For a graphical guide to choosing your SAQ type please see Which SAQ Best Applies to My Environment on page 18 PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 12 SAQ B  Merchants with Only Imprint Machines or Only Standalone Dial Out Terminals No Electronic Cardholder Data Storage SAQ B has been developed to address requirements applicable to merchants who process cardholder data only via imprint machines or standalone  dialout terminals SAQ B merchants may be either brick andmortar card present or mailtelephone order card notpresent merchants  and do not store cardholder data on any computer system  SAQ B merchants will confirm that they meet the following eligibility criteria for this payment channel  Your company uses only an imprint machine andor uses only standalone dial out terminals connected via a phone line to your processor to take your customers payment card information  The standalone dial out terminals are not connected to any other systems within your environment  The standalone dial out terminals are not connected to the Internet  Your company does not transmit cardholder data over a network either an internal netw ork or the Internet  Any cardholder data your company retains is on paper for example printed reports or receipts  and these documents are not received electronically and  Your company does not store cardholder data in electronic format This SAQ is not applicable to e commerce channels For a graphical guide to choosing your SAQ type please see Which SAQ Best Applies to My Environment on page 18 PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 13 SAQ B IP  Merchants wit h Standalone IPConnected PTS PointofInteraction POI terminals  No Electronic Cardholder Data Storage SAQ B IP has been developed to address requirements applicable to merchants who process cardholder data only via standalone PTS approved point ofinteraction POI devices with an IP connection to the payment processor SAQ BIP merchants may be either brick andmortar card  present or mailtelephone order card notpresent merchants  and do not store cardhold er data on any computer system SAQ B IP merchants will confirm that they meet the following eligibility criteria fo r this payment channel   Your company uses only standalone PTS approved point ofinteraction POI devices excludes SCRs connected via IP to your payment processor to take your customers payment card information  The standalone  IPconnected POI devices are validated to the PTS POI program as listed on the PCI SSC website excludes SCRs  The standalone  IPconnected POI devices are not connected to any other systems within your environment this can be achieved via network segmentation to isolate POI de vices from other systems  The only transmission of cardholder data is from the PTS approved POI devices to the payment processor  The POI device does not rely on any other device eg computer mobile phone tablet etc to connect to the payment processor  Any cardholder data your company retains is on paper for example printed reports or receipts  and these documents are not received electronically and  Your company does not store cardholder data in electronic format This SAQ is not applicabl e to e commerce channels For a graphical guide to choosing your SAQ type please see Which SAQ Best Applies to My Environment on page 18 PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 14 SAQ C VT  Merchants with Web Based Virtual Terminals No Electronic Cardholder Data Storage SAQ C VT has been developed to address requirements applicable to merchants who process cardholder data only via isolated virtual paymen t terminals on a personal computer connected to the Internet A virtual payment terminal is web browser based access to an acquirer processor or thirdparty service provider website to authorize payment card transactions where the merchant manually enters payment card data via a securely connected web browser  Unlike physical terminals virtual payment terminals do not read data directly from a payment card  Payment card transactions are entered manually  SAQ C VT merchants process cardholder data only via a virtual payment terminal and do not store cardholder data on any computer system  These virtual terminals are connected to the Internet to access a third party that hosts the virtual terminal payment processing function  This third party may be a processor acquirer or other third party service provider who stores processes andor transmits cardholder data to authorize andor settle merchants virtual terminal payment transactions This SAQ option is intended to apply only to merchants who manually enter a single transaction at a time via a keyboard into an Internet based virtual terminal solution  SAQ C VT merchants may be brick andmortar card present or mailtelephone order card notpresent merchants  SAQ C VT merchants will confirm that they meet the following eligibility criteria for this payment channel   Your companys only payment processing is via a virtual payment terminal accessed by an Internet connected web browser  Your companys virtual payment terminal solution is provided and hosted by a PCI DSS validated thirdparty service provider   Your compan y accesses the PCI DSS compliant virtual payment terminal solution via a computer that is isolated in a single location and is not connected to other locations or systems within your environment this can be achieved via a firewall or network segmentation to isolate the computer from other systems  Your companys computer does not have software installed that causes cardholder data to be stored for example there is no software for batch processing or store andforward   Your companys computer does not have any attached hardware devices that are used to capture or store cardholder data for example there are no card readers attached  Your company does not otherwise receive or transmit cardholder data electronically through any channels for example v ia an internal network or the Internet  Any cardholder data your company retains is on paper for example printed reports or receipts and these documents are not received electronically and  Your company does not store cardholder data in electronic for mat This SAQ is not applicable to ecommerce channels For a graphical guide to choosing your SAQ type please see Which SAQ Best Applies to My Environment on page 18 PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 15 SAQ C  Merchants with Payment Application Systems Connected to the Internet No Electronic Cardholder Data Storage SAQ C has been developed to address requirements applicable to merchants whose payment application systems for example point ofsale systems are connected to the Internet for example via DSL cable modem etc SAQ C merchants process cardholder data via a point ofsale POS  system or other payment application systems connected to the Internet do not store cardholder data on any computer system and may be either brick andmortar card present or mail telephone order card notpresent merchants SAQ C merchants will confirm that they meet the following eligibility criteria for this payment channel   Your company has a payment application system and an Internet connection on the same device andor same local area network LAN  The payment application systemInternet device is not connected to any other systems within your environment this can be achieved via network segmentation to isolate payment application systemInternet device from all other syste ms  The physical location of the POS environment is not connected to other premises or locations and any LAN is for a single store only  Any cardholder data your company retains is on paper for example printed reports or receipts  and these documents are not received electronically  and  Your company does not store cardholder data in electronic format  This SAQ is not applicable to e commerce channels  For a graphical guide to choosing your SAQ type please see Which SAQ Best Applies to My Environment  on page 18 PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 16 SAQ P2PE  Merchants using Only Hardware Payment Terminals in a PCI SSC listed P2PE Solution No Electronic Cardholder Data Storage SAQ P2PE has been developed to address requirements applicable to merchants who process cardholder data only via payment terminals included in a validated and PCI SSC listed Point toPoint Encryption P2PE solution SAQ P2PE merchants do not have access to clear text account data on any computer system and only enter account data via hardware payment termi nals from a PCI SSC approved P2PE solution  SAQ P2PE merchants may be either brick andmortar card present or mailtelephone order card notpresent merchants For example a mailtelephone order merchant could be eligible for SAQ P2PE if they receive c ardholder data on paper or over a telephone and key it directly and only into a P2PE validated hardware device  SAQ P2PE merchants will confirm that they meet the following eligibility criteria for this payment channel  All payment processing is via a va lidated PCI P2PE solution approved and listed by the PCI SSC  The only systems in the merchant environment that store process or transmit account data are the Point of Interaction POI devices which are approved for use with the validated and PCI  listed P2PE solution  Your company does not otherwise receive or transmit cardholder data electronically  There is no legacy storage of electronic cardholder data in the environment  Any cardholder data your company retains is on paper for example printed reports or receipts and these documents are not received electronically  and  Your company has implemented all controls in the P2PE Instruction Manual PIM provided by the P2PE Solution Provider  This SAQ is not applicable to ecommerce channels For a graphical guide to choosing your SAQ type please see Which SAQ Best Applies to My Environment on page 18 PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 17 SAQ D for Merchant s  All Other SAQ Eligible Merchants SAQ D for Merchants applies to SAQ eligible merchants not meeting the criteria for any other SAQ type Examples of merchant environments that would use SAQ D may include but are not limited to  Ecomm erce merchants who accept cardholder data on their website   Merchants with electronic storage of cardholder data   Merchants that dont store cardholder data electronically but that do not meet the criteria of another SAQ type   Merchants with environments t hat might meet the criteria of another SAQ type but that have additional PCI DSS requirements applicable to their environment  SAQ D for Service Providers  SAQ Eligible Service Providers SAQ D for Service Providers applies to all service providers defined by a payment brand as being SAQ eligible Note for SAQ D for Merchants and SAQ D for Service Providers While many organizations completing SAQ D will need to validate compliance with every PCI DSS requirement some organizati ons with very specific business models may find that some requirements do not apply For example a company that does not use wireless technology in any capacity would not be expected to validate compliance with the sections of the PCI DSS that are specifi c to managing wireless technology See the specific guidance in the respective SAQ D for information about the exclusion of other specific requirements For a graphical guide to choosing your SAQ type please see Which SAQ Best Applies to My Environment  on page 18 PCI DSS Self Assessment Questionnaire Instructions and Guidelines v 321 June 2018  2006 2018 PCI Security Standards Council LLC All Rights Reserved Page 18 Which SAQ Best Applies to My Environment ,https://www.altexsoft.com/blog/payment-gateway-integration/,E-commerce,1910,9885
Email Services in Web Development,Lee MunroeJan 10 20170 commentsAn Introduction To Building And Sending HTML Email For Web Developers21 min readCoding HTML EmailsShare on Twitter LinkedInAbout The AuthorLee Munroe is Head of Design for OneSignal and creator of HTMLemailio based in San Francisco More about Lee Email NewsletterYour smashing email Weekly tips on frontend  UXTrusted by 200000 folks Smart Interface Design Patterns 9hvideo course Scalable CSS Masterclass with Andy Bell Watch Information Session to Learn More Smart Interface Design Patterns 9hvideo course Build layouts 10x faster UX Strategy Masterclass with Vitaly FriedmanEmail design and development is a beast Email client vendors havent been as progressive as web browser vendors in adopting new standards Not much has changed in email design In fact it has gotten worse With the introduction of mobile devices and more and more email clients we have even more caveats to deal with when building HTML email In this article Lee Munroe brings you an insight into the world of building and sending email and a couple of code snippets and resources that are sure to add some hours back into your lifeIve spent the past several years building development tools  two of those years as product design lead at Mailgun an email service for developers where I learned a lot about how email works and the problems that developers face when building HTML email In this post Ill share some of my knowledge about the topicHTML email Two words that when combined brings tears to a developers eyes If youre a web developer its inevitable that coding an email will be a task that gets dropped in your lap at some time in your career whether you like it or not Coding HTML email is old school Think back to 1999 when we called ourselves webmasters and used Frontpage WYSIWYG editors and tables to mark up our websitesNot much has changed in email design In fact it has gotten worse With the introduction of mobile devices and more and more email clients we have even more caveats to deal with when building HTML emailIve spent the past several years building development tools  two of those years as product design lead at Mailgun an email service for developers where I learned a lot about how email works and the problems that developers face when building HTML email In this post Ill share some of my knowledge about the topicMeet Image Optimization Addy Osmanis new practical guide to optimizing and delivering highquality images on the web Everything in one single 528pages bookJump to table of contents Introduction To Sending EmailAs a developer responsible for an email campaign or all of the emails your company sends you will need to know how email works the legal requirements and how to actually get email delivered Companies send a few different types of email Lets take a lookMarketing EmailA lot of email service providers ESPs specialize in marketing and promotional emails SendPulse Email Campaign Monitor MailChimp Emma Constant Contact to name just a few They provide full solutions for managing subscribers working with email templates running bulk email campaigns and reportingTransactional EmailTransactional email includes receipts alerts welcome emails password resets and so on and it is typically implemented with development tools and APIs such as SendPulse Transactional Mailgun SendGrid and Postmark These tools are more APIfocused less CMS and WYSIWYGbased however combined with a service such as Sendwithus they can be made even more powerfulAn alternative to using a service is to roll your own email server with something like Postfix The downside of this is that its up to you to set up and configure it and to understand the technical details of sending email implementing tracking and unsubscribing and getting email delivered to inboxesLifeCycle EmailLifecycle and behaviorbased email services help with onboarding engagement and more A lot of ESPs focused on marketing also offer this service but I tend to group services such as SendPulse Automation Intercom Customerio Drip Vero and ConvertKit into this categoryEmail List Best PracticesDont buy email lists Maybe a handful of legit services are out there but youre best off staying away from buying lists altogetherMy experience is that anyone who buys an email list will suffer from a lot of bounces give their Internet Protocol IP address a bad reputation and get their emails blocked by Internet service providers ISPs or sent to spam 85 of the worlds email is considered spam according to SenderBase dont fall into this bucketDouble OptInA subscriber having to verify their email address adds an extra step to the process but it makes sense and stops other people from abusing their email address by signing them up for lists without their permission It also helps to keep your subscription list clean and is the 100 correct way to validate an email addressCAN SPAMThese are your legal requirements for sending email enforced by the CANSPAM Act of 2003Dont use false or misleading header informationDont use deceptive subject linesIdentify the message as an adTell recipients where youre locatedTell recipients how to opt out of future email from youHonor optout requests promptlyMonitor what others are doing on your behalfMailChimp has a good list of email legal requirements by countryAnalytics And Measuring PerformanceMeasure everything You need to measure to know whether your emails are improving The numbers will differ vastly depending on what you do your industry the type of emails you send and the context However in general20 is a good open rate3 to 7 is a good clickthrough rate5 is a poor bounce rate001 is a poor spam rate1 is a poor unsubscribe rateAlso remember that open rates and clickthrough rates can be vanity metrics read they dont really matter At the end of the day what you really want to track is that end goal or conversion At Airbnb they track an email quality score which is a good indicator on engagement qualityGoogles URL builder can help with tracking if youre using Google AnalyticsSending Score And ReputationYour emails have a reputation and score associated with them This affects how ISPs and mailbox providers deal with your email whether they accept or reject it and whether they send it to the recipients inbox or straight to spamSome contributing factors areyour IP reputation check yours with SenderScoreyour domain name signature see DKIM and SPFbounce rates and complaint ratesSending Bulk EmailWhen you send a lot of emails imagine a campaign with millions of emails they are not all sent instantaneously They can only be sent as fast as the servers and IP addresses can handle them Keep in mind that your recipients might not receive the emails at exactly the same timeSo if youre sending millions of emails at once youll probably want quite a few IPs to handle the loadEmail ClientsLitmus keeps track of the market share of email clients based on its own internal statistics Keep in mind that this is probably not the same for your customer base but it is a good indicator to go byHere are the statistics as of December 2016iPhone 33Gmail 19iPad 12Android 8Apple Mail 7Bear in mind that not all emails can be tracked Email tracking is done via pixeltracking so only those clients with images enabled will report backHTML TemplatesBuilding HTML email templates can be a slog As a result a lot of poorly designed email is out there  clunky themed verbose pointless distracting If you enjoy a challenge or want a unique look and feel then building your own can actually be fun and rewarding Alternatively some good email templates are availableLitmus TemplatesReally Simple Responsive HTML Email TemplateHTML Email TemplatesBuilding HTML Email TemplatesNow you know how to properly set up and send emails The next decision youll make is whether to code your own HTML template This is a bit more complex than coding the average web page Lets dive inClientRendering EnginesEmail design is still in the dark ages Due to the numerous email clients and devices your email will get rendered for users in a variety of waysEmail clients use different engines to render HTML emailsApple Mail Outlook for Mac Android Mail and iOS Mail use WebKitOutlook 2000 2002 and 2003 use Internet ExplorerOutlook 2007 2010 and 2013 use Microsoft Word yes WordWeb clients use their browsers respective engine for example Safari uses WebKit and Chrome uses BlinkClients will also add their own flavor of styles on top of yours For example Gmail sets all td fonts to fontfamily ArialsansserifLook at your own statistics so that you know what to design forGmail Support For Inline CSS And Media QueriesOnly recently did Google announce support for embedded CSS and media queries in Gmail This is huge for the email development industryNow as of September 2016 Gmail will support a slew of CSS properties which makes template development for Gmail a lot easierUsing HTML Tables For LayoutDivs have positioning and boxmodel issues in different clients  in particular those that use Microsoft Word to render ie Outlook You can use divs if you want but its safer to code like its 1999 and stick to tables This meanstable instead of divFFFFFF instead of FFFpadding instead of marginCSS2 instead of CSS3HTML4 instead of HTML5backgroundcolor instead of backgroundHTML attributes instead of CSSinline CSS instead of style sheets or style blocksThese are best practices You could certainly ignore the safe route and go above and beyondWhen using tables dont forget border0 cellpadding0 cellspacing0 If youre using Premailer it has special CSS declarations for applying these HTML attributesInline CSSSome clients most notably Gmail until recently will strip any CSS that isnt inlined You have a couple of options herewrite CSS inline as you gouse a webbased CSS inlineruse a programmatic CSS inlinerlet your ESP handle the inlining for you if it supports itWriting inline as you go isnt exactly a scalable or maintainable solution so I tend not to recommend this but I know that a lot of email developers prefer this in order to maintain 100 control If you do write your CSS inline manually then I recommend making use of snippets andor a templating language with partials and helpers This will save you from having to repeat yourselfWebbased inliners include HTML Emails Responsive CSS Inliner and Foundation for Emails Responsive Email InlinerFor a programmatic inliner I recommend the Nodejs module Juice The Premailer gem and Roadie are good Ruby alternativesButtonsTrying to achieve the perfect crossclient button is painful As mentioned you should be using tables and table cells for pretty much everything including buttonsMy preference is to use the following solution Here is how you might normally style a button for the web a href classbtn btnprimaryClick Herea Instead write it like this table border0 cellpadding0 cellspacing0 classbtn btnprimary tr td aligncenter table border0 cellpadding0 cellspacing0 tr td a href target_blankTake action nowa td tr table td tr table Then once your CSS is inlined it will look like this table border0 cellpadding0 cellspacing0 classbtn btnprimary stylebordercollapse separate msotablelspace 0pt msotablerspace 0pt width 100 boxsizing borderbox minwidth 100 important width100 tr td aligncenter stylefontfamily sansserif fontsize 14px verticalalign top paddingbottom 15px valigntop table border0 cellpadding0 cellspacing0 stylebordercollapse separate msotablelspace 0pt msotablerspace 0pt width auto tr td stylefontfamily sansserif fontsize 14px verticalalign top backgroundcolor 3498db borderradius 5px textalign center valigntop bgcolor3498db aligncenter a href styledisplay inlineblock color ffffff backgroundcolor 3498db border solid 1px 3498db borderradius 5px boxsizing borderbox cursor pointer textdecoration none fontsize 14px fontweight bold margin 0 padding 12px 25px texttransform capitalize bordercolor 3498dbTake action nowa td tr table td tr table Whats going on here The first td is a wrapper to help us center the button The second td is the size of the button Some clients such as Outlook dont recognize the padding on the a tag so we fill in the background color of the table cell The a tag then takes up space available in the second td and the whole area becomes clickable Check out the code and client tests on LitmusThis is just one way to implement buttons in email Admittedly it doesnt always look identical in every client but the web is not always pixelperfect either I prefer this because its simpler and doesnt involve using image assets or VMLWhats VML If youve spent any time developing emails youve likely come across some reference to it Vector Markup Language VML is supported by old versions of Outlook According to Microsoft as of Internet Explorer IE 10 VML is obsolete which means that it is no longer supported in new versions of IE However as long as Outlook 2007 2010 and 2013 are around you will see it being used typically for background imagesTypographyIn general sticking with standard system fonts is easiest This includes Helvetica Arial and so on However we can use web fonts such as Google Fonts Put them behind a WebKit conditional media query so that Outlook doesnt mess them upstyle import urlhttpsfontsgoogleapiscomcssfamilyPacifico  Type styles for all clients  h1  fontfamily Helvetica Arial serif   Type styles for WebKit clients  media screen and webkitmindevicepixelratio0  h1  fontfamily Pacifico Helvetica Arial serif important   style Remember to include a font family font size and color for every td or else you risk the client overwriting your carefully chosen type stylesConditionalsWe can apply specific CSS styles and show or hide elements and content for different versions of OutlookThe following targets all Microsoft Wordbased versions of Outlookif mso Only Microsoft Wordbased versions of Outlook will see this endif This next snippet targets all IEbased versions of Outlookif IE Only IEbased versions of Outlook will see this endif We can also target specific version numbers of Outlookif mso 12 Only Outlook 2007 will see this endif We can target WebKitbased clients with a media queryspecialwebkitelement  display none  media screen and webkitmindevicepixelratio0  specialwebkitelement  display block important   Images And MediaImages In EmailSome clients will show images by default Some wont Keep this in mind when including images in your email content This also affects tracking metrics because images will typically be used to track opensOutlook blocks imagerendering by defaultApple Mail doesntGmail doesnt anymoreRemember to include good alt text for all of your images The text could either tell the user what the image says or just describe what it is for example company logo You can get creative with alt text for clients that turn off images as Email Monks doesRemember to include a basic reset for all images img srchttpswwwsmashingmagazinecomwpcontentuploads201611 alt width height border0 styleborder0 outlinenone textdecorationnone displayblock Animated GIFs are supported in most clients Outlook versions 2007 to 2013 do not support animated GIFs instead falling back to the first frameRemember to compress your media assets and upload them to a content delivery network CDN such as Amazon Web Services Cloudinary or imgix Most marketing ESPs will handle this for youScalable vector graphics SVGs have a lot of advantages on the web As you would expect email support varies and SVG requires a couple of fallback hacks or conditionals I typically recommend staying away from SVG in email but if you want to get serious about it then CSSTricks has a guide on SVG support in emailFor Retinaready images supply a larger image 15 to 3 and resize it Ill typically save a lowquality image that has 2 dimensions which works well Ive written more on this techniqueKeep in mind that for Outlook you need to declare how wide an image should be with the width attribute Otherwise Outlook might render the actual width of the image and break your emailVideo In EmailVideo is supported in iOS Apple Mail and Outlookcom You can use media queries to show or hide a video based on the client Email on Acid has more on email video supportFor inspiration check out Kevin Mandevilles tutorial on coding HTML5 video as a background in an email  impressive stuff and worth a lookForms In EmailSupport for form elements varies Try to steer clear and link to an external form if you need one Campaign Monitor offers some advice on formsObviously it depends on your objectives Staying away from forms is safer but Rebelmail and Mixmax have done interesting things with forms for surveys and ecommerce with good fallback supportGmail ActionsGoogle makes handy actions available for Gmail Youve probably seen them on GitHub for issues or on Amazon for ordersAdding the code is straightforward You have two optionsJSONLDmicrodataGetting whitelisted involves a few more steps You can test Gmail actions with an gmailcom addressPreheader TextSomething important but often forgotten is preheader text Some clients show preview text next to or under the subject line These clients include iOS Apple Mail Outlook 2013 Gmail and AOLClients will grab the first bit of text they find in your emails body and display it here Make the most of this and add a hidden element to your bodys content that appears first This text should provide an extra incentive for the user to open your email Hide the text like so span stylecolor transparent display none important height 0 maxheight 0 maxwidth 0 opacity 0 overflow hidden msohide all visibility hidden width 0Preheader text goes herespan Use Austin Woodalls subject and preheader tool to preview your email subjects and preheadersTesting EmailI dont think Ive ever sent an email successfully the first time There is always something to fix always a typo always a rendering issue in Outlook always something Ive forgotten to addYou can test your email in a few waysSend an email to yourself and check it on a desktop client Outlook a web client Gmail and a mobile client iOS MailAutomate tests using Litmus or Email on AcidProofread the content and check the layout rendersAB test various types of content lengths of content and subject linesHow do you send HTML emails to yourself Good question Its harder than you think PutsMail lets you do this quite easily and Thunderbird lets you compose with its HTML editorMIME MultiPartA plaintext email is just that plain text An HTML email is just HTML Most emails you send or receive are MIME Multipurpose Internet Mail Extensions multipart emails not to be confused with MIME type This standard combines both plain text and HTML leaving it up to the recipient to decide which to renderWhen you send an email whether transactional or bulk include both the HTML and plaintext versions Even if in your mind every one uses a client that renders HTML still send plain textAlso note that some clients render plaintext email as HTML for example Gmail will add some default styles and turn URLs into links Most ESPs will construct the MIME for you so you dont really need to worry about it Some will also create a plaintext version based on your HTMLPro tip In Gmail select Show original from the dropdown menu to see the full MIMEA new MIME part has surfaced textwatchhtml This content will only be displayed in Apple Watch and any other clients that support this MIME type going forwardAccessibilityOn the web if you follow standards and best practices and use semantic markup and valid HTML syntax you tend to get basic accessibility out of the box Unfortunately with email due to our excessive hacks and the poor support for HTML accessibility is often ignoredIve seen little discussion on email accessibility but one that stands out is Mark Robbins post on accessibility He recommends the followingAdd rolepresentation to each table so that its clear the table is being used for layoutProvide alt text with meaningful descriptionsIf you dont need or want alt text then use alt so that screen readers know it is meant to be blankUse semantic HTML tags such as p and h1 where applicableUse the role attribute for elements such as headers and footers for example roleheaderResponsive Email DesignEmail opens on mobile are at 50 and rising The exact metric depends on which report you check and which audience you cater to but I think we can all agree that this is importantEmail Client Market Share as of August 2016 puts iPhone at 33 iPad at 11 and Android at 10 thats over 50MailChimp found that unique clicks among mobile users for responsive campaigns rose from 27 to 31  a nearly 15 increaseResponsive web design is a phrase coined by Ethan Marcotte back in 2010By marrying fluid gridbased layouts and CSS3 media queries we can create one design that well responds to the shape of the display rendering itIn the email world we can still make use of fluid design gridbased layouts and media queries The problem is that not all clients support these Therefore we need some hacks along the wayUntil recently Gmail did not support media queries Thankfully as of September 2016 most of its clients do However several mobile clients still do not including Yahoo Windows Phone 8 and Gmail for AndroidSeveral techniques are used in the email world to get around a lack of support for media queries Some of the terms youll hear are fluid adaptive responsive hybrid and spongyFluidThe easiest solution is to stick to a single column and make your emails fluid This means that as the viewport shrinks your content area shrinkscontainer  maxwidth 600px width 100  Responsive And AdaptiveUsing media queries and breakpoints we can provide alternate styles for differentsized viewports We can also hide or show elementsThis starts to get complicated once you introduce a grid and columns You could have a twocolumn layout and then switch to a stacked onecolumn layout below a certain viewport widthBut as weve seen media queries arent supported everywhere so this isnt always reliableHybrid And SpongyThis technique uses a bit of fluid a bit of responsive and a couple of hacks for Outlook support We also get to ensure that the columns stack without media queriesThis technique is outlined by ActionRocket and Nicole Merlin has written a great stepbystep tutorial on itHere is a snippet of the code I use to build most of my emails if gte mso 9IE table alignleft border0 cellspacing0 cellpadding0 width100 tr td alignleft valigntop width50 endif div classspan3 styledisplay inlineblock Marginbottom 40px verticalalign top width 100 maxwidth 278pxdiv if gte mso 9IE td td alignleft valigntop width50 endif div classspan3 styledisplay inlineblock Marginbottom 40px verticalalign top width 100 maxwidth 278pxdiv if gte mso 9IE td tr table endif media only screen and maxwidth 620px  span3  maxwidth none important width 100 important  span3  table  maxwidth 100 important width 100 important   Take a look at Fabio Carneiros spongy opensource repository on GitHub and read Stigs take on coding mobilefirst emails Rémi Parmentier also has another responsive technique that doesnt need media queries and makes use of calc functionResponsive ImagesAs mentioned use Retina images at 15 to 3 and set image dimensions inline img srchttpswwwsmashingmagazinecomwpcontentuploads201611logopng height100 width600 altCompany Logo stylemaxwidth 100 We cant rely on maxwidth 100 because some clients ignore it You will also want to embed the following CSS media only screen and maxwidth 620px  img  height auto important maxwidth 100 important width auto important   Automating Your WorkflowThe process of putting together a bulletproof email is complex There are a lot of steps and there is room for a lot of things to go wrongLike any monotonous task with steps I recommend automating what you can so that you build the system once and make it easier for future workBrian Graves has a good post on making your email modular Just as you have a design system and pattern library for a website or application you should do so for email making components reusable and emails consistent across your product and companyKevin Mandeville recommends using snippets of reusable code to optimize your workflow so that youre not constantly rewriting code In his post he outlines how to use snippets in modern editors such as Atom and Sublime and he points to the communitycontributed library of snippets hosted by LitmusFor my own part Ive put together and opensourced a Grunt workflow for automating email builds It runs various tasks such as inlining CSS compressing images uploading images to a CDN sending a preview and testing with Litmus all with one command If youre new to Grunt Ive written a detailed tutorial on how it works Foundation for Email also has some great automation tools for developers as does Mailjet with its responsive email framework MJMLLooking To The FutureGoogle just recently rolled out support for media queries Microsoft has just partnered with Litmus to make email better and AOLs Alto now supports responsive email So the future is looking much brighterMore and more companies and developers are experimenting with whats possible with email technology CSS animation audio shopping carts in email Expect more instances of interactive and kinetic email emerge in 2017ConclusionEmail design and development is a beast It is a lot like building a web page 10 years ago Email client vendors havent been as progressive as web browser vendors in adopting new standards and we users and companies dont adopt new email clients like we do with web browsers Add to that the rise of mobile and were left in this state of having to support a convoluted mix of clients and versionsMy introduction here is a highlevel overview you could dive deep into every one of these points Hopefully its given you good insight into the world of building and sending email and the code snippets and resources have added some hours back to your lifeRecommended ResourcesReally Simple Responsive HTML Email Template Lee Munroe my free opensource email templateProfessional Email Design Jason RodriguezUnmasking HTML Emails course Dan Denney Code SchoolThe Best Email Designs in the Universe That Came Into My Inbox Really Good EmailsDynamic and Interactive Kinetic Email Examples and Techniques Justin KhooBlogs To FollowCampaign MonitorMailChimpLitmusEmail on AcidFurther ReadingDesign And Build Email Newsletters Without Losing Your Mind18 Email Templates For Web Designers And DevelopersMaking Responsive HTML Email Coding Easy With MJMLHow To Improve Your Email Workflow With Modular Design il vf al mrnExplore more onCodingHTMLEmailsSmashing NewsletterTips on frontend  UX delivered weekly in your inbox Just the things you can actually useFrontEnd  UX Workshops OnlineWith practical takeaways live sessions video recordings and a friendly QATypeScript in 50 LessonsEverything TypeScript with code walkthroughs and examples And other printed books SMART INTERFACE DESIGN PATTERNS  with K VITALY FRIEDMAN VIDEO COURSE  LIVE UX TRAINING Scalable CSS Masterclass Andy Bell  BUILD YOUF SMART INTERFACE DESIGN PATTERNS  with K VITALY FRIEDMAN VIDEO COURSE  LIVE UX TRAINING vom ES Gey drag  dvop Vilder UX Strategy Masterclass Vitaly Friedman o  fe  Jan 23  Feb 6  Image Optimization by Addy Osmani State Of JavaScript Plato Contirm Subscription uy yours hone get alo mow Sender Score Metrics for sendleemunroecom Sending Domain information BZ mxrecord  BH SSL Certificate  spr Record  Recent Campaigns Subject Line Date From Domain inbox Spam  vesgn esti ow vonone sendteemunroecom coasts fot supports media queries etais SencingPs Q Hostname Volume   Senderscore  mamsez 7 Veytow 98 us aby brain ty tno Poot Se sri atte ety fates etc ai an ipa Sheree sp ters at Soa re to sr aaa LEPEtiitatert yer vcs il es Mat  ats me 83 pag o Ciaty motae sy defn hts un p pean fxs san liens il sho a tants preva colle tree ster ieee write atts mente ice iy motbternces ts oan et upp yc sy tcc ae nrc on gfe stg sgaewa yetonar ant areas aay accuse everett ado by bags Hf are rain Sot ae  Si came serotype EAMG clgeionee cleo syintoraeclien spats sebeipoens noone Happy Easier HAPPY EASTER happiness at Easter and always app 28 at Eastor and always lover enetwostonpemate or 82 10 Pi ema Srecty o view ton Gt hepighuhcomiemoniteratwontowtaney  inte Leotenetwoo Pec ty tuned i thn eh owe bang ema amen onanttn 135 070 eral ny ven LONG enmaceniemneitenalncnt Aer Ra oe   ry iE  ER Headers Body Part 1 textplain Part 2 texthtml _configsess globalscss eee ih _linkssess oj othersess typesess Le  Bemaits  confirm hbs   transactionhbs YB layouts vn vari defaulthbs transactionhtml confirm htm confirmhtml   Ss TYPESCRIPT LESSONS STEFAN BAUMGARTNER a href classbtn btnprimaryClick Herea table border0 cellpadding0 cellspacing0 classbtn btnprimary tr td aligncenter table border0 cellpadding0 cellspacing0 tr td a href target_blankTake action nowa td tr table td tr table table border0 cellpadding0 cellspacing0 classbtn btnprimary stylebordercollapse separate msotablelspace 0pt msotablerspace 0pt width 100 boxsizing borderbox minwidth 100 important width100 tr td aligncenter stylefontfamily sansserif fontsize 14px verticalalign top paddingbottom 15px valigntop table border0 cellpadding0 cellspacing0 stylebordercollapse separate msotablelspace 0pt msotablerspace 0pt width auto tr td stylefontfamily sansserif fontsize 14px verticalalign top backgroundcolor 3498db borderradius 5px textalign center valigntop bgcolor3498db aligncenter a href styledisplay inlineblock color ffffff backgroundcolor 3498db border solid 1px 3498db borderradius 5px boxsizing borderbox cursor pointer textdecoration none fontsize 14px fontweight bold margin 0 padding 12px 25px texttransform capitalize bordercolor 3498dbTake action nowa td tr table td tr table style import urlhttpsfontsgoogleapiscomcssfamilyPacifico  Type styles for all clients  h1  fontfamily Helvetica Arial serif   Type styles for WebKit clients  media screen and webkitmindevicepixelratio0  h1  fontfamily Pacifico Helvetica Arial serif important   style if mso Only Microsoft Wordbased versions of Outlook will see this endif if IE Only IEbased versions of Outlook will see this endif if mso 12 Only Outlook 2007 will see this endif specialwebkitelement  display none  media screen and webkitmindevicepixelratio0  specialwebkitelement  display block important   img srchttpswwwsmashingmagazinecomwpcontentuploads201611 alt width height border0 styleborder0 outlinenone textdecorationnone displayblock span stylecolor transparent display none important height 0 maxheight 0 maxwidth 0 opacity 0 overflow hidden msohide all visibility hidden width 0Preheader text goes herespan container  maxwidth 600px width 100  if gte mso 9IE table alignleft border0 cellspacing0 cellpadding0 width100 tr td alignleft valigntop width50 endif div classspan3 styledisplay inlineblock Marginbottom 40px verticalalign top width 100 maxwidth 278pxdiv if gte mso 9IE td td alignleft valigntop width50 endif div classspan3 styledisplay inlineblock Marginbottom 40px verticalalign top width 100 maxwidth 278pxdiv if gte mso 9IE td tr table endif media only screen and maxwidth 620px  span3  maxwidth none important width 100 important  span3  table  maxwidth 100 important width 100 important   img srchttpswwwsmashingmagazinecomwpcontentuploads201611logopng height100 width600 altCompany Logo stylemaxwidth 100 media only screen and maxwidth 620px  img  height auto important maxwidth 100 important width auto important   ,https://www.smashingmagazine.com/2017/01/introduction-building-sending-html-email-for-web-developers/,Marketing,1743,4994
Social Media Integration, Strategy 12 Winning Social Media Integration Strategies for 2024 Social media integration gives your audience more ways to engage and interact with your brand Get the tips and tools to do it right Michelle Martin October 30 2023 Table of Contents What does social media integration mean 7 examples of social media integration Social media integration with Hootsuite Synergy disruption omnichannel The three prongs of every mid2000s marketing plan Were more evolved now right In 2023 social media integration goes beyond buzzwords and is the fundamental piece of every successful digital marketing strategy Socialled brands continue to build more loyalty and attract more new customers and followers than brands marketing the traditional way With you know synergy Heres how to use social media integration station to become a truly socialfirst marketer 1 Social Media Tool Create Schedule Publish Engage Measure Win Free 30Day Trial What does social media integration mean Social media integration is the practice of using social media not just as another spoke in your marketing strategy but as the foundation Integration goes beyond posting social media content Social media integration incorporates your social channels into every part of your campaigns using smart tools to keep everything connected automated and measurable A few common places for social media integration are Website Email marketing campaigns CRM software Ecommerce software Customer service software Bonus Read the stepbystep social media strategy guide with pro tips on how to grow your social media presence 7 examples of social media integration 1 Including social share buttons on your blog You see these everywhere  theyre a staple on most websites Share buttons make it easy for readers to share your content with a single click Everyone should use them period Most people place these social sharing links at either the top or bottom of an article or both or have buttons along the side that follow as you scroll down the page How to add sharing buttons depends on the platform your website is built on Popular WordPress plugins to add sharing functions include SocialSnap Shareaholic Social Share Button As a bonus improve your analytics tracking accuracy by attaching UTM parameters to your share buttons That way you can more accurately track where new visitors are coming from and how they found you 2 Using UGC as social proof on your website Usergenerated content UGC is powerful on social networks but dont overlook your website as a place to feature it as social proof too An obvious use case is on product pages to encourage sales by featuring reallife people using your products This builds trust as people know its not a commercial you filmed its real people sharing their experience UGC can also show the versatility of your product or how people use it in different ways GoPro features clips from many different creators on their product page to showcase different features Source GoPro 3 Embedding social posts on your website Adding social media posts to your website is a versatile way to add social proof Screenshot comments people leave on your social posts or embed entire posts with testimonials A popular option is to embed an automatic post feed somewhere on your site usually in the footer and usually with Instagram since its a visual platform You can set it up to show all posts using your branded hashtag and many post feed apps allow you to manually approve which posts appear on your website protecting you from potential spam Adding an Instagram or other platform feed to your site depends on your websites software but popular WordPress plugins include Easy Social Feed Smash Balloon Spotlight Source Fabletics You can also take screenshots of social media comments or posts and put them on product or services pages as another form of social trust Fitbit puts a unique spin on this with a dedicated Fitbit in the Wild section compiling social media posts of celebrities wearing their products Source Fitbit Lastly add visual interest to your blog posts by embedding entire social media posts as examples for the things youre talking about like this View this post on Instagram A post shared by Hootsuite  hootsuite Source Hootsuite on Instagram 4 Automating product sharing with ecommerce integrations Most ecommerce platforms offer social media automations aka a way to easily share your products to your social accounts Ill cover a super easy way to automatically share Shopify WooCommerce or Magento products with Hootsuite later in this article Even if your ecommerce platform doesnt have an automatic way to do this remember to share your products on social manually Not enough to spam people but enough to showcase new stuff promote sales and ensure everyone knows what youre selling Many platforms also automatically sync your products with social selling tools like Facebook and Instagram Shops Source Bootlegger on Facebook 5 Building a social community Most brand social media profiles serve as broadcast channels Look at this new product Shop this sale Essentially businesses use social to tell people about their stuff You gotta do some level of selfpromotion as a business but you can also use your social profiles to build a real community Encourage customers and fans to interact with each other in the comments section Encourage them to jump in and help each other if they know the answer to a question Spark conversations Or take it even further and create a private social community as a subset of your public channels like a Discord server private subreddit or Facebook Group Source Stahls on Facebook Offer this group something special like great educational content the opportunity to provide input into new products or exclusive contests or discounts Treat this private group like your VIP section and the reward will be a highly loyal group of customers who will be excellent brand ambassadors both on and offline 6 Running cohesive campaigns This is fairly standard advice by now but social media should be integrated into every part of your marketing campaigns Not just new launches or sales It should be connected to every other part of your content strategy New blog post Shout it on social Instore or online event Promote it on social Newsletter just went out Encourage signups on social You get the idea Talk about everything youre doing on social Your social channels become the common point between all these campaign touchpoints tying everything together and either introducing your audience to the campaign or reinforcing messaging theyve already seen in your newsletter or on your website Like this post where we share a statistic from our free 2023 Social Media Career Report View this post on Instagram A post shared by Hootsuite  hootsuite Source Hootsuite on Instagram 7 Make customer service social Social media has a lot more to do with customer service than it seems at first 52 of customers expect a brand to reply to their customer service inquiry on social media within one hour Source Statista Not paying attention to or not responding to these messages can damage your brand reputation with not only that customer but also others who see it go unanswered Some brands set up separate social media accounts for customer service issues like Nike Source NikeService on X Twitter While others reply to inquiries from their main brand account Source Glossier on TikTok How do you ensure you see and reply to every message or comment that needs a reply Even with thousands of incoming messages across multiple social media platforms Hootsuite Inbox helps you bridge the gap between social media engagement and customer service  and manage all of your social media messages in one place You can handle messages as a team with intuitive message queues task assignments statuses and filters Everyone can see whats been replied to and what needs a reply at a glance right inside their Hootsuite dashboard Try for free In fact there are plenty of ways to integrate your social media with Hootsuite Social media integration with Hootsuite Hootsuite isnt only a social media content scheduler and publisher it also integrates with all your favorite tools to make social media management fast and dare I say fun Use AI to grow faster on social media OwlyWriter AI helps you write social media captions in seconds suggests post ideas and creates variations of your existing posts so you can schedule more content in less time And its included with all Hootsuite plans Praise the robots Hootsuite also integrates with many other AI content production apps including Lately AI for effortless repurposing DallE for graphic creation Engage AI for LinkedIn comments and more Want the best bang for your AI bucks Check out the top 10 AI content creation tools you should be using in 2023 Content planning and scheduling Of course you already know Hootsuite makes planning and scheduling social media content across all your accounts easy Besides one place to manage all your social media Hootsuite Composer includes Personalized best time to post suggestions based on when your target audience is online Canva integration for instant graphic creation with free templates AIpowered copy ideas and hashtag suggestions Hootsuite Planner displays your scheduled and already published content across all your accounts in one place or you can narrow it down per account with filters It even pulls in content published outside of Hootsuite so you always know whats out there and whats scheduled to go out at a glance Claim free 30day trial From personal experience this is one of my favorite parts about using Hootsuite It doesnt seem like a showstopping feature  seeing posts across platforms on a calendar  but theres truly nothing else like it where you can see everything across different platforms together in one weekly or monthly view For my visuallearning brain its essential for proper campaign planning Mailchimp social media integration Hootsuite directly integrates with Mailchimp one of the worlds top email marketing platforms With the free Mailchimp social media integration in the Hootsuite app directory you can keep an eye on your list growth and campaign performance right from your Hootsuite dashboard You can also share campaigns as new posts to schedule across your networks and look up performance analytics percampaign or persubscriber from Hootsuite Streams Its a must have if you use Mailchimp for email marketing Salesforce social media integration Live that one browser tab lifestyle using Hootsuites free Salesforce social media integration and see all your Salesforce leads opportunities accounts cases and contacts from inside Hootsuite You can add users as leads or contacts right from Hootsuite Streams Clicking Send to Salesforce will search that username to find either your existing record or allow you to create a new one see contacts at that company and more Work smarter not harder with the dynamic duo of Salesforce and Hootsuite together Source Salesforce social media integration user guide Shopify social media integration Ecommerce social media planning has never been easier With the free Hootsuite Shopify social media integration app share products from your Hootsuite dashboard reply to comments and DMs with product links and even edit and markup product images before scheduling and publishing your content Its your full Shopify catalog searchable and easily shareable all right inside Hootsuite Source Shopify social media integration docs The Shopview social media integration also connects WooCommerce and Magento ecommerce platforms with Hootsuite Managing your businesss social media presence is easy with Hootsuite From a single dashboard you can publish and schedule social media content find relevant conversions engage the audience measure results and more Try it free today Get Started Do it better with Hootsuite the allinone social media tool Stay on top of things grow and beat the competition Free 30Day Trial Social media strategy Become a better social marketer Get expert social media advice delivered straight to your inbox Email address Sign up By Michelle Martin As an exagency strategist turned freelance WFH fashion icon Michelle is passionate about putting the sass in SaaS content Shes known for quickly understanding and distilling complicated technical topics into conversational copy that gets results She has written for Fortune 500 companies and startups and her clients have earned features in Forbes Strategy Magazine and Entrepreneur Read more by Michelle Martin Related Articles Strategy What Is Social Media Marketing Complete 2024 Guide This complete guide will help you get started with social media marketing and follow the right best practices from day one January 4 2023 Strategy How to Create a Social Media Marketing Strategy in 9 Easy Steps Free Template Creating your social media marketing strategy doesnt need to be painful Create an effective plan for your business in 9 simple steps October 18 2022 Strategy 15 Digital Marketing Tools for Every Team and Budget in 2023 The right tools can make your job a lot easier Weve got 15 essential digital marketing tools for teams and budgets of all sizes January 10 2023 Strategy Social Media Marketing Tools The Complete Guide Automate your work save time and build better relationships with your audience by using the right social media marketing tools February 28 2023 Show Comments Hide Comments Calendar Content Account Vv Date v effje   Mon Tues Wed Thurs  Hootsuite OHootsuite  Hootsuite  Hootsuite 100PM 100PM 100PM 100PM LF  Ly  O Hootsuite  Hootsuite  Hootsuite  Hootsuite 200PM 200PM 200PM 200PM Ld a a  90000000 Social media scheduling Social media strategy GQ of w in New TimeCode Syne FABLETICS ON YOU MYFABLETICS ember wh wore thee sys FITBIT IN THE WILD CELEBRITY SOCIAL POSTS ston Fete spate meng ts HR thle camotnghe es Gore Get sinner soe pon com pie Sutton Foster Halsey Chloe Conwelt CELEBRITY SIGHTINGS Gwyneth Paltrow spotted wearing Alta HR out and about 47 59 United States  Global average wo Nike Service  NikeService Athletes helping athletes 7 days a week Languages supported English Spanish and French  Beaverton Oregon J Joined April 2008 514 Following 2027K Followers  Followed by Tiffany H MEd MBA and Lenny Goh Posts Replies Media Likes  Nathan Stevens stevens90626  th  oe hey Nike  ordered these Nike invincible run 3s they fell apart after a few months Ive sent them back to you Ive now been without my running shoes for 6 weeks and I havent heard anything This is terrible customer service  wont be buying anymore shoes from you 01 ua iv i 3 a Nike Service  NikeService  41m Hey Nathan Could you meet us in DM with your Nike Member email along with the order number for those Well take a closer look into this for you  ua 9 dS a lear Profiles D twitter Schedule post itimage aicattort 11009 setectfiestouplond __ srowse yourmedia S20 pm 3 Fe sutzsacszcoonn x  Poatnow e Malichimp   ndaseeam  surscrbertitsnacioe Merona  comosigneneciee Germ te ignore tan mop tein tae tenin  Hostsuite ohootsuite  Add tag  40 mins ago 81 of shoppers research products on Q Send to HipChat Instagram and Facebook L Y Send to JIRA Service Desk Q Send to HipChat Beta Shopview Select Shop serenature Template Default Keyword Made from three varieties of sacred holy asl this tea blend will help you reduce stress and keep your in a calm state of mind Organic Mint Tea Bl eegrua Y Dominos MELIA con SXSW ,https://blog.hootsuite.com/social-media-integration-for-your-website/,Social Media,1016,2527
Web Scraping Techniques," From Wikipedia the free encyclopedia For broader coverage of this topic see Data scraping Data scraping used for extracting data from websites Web scraper redirects here For websites that scrape content see Scraper site This article needs additional citations for verification Please help improve this article by adding citations to reliable sources Unsourced material may be challenged and removedFind sources Web scraping  news  newspapers  books  scholar  JSTOR April 2023 Learn how and when to remove this template message Web scraping web harvesting or web data extraction is data scraping used for extracting data from websites1 Web scraping software may directly access the World Wide Web using the Hypertext Transfer Protocol or a web browser While web scraping can be done manually by a software user the term typically refers to automated processes implemented using a bot or web crawler It is a form of copying in which specific data is gathered and copied from the web typically into a central local database or spreadsheet for later retrieval or analysis Scraping a web page involves fetching it and extracting from it Fetching is the downloading of a page which a browser does when a user views a page Therefore web crawling is a main component of web scraping to fetch pages for later processing Once fetched extraction can take place The content of a page may be parsed searched and reformatted and its data copied into a spreadsheet or loaded into a database Web scrapers typically take something out of a page to make use of it for another purpose somewhere else An example would be finding and copying names and telephone numbers companies and their URLs or email addresses to a list contact scraping As well as contact scraping web scraping is used as a component of applications used for web indexing web mining and data mining online price change monitoring and price comparison product review scraping to watch the competition gathering real estate listings weather data monitoring website change detection research tracking online presence and reputation web mashup and web data integration Web pages are built using textbased markup languages HTML and XHTML and frequently contain a wealth of useful data in text form However most web pages are designed for human endusers and not for ease of automated use As a result specialized tools and software have been developed to facilitate the scraping of web pages Newer forms of web scraping involve monitoring data feeds from web servers For example JSON is commonly used as a transport mechanism between the client and the web server There are methods that some websites use to prevent web scraping such as detecting and disallowing bots from crawling viewing their pages In response there are web scraping systems that rely on using techniques in DOM parsing computer vision and natural language processing to simulate human browsing to enable gathering web page content for offline parsing Historyedit This section does not cite any sources Please help improve this section by adding citations to reliable sources Unsourced material may be challenged and removed October 2018 Learn how and when to remove this template message The history of web scraping dates back nearly to the time when the World Wide Web was born After the birth of the World Wide Web in 1989 the first web robot2 World Wide Web Wanderer was created in June 1993 which was intended only to measure the size of the web In December 1993 the first crawlerbased web search engine JumpStation was launched As there were fewer websites available on the web search engines at that time used to rely on human administrators to collect and format links In comparison JumpStation was the first WWW search engine to rely on a web robot In 2000 the first Web API and API crawler were created An API Application Programming Interface is an interface that makes it much easier to develop a program by providing the building blocks In 2000 Salesforce and eBay launched their own API with which programmers could access and download some of the data available to the public Since then many websites offer web APIs for people to access their public database Techniquesedit Web scraping is the process of automatically mining data or collecting information from the World Wide Web It is a field with active developments sharing a common goal with the semantic web vision an ambitious initiative that still requires breakthroughs in text processing semantic understanding artificial intelligence and humancomputer interactions Human copyandpasteedit The simplest form of web scraping is manually copying and pasting data from a web page into a text file or spreadsheet Sometimes even the best webscraping technology cannot replace a humans manual examination and copyandpaste and sometimes this may be the only workable solution when the websites for scraping explicitly set up barriers to prevent machine automation Text pattern matchingedit A simple yet powerful approach to extract information from web pages can be based on the UNIX grep command or regular expressionmatching facilities of programming languages for instance Perl or Python HTTP programmingedit Static and dynamic web pages can be retrieved by posting HTTP requests to the remote web server using socket programming HTML parsingedit Many websites have large collections of pages generated dynamically from an underlying structured source like a database Data of the same category are typically encoded into similar pages by a common script or template In data mining a program that detects such templates in a particular information source extracts its content and translates it into a relational form is called a wrapper Wrapper generation algorithms assume that input pages of a wrapper induction system conform to a common template and that they can be easily identified in terms of a URL common scheme3 Moreover some semistructured data query languages such as XQuery and the HTQL can be used to parse HTML pages and to retrieve and transform page content DOM parsingedit Further information Document Object Model By embedding a fullfledged web browser such as the Internet Explorer or the Mozilla browser control programs can retrieve the dynamic content generated by clientside scripts These browser controls also parse web pages into a DOM tree based on which programs can retrieve parts of the pages Languages such as Xpath can be used to parse the resulting DOM tree Vertical aggregationedit There are several companies that have developed vertical specific harvesting platforms These platforms create and monitor a multitude of bots for specific verticals with no man in the loop no direct human involvement and no work related to a specific target site The preparation involves establishing the knowledge base for the entire vertical and then the platform creates the bots automatically The platforms robustness is measured by the quality of the information it retrieves usually number of fields and its scalability how quick it can scale up to hundreds or thousands of sites This scalability is mostly used to target the Long Tail of sites that common aggregators find complicated or too laborintensive to harvest content from Semantic annotation recognizingedit The pages being scraped may embrace metadata or semantic markups and annotations which can be used to locate specific data snippets If the annotations are embedded in the pages as Microformat does this technique can be viewed as a special case of DOM parsing In another case the annotations organized into a semantic layer4 are stored and managed separately from the web pages so the scrapers can retrieve data schema and instructions from this layer before scraping the pages Computer vision webpage analysisedit There are efforts using machine learning and computer vision that attempt to identify and extract information from web pages by interpreting pages visually as a human being might5 Softwareedit There are many software tools available that can be used to customize webscraping solutions This software may attempt to automatically recognize the data structure of a page or provide a recording interface that removes the necessity to manually write webscraping code or some scripting functions that can be used to extract and transform content and database interfaces that can store the scraped data in local databases Some web scraping software can also be used to extract data from an API directly Legal issuesedit The examples and perspective in this section deal primarily with the United States and do not represent a worldwide view of the subject You may improve this section discuss the issue on the talk page or create a new section as appropriate October 2015 Learn how and when to remove this template message The legality of web scraping varies across the world In general web scraping may be against the terms of service of some websites but the enforceability of these terms is unclear6 United Statesedit In the United States website owners can use three major legal claims to prevent undesired web scraping 1 copyright infringement compilation 2 violation of the Computer Fraud and Abuse Act CFAA and 3 trespass to chattel7 However the effectiveness of these claims relies upon meeting various criteria and the case law is still evolving For example with regard to copyright while outright duplication of original expression will in many cases be illegal in the United States the courts ruled in Feist Publications v Rural Telephone Service that duplication of facts is allowable US courts have acknowledged that users of scrapers or robots may be held liable for committing trespass to chattels89 which involves a computer system itself being considered personal property upon which the user of a scraper is trespassing The best known of these cases eBay v Bidders Edge resulted in an injunction ordering Bidders Edge to stop accessing collecting and indexing auctions from the eBay web site This case involved automatic placing of bids known as auction sniping However in order to succeed on a claim of trespass to chattels the plaintiff must demonstrate that the defendant intentionally and without authorization interfered with the plaintiffs possessory interest in the computer system and that the defendants unauthorized use caused damage to the plaintiff Not all cases of web spidering brought before the courts have been considered trespass to chattels10 One of the first major tests of screen scraping involved American Airlines AA and a firm called FareChase11 AA successfully obtained an injunction from a Texas trial court stopping FareChase from selling software that enables users to compare online fares if the software also searches AAs website The airline argued that FareChases websearch software trespassed on AAs servers when it collected the publicly available data FareChase filed an appeal in March 2003 By June FareChase and AA agreed to settle and the appeal was dropped12 Southwest Airlines has also challenged screenscraping practices and has involved both FareChase and another firm Outtask in a legal claim Southwest Airlines charged that the screenscraping is Illegal since it is an example of Computer Fraud and Abuse and has led to Damage and Loss and Unauthorized Access of Southwests site It also constitutes Interference with Business Relations Trespass and Harmful Access by Computer They also claimed that screenscraping constitutes what is legally known as Misappropriation and Unjust Enrichment as well as being a breach of the web sites user agreement Outtask denied all these claims claiming that the prevailing law in this case should be US Copyright law and that under copyright the pieces of information being scraped would not be subject to copyright protection Although the cases were never resolved in the Supreme Court of the United States FareChase was eventually shuttered by parent company Yahoo and Outtask was purchased by travel expense company Concur13 In 2012 a startup called 3Taps scraped classified housing ads from Craigslist Craigslist sent 3Taps a ceaseanddesist letter and blocked their IP addresses and later sued in Craigslist v 3Taps The court held that the ceaseanddesist letter and IP blocking was sufficient for Craigslist to properly claim that 3Taps had violated the Computer Fraud and Abuse Act Although these are early scraping decisions and the theories of liability are not uniform it is difficult to ignore a pattern emerging that the courts are prepared to protect proprietary content on commercial sites from uses which are undesirable to the owners of such sites However the degree of protection for such content is not settled and will depend on the type of access made by the scraper the amount of information accessed and copied the degree to which the access adversely affects the site owners system and the types and manner of prohibitions on such conduct14 While the law in this area becomes more settled entities contemplating using scraping programs to access a public web site should also consider whether such action is authorized by reviewing the terms of use and other terms or notices posted on or made available through the site In a 2010 ruling in the Cvent Inc v Eventbrite Inc In the United States district court for the eastern district of Virginia the court ruled that the terms of use should be brought to the users attention In order for a browse wrap contract or license to be enforced15 In a 2014 case filed in the United States District Court for the Eastern District of Pennsylvania16 ecommerce site QVC objected to the Pinterestlike shopping aggregator Resultlys scraping of QVCs site for realtime pricing data QVC alleges that Resultly excessively crawled QVCs retail site allegedly sending 200300 search requests to QVCs website per minute sometimes to up to 36000 requests per minute which caused QVCs site to crash for two days resulting in lost sales for QVC17 QVCs complaint alleges that the defendant disguised its web crawler to mask its source IP address and thus prevented QVC from quickly repairing the problem This is a particularly interesting scraping case because QVC is seeking damages for the unavailability of their website which QVC claims was caused by Resultly In the plaintiffs web site during the period of this trial the terms of use link are displayed among all the links of the site at the bottom of the page as most sites on the internet This ruling contradicts the Irish ruling described below The court also rejected the plaintiffs argument that the browsewrap restrictions were enforceable in view of Virginias adoption of the Uniform Computer Information Transactions Act UCITAa uniform law that many believed was in favor on common browsewrap contracting practices18 In Facebook Inc v Power Ventures Inc a district court ruled in 2012 that Power Ventures could not scrape Facebook pages on behalf of a Facebook user The case is on appeal and the Electronic Frontier Foundation filed a brief in 2015 asking that it be overturned1920 In Associated Press v Meltwater US Holdings Inc a court in the US held Meltwater liable for scraping and republishing news information from the Associated Press but a court in the United Kingdom held in favor of Meltwater Internet Archive collects and distributes a significant number of publicly available web pages without being considered to be in violation of copyright lawscitation needed European Unionedit In February 2006 the Danish Maritime and Commercial Court Copenhagen ruled that systematic crawling indexing and deep linking by portal site ofirdk of real estate site Homedk does not conflict with Danish law or the database directive of the European Union21 In a February 2010 case complicated by matters of jurisdiction Irelands High Court delivered a verdict that illustrates the inchoate state of developing case law In the case of Ryanair Ltd v Billigfluegede GmbH Irelands High Court ruled Ryanairs clickwrap agreement to be legally binding In contrast to the findings of the United States District Court Eastern District of Virginia and those of the Danish Maritime and Commercial Court Justice Michael Hanna ruled that the hyperlink to Ryanairs terms and conditions was plainly visible and that placing the onus on the user to agree to terms and conditions in order to gain access to online services is sufficient to comprise a contractual relationship22 The decision is under appeal in Irelands Supreme Court23 On April 30 2020 the French Data Protection Authority CNIL released new guidelines on web scraping24 The CNIL guidelines made it clear that publicly available data is still personal data and cannot be repurposed without the knowledge of the person to whom that data belongs25 Australiaedit In Australia the Spam Act 2003 outlaws some forms of web harvesting although this only applies to email addresses2627 Indiaedit Leaving a few cases dealing with IPR infringement Indian courts have not expressly ruled on the legality of web scraping However since all common forms of electronic contracts are enforceable in India violating the terms of use prohibiting data scraping will be a violation of the contract law It will also violate the Information Technology Act 2000 which penalizes unauthorized access to a computer resource or extracting data from a computer resource Methods to prevent web scrapingedit The administrator of a website can use various measures to stop or slow a bot Some techniques include Blocking an IP address either manually or based on criteria such as geolocation and DNSRBL This will also block all browsing from that address Disabling any web service API that the websites system might expose Bots sometimes declare who they are using user agent strings and can be blocked on that basis using robotstxt googlebot is an example Other bots make no distinction between themselves and a human using a browser Bots can be blocked by monitoring excess traffic Bots can sometimes be blocked with tools to verify that it is a real person accessing the site like a CAPTCHA Bots are sometimes coded to explicitly break specific CAPTCHA patterns or may employ thirdparty services that utilize human labor to read and respond in realtime to CAPTCHA challenges Commercial antibot services Companies offer antibot and antiscraping services for websites A few web application firewalls have limited bot detection capabilities as well However many such solutions are not very effective28 Locating bots with a honeypot or other method to identify the IP addresses of automated crawlers Obfuscation using CSS sprites to display such data as telephone numbers or email addresses at the cost of accessibility to screen reader users Because bots rely on consistency in the frontend code of a target website adding small variations to the HTMLCSS surrounding important data and navigation elements would require more human involvement in the initial set up of a bot and if done effectively may render the target website too difficult to scrape due to the diminished ability to automate the scraping process Websites can declare if crawling is allowed or not in the robotstxt file and allow partial access limit the crawl rate specify the optimal time to crawl and more See alsoedit Archivetoday Comparison of feed aggregators Data scraping Data wrangling Importer Job wrapping Knowledge extraction OpenSocial Scraper site Fake news website Blog scraping Spamdexing Domain name drop list Text corpus Web archiving Web crawler Offline reader Link farm blog network Search engine scraping Web crawlers Referencesedit  Thapelo Tsaone Swaabow Namoshe Molaletsa Matsebe Oduetse Motshegwa Tshiamo Bopape MaryJane Morongwa 20210728 SASSCAL WebSAPI A Web Scraping Application Programming Interface to Support Access to SASSCALs Weather Data Data Science Journal 20 24 doi105334dsj2021024 ISSN 16831470 S2CID 237719804  Search Engine Historycom Search Engine History Retrieved November 26 2019  Song Ruihua Microsoft Research Sep 14 2007 Joint optimization of wrapper generation and template detection PDF Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining p 894 doi10114512811921281287 ISBN 9781595936097 S2CID 833565 Archived from the original PDF on October 11 2016  Semantic annotation based web scraping  Roush Wade 20120725 Diffbot Is Using Computer Vision to Reinvent the Semantic Web wwwxconomycom Retrieved 20130315  FAQ about linking  Are website terms of use binding contracts wwwchillingeffectsorg 20070820 Archived from the original on 20020308 Retrieved 20070820  Kenneth Hirschey Jeffrey 20140101 Symbiotic Relationships Pragmatic Acceptance of Data Scraping Berkeley Technology Law Journal 29 4 doi1015779Z38B39B ISSN 10863818cite journal CS1 maint multiple names authors list link  Internet Law Ch 06 Trespass to Chattels wwwtomwbellcom 20070820 Retrieved 20070820  What are the trespass to chattels claims some companies or website owners have brought wwwchillingeffectsorg 20070820 Archived from the original on 20020308 Retrieved 20070820  Ticketmaster Corp v Ticketscom Inc 20070820 Retrieved 20070820  American Airlines v FareChase PDF 20070820 Archived from the original PDF on 20110723 Retrieved 20070820  American Airlines FareChase Settle Suit The Free Library 20030613 Archived from the original on 20160305 Retrieved 20120226  Imperva 2011 Detecting and Blocking Site Scraping Attacks Imperva white paper  Adler Kenneth A 20030729 Controversy Surrounds Screen Scrapers Software Helps Users Access Web Sites But Activity by Competitors Comes Under Scrutiny Archived from the original on 20110211 Retrieved 20101027  QVC Inc v Resultly LLC No 1406714 ED Pa filed Nov 24 2014 PDF 20141124 Archived from the original PDF on 20130921 Retrieved 20151105  QVC Inc v Resultly LLC No 1406714 ED Pa filed Nov 24 2014 United States District Court for the Eastern District of Pennsylvania Retrieved 5 November 2015  Neuburger Jeffrey D 5 December 2014 QVC Sues Shopping App for Web Scraping That Allegedly Triggered Site Outage The National Law Review Proskauer Rose LLP Retrieved 5 November 2015  Did IqbalTwombly Raise the Bar for Browsewrap Claims PDF 20100917 Archived from the original PDF on 20110723 Retrieved 20101027  Can Scraping NonInfringing Content Become Copyright Infringement Because Of How Scrapers Work  Techdirt Techdirt 20090610 Retrieved 20160524  Facebook v Power Ventures Electronic Frontier Foundation Retrieved 20160524  UDSKRIFT AF SØ  HANDELSRETTENS DOMBOG PDF in Danish bvhddk 20060224 Archived from the original PDF on 20071012 Retrieved 20070530  High Court of Ireland Decisions  Ryanair Ltd v Billigfluegede GMBH 2010 IEHC 47 26 February 2010 British and Irish Legal Information Institute 20100226 Retrieved 20120419  Matthews Áine June 2010 Intellectual Property Website Terms of Use Issue 26 June 2010 LK Shields Solicitors Update p 03 Archived from the original on 20120624 Retrieved 20120419  La réutilisation des données publiquement accessibles en ligne à des fins de démarchage commercial  CNIL wwwcnilfr in French Retrieved 20200705  FindDataLabcom 20200609 Can You Still Perform Web Scraping With The New CNIL Guidelines Medium Retrieved 20200705  National Office for the Information Economy February 2004 Spam Act 2003 An overview for business Australian Communications Authority p 6 Archived from the original on 20191203 Retrieved 20171207  National Office for the Information Economy February 2004 Spam Act 2003 A practical guide for business PDF Australian Communications Authority p 20 Retrieved 20171207  Mayank Dhiman Breaking Fraud  Bot Detection Solutions OWASP AppSec Cali 2018 Retrieved February 10 2018 Retrieved from httpsenwikipediaorgwindexphptitleWeb_scrapingoldid1188411497 Category Web scrapingHidden categories CS1 maint multiple names authors listCS1 Danishlanguage sources daCS1 Frenchlanguage sources frArticles with short descriptionShort description matches WikidataArticles needing additional references from April 2023All articles needing additional referencesArticles needing additional references from October 2018Articles with limited geographic scope from October 2015United StatescentricAll articles with unsourced statementsArticles with unsourced statements from April 2023 This article needs additional citations for verification Please help improve this article by adding citations to reliable sources Unsourced material may be challenged and removedFind sources Web scraping  news  newspapers  books  scholar  JSTOR April 2023 Learn how and when to remove this template message 0 This article needs additional citations for verification Please help improve this article by adding citations to reliable sources Unsourced material may be challenged and removedFind sources Web scraping  news  newspapers  books  scholar  JSTOR April 2023 Learn how and when to remove this template message This section does not cite any sources Please help improve this section by adding citations to reliable sources Unsourced material may be challenged and removed October 2018 Learn how and when to remove this template message 0 This section does not cite any sources Please help improve this section by adding citations to reliable sources Unsourced material may be challenged and removed October 2018 Learn how and when to remove this template message The examples and perspective in this section deal primarily with the United States and do not represent a worldwide view of the subject You may improve this section discuss the issue on the talk page or create a new section as appropriate October 2015 Learn how and when to remove this template message 0 The examples and perspective in this section deal primarily with the United States and do not represent a worldwide view of the subject You may improve this section discuss the issue on the talk page or create a new section as appropriate October 2015 Learn how and when to remove this template messageJointOptimizationofWrapper Generation and TemplateDetection Shuyi Zheng PennsylvaniaState University University ParkPA 16802 shzhengcsepsueduDi Wu TheChinese Universityof Hong Kong HongKong China dwusecuhkeduhkRuihua Song JiRong Wen MicrosoftResearchAsia Beijing 100080 China rsongjrwen microsoftcom ABSTRACT Many websites have large collections of pages generated dy namically from an underlying structured source like a datab ase The data of a category are typically encoded into similar pages by a common script or template In recent years some valueadded services such as comparison shopping and vertical search in a speciﬁc domain have motivated the re search of extraction technologies with high accuracy Almo st all previous works assume that input pages of a wrapper in duction system conform to a common template and they can be easily identiﬁed in terms of a common schema of URL However we observed that it is hard to distinguish diﬀerent templates using dynamic URLs today Moreover since ex traction accuracy heavily depends on how consistent input pages are we argue that it is risky to determine whether pages share a common template solely based on URLs In stead we propose a new approach that utilizes similarity between pages to detect templates Our approach sepa rates pages with notable inner diﬀerences and then generate s wrappers respectively Experimental results show that ou r proposed approach is feasible and eﬀective for improving ex  traction accuracy Categories andSubject Descriptors H3m  Information Storage and Retrieval  Miscella neous Data Extraction Wrapper Generation Web General Terms Algorithms Experimentation Performance Keywords Wrapper Template Detection Information Extraction Work was done when the authors were visiting Microsoft Research Asia Permission to make digital or hard copies of all or part of thi s work for personal or classroom use is granted without fee provided th at copies are not made or distributed for proﬁt or commercial advantage an d that copies bear this notice and thefull citation on theﬁrstpage Tocop y otherwise to republish topostonserversortoredistribute tolistsre quires priorspeciﬁc permission andor afee KDD07 August 1215 2007 San Jose California USA Copyright 2007 ACM 9781595936097070008  5001 INTRODUCTION Websites like Amazoncom are dataintensive and infor mation on them comes from structured sources Often the data are encoded into semistructured HTML pages that employ templates for rendering Some valueadded services  such as comparison shopping are emerging to query or ma nipulate the data such as products and reviews from sev eral websites To achieve high accuracy the task of extract  ing structured information from Web pages is usually im plemented by programs called wrappers Manually writing wrappers for Web sources 9 is a tedious timeconsuming and errorprone job thus the study of automatic wrapper induction using machine learning techniques has been a sub ject of research in recent years 12 11 17 16 3 6 5 18 4 21 10 This paper also focuses on wrapping Web sources in an automatic manner Although diﬀerent wrapper induction systems employ var ious techniques and strategies to generate wrappers they a ll separate template detection from learning wrappers The detection groups training pages into several clusters or cl asses based on cues like URLs For example 7 assumes that pages belonging to the same template are located at the same subdirectory of a website Thus pages are considered to share a common template if their URLs ﬁt a common schema Grouped pages are then fed into an induction mod ule The module generally assumes that a group of pages conforms to a common template and generates a wrapper per class The separated template detection strategy has at least two limitations 1 With the popularity of dynamic URLs it is no longer as eﬀective to detect templates by URLs as before especially for some largescale websites Figure 1 lists four sample pages collected from Amazoncom From their appearances it is easy to tell that Figure 1a and Figure 1b share a common template and Figure 1c and Figure 1d share another template Comparing their URLs we ﬁnd there are no cues to allow correct grouping of the pages 2 Even if URLs can group pages that share a template such a method is sometimes far from optimal to gen erate only one wrapper for a complex template For example by looking closely at page c and d in Figure 1 we observe that page d is diﬀerent from page c in some aspects Page d has an additional attribute named Color and it lists some alsovieweda httpwwwamazoncomgpproductB000BNLGJA b httpwwwamazoncomgpproductB00007J8SC c httpwwwamazoncomgpproductB0000DD95R d httpwwwamazoncomgpproductB0000A1AT9 Figure 1 Sample pages from wwwamazoncom items in a column whereas page c lists some you mayalsolike items in a row Building two wrappers for such a complex template may achieve better ex traction accuracy To solve the problems above we propose detecting tem plate solely based on the similarity among page represen tations that are also used in wrapper generation In our system tree structures are used as representations for pag es and wrappers Based on a distance metric between a page and a wrapper a clustering algorithm is employed to clus ter similar enough pages into a class and induces a central wrapper for the class at the same time Such a joint ap proach makes it possible to optimize the ﬁnal performance of extraction by involving template detection in the traini ng process Compared with prior works our approach has two advan tages 1 Our approach is more stable because it does not rely on URLs or any other external features to detect tem plates Instead we attempt to detect templates based on inner structure similarity of pages which is consis tent with the principle of wrapper induction 2 Given a set of pages the number of wrappers is de termined by how similar they are This number can be optimized under the criterion of overall extraction accuracy of generated wrapper set The rest of this paper is organized as follows We ex plain our main idea by clarifying two concepts on template in Section 2 Section 3 provides the basic representations Section 4 formally states the addressed problem and brieﬂyoverviews our solution In Section 5 we describe wrapper induction algorithm that is implemented in our system and propose a new wrapperoriented page clustering algorithm that joins template detection with wrapper generation to gether Section 6 reports some experimental results while Section 7 describes related works Section 8 concludes the paper with directions for future work 2 GROUNDTRUTH TEMPLATES AND SIMILARITYBASED TEMPLATES Before going to the details of our approach in this section we will ﬁrst describe the main idea of this paper Whats a groundtruth template In previous related work the concept of template has been presented by var ious descriptive deﬁnitions Most of them associate a tem plate with a script that encodes the data of a category into a group of HTML pages called a page class For example we can guess that both page a and page b in Figure 1 are generated dynamically by a script for the category of computer while page c and page d generated by another script for the category of cap This kind of templates does exist and it is indispensable for wrapper induction systems to generate eﬀective wrappers in reverse We call these kind of templates GroundTruth Templates because they denote the original relations among pages of a website The corre sponding page classes are called Groundtruth Page Classes  However the ultimate purpose of template detection is not to guess which pages are encoded by a groundtruth tem plate but to generate more eﬀective wrappers that can cor rectly extract data What we propose is to cluster pages into several groups based on how similar they are In general apage is less diﬀerent from the pages in the same group than those pages in other groups Each group is corresponded to a template that is called Similaritybased Template and the group itself is a Similaritybased Page Class  For a particular page set P since the groundtruth tem plates are invisible to us it is diﬃcult and not necessary to ensure that detected similaritybased templates are exact ly same to groundtruth templates For example for pages like page c and page d in Figure 1 a groundtruth page class may be divided into two similaritybased page classes because the color attribute is optional so that some pages like page d have such attributes while others like page c do not It is very likely that extracted results by using two similaritybased templates are good and even better than those by inducing one groundtruth template because the complexity of these templates becomes lower than that of one groundtruth template In addition we found that the deﬁnition of similarity is highly related to alignment in the stage of wrapper induc tion We propose to use consistent representations in both template detection and wrapper generation and jointly op timize these two stages to achieve better extraction perfor  mance In our system treestructures are used as represen tations for pages and wrappers although the representatio n is not restricted to treestructure 3 DATAREPRESENTATIONS We describe the representations of a Web page and a wrapper in this section 31 DOM Document Object ModelTree DOM tree is the representation of a HTML page in our system Each DOM node of a DOM tree represents an HTML tag pair eg TABLE andTABLE  The nested structure of HTML tags corresponds to the parentchild re lationship among DOM nodes Thus a DOM tree is formed naturally More information about DOM speciﬁcation can be found at 1 In our experiments DOM trees used for wrapper gener ation are manually labeled so that the generated wrappers can extract values and assign labels in one step Labels are only assigned to leaf nodes of a DOM tree DOM nodes with diﬀerent labels are considered diﬀerent no matter whether they have the same tag or not In the rest of this paper for a given DOM node σ we use Tσ and Lσ to denote its tag and label 32 Wrapper In our system a wrapper is also presented in tree structure that can be regarded as extended DOM trees with Signfor each node Definition 1Node Sign Given a wrapper node σ its signSσindicates its matching rule in the alignment be tween its owner wrapper and a DOM tree Sσcan be 1 or an integer NN2or one of the following wildcards  Rule 1Given a wrapper node σ  Sσ  1means σcan only match one DOM node  Sσ NN2means σcan match consecutive N DOM nodes Sσ means σcan match one DOM node or no DOM node at all  Sσ   means σcan match consecutive NDOM nodes N1  Sσ means σcan match consecutive NDOM nodes N1or no DOM node at all Such wrapper node signs are similar to the wildcards used in other works like 6 18 Another diﬀerence between a wrapper and a DOM trees is that a wrapper may have a kind of special nodes that act like pairs of parentheses called Parentheses Nodes  These nodes have no corresponding tags and must be inner nodes with at least one child For the sake of convenience we call other DOM nodes or wrapper nodes as Tag Nodes  4 PROBLEM DEFINITION AND SYSTEM OVERVIEW In this section we formally deﬁne the extraction problem and brieﬂy overview our solution 41 Problem Deﬁnition We deﬁne the problem as follows Given a set of labeled DOM trees Dparsed from pages of a particular website a group of wrappers  w1w1 wn should be learned from D And the target is to maximize the overall extraction accuracy Pwhen generated wrappers are tested on another DOMtree set Dprimethat comes from the same website In this paper we use manually labeled training data to explain and verify our ideas Although the idea of joint op timization of wrapper induction and template detection is not constrained to labeled data we do so for several reasons  First our main focus is not on the algorithm of wrapper induction but on how to detect similaritybased templates and how the detection inﬂuences extraction performance Labeled data can simplify the evaluation of extraction re sults Second using labeled data to generate wrappers is commonly used in some scenarios such as comparison shop ping As the accuracy of price is required to be close to 100 percent automatic attributes labeling methods cannot mee t the requirement Furthermore inducing wrappers based on labeling data is selectively used for only a few of head sites  For each site as few as tens of pages are enough to train a robust wrapper set Thus the cost of labeling is acceptable  42 System Overview A ﬂowchart of our system is shown in Figure 2 To begin with training pages are parsed into DOM trees before they are processed by our system We will not discuss the HTML parsing technique since it is beyond the scope of this paper Second the DOM trees will be fed to the wrapperoriented page clustering module that combines template detection and wrapper generation into one step and outputs a set of wrappers A byproduct in the step is that the train ing DOM trees are also clustered into similaritybased page classesTraining Pages Wrapper Set Joint Template Detection and Wrapper Generation ModuleWeb Page Parsing Web Page Parsing   Wrapper Selection Data ExtractionName Image Price            New Pages Figure 2 System overview When a new Web page is introduced it will be parsed into a DOM tree ﬁrst Then our system can automatically select a wrapper from the generated wrapper set which makes a best match with the DOM tree At last data is extracted and saved in a structured format like a relational database 5 JOINT OPTIMIZATION OF WRAPPER GENERATIONAND TEMPLATE DETECTION In this section we present the idea of joint optimization of wrapper generation and template detection in detail We ﬁrst introduce the wrapper generation algorithm that is im plemented in our system We then describe how template detection is combined with wrapper generation by a pro posed algorithm called wrapperoriented page clustering 51 Wrapper Generation In Section 511 we describe how to convert a DOM tree to a wrapper tree This is the ﬁrst step for a page before it is evolved in wrapper generation in our system In Sec tion 512 and Section 513 we implement a costdriven al gorithm to perform wrapper induction This algorithm syn thesizes several stateoftheart techniques 6 4 18 e g regular expression inference 511 ConvertaDOM treeto a Wrapper Given a source DOM tree Td supposing that the con verted wrapper is Tw we use TdTwto indicate this con version InTdTw we need to perform a repeat pattern combi nation algorithm to make Twmore compact than Td This combination algorithm is similar to the work in 15 If NN2 identical consecutive subtrees are detected in Td they will be merged as one subtree rooted at a tag node σinTw where Sσ N IfNN2 identical consecutive subforests are detected in Td they will be merged as onesubforest rooted under a parentheses node pinTw where Sp N Node labels are considered in the algorithm Fig ure 3 illustrates this procedure where letters indicate no des tags and subscripts indicate nodes labels A B C D1D1D2B C D1D1D2A B C D1 D222  Figure 3 Repeat pattern combination 512 CostDrivenTreeAlignment Tree alignment is a frequently used algorithm in our sys tem There are two types of treealignment algorithms one is for aligning two diﬀerent wrappers called WWalignment  and the other is for aligning a wrapper and a DOM tree called WDalignment We employ costdriven dynamic pro gramming for both algorithms In the treealignment algorithm DOM nodes and wrapper nodes are the basic units for matching Mismatched nodes will cause cost in the alignment To calculate the cost we need to assign weight to each node before aligning Definition 2DOMNode Weight Given a DOM node σ its weight Wσequals the number of nodes in the subtree rooted at σ including itself Definition 3WrapperNode Weight Given a wrapper nodeσ its weight Wσcan be calculated as follows Ifσis a leaf tag node and Sσ  1 then Wσ  1 Ifσis a inner tag node and Sσ  1 then Wσ  1sum of its child nodes weightIfσis a parentheses node and Sσ  1 then Wσ  sum of its child nodes weight IfSσ orSσ  then Wσ  0 IfSσ    then Wσ Wσprime where σprimeis the same to σexcept for Sσprime  1 IfSσ N then Wσ N Wσprime where σprimeis the same to σexcept for Sσprime  1 The reason we set a wrapper node σs weight as 0 if Sσ   orSσ is that this kind of wrapper node is allowed to be mismatched without causing any cost In this subsection we only describe WWalignment and leave WDalignment to Section 522 Given two wrappers Tw1andTw2 the basic procedure of WWalignment is to align two forests AFw1 Fw2 It is performed in a topdown order layer by layer Only nodes at the same layer of Tw1andTw2can be aligned with each other Rule 2Given two wrapper nodes σw1andσw2 we say σw1matches σw2 iﬀ all the following rules are satisﬁed 1σw1andσw2are either both inner nodes or both leaf nodes 2Tσw1 Tσw2 3 Ifσw2andσw2are both leaf nodes Lσw1 Lσw2 At each layer AFw1 Fw2 performs a sequence alignment between the array of Fw1s root nodes and that of Fw2s Dy namic programming is adopted here to minimize the cost All mismatched root nodes in Fw1andFw2contribute their weight as cost to AFw1 Fw2 For a pair of matched nodes σw1andσw2that are inner nodes AchildF w1 childF w2 will be invoked recursively where childF w1andchildF w2 are the subforests consisting of subtrees rooted at the ch ild nodes of σw1andσw2 The cost caused by AchildF w1 childF w2 will be counted in the cost calculation of AFw1 Fw2 Be cause our WWalignment algorithm works in such a top down recursive way it attempts to align nodes in two wrap pers only if their parent nodes are aligned with each other Such a mechanism saves some unnecessary alignment Figure 4 shows an example of WWalignment In this ex ample label diﬀerence is ignored for statement convenienc e The alignment algorithm works as follows First AAA recursively invokes Aparenleftbig BC3DEBC3Eparenrightbig  Then according to the matching rule of wildcards  Rule 1 Aparenleftbig BC3DEBC3Eparenrightbig seeks a better solution between ABC3DEBC3E and ABBC3E Obviously the former one costs less by now Then AF2FG is invoked recursively by both ABC3DEBC3E and ABBC3E to calculate the cost of these two solutions In this exam ple WWalignment algorithm can ﬁnd an optimal result as Figure 4 shown with the cost of 2 513 WrapperInduction After WWalignment obtains an optimal result between two wrappers a new wrapper can be constructed accordingA B FC E3 2 A B FC E3  G A B FC E3   G Tw1 Tw2 Tw3D D Gray nodes are mismatched nodes Figure 4 Wrapper induction to the signinference function I I1NULL   I N   INULL   I   InNULL  I1   INULL  IN   INULL  I   I11  1 I   IN N  NI1 N   I   IN   I   I1   I  IN1 N2   I1   whereNULLrepresents a mismatch of a wrapper node For example I1NULL is applied for Dnode because Dhas the sign 1 in Tw1while it is mismatched in Tw2 Given two source wrappers Tw1andTw2 supposing that the generated wrapper is Tw3 we use Tw1Tw2Tw3to denote this induction procedure Figure 4 also illustrates how to construct a new wrapper based on the alignment result 52 Combine WrapperGeneration with Template Detection In Section 521 we describe the clustering algorithm that combines template detection and wrapper generation to achi eve joint optimization For clustering a distance metric is de  ﬁned in Section 522 521 WrapperOrientedPageClusteringAlgorithm Wrapperoriented page clustering WPC is the most novel part of our system Given a set of DOM trees D our WPC algorithm clusters DOM trees in Dand generates a wrapper for each cluster Actually templates are detected one by on e in WPC After a templates clustering process is completed all clustered DOM trees of this template will be removed and then clustering for another template will start The cycles will stop when no DOM tree is left Here we use Figure 5 to illustrate the clustering process of one template In Figure 5 W represents a wrapper for this template and positive points represent DOM trees that belong to the same template as the centered wrapper Each     W a Level1 wrapper    W b Level2 wrapper   W c Level3 wrapper   W d Level4 wrapper Figure 5 Wrapperoriented page clustering for one templat e gray point represents a chosen DOM tree that will be used to reﬁne the centered wrapper In the WPC algorithm we use Wrapper Level to indicate a wrappers complexity and generality It is deﬁned as the number of training DOM trees used to learn this wrapper First a level1 wrapper Twis converted from a randomly chosen DOM tree and taken as the center for this template Figure 5a DOM trees whose distance to Twis less than a given threshold epsilon1dashed circle in Figure 5 are considered belonging to the same template of Twand will be used to reﬁne Tw Reﬁning Twwith a DOM tree Tdincludes three steps converting Tdto a level1 wrapper Tprime w generating a new wrapper from TwandTprime w and replacing Twwith the new wrapper After Twis reﬁned it is upgraded by one level and be comes more general Actually for any DOM tree Td the recalculated distance between TwandTdis expected to de crease For the DOM trees that match the wrapper perfectly eg central DOM tree in Figure 5c we will not use them to reﬁne the centered wrapper because they will not bring any changes to it For those DOM trees whose distance to the centered wrapper is less than threshold epsilon1Tdwill be employed to reﬁne TwFigure 5a and Figure 5b Finally the WPC algorithm stops for one template when no DOM tree is within the given threshold Figure 5d The full algorithm of WPC is listed in Figure 6 Our proposed WPC algorithm has only one parameter ie the distance threshold Fortunately there is a wide threshold to assure high performance Please refer to exper  imental results shown in Section 6 522 DistanceMetric In our system instead of measuring the similarity between two DOM trees directly we derive a WrapperDOM Distance WDDistance to measure the distance between a wrapper and a DOM tree This distance is used in both the wrapper oriented page clustering module and the wrapper selection module WDDistance is calculated based on the WDalignments cost WDalignment algorithm is similar to WWalignment Thus we will not describe it in detail but only present the diﬀerence between them In WWalignment nodes are aligned in a onetoone manner while in WDalignment a wrapper node whose sign is   or Ncan be aligned with multiple DOM nodes Figure 7 For WDalignment between a wrapper Twand a DOM treeTd we use CwTw Td to denote the total cost caused by mismatched wrapper nodes and use CdTw Td to denote the total cost caused by mismatched DOM nodes WhenAlgorithm  WPC D DOM tree set epsilon1 threshold 1begin 2 R page cluster set 3 W wrapper set 4 while Dis not empty 5 create a new page cluster C 6 select a DOM tree Td1fromDrandomly 7 Td1Tw1 8 move Td1fromDtoC 9 for each TdinD 10 ifΨTw1 Td  0 11 move TdfromDtoC 12 endif 13 endfor 14 while Td2D ΨTw1 Td2 epsilon1 15 Td2Tw2 16 Tw1Tw2Tw3 17 Tw1Tw3 18 move Td2fromDtoC 19 for each TdinD 20 ifΨTw1 Td  0 21 move TdfromDtoC 22 endif 23 endfor 24 endwhile 25 add CtoR add Tw1toW 26 endwhile 27 return RandW 28end Figure 6 Wrapperoriented page clustering algo rithm calculating the WDDistance it is necessary to normalize the cost CwTw Td and CdTw Td by the weight of a whole tree because the larger the number of nodes in the tree the greater is the likelihood of the tree having nodes that are mismatched Thus WrapperDOM Distance is deﬁned as follows Definition 4WrapperDOM Distance Given a wrap perTwand a DOM tree Td the wrapperDOM distance ΨTw Td parenleftBigCwTw Td WTwCdTw Td WTdparenrightBigslashBig 2 Here weight of a DOM tree and weight of a wrapper are deﬁned as below Definition 5DOMTree Weight Given a DOM tree Tdwhose root node is τ then WTdWτA B EC D 3A B EC C E EDWrapper Tree T w DOM Tree T d   Figure 7 Alignment of a wrapper with a DOM tree Definition 6Wrapper Weight Given a wrapper Tw whose root node is σ then WTwWσ According to Deﬁnition 4 WDdistance is the arithmetic mean of the normalized cost caused by the wrapper side and that caused by the DOMtree side Thus values are normal ized in the range between 0 and 1 Ψ Tw Td  0 means Tw perfectly matches Tdwithout any cost and Ψ Tw Td  1 means none of the nodes in TwandTdmatch in the align ment 6 EXPERIMENTS We test the performance of our approach through exper iments 61 Experiment Setup We use a dataset of 1700 product pages from Amazoncom and a dataset of mixed 1000 pages from 10 shopping web sites We call the former dataset Amazon and the latter M10 hereinafter The reason we choose these datasets is that they are reallife largescale Web sites and their Web pages are relatively more complex than datasets used in ear lier works Although we can also gain very good results on simple datasets ie all pages are similar of each site us  ing complex reallife datasets is a better choice to show the eﬀectiveness of our joint approach In each page product records and their three attributes namely product name product image and product price are manually labeled For each website twofold cross val idation is conducted We use precision recall and F1 as measures in evaluation of data extraction results These measures are calculated based on whether a labeled node is correctly extracted All experiments were run on a PC with a 306 GHz Pen tium 4 processor and 387 GB RAM 62 Experimental Results ExperimentI EffectivenessTest On the Amazon data our joint optimization approach achieve s as high F1 as 9488 by setting the threshold as 03 Fig ure 8 with 44 wrappers generated For comparison we im plement the separated template detection strategy based on URLs For speciﬁc training pages are divided into several templates by their URLs Then each template generates a wrapper using the same wrapper induction technique as that used in our WPC algorithm The experimental result shows that these wrappers can only achieve 78 accuracy in terms of F1 Therefore our approach outperforms the traditional method by about 17 pointsTo further evaluate the performance of the WPC algo rithm we run the experiment on M10 data Table 1 shows the evaluation results for each site As we see the average F1 is as high as 972 For seven sites out of 10 the pro posed WPC algorithm achieves F1 higher than 98 The lowest F1 is got on pages from ftdcom By case study we ﬁnd that the number of templates are unbalanced between the training set and the test set When some templates are unseen in the stage of training the generated wrappers reject those pages and extract nothing in testing But for those seen templates the wrappers can handle them well That is why we get high precision and low recall Table 1 Results on 10 shopping websites Website Wra  Pre Rec F1 ashfordcom 1 10000 10000 10000 circuitcitycom 2 10000 10000 10000 costcocom 23 09667 09153 09403 diamondcom 1 09875 09975 09925 ebagscom 2 09976 10000 09988 ftdcom 2 09833 07528 08527 oﬃcedepotcom 1 09850 10000 09924 overstockcom 6 09224 09979 09587 pricegrabbercom 1 09970 09773 09870 searscom 3 09960 10000 09980 Average 42 09835 09640 09720 We notice that pages in site Costcocom are clustered into 23 similaritybased templates It is surprising because in the viewpoint of a human training pages of this site share only one template Then we use all training pages of this site to generate one wrapper The wrapper can only achieve 87 accuracy in terms of F1 which is lower than the 23 wrappers generated by our approach ExperimentII WPC with DifferentThresholds We evaluate the performance of WPC algorithm as the thresh old changing on Amazon data We run WPC 18 times under diﬀerent thresholds from 0 to 085 with a 005 interval Fig  ure 8 shows three curves on performance when the thresh old increases from 0 to 085 There is no result with greater thresholds because pages chosen are too diverse to learn a wrapper 0 02 04 06 08 1085090951 Threshold Precision Recall F1Value Figure 8 WPC performance under diﬀerent thresh oldsWhen the threshold is set as 0 only exactly matched pages can be absorbed by the wrapper Thus we got the highest precision while the recall is the lowest It means that a generated wrapper is speciﬁc for the small number of pages although the wrapper is precise in its scope As we increase the threshold the precision drops down and the recall goes up In terms of F1 the peak value of 9488 is achieved by setting the threshold to 03 Af ter that F1 stays above 94 and becomes stable until the threshold is set to 085 The stable range from 03 to 08 in dicates that it is not hard to set an appropriate ﬁxed thresh old in the approach We also list comparison of the number of wrappers gen erated with diﬀerent thresholds in Figure 9 The number of wrappers or similaritybased templates decreases quick ly from 832 to 44 as the threshold increases from 0 to 03 Then the wrapper number decreases slowly There is an ob vious drop if the threshold is set to 085 All training pages are clustered into just four Such wrappers can cover more pages by sacriﬁcing the eﬀectiveness of extraction 0 02 04 06 08 102004006008001000 ThresholdTemplate Number Figure 9 Template detection under diﬀerent thresh olds The impact of diﬀerent thresholds is also presented by the runtime of our algorithm in the wrapper generation process When the threshold is set to 0 it takes 13197 seconds 367 hours to generate 832 wrappers Then it drops to 1424 040 hours seconds when the threshold increase to 015 and keeps stable around 2000 seconds 056 hours until the threshold reaches 08 After that the runtime increases dr a matically to 24666 seconds 685 hours when the threshold is set to 085 The runtime gets too much to tolerate when the threshold is greater So we treat the situations as if the y fail to learn a wrapper ExperimentIII Stability Test Since our algorithm chooses the initial DOM tree for clus tering in a random way we evaluate how the initial choice impacts performance of our approach in the experiment We conducted WPC algorithm ﬁve times with the threshold set to 02 on Amazon dataset Table 2 lists the number of tem plate extraction precision and recall of each run As Table 2 shows in terms of F1 the mean is 94 while the standard variance is smaller than 4E5 It indicates tha t our proposed approach is quite stable with the random strat egy to select an initial DOM treeTable 2 Stability test result Template  Precision Recall F1 1 99 09683 09249 09461 2 116 09460 09254 09356 3 111 09606 09238 09418 4 113 09510 09138 09320 5 111 09664 09236 09445 ExperimentIVLabelingCost As stated earlier our approach requires manually labeling for wrapper generation This experiment was designed to show how many training pages are required for learning wrappers to achieve an accuracy higher than 95 in terms of F1 Table 3 shows the results for all sites in M10 Actu ally most websites only need a handful of labeled pages to meet the demand of accuracy That proves that the cost of manually labeling in our approach is acceptable Table 3 Labeling test result Website Page  Website Page  ashfordcom 12 circuitcitycom 19 costcocom 31 diamondcom 12 ebagscom 19 ftdcom NA oﬃcedepotcom 19 overstockcom 16 pricegrabbercom 7 searscom 27 7 RELATED WORK Our work is in the area of Web Information Extraction  It is highly related to previous works on wrapper induc tion Several automatic or semiautomatic wrapper learnin g methods have been proposed For example WIEN 12 is the earliest method as we know on automatic wrapper induc tion Other representative ones are SoftMeley 11 Stalke r 17 RoadRunner 6 EXALG 2 TTAG 4 works in 18 and ViNTs 21 Here we only discuss RoadRunner TTAG and works in 18 and refer the reader to two surveys 13 8 and two tutorials 19 14 for more studies related to infor mation extraction and wrapper induction In previous work page clustering for wrapper induction is considered a trivial task in most previous wrapper induc tion systems Among them only RoadRunner 6 7 and 18 proposed automatic approaches to implement page cluster ing for wrapper generation Other methods all manually collect training pages template by template In 7 page clustering for RoadRunner system is discussed They use four types of page features to calculate the similar  ity between two pages 1 distance from the home page 2 url similarity 3 tag probability 4 tag periodicity B ased on page similarity they adopt a popular nonsupervised clustering algorithm MiniMax to conduct the page cluster ing process This process is isolated from the wrapper gen eration process which is the primary diﬀerence compared with our WPC algorithm Wrapper selection problem is also discussed in 7 In 18 tree edit distance is used to measure the distance between two pages They use traditional hierarchical clus tering techniques 20 in which the distance measured is the output of a restricted topdown tree mapping algorithmRTDM The RTDM algorithm does not distinguish node tag and it is designed only for ﬁnding the main contents in news pages This restricts that method from being applied to general information extraction problems Similar to our system works in 18 can also derive a similarity between a wrapper called extraction patterns and a page when se lecting a proper wrapper for extracting data from a new page However template detection is still isolated from th e wrapper generation process We need to mention TTAG because wrappers in TTAG are also presented as a tree structure with wildcards The authors also employ a topdown layerbylayer alignment but the alignment in any layer is isolated from that in other layers As a result child nodes can still be aligned even when their parent nodes do not match That is a diﬀer ent strategy from ours Moreover like most other previous systems template detection is not discussed in TTAG 8 CONCLUSIONSAND FUTUREWORK In this paper we propose a novel wrapper induction sys tem that expresses a diﬀerent opinion regarding the relatio n between template detection and wrapper generation Our system takes a miscellaneous training set as input and con ducts template detection and wrapper generation in a single step By the criterion of generated wrappers extraction accuracy our approach can achieve a joint optimization of template detection and wrapper generation Experimental results on reallife shopping websites prove the feasibili ty and eﬀectiveness of our approach The preliminary compar ison demonstrates that our approach signiﬁcantly outper forms the separated template detection strategy Our wrapper induction algorithm only leverages the HTML tagtree structure and does not involve any content As fu ture work we will try to extend the approach to handle the templates that contain some content strings 9 ACKNOWLEDGMENTS We are grateful to Dwight Daniels for detailed edits on writing this paper Comments from the three anonymous referees are invaluable for us to prepare the ﬁnal version 10 REFERENCES 1 httpwwww3orgdom 2 A Arasu and H GarciaMolina Extracting structured data from web pages In Proceedings of the 2003 ACM SIGMOD International Conference on Management of Data pages 337  348 2003 3 CH Chang and SC Lui Iepad information extraction based on pattern discovery In Proceedings of the 10th International Conference on World Wide Web pages 681688 2001 4 SL Chuang and J Yj Hsu Treestructured template generation for web pages In Proceedings of IEEEWICACM International Conference on Web Intelligence  pages 327  333 2004 5 W W Cohen M Hurst and L S Jensen A ﬂexible learning system for wrapping tables and lists in html documents In Proceedings of the 11th International Conference on World Wide Web  pages 232  241 2002 6 V Crescenzi G Mecca and P Merialdo Roadrunner Towards automatic data extraction from large websites In Proceedings of the 27th International Conference on Very Large Data Bases  pages 109  118 2001 7 V Crescenzi G Mecca and P Merialdo Wrappingoriented classiﬁcation of web pages In Proceedings of the 2002 ACM symposium on Applied computing  pages 1108  1112 2002 8 S Flesca G Manco E Masciari E Rende and A Tagarelli Web wrapper induction a brief survey AI Communications  1757  61 2004 9 J Hammer H GarciaMolina J Cho A Crespo and R Aranha Extracting semistructured information from the web In Proceedings of the Workshop on Management fo Semistructured Data  1997 10 A Hogue and D Karger Thresher automating the unwrapping of semantic content from the world wide web In Proceedings of 14th International Conference on World Wide Web  pages 86  95 2005 11 CN Hsu and MT Dung Generating ﬁnitestate transducers for semistructured data extraction from the web Information Systems Special Issue on Semistructured Data  238521538 1998 12 N Kushmerick D S Weld and R B Doorenbos Wrapper induction for information extraction In Proceedings of the International Joint Conference on Artiﬁcial Intelligence  pages 729737 1997 13 A H F Laender B A RibeiroNeto A S da Silva and J S Teixeira A brief survey of web data extraction tools SIGMOD Record  3128493 2002 14 B Liu Web content mining tutorial In Proceedings of the 14th International Conference on World Wide Web 2005 15 B Liu R Grossman and Y Zhai Mining data records in web pages In Proceedings of the 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining  pages 601  606 2003 16 L Liu C Pu and W Han Xwrap an xmlenabled wrapper construction system for web information sources In Proceedings of the 16th International Conference on Data Engineering  pages 611621 2000 17 I Muslea S Minton and C Knoblock A hierarchical approach to wrapper induction In Proceedings of the 3rd Annual Conference on Autonomous Agents  pages 190  197 1999 18 D C Reis P B Golgher A S Silva and A F Laender Automatic web news extraction using tree edit distance In Proceedings of the 13th International Conference on World Wide Web  pages 502  511 2004 19 S Sarawagi Automation in information extraction and data integration tutorial In Proceedings of the 28th International Conference on Very Large Data Bases 2002 20 P Willett Recent trends in hierarchic document clustering a critical review Information Processing and Management  245577597 1988 21 H Zhao W Meng Z Wu V Raghavan and C Yu Fully automatic wrapper generation for search engines In Proceedings of the 14th International Conference on World Wide Web  pages 66  75 2005 4 CAUSENO06719402202 AMERICAN AIRLINES INC INTHEDISTRICT COURT vs 67THDISTRICTCOURT  FARECHASE INC TARRANT COUNTY TEXAS TEMPORARY INJUNCTION OnFebruary122003CAMETOBEHEARDPlaintiffAmericanAirlines IncsAmerican Application forTemporary InjunctionagainstDefendant Farechase IncFarechase containedinAmericans FirstAmended Original PetitiondulyverifiedbyAmericans authorized representative ScottLHyden andcameAmerican Farechase andIntervenor SabreIncSabreeachby andthroughtheirauthorized representatives andattorneysofrecordandeach partyannounced readyandtheCourthavingconsidered thepleadingsofthe partiestheevidenceadducedandtheargumentofcounselanditclearly appearing thatAmerican hasproducedevidenceofanddemonstrated aprobable rightofrecoveryagainstFarechase andthatithasnoadequateremedyatlaw andthatitwillsufferimmediate andirreparable injurylossanddamageifthis temporary injunction isnotenteredbeforetrialonthemeritsmaybeconsidered forthefollowingreasons 1Farechase developed marketsandlicensestocommercial users suchasandincludingSabreotherlargetravelglobaldistribution systemsandtravelagentsWebAutomation softwarethat enablestheuserstoobtainaccesstoAmericans computersystem andAAcomwebsiteAAcom TheFarechase softwareobtains andcopiesAmericanflightschedules seatavailability andfare 1 contentfromAAcomincludingAmericans webfares whichare lowerpricedfaresavailableonarestrictedbasisandnotgenerally availableforcommercial distribution purposes Inaddition Farechase employees regularlyaccessandinteractwithAAcomin ordertofurtheritscommercial purposesincludingmonitoring AAcomandupdateandqualitycheck theFarechase softwareAll suchaccessofAAcombyFarechase anditssoftwareis unauthorized andwithouttheconsentofAmerican 2Farechases actionsareintentional andwithoutAmericans consent 3Farechase isinviolationofAmericans termsandconditions ofuse oftheAAcomwebsiteaspostedonAAcomtheUser Agreement Farechase itslicenseesandendusersaccess obtaincopyanduseinformation fromAAcomforcommercial purposes contrarytotheUserAgreement thusfrustrating Americans objectives andeffortsindeveloping andmaintaining AAcom 4Farechases unauthorized accesstoAAcommaybeaviolationof  Section3302oftheTexasPenalCode 5Farechases actionsareunauthorized andwithoutAmericans consentAmerican repeatedly hasnotifiedFarechase thatitmust ceaseanddesisttheunauthorized accessing andscrapingof AAcomaswellasthedistribution ofitssoftwarewiththedata retrieverthatisdesignedspecifically toaccessandscrapeAAcom Farechase refusestoceasesuchactivityandcontinuesto distributeitssoftwarewithAAcomdataretrievertoitslicensees sothatunauthorized accessandcopyingofAAcomdatacontinues thisdayFarechase intentionally andwithoutauthorization from American continuestointerferewithAmericans possessory interestinitsowncomputersystemFarechases conduct intermeddles withandinterfereswithAmericans personalproperty Suchconductconstitutes atrespass 6Farechases conductinterfereswithAmericans computernetwork andsystemandresultsinauseandlossofitscomputersystem capacityalossordiminution ofcustomergoodwillandthe opportunities forgainingandincreasing customergoodwill increased expenseandtheinabilitytoplanfortheneedfor increased capacitysuchactionsadverselyaffectandharm American andthecondition qualityandvalueofAmericans property 2 7Farechase anditslicenseeshaveannounced planstodistributethe WebAutomation softwaretomanymoreusersSuchrolloutwill significantly increasetheamountofaccessing ofandcopyingfrom AAcomimminently threatenstoadversely impactandharmthe performance ofAAcomandtoplaceadditional burdenson Americans websiteinfrastructure Additionally ifaninjunction is notenteredcompetitors ofFarechase andtheirlicenseeswillbe encouraged toaccessandobtaininformation fromAAcomwithout Americans consenttherebycompounding andincreasing the threatandriskofharmtoAmerican 8Farechases continued andunauthorized useofitssoftwareto accessandcopyinformation fromAAcomsubstantially interferes withAmericans effortstoreducethecostofdistribution ofitsairline ticketsSuchcontinued andunauthorized usehasharmedandwill furtherharmAmericans goodwillandeffortstomaintainand possiblyreacquirecustomerloyalty 9Farechases conducthasforcedAmericantoattemptselfhelp Americantimeandresources havebeendedicated tocreatingand implementing technological barriersinanattempttoblock unauthorized usersofFarechase softwarefromaccessing the AAcomcomputersystemSuchactionsbyAmericantoblockhave beencircumvented byFarechases intentional inclusioninits softwareofamasking featurebywhichthesoftwaredisguises its identitysothatAmerican isunabletodetermine whoisgaining accesswithoutauthorization therebypreventing American from blockingallunauthorized accessbytheFarechase software 10AmericanhasnoadequateremedyatlawItsdamagesarenot susceptible ofdetermination withsufficientandreasonable certainty inasmuchasiitisimpossible orextremely difficulttoA determine thenumberofpotentialusersofAAcomthatAmerican isseekingtoencourage bythelimitedavailability ofitswebfares whowillnothavetheincentivetouseAAcomiftheycanobtainthe webfaresfromtravelagentsgenerallywhichwillbethecaseifthis injunctionisnotenteredBestimatetheharmthatwillresultfrom thefrustration toordemiseofAmericans currenteffortstoredirect salesofticketstolowercostdistribution channels Ccalculatein moneydamagestheinjuryanddamageresultingfromthelossof goodwillandlossofAAcomcustomers orDcalculatethemoney damageswhichwillresultfromtheunlawfuluseofAmericans propertybyFarechase andthepresentandunknownnumberof futureusersoftheFarechase softwareifthistemporary injunction isnotenteredandfromtheprobablescrapingofAmericans websitebyanunknownnumberofcompetitors ofFarechase and 3 theirlicenseeswhowillbeencouraged tobegindoingsoifthis injunctionisnotenterediiitisimpossible orextremely difficultto determine thenumberoftravelagentswhoarepotentialusersof Americans EveryFare programthroughwhichAmerican isseeking toreduceitsdistribution costswhowillnothavetheincentivetojoin intotheEveryFare programiftheycanobtainAmericans webfares usingFarechase softwarewhichwillbethecaseifthisinjunction is notenteredortocalculateinmoneydamagestheinjuryand damageresultingfromthelossofsuchcommercial opportunity iii Farechase hasevidenced thatithaslimitedcashresources ofits ownandthereforeisunlikelytobeabletorespondinmoney damages evenifdamageswereabletobedetermined with reasonable certaintyandivitwouldbeimpractical costandcourt inefficientandeconomically unfeasible ifAmericanwererequiredto sueindividually theultimateusersoftheFarechase softwareits competitors andtheirlicensees ifthisinjunctionisnotentered ITISTHEREFORE ORDERED ADJUDGED andDECREED that Defendant Farechase Incitsofficersagentsservantsemployees attorneys andallpersonsinactiveconcertorparticipation withthemarehereby immediately andtemporarily restrained andenjoinedpendenteIitefrom iaccessing usingorscrapingAAcomwithoutthewritten consentofAmerican iiaccessing usingorscrapingAAcomforanycommercial purposeincludingforthepurposeofupdatingFarechase softwarewithoutthewrittenconsentofAmerican iiiaccessing usingorscrapingAAcombyuseofany automated deviceormeansincludingelectronic devicesor meanscommonly knownintheindustryasrobotsorspiders withoutthewrittenconsentofAmerican and ivlicensingorotherwise providingtoanypersonorentityany softwareincludingupdatestoexistingsoftwarewhichis capableofaccessing AAcomwithoutthewrittenconsentof American 4 TheClerkofthisCourtisherebyorderedtoissueatemporary injunction enjoining theDefendant Farechase Incassetoutaboveprovidedhowever thatpriortotheissuancethereofAmerican shallfilewiththeClerkofthisCourta bondorcashdepositinlieuofbondintheamountofTHREEHUNDRED FIFTY THOUSAND ANDNOi00DOLLARS 35000000 conditioned according to lawwhichbondshallbeexecutedbyAmericanandacorporatesuretyortwoor moreindividual sureties ITISFURTHER ORDERED thatanymoniesplacedwiththeClerkofthis Courtshallbeplacedinaninterestbearingaccount ITISFURTHER ORDERED thatthiscaseisSPECIALLY setfortrialon themeritsonJuly72003at900AMinthecourtroom ofthe67thDistrictCourt ThisTemporary Injunction isbindingonFarechase Incitsofficers agentsservants employees attorneysandallpersonsinactiveconcertor participation withthemwhoreceiveactualnoticeofthisTemporary Injunction whetherbypersonalservicetelephone letterfacsimiletransmission or otherwise ENTERED this8thdayofMarch2003at715oclockAM  DonaldJCosby PresidingJudge 5 WHITE PAPERDetecting and Blocking Site Scraping Attacks Protecting Valuable Data and Intellectual Property from Online Thieves Data theft is one of the most dangerous threats for online businesses today And site scraping tools have become the weapon of choice to perform data theft From highly publicized scraping attacks on sites like Google RyanAir and EasyJet to innumerable unpublished incidents scraping has become a widespread menace Scraping attacks range from harmless data collection for personal research purposes to calculated repeated data harvesting used to undercut competitors prices or to illicitly publish valuable information Site scraping can undermine victims revenues and profits by siphoning off customers and reducing competitiveness Unfortunately site scrapers can be very difficult to differentiate from legitimate Web application users This paper investigates various types of scraping attacks site scraping tools and effective techniques to detect and stop future attacks2Introduction When you picture a thief do you envision a masked man lurking in a dark alley Or a teenage hacker in a dimlylit basement breaking into remote Web servers What about car manufacturers and online travel software financial news and event planning companies All of these organizations and many others have been accused of stealing data by site scraping Site scraping alternately called data harvesting screen scraping or Web scraping is a technique used to extract data from a Website Site scraping can be performed by manually copying Website content from Web browsers However the overwhelming majority of site scraping attacks are performed by software programs that automatically extract data from Websites Site scraping tools range from simple home grown scripts to commercial scraping software with embedded Web browsers that can parse HTML and store scraped data in databases Site scraping can be used for legitimate purposes such as search engine indexing or mashups like comparative shopping tools Site scraping can also offer a way for individual users to quickly and automatically gather data such as stock price information or daily temperatures which can be used for personal research While not blatantly illegal such actions can burden sites with traffic while bypassing online ads Site scraping quickly crosses over from being innocuous to malicious when individuals or businesses reuse scraped data for financial gain The following are just a few of the use cases for site scraping Collecting email addresses from Websites for spam email campaigns Harvesting user information from social network sites or user forums Detecting changes on competitors Websites Gathering product and pricing data to undercut rivals prices for goods and services Plagiarizing content such as news articles blog posts medical information financial research Republishing Website listings such as job board postings real estate listings and phone directories Repurpose scraped content for applications such as comparison shopping sites or reverse phone lookup tools Auction sniping or placing bids on online auction sites within minutes or seconds of the auction ending The actions listed above violate the intended use for application data For Webbased companies site scraping threatens revenues and competitiveness and can even endanger business viability3High Profile Site Scraping Attacks While the vast majority of scraping attacks are not publicized several incidents have garnered national and even international attention Discount Irish airline Ryanair has embarked on a multiyear battle against companies that it believes are scraping its Website Ryanair sent cease and desist notices to over 300 travel reservation and comparison sites in 2008 prohibiting them from scraping the Ryanair Website Ryanair subsequently sued companies in Germany Spain The Netherlands and Ireland for scraping flight data and then selling airline tickets to customers at inflated prices Ryanairs legal action against site scrapers resulted in multiple lawsuits and the attempted cancellation of flights booked through third party sites Ryanair is not alone several other airlines including American Airlines and Southwest Airlines have sued travel sites for their site scraping practices Southwest Airlines claimed that scraping by FareChase and Outtask constituted Computer Fraud and Abuse and Trespassing and led to Damage and Loss for the carrier Although the cases were never resolved in the Supreme Court FareChase was eventually shuttered by parent company Yahoo and Outtask was purchased by travel expense company Concur In another case event planning Website Cvent sued rival Eventbrite for hiring a third party contractor to scrape Cvents Website for event venue information Eventbrite subsequently republished the scraped content on its own site In October 2010 Cvent and Eventbrite settled the litigation with Eventbrite agreeing that it would limit the scope of its venue listings and it would not scrape nor hire third parties to scrape the Cvent site Many other companies including eBay and Facebook have taken legal actions against scrapers that harvest user information and product listings An eBay lawsuit against Bidders Edge resulted in an injunction preventing Bidders Edge from harvesting data from the eBay Website FaceBook has sued several pornography and dating sites that had scraped FaceBook user profiles One such site LovelyFacescom displayed 250000 user profiles that had been scraped from Facebooks Website The LovelyFacescom creators used an automated Facebot to scrape one million profiles to a FacetoFacebook database Then Facebook profile photos were analyzed by facial recognition software to classify users into categories such as easy going smug climber sly and funny Facebook users were then showcased on the LovelyFacescom Website4 Debuting in February 2011 the LovelyFacescom Website showcased hundreds of thousands of scraped Facebook user profiles LovelyFacescom was quickly taken down after Facebook threatened legal action Recent highprofile incidents represent a small fraction of all site scraping attacks Site scraping has become a pervasive challenge for hundreds of thousands of Webbased businesses Scraping Tools and Techniques Dozens of vendors advertise site scraping solutions that quickly and efficiently harvest information while saving clients hundreds of thousands of manhours and money Because site scraping software can be easily developed many different tools have sprung up to scrape Web content for a multitude of purposes Scraping vendors brazenly claim that their solutions can gather sales leads capture job postings harvest product pricing data collect dating site information and duplicate online databases Such use cases are often illegal because they violate the Terms of Use policies of the targeted sites Site scraping software ranges from simple custom scripts to advanced software tools with builtin browserlike capabilities to parse HTML and DOM Document Object Model and to interpret JavaScript Some scraping tools have been designed to impersonate normal usersthey provide Internet Explorer or Mozilla Firefox browser agent information they can login to privileged areas of a Website and they can limit the rate of requests to simulate manual Web browsing Many scraping tools also include Web site crawlers that help automate initial configuration Impervas research organization the Application Defense Center ADC has observed a multitude of site scraping attacks against online phone directories finance sites job postings sites and many more Analyzing real application traffic including Tor honeypot logs the ADC has uncovered a variety of site scraping attacks While some advanced attacks leveraged scraping software such as AutoHotkey others relied on homegrown scripts In one case a Microsoft Excel spreadsheet distributed by eTrader Zone was used to scrape historical stock quotes from the Yahoo Finance While not illegal or malicious this tool could potentially violate the sites Terms of Use policy by exceeding reasonable request volumes5Site Scraping Mitigation Strategies There are several ways that businesses can reduce or eliminate site scraping take legal action against site scrapers implement barriers in the Web application to hinder scraping attacks and block scraping clients using a Web Application Firewall Since there are no clear laws that prevent the harvesting of public data using legal channels to stop site scraping can be challenging and expensive and require years to resolve Victims must clearly demonstrate that site scrapers have violated the Terms of Use policy for the Website Victims have legally prohibited site scraping by proving that defendants committed Trespass to Chattels for misusing personal property or performed Computer Fraud and Abuse or Unauthorized Access While legal decisions in scraping cases have been mixed many defendants stop scraping victims sites in order to avoid further legal action Alternatively organizations can prevent site scraping activity by building antiautomation obstacles into their applications There are options like CAPTCHAs and code obfuscation that can prevent scriptbased scrapers from harvesting content However more advanced scraping tools can evolve to circumvent such measures rendering codebased mitigation techniques ineffective over the long term Lastly organizations can deploy a Web Application Firewall to proactively detect and block scraping attacks Since site scrapers can be extremely difficult to differentiate from legitimate users identifying scrapers can be extremely challenging While simple scraping tools are relatively easy to detect advanced scraping software may require a combination of detection methods The following are a list of security measures that can be used by a Web Application Firewall or implemented via code changes to prevent site scraping attacks Use cookies or JavaScript to verify that the client program is a standard Web browser Most simple scraping tools cannot process complex JavaScript code or store cookies To verify that the client is a real Web browser inject a complex JavaScript calculation and determine if JavaScript is correctly computed Implement CAPTCHAs to verify that the user is human CAPTCHAs1 can significantly hinder site scraping attacks However bots are increasingly finding ways to circumvent CAPTCHAs Up to 60 percent of bots can crash through CAPTCHAs according to recent security research2 Nevertheless CAPTCHAs are still an effective defense against many types of scraping agents Rate limit requests Automated clients typically request Web pages much more frequently than real users Advanced scraping clients will try to evade detection by slowing down scraping request rates However automated clients will expose themselves by requesting Web content after a consistent time period Scrapers are also more likely to open an unusually high number of concurrent connections and access many more pages than most users Some scrapers will only access html files and ignore images and other binary files Obfuscate data Site scrapers are designed to extract text from Web pages Displaying Web content as images or flash files can hinder site scrapers Alternatively because most scraping tools cannot interpret JavaScript or CSS applications can compile text using script or style sheets to evade scraping tools Detect and block known malicious sources Since competitors often perpetrate scraping attacks blocking competitors IP address ranges can deter scraping activity Many site scrapers use evasion techniques to conceal their identity such as anonymous proxies Tor network servers or leased botnets Detecting and blocking known malicious sources can hinder scraping attacks 1 CAPTCHAs are tests to distinguish between computers and humans A common CAPTCHA requires that users type characters from a distorted online image 2 Botnets Target Websites with Posers  Dark Reading June 1 20106 Detect and block known bot agents and scraping tools Most scraping activity is performed using simple tools that have identifiable signatures such as a unique user agent string Tools that recognize bot agents can immediately stop these scraping tools Constantly change html tags to deter repeated scraping attacks Scrapers must be programmed to parse sites and extract desired data Altering HTML tags and Web structure by for example adding white spaces and comments changing tag names hyperlink strings and URLs can impede repeat site scraping attacks Use fake Web content images or links to ensnare site scrapers If an organization suspects that its proprietary data is being plagiarized it can produce fictitious content as proof Monitoring services purposely designed to identify plagiarism or even a simple online search can uncover fictitious content published on other sites Since some scrapers include an automated crawler creating a hidden hyperlink to a fake page can trap an automated scraper Since several of the detection techniques are not decisive they can be used in combination to accurately pinpoint site scraping attacks For example excessive Web requests may indicate a scraping attack or it may reveal an AOL proxy address representing hundreds of simultaneous users Some legitimate users disable cookies and JavaScript However extremely fast request rates detected together with browser irregularities often indicate an automated attack such as site scraping If organizations implement the mitigation techniques listed above they can significantly reduce or eliminate site scraping Practical Measures to Reduce Site Scraping Attacks Site scraping attacks can reduce company revenues and profits by stealing Web site visitors and copying valuable content Scraping can also undermine business competitiveness because rivals can use scraped pricing information to undercut product prices Therefore site scraping attacks can cost organizations millions of dollars in lost business To mitigate site scraping activity victims can take legal action against perpetrators they can implement barriers in their applications to stop automated users or they can proactively block site scraping exploits The Imperva SecureSphere Web Application Firewall provides an effective defense to eliminate site scraping attacks in realtime SecureSphere offers unique detection techniques that can identify and stop automated attacks like site scraping In addition SecureSphere offers flexible customization allowing organizations to fine tune security rules based on applicationspecific requirements SecureSphere Protection against Site Scraping Imperva SecureSphere offers multiple layers of protection to identify and stop site scraping SecureSphere fortifies Web applications using Protection against known malicious sources Many site scrapers use anonymous proxies or Tor networks to conceal their identity Site scrapers also leverage botnets for concealment or for largescale scraping attacks Impervas industryfirst reputation based security service detects and optionally blocks anonymous proxies Tor networks and known malicious IP addresses ThreatRadar receives near realtime feeds of known bad users from security research organizations located around the world Bot agent detection Site scraping is typically performed by dedicated scraping software SecureSphere can identify and stop hundreds of the most common bot agents that are used to perform site scraping Cookie enforcement Most site scraping agents can imitate a legitimate Web browser but they do not support all browser capabilities such as storing cookies set by a Web server using JavaScript SecureSphere can require the existence of these cookies to verify that the client program is a true Web browser Forceful browsing SecureSphere can be configured to detect forceful browsing when users do not access Web pages in an expected order SecureSphere can confirm that the Web pages referers are from the same site Users can create custom rules to enforce specific referers per URL enforcing the specific order of Web page requests Rate limiting Typically site scraping agents request Web pages much more quickly than a human user Site scrapers also usually accessand harvestmany more pages than average users SecureSphere can be configured to detect and block excessive requests7 Custom security rules Because site scraping can be difficult to distinguish from legitimate requests analyzing multiple attributes together will more accurately identify site scraping Custom Web security rules can be defined that will block a user that requests dozens of pages in a short period of time does not have a valid session token and does not have a correct Web page referrer Custom rules can be built using over two dozen match criteria including HTTP protocol violations number of occurrences user agents signatures referrer URL request header and cookie data Using SecureSpheres powerful custom security rules organizations can accurately block site scrapers with an extremely low rate of false positives Configuring a custom site scraping policy in SecureSphere Realtime monitoring and analytics SecureSphere offers detailed security alerts that enable customers to monitor scraping attacks and suspicious events For example if alerts reveal suspected scraping activity from a competitors IP address a customer can create a rule to permanently block that IP address Security alerts include the entire Web request the source address the time of day type and severity of the alert and a link to the policy that triggered the violation Clear complete alerts provide customers full visibility into site scraping activity Building a Strategy to Stop Site Scraping Attacks Site scraping attacks target a myriad of organizations including online retailers auction sites airline real estate social networking online job listing companies and many more Site scraping attacks can cost organizations millions of dollars because perpetrators can repost content steal customers and undercut product prices Mitigating site scraping attacks is difficult because site scrapers are hard to distinguish from legitimate users Therefore an effective solution must evaluate multiple attributes to correctly identify site scrapers SecureSphere offers ironclad protection against automated attacks like site scraping because it detects malicious source IP addresses bot user agents session information and other unusual activity Detailed security alerts and a powerful graphical reporting engine make it easy for organizations to monitor site scraping activity and measure mitigation efforts Organizations can rely on Imperva SecureSphere to stop site scraping attacks The marketleading SecureSphere Web Application Firewall offers protection against a myriad of Web application threats including SQL injection XSS CSRF directory traversal site reconnaissance sensitive data leakage message board comment spam and more Imperva SecureSphere is trusted by organizations around the world to stop Web application security threats like site scrapingwwwimpervacom  Copyright 2014 Imperva All rights reserved Imperva and SecureSphere are registered trademarks of Imperva All other brand or product names are trademarks or registered trademarks of their respective holders WP SITESCRAPINGATTACKS 03141About Imperva Imperva pioneering the third pillar of enterprise security fills the gaps in endpoint and network security by directly protecting high value applications and data assets in physical and virtual data centers With an integrated security platform built specifically for modern threats Imperva data center security provides the visibility and control needed to neutralize attack theft and fraud from inside and outside the organization mitigate risk and streamline compliance  Craigslist Fighting to Keep CDA 230 First Amendment Case Alive in South Carolina  Main  Mixed Result for Google Today in European Courts  September 17 2010 Did IqbalTwombly Raise the Bar for Browsewrap Claims Judge Leonie Brinkema of the Eastern District of Virginia issued an interesting opinion earlier this week in a case involving one companys multiple acts of datamining a competitors website with a screen scraping program Among other things the court held that the plaintiff had failed to allege a valid breach of contract claim a claim based on data use restrictions in a browsewrap presentation The court said that the plaintiffs unadorned allegations that the terms of the TOUs Terms of Use are readily available for review and that the defendants had an opportunity to review the terms fell short of the pleading standards set out in a pair of recent Supreme Court decisions In Bell Atl Corp v Twombly  550 US 544 2007 the high court said that allegations must be sufficient to nudge a claim from conceivable to plausible Two years later in Ashcroft v Iqbal  129 S Ct1937 2009 the court stated that if the wellpled facts do not permit the court to infer more than the mere possibility of misconduct the complaint has allegedbut it has not shownthat the pleader is entitled to relief The TwomblyIqbal pleading standard was not met here the court said In order to allege a plausible contract claim based on a browsewrap agreement the website user must have had either actual or constructive knowledge of the website terms and must also have manifested agreement to those terms The court looking at screenshots submitted by the defendant remarked that the terms were buried at the bottom of the first page in extremely fine print that users must affirmatively scroll down to the bottom of the page to even see the link Against the evidence of these screenshots the court said that the plaintiffs allegations that the plaintiffs conclusory allegations about the defendants knowledge of the website terms and assent to those terms merely by accessing the site are plainly insufficient under the Iqbal and Twombly standard to state a plausible claim for relief So now I am wondering if the courts injection of IqbalTwombly into the browsewrap equation has made matters more difficult for sites seeking to protect their data with bottomofthepage behinda hyperlink terms of use contracts Obviously IqbalTwombly set out a rule of pleading not a rule of substantive contract law However it looks to me like the court is saying that conclusory pleadings about the existence of a browsewrap contract will not overcome a screenshot indicating only a modest effort to bring the contract to the users attention Practically speaking websites will have to do more if they expect their terms of use to be enforced At least in this district Over at the plaintiffs website  you can see the terms of use link sitting there among other links white text against a black background at the bottom of the page Not exactly conspicuous but certainly no worse than many other website terms presentations I wonder if this ruling will lead Cvent to reconsider its strategy of leaving its events database wide open to any internet user without a password or any sort of authentication protected only by restrictions in a terms of use document accessible via a hyperlink at the bottom Subscribe to this blogs feed T W I T T E R U P D A T E S Pretty chesty post from one of the ICANN has a license to print money crowd httpbitly9MUGZq 19 days ago Deparment of Commerce is seeking public comment on relationship between copyright protection and innovation httpbitlycWWFqT 19 days ago Blogged Will the Supreme Court Ever Hear an Information Privacy Case httpbitlydcDK2H 19 days ago RT  aallcopyright  YouTube Inks Deal With French Copyright Society SACEM httpowly2MV98 23 days ago RT  MarieAndreeW   bnatechlaw Wrote post about the French Google Suggest case and translated bits of the ruling httpbitlyab5pSP 23 days ago follow me on Twitter R E C E N T P O S T S Will the Supreme Court Ever Hear an Information Privacy Case Mixed Result for Google Today in European Courts Did IqbalTwombly Raise the Bar for Browsewrap Claims Craigslist Fighting to Keep CDA 230 First Amendment Case Alive in South Carolina Lawyers Love Social Media Pro Se Litigants Secure Big Victory for Domain Owners in Ninth Circuit Trademark Ruling Utah ESignatures Ruling Could Have Broad Reach EMail Headers Designed to Elude Spam Filters Arent Unlawful in California High Court Sidesteps Big Privacy Questions in Quon Pager Case Improbable Argument Lifts Katrina Scammers Identity Theft Conviction R E C E N T C O M M E N T S Nicolas on Mixed Result for Google Today in European converted by Web2PDFConvertcomof the web page Are browsewrap terms of use no longer a prudent strategy or was Cvents execution of browsewrap contracting a little bit off the mark The plaintiff vigorously argued in its brief that the question of the defendants knowledge of the website terms and its assent to them by accessing the site data were factual matters that could not be resolved on a summary judgment motiona losing argument in this case Neither party raised IqbalTwombly in their briefs The court brought it up on its own Along the way the court rejected the plaintiffs argument that the browsewrap restrictions were enforceable in view of Virginias adoption of the Uniform Computer Information Transactions Act UCITAa uniform law that many believe put its thumb on the scale in favor of common browsewrap contracting practices There is a lot more worth reading in this opinion Such as the courts rejection of the plaintiffs Computer Fraud and Abuse Act claim which foundered largely on the courts conclusion that the CFAA prohibits unlawful access not unauthorized use And the courts holding that the plaintiff could go forward with a reverse passing off trademark claim based on the defendants alleged copying of the plaintiffs event data and passing it off as its own The case is Cvent Inc v Eventbrite Inc  No 10cv481 ED Va Sept 14 2010 Judge Brinkema is no stranger to interesting cyberlaw disputes She ruled in the GEICO v Google lawsuit that the sale of a trademark as a search engine keyword is a commercial use of the mark but such use to trigger a competitors advertisements is nevertheless not infringing due to lack of evidence of consumer confusion  Posted by Thomas OToole on September 17 2010 in Contracts  Permalink Comments Post a comment Comments are moderated and will not appear until the author has approved them You can use HTML tags like b i and ul to style your text URLs automatically linked Your Information Name and email address are required Email address will not be displayed with the comment Name Email Address Web Site URL Post Preview Google Today in European Courts James OBrien on EMail Headers Designed to Elude Spam Filters Arent Unlawful in California Joe Wagner on EMail Headers Designed to Elude Spam Filters Arent Unlawful in California Thomas OToole on EMail Headers Designed to Elude Spam Filters Arent Unlawful in California Joe Wagner on EMail Headers Designed to Elude Spam Filters Arent Unlawful in California Brian on Domain Registrant Prevails in Gripe Site Case Thomas OToole on Congressman Wants Consumers to Have Personal Information TakeDown Right Dave Delany on Congressman Wants Consumers to Have Personal Information Take Down Right Mr Gunn on Congressman Wants Consumers to Have Personal Information Take Down Right Phil Cahan on Readability and Web Contracts N O T I C E T O S U B S C R I B E R S BNA Blogs Terms of Use C A T E G O R I E S Accessibility Antitrust Attorneys Authentication Broadband Communications Decency Act Communications Policy Computer Crime Consumer Protection Content Regulation Contracts Copyrights Defamation Diversions Domain Names DRMs Electronic Discovery Electronic Surveillance Federal Preemption Free Speech Government Services Identity Theft Information Security Intellectual Property Internet Governance converted by Web2PDFConvertcomJudicial Process Jurisdiction Legal Profession Marketing Mobile Devices Net Neutrality Network Security Online Publishing Open Source Patents Political Activity Privacy Search Engines Social Networks Standards Taxation Trademarks UserGenerated Content Virtual Games A R C H I V E S October 2010 September 2010 August 2010 July 2010 June 2010 May 2010 April 2010 March 2010 February 2010 January 2010 More C O P Y R I G H T Copyright  2010 The Bureau of National Affairs Inc All rights reserved A B O U T TechLaw About BNAs E Commerce and Tech Law Blog converted by Web2PDFConvertcom V0108000  AMB UDSKRIFT AF SØ  HANDELSRETTENS DOMBOG ____________ Den 24 februar 2006 blev af retten i sagen V10899 home as Advokat Dorte Wahl mod OFIR as tidligere Søndagsavisen as Advokat Janne Glæsel afsagt sålydende D O M I denne dom er hovedspørgsmålet om sagsøgte OFIR as som på inter nettet har en boligtjeneste httpboligofirdk herefter boligofir overtræder ophavsretslovens  71 stk 1 subsidiært stk 2 ved at foretage kopiering af data fra den database der er knyttet til sagsøgeren home as hjemmeside wwwhomedk herefter homedk til boligofir Der er yderligere et selvstændigt spørgsmål om hvorvidt sagsøgte ved på boligofir at stille dybe link til rådighed til ejendomsannoncer uden om sagsøgers forside overtræ der markedsføringslovens  1 og et subsidiært spørgsmål om hvorvidt sagsøgte  samlet set  ved sin handlemåde overtræder markedsføringslovens  1 Der er under sagen endvidere bla rejst spørgsmål om hvorvidt sagsøg eren overtræder konkurrencelovens  6 og  11  2  Påstande Sagsøgerens påstande 1 Sagsøgte tilpligtes at anerkende at have været og være uberettiget til ved etableringen og vedligeholdelsen af boligtjenesten boligofir tidligere BoligForum på adressen httpboligofirdk tidligere wwwboligforumdk boligofirpå internettet a at foretage løbende og systematiske udtræk af oplysninger fra den til sagsøgerens hjemmeside wwwhomedk homedk knyttede database ved at fore tage løbende og systematiske søgninger på sagsøgerens hjemmeside homedk der frembringer skærmbilleder med sagsøgerens resultatliste hvorfra sagsøgte uddrager de i bilag R markerede 13 data som sagsøgte kopierer til sagsøgtes database samt b at stille link til rådighed på boligofir til annoncer på homedk udenom sagsøgerens søgekriterier og forside 2 Sagsøgte tilpligtes at betale til sagsøgeren erstatning og vederlag på kr 25000000 eller et mindre beløb efter rettens skøn for den skete krænkelse af sagsøgerens rettigheder i henhold til ophavsretsloven og markedsføringsloven med tillæg af sædvanlig procesrente fra den 30 april 2001 til betaling sker Sagsøgte har nedlagt påstand om frifindelse Der er mellem parterne enighed om at benytte ordene kopiere og ko piering som samlebetegnelse for ophavsretslovens  71 stk 1s udtryk fremstille eksemplarer eksemplarfremstilling og gøre tilgængeligt tilgængeliggørelse EuropaParlamentet og Rådets direktiv af 11 marts 1996 om retlig beskyttelse af databa ser 969 herefter databasedirek tivet benytter i art 7 stk 1 og 5 betegnelsen udtræk ogeller genan vendelse Direktivet blev implemente ret i dansk ret i 1998 Sagsøgte gør  3  under sagen gældende at direktivet er et totalharmoniseringsdirektiv mens sagsøger mener at direktivet er et minimumsdirektiv Sagsfremstilling Parterne Sagsøgeren er et datterselskab af Danske Bank AS Homekæden drives på franchisebasis Sagsøgeren er fr anchisegiver og de enkelte ejen domsmæglerforretninger har status som francisetagere Franchisegiver og franchisetagerne er selvstændige juridiske enheder og har ingen gen sidige ejerandele Sagsøgeren stiller markedsføringsværktøjer og andre faciliteter til rådighed for ejendoms mæglerforretningerne herunder in ternethjemmesiden homedk med dertil knyttede databaser Sagsøgte er et datterselskab af medievirksomheden Søndagsavisen as Sagsøgte har under sit forretningsområde internetportalvirksomhed og udbyder annoncetjenester og services  herunder boligtjenesten boligofir Sagens begyndelse Ved brev af 5 juni 1998 med overskriften  Gratis boligannoncering på internet rettede Søndagsavisen as henvendelse til sagsøgeren Home Gruppen AS med indbydelse til omk ostningsfrit at komme med i et nyt boligindeks på internettet der både bliver Danmarks første og stør ste landsdækkende boligmarked Af sk rivelsen fremgik at det nye bolig indeks skulle starte den 6 juni 1998 og endvidere bla  Målet  er at samle alle de ejendomme der udbydes i hele landet og dermed give alle boligkøbere og sælgere i Danmark mulighed for på ét sted at finde de mest relevante informationer om ejendomme til salg  Vi søger et samarbejde hvor alle ejendomsformidlere leverer materiale  hvilket også vil være med til at skabe større trafik hos dem der allerede har egne sider på Internettet BoligForum bliver åben  og gratis  for alle   4  Et landsdækkende boligindeks opfylder desuden et af de ønsker der blev udtrykt af den Idégruppe som daværende erhvervsminister Mimi Jakobsen nedsatte i juni 1996 med det formål at gøre det nemmere og billigere at handle bolig Gruppen fandt nemlig at et sådant landsdæk kende indeks er en væsentlig forudsætning for at etablere et mere effek tivt og konkurrencepræget boligmarked Vi mener at fordelene for både forbrugere og ejendomsformidlere er åbenlyse Ejendomsformidlere får muli ghed for hurtigt at nå ud til en bred kreds af købere helt uden geografiske begrænsninger Forbrugerne kan nemt og på en enkel og overskuelig måde få overblik over boligmarkedet Ved at klikke sig ind får man et overblik over hvilke boliger der er til salg inden for det geografiske område hvor man er interesseret i at bo Samtidig får man oplyst boligtype størrelse prisniveau og mægler  uden at være nødt til at kontakte samtlige ejendomsformidlere i området én ad gangen Søndagsavisen as har allerede med wwwforumdk et af Danmarks mest besøgte sites på Internet wwwforumdk rummer i dag annonceinfor mationer om job biler markedsplads og kontaktannoncer  og det var oplagt at udvide med boliger I dag hvor vi har en markedsplads der fungerer håber vi gennem denne henvendelse at kunne opbygge et samarbejde direkte med jer  Efter et møde og telefonisk kontakt mellem parterne rettede sagsøgeren henvendelse til Søndagsavisen as ved brev af 2 juli 1998 hvoraf bla fremgik  Vi må afvise det dd telefonisk frem satte tilbud om gratis annonceplads i Søndagsavisen til en værdi af ca 250 000 kr til afvikling i løbet af 1998 til gengæld for at give Søndagsavise n adgang til automatisk at hente visse data fra wwwhomedk samt etablere relevante links fra wwwboligforumdk til homes internetplatform Dels vurderer vi ikke umiddelbart Søndagsavisen som en tilstrækkelig interessant markedsplads i forhold til vort medievalg i øvri gt Dels vurderer vi at det fremsat te tilbud er økonomisk uinteressant i forhold til den værdi vi vurderer en sådan aftale generelt vil have for Søndagsavisen Vi må videre fastholde at vi ikke anser markedsføringslovens spilleregler for overholdt for så vidt angår god markedsføringsskik mv ligesom vi igen skal gøre opmærksom på at vi betragter den af Søndagsavisen an vendte fremgangsmåde i forbindelse med projektets gennemførelse herunder indhentning af de indlysende nødvendige forhåndsgodkendelser som helt uacceptabel Som nævnt i vort brev af 10 juni 1998 anser vi endvidere den nuværende funktionalitet for teknisk uforsvarlig Vi forbe holder os ret til senere at rejse kr av for den skade homes image måtte lide som følge heraf Vi skal således igen anmode Dem om uden ophold at ophøre med at anvende data fra homes internetplat form herunder at ophøre med at foretage automatiske søgninger i homes internetdatabase  5   Det vi kan tilbyde pt er at Søndagsavisen etablerer et link fra siden wwwboligforumdk til wwwhomedk   Vi går ud fra at ovenstående bliver effektueret senest den 3 juli så vi kan undgå at tage retslige skridt i forhold til Søndagsavisen Der blev herefter udvekslet yderligere korrespondance uden at parterne nåede til enighed Ved skrivelse af 21 oktober 1998 rettede Søndagsavisen as henvendelse til Erhvervs og Sels kabsstyrelsen med kopi til erhvervsminister Pia Gjellerup Søndagsavisen as henviste bla til Høringen vedr Lov om ændring af lov om omsætning af fast ejendom mv og henledte op mærksomheden på at Søndagsavisen as allerede havde et søgesystem wwwboligforumdk på internettet svar ende til lovforslagets intentioner Af skrivelsen hvori Søndagsavisen as anmodede om et møde for at drøfte lovforslagets tekniske gennemf ørelse fremgik endvidere bla  Søgesystemet  blev igangsat udviklet på baggrund af Boligrapporten som daværende erhvervsmini ster Mimi Jacobsen igangsatte i juni 1996 Søndagsavisen tog den 23 januar 1998 kontakt til Dansk Ejendoms mæglerforening ved direktør Palle Ulst rup hvor vi inviterede til samar bejde men det fandt desværre ingen interesse  kan vi konstatere at forbrugerne har været meget ivrige brugere af søgesystemet siden idriftsættelsen I modsætning hertil har Dansk Ejendomsmæglerforening samt et par af de store kreditforeningskontrollere de ejendomsmæglerkæder været meget passive og endog ligefrem ob struerende overfor forbrugernes anvendelse af søgesystemet Søgesystemet  er nemt og enkelt samt giver alle lige muligheder for at være med  Erhvervsministeren afviste ved brev af 9 november 1998 Søndagsavi sens anmodning om et møde under henvisning til at det ikke er hensig ten at Erhvervs og Selskabsstyrelse n skal godkende de enkelte private søgesystemer Af skrivelsen fremgik endvidere bla  Det har glædet mig meget at der nu fra flere sider er taget initiativ til at etablere søgesystemer og dermed virkeliggøre tankerne bag Boligrapporten Det viser at priv ate aktører kan se mulighederne i at oprette søge 6  systemer som jeg er sikker på vil være til gavn for såvel købere som sælgere Ideen med lovforslaget er netop at de r i privat regi bliver indført veleg nede søgesystemer over udbudte ejendomme Hjemlen for Erhvervs og Selskabsstyrelsen til oprettelse af søgesystemet er da også kun tænkt anvendt som en nødbremse hvis det mod forventning skulle vise sig at der alligevel ikke kommer noget tilfredsstillende system ud af de private initiativer  Parterne på internettet Sagsøgerens hjemmeside Ved at besøge sagsøgerens hjemmeside på internettet homedk kan interesserede bla få oplysninger om hvilke ejendomme homeejendomsmæglerne på landsbasis har til salg på besøgstidspunktet Der er på hjemmesiden nu også oplysninger om ejendomme der er udbudt af nogle konkurrerende ejendomsmæglerforretninger feks Nybolig Grundlaget for hjemmesiden homedk er den til homedk knyttede data base homedkdatabasen hvor de oplysninger som præsenteres på hjemmesiden er samlet Hvordan oplysningerne samles i databasen og hvilken kontrol der udøves mht til oplysningerne før de præsenteres på hjemmesiden vil fremgå af forklaringerne navnlig vidneforklaringen af sagsøgerens ITchef Hanne Brandt med udgangspunkt i et af sagsøge ren udarbejdet skematisk hjælpebilag der er optrykt i forbindelse med gengivelsen af vidnets forklaring nedenfor Sagsøgerens hjemmeside har gennem årene undergået forandringer dels med hensyn til layout dels med hens yn til detailfunktionalitet og  strukturering Der er løbende blevet stillet flere oplysninger og flere søgemuligheder til rådighed men den grundlæggende funktionalitet har været uændret Hjemmesiden har i et hierarkisk opby gget system bestå et af en forside og flere lag af un dersider Forsiden som er den side den besøgende altid vil komme til ved at søge wwwhomedk har indeholdt en række muligheder som den besøgende har kunnet opsøge ved at klikke på en af de tilbudte overskrifter der fungerer som indgangsnøgle til emnet Blandt mulighederne har brugerne kunnet vælge at søge mål 7  rettet mod ejendomme til salg Der har herefter ved brug af detailsøge kriterier feks beliggenhed pris størrelse været mulighed for at søge mere specifikt efter ejendomstyper svarende til den enkelte brugers in teresse Denne søgning har udmøntet sig i en liste resultatliste over de ejendomme der svarer til de af brugeren anvendte søgekriterier For den enkelte ejendom på listen har der foreligget et gennem årene sti gende antal oplysninger som der ved at klikke på en udvalgt ejendom med adgang til ejendommens annonceside har været mulighed for at få yderligere suppleret og uddybet bla i form af beskrivelse billeder de tailbeliggenhed etc Sagsøgeren har under sagen præsenteret 3 variationer af hjemmesiden fra henholdsvis årene 1998 2003 og 2005 hvis forsider  i den nævnte rækkefølge  så således ud  8   9  Hjemmesiden fra 1998 Hjemmesiden fra 1998 var den aktuelle på tidspunktet for tvistens opstå en og sagens anlæg og var i det væsentlige uændret under den største del af sagens forberedelse Ved blandt 1998forsidens søgemuligheder bla søgning på sagsnum mer fra avisannoncering  se nærmere på ovenstående illustration at klikke på BOLIGER fremkom nedenstående underside  hvoraf bla fremgik at der på dette tidspu nkt var 4681 boliger til salg Ved at klikke på Almindelig søgning  fremkom en underside hvor bruge ren havde mulighed for at vælge efter hvilke nærmere kriterier boligtype beliggenhed kontantpris og større lse der skulle søges efter boliger til salg Efter at have klikket på sine valgte kriterier blev brugeren præ senteret for en resultatliste  der matchede de valgte søgekriterier se føl gende eksempel hvoraf fremgår at resultatlisten indeholdt 9 resultatda 10  ta vejnavn brutto netto udbetalin g kontantpris sagsnummer grund areal boligareal og antal værelser Ved at klikke på den enkelte ejendom fremkom en side med et billede af ejendommen ejendomsannoncesiden og en række oplysninger herunder feks også nøjagtig adresse og byggeår samt en beskrivelse se eksemplet nedenfor  11   12  Hjemmesiden fra 2003 præsenterede sig væsentlig anderledes end 1998 udgaven med flere nye valgmuligheder feks myhome og home Fi nish og der kunne som lynsøgning søges direkte efter boliger på grundlag af ønsker om pris boligtype og postnummer I øvrigt var funktionaliteten grundlæggende uændret og der kunne fremdeles søges di rekte på grundlag af sagsnummer fra avisannoncen En skærmudskift fra maj 2004 angav at der var 16612 boliger til salg Som noget nyt i for hold til 1998udgaven kunne man nu ved at klikke vi a home skyline  se de udvalgte boliger fra luften Der var tilføjet nye oplysninger om de enkelte ejendomme på resultatlisten feks oplysninger om kælder og antal plan Der var på hjemmesiden endvidere oplysninger om ejendomme til salg hos konkurrenterne Nybolig og Estatemæglerne samt en række mindre mæglervirksomheder Ved et enkelt klik på en ejendom til salg hos feks Nybolig kunne den interesser ede komme direkte til den pågælden de ejendoms side på Nyboligs hjemmeside Vedr den enkelte ejendom på ejen domsannoncesiden kunne brugeren feks klikke for at se kort og ruteplan kommuneinformation med oplysninger om skat daginstitutioner mv for at bestille salgsopstilling og få oplysninger om flyttehjælp hos Europcar Brugeren kunne også bestille sundhedsattest og tilstandsrapport og indhente indretningsforslag til boligen Der kunne på denne side som noget nyt klikkes for at blive præsenteret for en række fotos af ejendommen både indvendig fra ejendommens forskellige rum og de udvendige facadesider og have Hjemmesiden fra 2005 er for så vidt angår forsidens opsætning på ny ændret væsentligt og der er kommet nye oplysninger og søgemuligheder til Af et forsideprint fra 2005 frem går bla at der var 14863 boliger til salg Der var som noget nyt adgang til information om Forældrekøb og home BedsteBud var introduceret Man kunne klikke sig til at se de nye homereklamefilm fra TV Der var mulighed for at få information via tasterne Om home Pre sse og Boligleksikon Der kunne via indtast ninger af oplysninger om sagsnummer kontantprisniveau ønsket arealstørrelse beliggenhed i amt mv søges til udbudte ejendomme der mat chede kriterierne  13  Ved at klikke på søg bolig på fors iden og efter herefter at have valgt indtastning blandt de søgekriterier der fremkom på grundlag af klikket fremkom som i de tidligere udgaver en resultatliste fra hvilken der kunne klikkes direkte til den enkelte ejendoms annonceside På denne var antallet af data yderligere udbygget ligesom opsætningen og systematikken vær ændret Der kunne klikkes for 360 grvisning Ved klik kunne ses Interaktiv plantegning over ejendommen og som tidligere bla KRAK kort med ejendommens beliggenhed kommuneoplysninger mv Sagsøgtes hjemmesider Sagsøgtes hjemmeside i 199899 Søndagsavisen as internetservice forum gjorde som nu brug af banne rannoncer Fra hjemmesidens por tal i venstre side kunne brugere blandt en flerhed af muligheder feks BilForum RejseForum Chat og Computer ved et klik aktivere BoligForum hvorefter fremkom en side med søgemuligheder for faste ejendomme beliggenhed boligtype areal og bruttoydelse pr måned Efter klik på de af brugeren valgte sø gekriterier og et efterfølgende klik på Find Bolig blev brugeren præsenteret for en resultatlisteside der kunne se således ud  14  Ved på resultatlisten med et dobbeltklik at aktivere home under rubrikken Mægler blev brugeren stillet om til sagsøgerens hjemmesides for side Ved at klikke på ejendommens gadenavn under Beliggenhed blev brugeren ledt direkte til ejendommens side på sagsøgerens hjemmeside  15  Sagsøgte har fremlagt følgende skærmprint af hjemmesiden ofirdk og boligofir  16  Sagsøgtes nuværende hjemmeside  wwwofirdk  se skærmprint oven for har som tidligere bannerannoncer ing her JyllandsPosten Portal mulighedernes overskrifter er Karriere  Jobsøger og Arbejdsgiver Ehandel  bla Shopping og Rejser Rubrik  Biler Bolig og Kontakt og Services  bla Chat Spil Nyheder og Debat På forsiden er der også mulighed for at søge danske websites feks vedr emner som Computer  Internet Kunst  Kultur Erhverv  Økonomi Sport  Friluftsliv Sundhed  Samliv Underholdning og Erotik På tidspunktet for det fremlagte skærmbillede var der aktuelt 39109 boliger til salg Ved blandt forsidens portalmuligheder at klikke for Bolig hvorved bru geren ledes til boligofir med banne rannoncering som det ses ovenfor for eksempelvis Nykredit LånFinans og DirekteBoligAdvokater og ef terfølgende efter eget valg at indtaste søgekriterier ejendomstype kon tantpris beliggenhed fremkommer en resultatlisteside med et antal boliger der matcher de af brugeren indt astede søgekriterier På et fremlagt print fra denne side ses en bannerannonce for LynLOTTO Resultatlisten indeholder 7 data vej antal værelser  boligens størrelse brutto netto kontantpris og mæglerfirma Ved at klikke på en ejendom fremkommer et rammebillede med supplerende oplysninger fuldstændig adresse grundens størrelse evt kælders størrelse byggeår og udbetaling I rammebilledet er der mulighed for at klikke på Se annonce hvorved brugeren bliver ledt direkte til ejendommens annonceside på ejendoms mæglerfirmaets feks sagsøgerens hjemmeside Ved denne direkte adgang til ejendommens annonceside springes såvel resultatliste som forside på sagsøgerens homedk over Det er ubestridt at der før omstillingen effektueres vises et skærmbillede hvor det op lyses at brugeren nu omstilles til sagsøgerens hjemmeside Når brugeren klikker sig ud af sag søgerens hjemmeside kommer han hun tilbage til boligofir Sagsøgtes resultatlisteside med aktiveret rammebillede og bannerannoncer ser sådan ud  17  De data som sagsøgte på boligofir præsenterer for brugerne vedr de ejendomme der er udbudt til salg af homeejendomsmæglerne overfø res fra homedk på den måde at en intelligent robot en gang i døgnet om natten besøger sagsøgerens hjemmeside hvor den søger på alle udbudte ejendomme Den resultatliste der fremkommer på grundlag af søgningen kopieres over i sagsøgtes database Parterne er enige om at sagsøgte kopierer følgende 13 af i alt 66 data sagens bilag R  Sagsnummer  Url den præcise adresse til ejen domsannoncen hvortil linket hen viser  Ejendommens adresse vejnavn og nummer  Postnummer  Kontantpris  Udbetaling  Brutto  Netto  Boligareal  Grundareal  18   Antal værelser  Kælderareal  Byggeår Sagsøgte tilføjer i sin database følgende supplerende data hvorom nærmere fremgår under vidneforklaringerne  BoligID  Dato  FormidlerID  Ejendomstype Sagsøgeren har siden 2002 haft et samarbejde med andre ejendomsmæglerkæder og forretninger om gensidig præsentation af ejendomme på internettet Formålet med aftalen var ifølge en fælles tekst på internettet at give et bedre overblik over boliger til salg samt skabe større gennemskuelighed på boligmarkedet Af teksten hvor home og Nybolig omtaltes som to af Danmarks stør ste ejendomsmæglerkæder fremgik under overskriften Mæglerkæder samler boliger på nettet endvidere bla  Udvekslingen af boligemner skal også ses i lyset af at flere og flere bo ligkøbere søger bolig via nettet hvilket gør det nødvendigt at skabe stærke hjemmesider i form af profe ssionelle markedspladser hvor kun derne kan finde så stort et udbud af boliger til salg som overhovedet mu ligt  Aftalen er ikke eksklusiv og  samarbejdet kan søges udvidet med en eller flere ejendomsmæglerkæder så ledes at udbudet af boliger der præsenteres på hjemmesiderne i bedst muligt omfang er repræsentativt for det samlede boligmarked  På Nyboligs hjemmeside præsenteres homeejendommene på resultatli sten uden billede Der linkes direkte til ejendommens side på homedk Tilsvarende præsenteres Nyboligejendommene på homedk uden billede og præsentationen finder først sted efter præsentationen af homes egne ejendomme Der linkes fra homedk direkte til ejendommens side hos Nybolig  19  Fra Dansk Ejendomsmæglerforenings hjemmeside Boligsidendk linkes der også direkte til den enkelte ejendo ms side På sin resultatliste gør DE brug af mæglervirksomhedernes logotyper ved angivelsen af den mæg lervirksomhed der har den pågælden de ejendom til salg DE gør ikke brug af bannerannoncer TV2 havde tidligere en boligtjeneste på internettet boligtv2dk På den ne optrådte homemæglernes ejendomme efter aftale Mæglervirksom hederne var også her angivet med logotyper På hjemmesiden var der bannerannoncer Hjemmesiden wwwJubiidk har et boligindeks der også omfatter home ejendomme og hvor der er direkte link til den enkelte ejendom hos sagsøgeren Mediepartnerne Berlingske Tidende Politiken JyllandsPosten Jydske Vestkysten Aarhus Stiftstidende og TV2 har etableret boligsøgetjenesten wwwBoligzonendk  Etableringsomkostninger Sagsøgeren har fremlagt et bilag bilag 9 til illustration af sine omkost ninger vedr homedkdatabasen Bilaget har som overskrift  Omkost ninger Internet I 1000 kr og har i øvrigt følgende indhold 1996 Drift af BAS  Udvikling Udvikling markedsføring ______________ _____________0 1997 Drift af BAS 1040 Udvikling  Udvikling markedsføring _______________ __________1040 1998 Drift af BAS 1234 Udvikling 798  20  Udvikling markedsføring ____________380 __________2412 1999 Drift af BAS 1500 Udvikling 887 Udvikling markedsføring ____________316 __________2703 2000 Drift af BAS 1945 Udvikling 879 Udvikling markedsføring ____________745 __________3569 2001 Drift af BAS 2958 Udvikling 1053 Udvikling markedsføring ___________ 587 __________4598 2002 Drift af BAS 2851 Udvikling 1408 Udvikling markedsføring ____________553 __________4812 2003 Drift af BAS 3986 Udvikling 1064 Udvikling markedsføring ____________889 __________5939 2004 Drift af BAS 4150 Udvikling 2352 Udvikling markedsføring ____________310 __________6812  Til bilaget er der afgivet forklaring af sagsøgerens ITchef Hanne Brandt Til illustration af sagsøgtes omkostninger har sagsøgtes direktør Jørgen Wittenkamp udarbejdet følgende bilag af 24 maj 2004 bilag Z med overskriften  Vedr Omkostninger ifm Boligtjenesten   21  Vi har kunnet sammenstille følgende henførbare omkostninger til OFIR Bolig tidl Boligforum I opgørelsen er ikke medtaget markedsføringsomkostninger som var meget væsentlige i starten i årene 19982000 Endvidere er der ikke prissat omkostningen ved at være inkluderet på OFIR tidl Forum portalen Omkostni ngen til Hardware er taget som en løbende omkostning I omkostningerne er der ikke medtaget andel af henførbart bidrag til direktion advokat mv År__ Udvikling  Vedligehold af tjenesten Hardware ITd rift  administration  1998 1072000 1200000 1999 1302750 1256000 2000 1466460 1266560 2001 980794 1266560 2002 769810 780800 2003 660152 809840 Særligt i opstarten var der tilstødende omkostninger Faldet i ressourceforbrug efter år 2000 er en følge af besparelser og nedskæringer internt i OFIR samt at prisen på linietrafik faldt  Sagsøgeren har i et bilag bilag 13 National kampagneplan 2005 illu streret omfanget af sin reklamekampagne herunder mht reklamespots i TV Der er endvidere fremlagt et eksempel på sagsøgerens publikation homenyt som annoncetillæg til Berlingske Tidende den 22 maj 2005 samt en annonce fra samme avisudgave hvor homenyt bla præsenteres således homenyt  Danmarks største boligavis  hver søndag i Ber lingske Tidende Det er under sagen oplyst at ho meejendomsmæglernes sagsbehand lingssystem er CB BoligSystem om hvilket det markedsføringsmæs sigt bla er omtalt CB BoligSystem er udviklet til at arbejde på Windows platform Det består af et alsidigt grundsy stem samt en pa lette af tillægs moduler der understøtter de helt individuelle behov Grundsystemet tilbyder alt hvad daglig sagsbehandling kræver samt understøtter hele det praktiske forløb  lige fra vurdering til færdigbehand ling  Automatiseringen af alle tænkeli ge rutiner sikrer at processen foregår med højeste sikkerhed og største effektivitet Sagsoplysninger som restgælde og kurser hentes elektronisk og ajourføres automatisk flere do kumenter kan udskrives samtidig osv Systemet tilbyder desuden et om fattende og brugervenligt beregningsmodul der sikrer brugeren det komplette overblik og et perfekt grundlag for økonomisk rådgivning Systemet tilgodeser således hele sagsgangen   22  CB BoligSystem tillægsmoduler CB Systemer lægger vægt på at kunne levere et system der arbejder fleksibelt sammen med det individuelle behov  derfor tilbydes en bred palette af tillægsmoduler Således kan alle  både mægleren der opere rer hjemmefra og den landsdækkende kæde  tilpasse sin forretning med CB BoligSystem et mix af de nødvendige tillægsmoduler  Af et skærmprint fra sagsøgerens hjemmeside fremgår det om homes PROFIL bla  Markedsføring ud over det sædvanlige  Som den første landsdækkende ejendomsmæglerkæde gik home på In ternet i 1996 Den stærke position på Internet kommer sælgere hos ho me til gode da de kommer i kontakt med flest mulige købere hvilket giver de bedste muligheder for en god handel til den rigtige pris I dag udsender home hver uge mange tusinde salgsopstillinger via Internet og hver uge klikker over 200000 besøgen de sig ind på Internet for at se homes boliger  Der har i retten bla været demonstration af opbygningen og funktionen af parternes hjemmesider Forklaringer Sagsøgerens administrerende direktør Niels Bjerregaard  har forklaret at han er uddannet økonom og stat sautoriseret ejendomsmægler Sagsø geren er et datterselskab i Danske Bankkoncernen og har hovedsæde i År0hus hvor 35 er ansat Danske Ba nk AS har fire yderligere brands ud over Danske Bank  BG Bank home Danica og Realkredit Danmark Sagsøgeren er et franchisegiverselskab og har 195 franchisetagerforretninger der er selvstændige ejendomsmæglervirksomheder Sagsø geren som har til opgave at fastholde og udvikle homebrandet stiller værktøjer til disposition for ejendoms mæglerne feks IT markedsføring produktudvikling ledelse og uddannelse Ejendomsmæglernes betaling består af flere komponenter herunder omsætningsafgifter stykafgifter husleje markedsføringsbidrag og leasingafgift vedr IT Mæglerne har ikke andel i sagsøgerens overskud Sa gsøgerens franchisekoncept er tra ditionelt minder vel om McDonalds men er formentlig lidt mere gammeldags  23  Sagsøgeren har  ligesom Danske Bank koncernen i øvrigt  positivt fra valgt bannerannoncering på sin hjemmeside Det kundesegment som har præference for home ville opleve sagsøgerens markedsføring negativt hvis der på hjemmesiden optrådte bannerannoncer Sagsøgeren skal stå for det seriøse og har ønsket at distancere sig fra tidligere tiders brugtbilsimage i ejendomsbranchen Sagsøgeren har det derfor heller ikke godt med at blive sat sammen med annoncerne på sagsøgtes hjem meside Sagsøgeren var blandt de første i verden til at markedsføre ejendomme på internettet Sagsøgeren bestræber sig på at gøre hjemmesiden så at traktiv som muligt og at forenkle scanningsprocessen mest muligt Homedk er entydigt den mest besøgte boligside af alle Vidnet tror at besøgstallet havde været endnu større hvis boligofir ikke havde været der I dag bliver langt de fleste ejendomme mellem 50 og 75  solgt via homedk Sagsøgerens hjemmeside har ca 300000 søgninger pr uge Der er transaktioner fra DEs Boligsiden til homedk på ca 1000000 pr måned Ejendomsmæglerne betaler en markedsf øringsafgift på 875 kr pr ejen dom der er til salg på homedk Dette gælder selvom ejendommen ikke sælges Sagsøgerens budget for 2005 er ca 20 mio kr sidste år var det 1718 mio kr Driftsoverskuddet var si dste år 126 mio kr hvilket ud gjorde ca 27  af selskabets samlede overskud på godt 45 mio kr Driftsomkostningerne for homedk andrager ca 48 mio kr Sagsøgerens basisindtjening var 125 mio kr At homeejendommene  udover på DEs hjemmeside  også optræder på Nyboligs hjemmeside er et strategisk tilvalg Formålet er at opnå flere søgninger Baggrunden for at DE tog initiativ til en boligsøgetjeneste var den nye regel  5a i lov om omsætnin g af fast ejendom Alle  bortset fra den private ejendomsudbyder  er med på DEs side men det er ikke en blomst der er groet i vidnets have  24  Sagsøgeren blev spurgt om man ønskede at være med hos boligsøgetje nesten Boligzonendk men sagsøgeren takkede nej hvilket blev re spekteret Sagsøgeren blev opfordret til at være med på sagsøgtes boligsøgetjeneste men afviste opfordringen som ikke var i sagsøgerens interesse Skadevirkningen ved at være med på sagsøgtes boligsøgetjeneste skal ses i lyset af det miljø som sagsøgeren sættes sammen med Det værste er imidlertid at hvis sagsøgte får lov til at have sagsøgeren med så kan alle andre også få lov Hvis de stor e TVselskaber og aviser slår sig sam men vil besøgstallet på homedk fald e drastisk og brandet vil lide skade alt med den følge at ejendomsmægler ne ikke vil betale for annoncering på sagsøgerens hjemmeside Dette er et skrækscenarium for vidnet Homebrandets værdi falder ved at kunderne via boligofir kan linke sig til den enkelte ejendom udenom sagsøgerens forside med den præsentation som sagsøgeren har ønsket at give kunderne De øvrige ejendoms mæglerkæder afventer hvad der sker med sagsøgeren i denne sag Da OFIR begyndte at annoncere boliger på Internettet var der en anden aktiv website Kapow der senere blev opkøbt af Danske Bank Kapows søgerobotter var på et meget højt niveau De 5 største ejendomsmæglerkæder er home EDC Nybolig Danbolig og Estate Mæglerne Home sælger ca hver 4 ejendom i Danmark svarende til formentlig 21  22000 stk i 2005 I første kvartal solgte home mæglerne 4999 ejendomme Markedsandelen er steget fra ca 20  til ca 25  mens retssagen har verseret Om bannerannoncerne på boligofirs forside forklarede vidnet at sagsøgeren eksempelvis ikke bryder sig om annoncer for Nykredit Lån  Fi nans og boligadvokaterne der udgør konkurrence i forhold til Danske Bankkoncernen Sagsøgtes portal er et sammensurium og ikke en seriøs sammenhæng for sagsøgerens brand Kunderne ønsker i stadig højere grad den rene vare Det er tidens trend  25  Erstatningskravet på 250000 kr er beskedent Vidnet har ikke haft nærmere fokus på tallet som han ikke kan forholde sig til Det afgørende er det principielle spørgsmål sagsøgtes adfærd er det rene snylteri Sagsøgeren har ikke ønsket at fremlægge TV 2kontrakten der er fortrolig og som ikke eksisterer længere Den gled ud i forbindelse med at TV 2 sammen med de store aviser etablerede boligzonendk Hanne Brandt har forklaret at hun er cand  mag i humanistisk datalogi Hun blev ansat hos sagsøgeren i 1996 og har været ITchef siden 1999 Hendes ansvarsområde er homedk Hun indgår aftaler med leverandørerne Homedkdatabasen består af 3 lag Nederst ligger de rå data i midten ligger forretningslogikken struktureri ngen og øverst ligger brugergræn sefladen glasruden Vidnets ansv arsområde er navnlig det midterste niveau En databases størrelse kan måles på flere måder feks på antallet af enheder her ejendomme eller den samlede mængde information i gigabyte Homedk fylder 70 gigabyte i al t inkl billeder hvilket er temmelig meget I relation til følgende hjælpebilag om homedkdatabasens opbygning  26  har vidnet forklaret at C  B er det sagsbehandlingsystem udbudt af C  B BoligSystem som er ejendomsmæglernes primære værktøj i forhold til deres arbejdsopgaver Det bru ges til registrering af den enkelte ejendom sælger og køber provenu og finansieringsberegning juridiske dokumenter herunder mæglings og købsaftaler etc Systemet indehol der alle sagens kernedokumenter Den enkelte mægler har en abonne mentsaftale på C  Bsystemet men sagsøgeren har haft forudgående dialog med C  B om aftalen hvor sagsøgeren bla har stillet krav vedr branding Den enkelte ejendomsmægler betaler selv for abonnementet  27  men fakturering sker via sagsøgeren Hverken sagsøgeren eller de enkel te mæglere bruger C  B BoligSystems standardmoduler Dagligt overføres næsten alle sager i C  Bsystemet til Base 2002 som er en SQLdatabase Dataene overføres i struktureret form Det er ikke samme struktur som ved overførslen fra Base 2002 til homedk Base 2002 anvendes til udveksling af sager de enkelte forretninger imellem således at der kan ske sagsbehandling på tværs af forretnin gerne Databasen bruges endvidere til st atistik samt til overførsel af data til DEs Boligsiden og Nybolig men ikke til at styre franchisekonceptet Sagsøgeren ejer Base 2002serveren Én gang i døgnet laves udtræk vedr de ejendomme der skal overføres til homedk Processen foregår automati sk ved hjælp af et edbprogram som er udviklet eksternt og som sagsøgeren har betalt for Programmet har udviklet sig gennem årene og er efterhånden noget kompliceret Sag søgeren bestemmer helt selv hvad der skal komme ud af programmet I Home MPS samles billeder og bill edtekst og der sker annoncestyring til aviser og andre trykte medier Fra Home MPS sker overførsel til ho medk To programmer som sagsøgeren har bekostet kommunikerer løbende med hinanden om hvorvidt der er matchende eller nye oplys ninger der skal overflyttes Én gang i døgnet overføres FTPteknisk fra Nyboligmæglerne og andre selvstændige mæglere et udtræk so m sagsøgeren lægger ind i databa sen Der er ikke noget prog ram der styrer indsamlingen OBHI er et ingeniørfirma der fo r størstedelen af mæglernes vedkom mende laver tilstandsrapporter og sundhedsattester Rapporterne overfø res som pdffiler til homedk og derf ra til de enkelte mæglere OBHI har et program til afsending og sagsøgeren har et til at rette forespørgsel og foretage match til den enkelte ejendomssag Mæglerne bruger tilstandsrapporterne i salgsarbejdet Bureau 2000 er et firma der indsamler oplysninger om lokalforhold feks børnepasning sportshaller skatteoplysninger etc Sagsøgeren har  28  en abonnementsaftale og modtager kva rtalsvis en opdateret fil Dataene lægges på homedkdatabasen Sagsøgeren har et modtagerprogram og modtagelsen sker næsten helt automatisk men oplysningerne kontrolle res også manuelt Mæglerne indhenter selv de kommunale oplysninger lokalt hos den relevante kommune til deres salgsarbejde Sagsøgeren har en fællesaftale med Krak og Cowi som har et tæt samarbejde Krak er leverandør af kortmateriale til ejendommene Når en ejendom er kommet ind i databasen laves en identifikation af ejendommen på kortet via Kraks database  Krak leverer koordinaterne der indlæses via et program der kører dagl igt Der er således tale om en ko ordinatidentifikation Kortet ligger hos Krak hvortil adgang opnås via sagsøgerens database Hos COWI modtages efter samme principper luftfotos og skyline De enkelte mægl ere gør brug af et print af kortet med ejendommens beliggenhed i deres salgsmateriale I det samlede system som beskrevet på hjælpebilaget findes forskellige import og eksportkontrol funktioner De ejendomssager der overføres fra Base 2002 til homedk skal opfylde bestemte grundlæggende kriterier og betingelser Når udtrækkene fra mæglerne kommer ind foretages en kontrol med hensyn til tilstedeværelsen af de data som sagsøgeren kræver af mæglerne feks brutto og nettoydelse og afstand til skole og strand Kontrollen tager 1½  2 timer Hvis oplysninger mangler kommer de på fejlliste der føres dagligt og som ses af mæglerne Det er en del af programmets funktionalitet at det kun accepterer sager hvor de kræ vede kriterier er opfyldt Sagsøgeren reagerer hvis fejlmængden pludse lig bliver stor Der udsendes daglig t mails om at importkontrollen er kørt og hvis der er problemer tager sagsøgeren fat om dem Mht Home MPS kontrolleres billedkvaliteten både størrelse og opløs ning Kontrollen sker også manuelt bl a foretages grafisk kontrol af den billedmæssige kvalitet af hensyn til opsætningen i aviser Der sker endvidere et check af om filnavn matcher til ejendommen Der føres automatisk daglig kontrol med mæglernes informationsmæng de Hvis der pludselig sker store udsv ing hejses flaget og der kigges nærmere på forholdet   29  Mht OBHI kontrolleres at der er overensstemmelse med sagsøgerens sagsnummer og at både sundhedsatte st og tilstandsrapport er kommet frem Hvis der er noget galt får mæglerne besked via homedk Vedr BUREAU 2000 sker stikprøvevis manuel kontrol med oplysningerne på den fil som sagsøgeren modtager og efterfølgende implemente rer Sagsøgeren har ingen automatisk kontrol af oplysningerne fra Krak og Cowi Fejl opdages typisk af mæglerne Det stiller store krav til forretningslogikken hvordan tingene struktureres og hænger sammen når der kommer flere data eller flere kunder til Når databaserne ikke kan bære mere kan en opgradering eller en omlægning af aktiviteterne til en anden opbygning komme på tale Det sker typisk hvert 34 år at databaserne ikke længere kan bære Til den nødvendige omlægning antages eksterne konsulenter men sagsøgerens folk er med på sidelinjen og definerer kravene fx om der skal etableres nye søgemuligheder Den eksterne bistand er dyr og kostede fx i 2004 500000 kr Håndtering af mange oplysninger ma nge brugere og en målsætning om hurtig ekspeditionstid stiller store kr av til såvel hardwarelaget som for retningslogiklaget Sagens bilag 9 Omkostninger Internet er udarbejdet af sagsøgerens regnskabsafdeling der har fundet gamle konti frem vedr drift og ud vikling af homedk Sagsøgerens forbru g af intern tid er ikke med i bila get Drift af BAS  som er kontoens navn angår driften af centrale serverløs ninger hvoraf homedk er den væsentligste og omfatter diverse abon nementer på software feks Krak og Cowi teknisk drift og overvågning af server feks vedr fysiske forhold og brudsikkerhed drift af billeddatabasen og teknikertimer der vedrører løbende at holde øje med den kørende drift En del af driften kan henføres til andet feks mægler nes udveksling af information og et mindre beløb i størrelsesordenen 50000  100000 kr angår finansieri ng af SMSbeskeder til kunderne  30  For 2004 var beløbet 67000 kr Posten kunne godt have været placeret under markedsføring Housing er med i Drift af BAS og udgør 20 25000 kr om måneden Posten dækker opbevaring af homedk serve ren der fysisk befinder sig hos firma Interxion i Ballerup Udgifter til programmer der indsamler og kontrollerer oplysninger samt programmer til KrakCowi og Bureau 2000 samt til overførsel af billeder udgjorde  for så vidt angår homedkdatabasen alene  i 2004 6 700000 kr I 2002 og 2003 hvor man begyndte med Skyline var belø bet 500 550000 kr og i årene forud herfor 300000 kr om året Abonnement på Bureau 2002 koster 25 000 kr pr år Krak og Cowi kostede i 2004 950000 kr inkl koordinater i 2003 ca 13 mio kr og i årene før 2 300000 kr årligt Fremov er koster det ca 11 mio kr om året Sagsøgeren har defineret udseendet på mæglernes salgsopstillinger Det er et led i sagsøgerens branding U dgifterne hertil er ikke medregnet i bilag 9 Udvikling dækker eksterne omkostninger til IT for så vidt angår teknik og forretningslogik ekskl hardware virker det mens udvikling markedsføring angår den reelle brugerflade brugergrænsefladen og dækker grafisk arbejde og reklamebureau ser det pænt ud Posten Udvikling dækker for 8090  udvikling af IT og forretningslogik Der er 4 ansatte i sagsøgerens ITafdeling der alle har med homedk at gøre Omregnet er skønsmæssigt 2 beskæftiget med homedk på fuld tid ekskl fast administrativ tid svarende til en lønomkostning på ca 2 x 500000 kr pr år Det varierer no get hvad der er hovedopgaven vedr homedk men der bruges megen tid på at den underliggende program struktur fungerer På bilag R er opregnet 66 mulige boligdata vedrørende de enkelte ejen domme på sagsøgerens hjemmeside Der er enkelte andre oplysninger end dem der fremgår af listen ca 70 i alt Der er gennem tiden kommet nye data til Nogle oplysninger er kun med hvis der er tale om en villa  31  fx grundværdi grundareal og kælder areal Andre kan frit vælges til feks brutto og netto ved afdragsfrit F1 lån afstand til city tidspunkt for åbent hus byggeår energiforhold ti lbehør listning og beskrivelser af hårde hvidevarer mv og mæglerforretningens navn adresse telefon fax samt email Sagsnummeret relaterer sig til mæglerens sagsnummer Brugerne søger primært på sagsnummer ejendomstype adresse post nummer kontantpris og boligareal De sekundære søgekriterier er kommunenummer brutto netto afstand til offentlig transport afstand til skole afstand til dagligvarer og stra nd grundareal antal plan antal væ relser antal soveværelser etage antal toiletter kælderareal gårdmiljø altan elevator byggeår husdyr tilladt  nye vinduer nyt tag sundhedsat test og vand På sagsøgerens resultat liste vises ejendomstype adresse postnummer kontantpris udbetaling brutto netto boligareal grundareal villa antal plan antal værelser etage kælderareal gårdmiljø altan og byggeår samt tidspunktet for å bent hus hvis et sådant er fastsat Det er de mest afgørende oplysninger der er nødvendige for kundernes skanningsproces De 13 data som kopieres af sagsøgte er alle helt centrale og dem som sagsøgeren kontrollerer mest grundigt så forkerte søgninger og forkerte resultater undgås Det er ikke muligt at sætte tal på hvor meget indsam lingen kontrollen og præsentationen af disse data har kostet Det vil væ re rent gætværk Udover de 13 data tilføjer sagsøgte selv 4 data BoligID som ikke er synlig for brugerne og som formentlig er en teknisk nøgle så sagsøgte kan adskille de enkelte ejendomme fra hinanden i databasen Dato som formentlig angår det tidspunkt hvor dataene er hentet fra sagsøgerens database og som indirekte er synlig for brugerne derved at sagsøg tes system oplyser om nye emner FormidlerID med navn og hjemme side som er bestemt ved søgningen her konkret sagsøgeren og Ejendomstype som lige så godt kunne være kopieret fra homedk Der er brugt megen tid og energi på at bygge homedks forside op For siden er meget vigtig Det er her sagsøgeren præsenteres for ejendoms kunderne Det er vigtigt at skabe en let adgang til ejendommene og det  32  skal vurderes hvilke oplysninger der er oppe i tiden Sagsøgeren har stadig flere oplysninger med på sin resultatliste Senest er der kommet endnu flere billeder med hvilket er ut rolig vigtigt På selve ejendomsan noncen er der nu op til 20 billeder Der er arbejdet meget med billedhåndteringen bla med pakningen af billeder således at kunder med modem rimeligt hurtigt kan få adgang Sagsøgerens resultatliste giver et bedre og hurtigere overblik over den enkelte ejendom end sagsøgtes Man kommer hurtigere til den enkelte ejendom via sagsøgerens hjemme side end via sagsøgtes Sagsøgte kopierer ikke homedks billedmateriale Sagsøgerens version af homedks forside fra 2003 kørte med småjusteringer frem til maj 2005 Der blev lavet forskellige ændringer herunder mht forretningslogikken og præsentationen af ejendommene og tilføjelse af nye søgemuligheder og enkelte oplysninger om ejendommene herunder afstand til skov Derfor er omkost ningerne til udvikling så store i 2004 2352000 kr Forskellen mellem sagsøgte og de generelle søgemaskiner hos feks Google er at man via Google normalt ender på forsiden Google laver indekseringer men kopierer ikke Søgerobotter er velkomne med henbli k på præsentation på Google og lign Vidnet har ikke været med til at programmere robotter Man kan godt gøre noget for at udelukke robotter fra hjemmesiden men sagsøgeren ønsker ikke at bruge en masse teknikertimer herpå Til syvende og sidst drejer det sig om hvis teknikere der er smartest Så vidt vidnet ved er der ikke penge mellem de mæglerkæder der kan linke til hinanden Vidnet bekræftede direktør Niels Bjer regaards forklaring om at antallet af besøgende på hjemmesiden er ca 300000 om ugen Besøgstallet må ler sagsøgeren selv Fra DEs boligsiden sker ca 1 mio henvisninger om måneden Disse tal kan læses i DEs blad Sagsøgeren er ikke med på Boligzonen hvor ejendomme fra Nybolig Danbolig EDC mæglerne samt nogle små mæglerforretninger ekspone res  33  Danske Bank købte retten til at benytte Kapows robotter dvs softwaren med adgang til Kapows bolig båd og bilmarked Ideen var at sælge lån til kundernes finansiering af boligkøb mv Hans Trautner har forklaret at han er uddannet candmerc og at han siden 2000 har været marketingchef hos sagsøgeren med ansvar for ho mebrandet Der sælges ca 80000 private ejendomme  villaer ejerlejligheder og fritidshuse  om året i Danmark hvoraf Homemæglerne sælger ca 20000 På homedk vises løbende ca 15000 ejendomme hvoraf de ca 8000 er udbudt af homemæglerne På Nyboligs hjemmeside annonceres ca 15000 ejendomme hvoraf ca 8000 kommer fra home På EDCs hjem meside annonceres ca 9000 ejendomme alle EDC hos Danbolig ca 6000 alle Danbolig på DEs Boligsiden ca 36000 på Boligzonen ca 15000 hvoraf ingen kommer fra home  og på sagsøgtes boligofir ca 40000 ejendomme Homes markedsandel er ca 25  ca det samme som EDC mens Nybo lig har ca 20  og Danbolig ca 10  De mindre og små virksomheder har ca 20  hvoraf Estatemæglern e og Place2Live hver har 23  Home har 193 forretninger Nybolig ca 200 EDC ca 270 og Danbolig ca 135 I alt ca 800 butikker har samlet ca 75  af markedet Sagsøgeren har udviklet en overordnet branding hvor br andet kobles til de forskellige koncepter herunder homedk ejendomsavisen Home Nyt og diverse brochurer herunder det nye produkt Bedste Bud Home Nyt blev opstartet i 1992 homedk i 1996 Sagsøgeren var den første med en samlet site homedk marked sføres på TV som det fremgår af den nationale kampagneplan for 2005 Mæglerne betaler 875 kr for at få et emne på homedk Home har en kendskabsgrad på 95   34  Hovedområdet for annoncering er av iser hvor 50  af ejendommene vises og internettet hvor mellem 50  75  af ejendommene vises Sagsøgeren tror på at det også i fremtiden vil være både og I 2004 er der i ejendomsmæglerbranchen brugt 275 mio kr på annoncering fordelt med 80  på aviser og 15  på TV Home EDC og Nybolig står for ca 20  hver Danbolig ca 10  Homes samlede omsætning er nok ca 800 mio kr Omkostningerne til reklamebureauets udvikling af hje mmesidens grafik design og layout var ca 1 mio kr i både 2004 og 2005 Skadevirkningerne ved sagsøgtes adfærd vil være færre besøgende på homedk svagere mægleropbakning og  som det værste  en reduktion af brandværdien Det vil branding mæssigt blive sværere at holde mæg lerne samlet Sagsøgerens strategi undergraves Sagsøgeren mister gre bet om det signal som sendes til markedet når brandet ligger alle mulige steder Hos sagsøgte befinder sags øgerens brand sig i et miljø som sagsøgeren ikke kan styre Sagsøger en har samarbejdsaftaler med Nybo lig Estatemæglerne og Scheel  Orloff og kan derfor styre tingene Sag søgeren har ikke konstateret nogen faktisk skade på nuværende tids punkt Der er ikke lavet målinger på virkningen Vidnet ved ikke om sagsøgeren har tal på hvilken omsætning der hidrører fra trafik fra sagsøg te Udviklingschef hos sagsøgte Claus Øbirk  har forklaret at han er uddan net cand merc jur Hans ITkompetence er selvlært Han arbejdede tidligere som selvstændig ITkonsulent og har været ansat hos sagsøgte siden 2001 Mængden af sider med information på internettet er vokset eksplosivt de senere år Siderne hvoraf der nu er flere milliarder er i dag mere komplicerede end tidligere og ikke rene tekstdokumenter Der er for at internettet kan fungere et stort behov for søgemaskiner der søger finder indekserer kopierer for derefter at gemme oplysningerne i egen data 35  base til brug for tilgængeliggørelse In gen kan i dag forestille sig et inter net uden søgemaskiner En generel søgemaskine tilbyder ét søgefelt til fritekstsøgning De gene relle tjenester linker på samme måde som de specialiserede og altså også til undersider til hjemmesider Der linke s til den side hvor informationen er Dette har fra starten været almindelig internetadfærd Google der er den største generelle søgetjeneste har ca 20 specialiserede søgetjene ster der hver kan fungere mere effektivt indenfor et bestemt afgrænset område En søgerobot er software Da vidnet blev ansat havde sagsøgte i forve jen en søgerobot som var omstændelig og som indebar manuelle processer Vidnet udviklede en ny robot hvilket tog 3 måneder Den fungerer grundlæggende på samme måde som den gamle men er mere effektiv Der føres dagligt kontrol med dens funktion Når en hjemmeside ændres skal også robotten ændres Søgerobotten gør i princippet det samme som et menneske ville gøre Der laves en søgning på grundlag af definerede søgekriterier der fås en resultatliste og fra det enkelte dokument uddrages de data der relevan te fx ejendommens kontantpris som herefter gemmes i sagsøgtes data base Man har aldrig kopieret mere end de omtvistede 13 data som efter sag søgtes vurdering er de relevante og af værdi for sagsøgtes brugere Sag søgtes database opdateres én gang i døgnet det sker om natten hvor der er mindre trafik Sagsøgte tilføjer et unikt BoligIDnummer der ikke er synligt for bru geren og som er en teknisk nødvendighed for at kunne referere til siden i sagsøgtes database Nummeret er en databasenøgle der feks kan vise hvornår sagsøgte ha r fået data ind Der tilføjes endvidere Dato der viser hvornår ejendommen første gang er udbudt på nettet FormidlerID der viser hvor man har hentet informationerne fra og Ejen domstype som er nødvendig af tekniske årsager af hensyn til søgnin gen  36  Når brugeren har fundet ejendommen på sagsøgtes hjemmeside aktive rer hanhun linket til ejendomsmæglerens hjemmeside Der åbnes heref ter et vindue i browseren hvor der står at man nu viderestilles og ca 2 sekunder senere står brugeren på ejendomssagens side som er den samme side som hvis brugeren var gået ind via sagsøgerens hjemmeside Brugeren kan ikke være i tvivl om hvor hanhun står Det er muligt at udelukke søgerobotter fra en hjemmeside Med programmet metaTAC kan man angive at man ikke ønsker robotter der indekserer eller hvor ofte man ønsker anbefaler at robotterne skal in deksere Sagsøgeren anbefaler at man som minimum opdaterer indekse ringerne hver 7 dag Programmet Robottxt er en standard hvor man lidt mere specifikt kan angive hvilke dele af hjemmesiden man ikke ønsker besøgt og modsat de dele hvor man gerne vil have besøg Med programmet er der også mulighed for at sige nej til specifikke søgerobotter feks sagsøgtes Sagsøgeren gør ikke brug af denne løsning Herudover kan man lave nogle tiltag hvor man spærrer eller vanskeliggør vejen for robotter Det gør sagsøgeren ikke Udviklingsomkostningerne til søgerobotten er omfattet af venstre kolonne Udvikling  vedligehold af tjenesten i bilag Z Udvikling er vidnets om råde Administrerende direktør hos sagsøgte Jørgen Wittenkamp  har forklaret at han er uddannet cand polit Han begyndte på Søndagsavisen as i 1990 som økonomichef og blev salgs og marketingsdirektør i 1991 Vidnet stod for udvikling af elektroniske annoncer Da man i 1994 blev opmærksom på internettets muligheder blev der nedsat en projektgruppe og i maj 19 96 introduceredes internettjenesten online med rubrikannoncer i Søndagsa visens regi wwwsøndagsavisen På samme tid gik Den Blå Avis online Internettet var fra starten vidnets område I slutningen af 1997 blev man opmærksom på at Erhvervsministeren ønskede et centralt bolig indeks på internettet Søgerobotter var allerede  37  fremme på dette tidspunkt Sagsøgte så et boligindeks som et supple ment til de traditionelle annoncetje nester som sagsøgte havde i forve jen I januar 1998 rettede man henvendelse til Palle Ulstrup Dansk Ejen domsmæglerforening Reaktionen var et skuldertræk internettet var ikke interessant Boligforum gik online den 6 juni 1998 I efteråret rettede sagsøgte henvendelse til erhvervsminister Pia Gjellerup samt direktøren for Er hvervs og Selskabsstyrel sen der udtrykte tilfredshed med boligforum og der var herefter ikke anledning for styrelsen til selv at etablere et re gister i offentligt regi Bestyrelsen bifaldt den rimeligt stor e investering i det nye boligindeks Bestyrelsens formand advokat Thore Andersen tilkendegav at der efter hans opfattelse juridisk ikke var noget til hinder for at gå i gang Efter lanceringen modtog sagsøgte i juli 1998 en indsigelse fra sagsøgerens advokat Indsigelsen blev behandlet på et bestyrelsesmøde i august hvor Thore Andersen anbefalede en uvildig juridisk vurdering da der var tale om et nyt område Den 15 september 1998 fik sagsøgte et responsum fra professor Mads Bryde Andersen hv oraf fremgik at Boligforum ikke var i strid med gældende regler eller god skik Sagsøgte fortsatte på den baggrund sit projekt Kapow havde en tilsvarende tjeneste som sagsøgtes og fik også en henvendelse fra sagsøgeren I juni 1999 gik Dansk Ejendomsmæglerfor enings Boligsiden online Den 17 ju ni 1999 købte Danske Bank Kapow og den 15 oktober 1999 blev der udtaget stævning mod sagsøgte Det har vakt undren hos sagsøgte at der gik mere end et år før sagsøgte blev stævnet Sagsøgtes primære målgruppe er mennesker der søger bolig De ca 4000 ekstra ejendomme som sagsøgte har i forhold til Boligsiden er private der lægger salgsannoncer ind Sagsøgte er ikke i konkurrence med sagsøgeren der driver ejendoms mæglervirksomhed Parterne konkurrerer ikke om mediepladsen Sag søgte har ingen planer om at gå ind på sagsøgerens forretningsområde  38  Den principielle forskel er at man på boligofir kan få overblik over alle ejendomme mens man på homedk kan se hvad en mægler udbyder Sagsøgte tjente fra starten penge på at sælge bannere Selve tjenesten er gratis for brugerne og mæglerne Google har bygget sin forretning op på samme måde Internettet er en enormt effektiv sa lgskanal der reducerer liggetiden for de udbudte ejendom Internettet skaber større interesse og giver større gennemsigtighed Sagsøgtes hjemmeside skader ikke mæglerne  tværtimod Den støtter mæglerne i deres markedsføring Mange mæglere har kontaktet sagsøgte og udtrykt tilfredshed med sagsøgtes tjeneste Brugere af boligofir er fortrolige med internettet Der vil komme stadig flere specialiserede søgetjenester Elever i folkeskolen uddannes til at søge på nettet Det er kun på sagsøgtes hjemmeside  og muligvis hos JUBII  at priva te kan annoncere Sagsøgte kopierer ikke homedks databasestruktur Sagsøgte kopierer alene 13 data Disse er udvalgt efter nøje overvejelse og er udtryk for laveste fællesnævner i den forstand at der er tale om data som alle udbydere har med i deres annoncering Sagsøgte tilbyder et indeks Hvis der er for mange data med er der ikke længere tale om et indeks Det har fra starten været sagsøgtes politik at være loyal mod kilden Sagsøgte stiller 2 link til rådighed ét til hovedsiden og ét til ejendommen på en underside og brugerne bestemmer selv hvor de går hen i modsætning til DEs Boligsiden og JUBII hvorfra der alene kan linkes til un dersiden De fleste  og stadig flere  klikker direkte til ejendommen Sagsøgtes tjeneste kunne ikke funger e uden de direkte link Brugerne ville opfatte det som dårlig serv ice ikke at kunne gå direkte Boligforum blev afløst af boligofir i 2000 men der er tale om samme tjeneste Grundfarven skiftede fra blå til rød  39  Det er sagsøgtes bannerpolitik at annoncerne skal være relevante feks finansierings flytte bank og forsikringsvirksomhed Erotik og kon taktannoncer kan ikke forekomme på OFIRs hovedside eller på boligofir Der er ingen interaktion så en så dan annonce pludselig kan dukke op Sagsøgte giver sagsøgeren gratis markedsføring og hjælper den boligsøgende til sagsøgerens hjemmeside hvor ejendommene er udbudt til salg Sagsøgerens modstand drejer sig alene om at forsøge at kontrollere markedet Ingen andre mæglervirksomheder har rejst indsigelse overfor sagsøgte Vidnet har udarbejdet redegørelsen for Omkostninger ifm Bolig tjenesten bilag Z Omkostningerne er direkte henførbare til sagsøgtes boligtjeneste Omkostningerne til drif ten er faldende dels fordi udviklin gen i teknologien har reduceret behovet for vedligeholdelse dels fordi sagsøgte har skåret ned på omkostningerne af økonomiske årsager Mar kedsføringsomkostninger er ikke med Markedsføring foregår primært internt ved annoncering i Søndagsavisen og som busreklamer Der er tjent alt for lidt på tjenesten Der har været større fortjeneste på andre tjenester Hvis en hjemmeside ændrer sig er man nødsaget til at ændre robotten Robotten arbejder hver dag og bliver løbende ændret Udvikling og vedligehold af tjenesten gælder al ene udgifter til robotten Vidnet kan ikke på stående fod sige hvad hardware højre kolonne udgør Hardware afskrives over 3 år Tallene er hentet fra sagsøgtes økonomisystem Oversigt over litteratur retspraksis mv som parterne har henvist til i deres procedurer Litteratur Mads Bryde Andersen Grundlæggende aftaleret 2 omarbejdede udgave 2002 Mads Bryde Andersen ITretten 2001 ITretten 1 udgave Mads Bryde Andersen ITretten 2 udgave 2005 ITretten 2 udga ve Mads Bryde Andersen Linking og robottering på Internettet U2000B311  40  Jon Bing Immaterialrettslige aspekter ved elektroniske agenter Fest skrift til Mogens Koktvedgaard 2003 Jon Bing Erling Borcher og Frank Bøggild Markedsføringsloven 2001 Andreas Christensen mfl Konkurrenceretten i EU 2 udg 2005 Mark Davison og P Bernt Hugenholtz Football fixtures horse races and spinoffs the ECJ domest icates the database right EIPR 2005 Issue no 3 Davison og Hugenholtz Kasper Heine mfl Internetjura 2 udgave 2002 Kasper Heine Henrik A Jensen Sui generis rett  betydningen af begrepene gjengi velse og viderebruk med forutsetningen om en vesentlig investering vurdert kvalitativt ogeller kvant itativt i databasedirektivet NIR 199968 Henrik A Jensen Mogens Koktvedgaard Konkurrenceprægede immaterialretsdispositioner 1965 Mogens Koktvedgaard Lærebog i immaterialret 7 udgave 2005 Immaterialretten Mogens Koktvedgaard Lærebog i konkurrenceret 5 udgave 2003 Konkurrenceretten Kirsten Levinsen Konkurrenceloven med kommentarer 2 udgave 2001 Kirsten Levinsen Lisa Vogt Lorentzen Databaseværn Sui Generisvern av sammenstillin ger etter gjennomføringen av databasedirektivet i åndsverkloven 43 2002 Lisa Vogt Lorentzen Thomas Riis Immaterialret og IT 2001 Thomas Riis Peter Schønning Ophavsretsloven m ed kommentarer 3 udg Peter Schønning Lars Stoltze Internet Ret 2001 Lars Stoltze Retspraksis U20031063S Newsbooster Sag 4869 Imperial Chemical Industries Farvestofsagerne Sag C 8985 mflCellulose II Sag 23887 VolvoVeng De Forenede Sager C24191 P og C24291 P Magill Sag T 50493 Ladbroke  41  Sag C35596 Silhouette Sag T34299 Airtours Sag C48101 P IMS Sag C41802 IMS Health Sag C4602 Fixtures Den finske Fixturessag Sag C20302 BHB eller Hill Sag C33802 Den svenske Fixturessag Svenska Spel Sag C44402 Græsk Fixturessag Dom af 13 juli 2005 afsagt af The Court of Appeal i sag 2005 EWCA Civ 863 BHB mfl ctr Hill Tysk Højesteretsdom i sagen BGH Urt v1772003 I ZR 25900 Pa perboy Andet Konkurrencerådets afgørelse af 21 oktober 2001 vedr home Rapport fra Kommissionen til EuropaParlamentet Rådet og det Europæiske Økonomiske og Sociale Udvalg 1 rapport om anvendelsen af Euro paParlamentets og Rådets direktiv 2000 31EF af 8 juni 2000 om visse retlige aspekter af informationssa mfundstjenester navnlig elektronisk handel i det indre marked direktivet om elektronisk handel KOM 2003 702 endelig Ophavsretslovens  71 stk 1 og 2 og databasedirektivets art 7 stk 1 og 5 Ophavsretslovens  71 stk 1 og 2 Stk1 Den som fremstiller et katalog en tabel en database eller lignen de hvori et større antal oplysninger er sammenstillet eller som er resultatet af en væsentlig investering ha r eneret til at råde over det pågæl dende arbejde som helhed eller en væse ntlig del deraf ved at fremstille eksemplarer af det og ved at gøre det tilgængeligt for almenheden Stk 2 Bestemmelsen i stk 1 finder tilsvarende anvendelse på en ek semplarfremstilling eller tilgængeliggørelse for almenheden af uvæsentlige dele af indholdet af et katalog en tabel en database eller lignende som foretages gentagne gange og systematisk såfremt de nævnte hand linger kan sidestilles med handlinger  der strider mod en normal udnyt telse af de pågældende arbejder eller som skader fremstillerens legitime interesser urimeligt   42  Databasedirektivets art 7 stk 1 og 5 Stk1 Når indsamling kontrol eller præsentation af en databases indhold ud fra et kvalitativt eller kvantitativt synspunkt er udtryk for en væsentlig investering sikrer medlemsstaterne databasens fremstiller en ret til at forbyde udtræk ogeller genanvendelse af hele basens indhold eller en væsentlig del deraf vurderet kvalitativt eller kvantitativt  stk 5 Gentagne og systematiske udtræk ogeller genanvendelser af uvæsentlige dele af databasens indhold der kan sidestilles med handlinger som strider mod en normal udnytt else af basen eller som skader databasefremstillerens legitime interesser urimeligt er ikke tilladt Procedure Retten har ved gengivelsen af parternes procedureindlæg fulgt systema tikken fra domsforhandlingen og opdelt hver parts procedure i 2 afsnit På denne måde afspejler gengivelsen at visse synspunkter i proceduren der fandt sted med dages mellemrum mellem nogle af indlæggene blev udviklet undervejs og at ny retspraksis blev behandlet i de senere ind læg Sagsøgerens procedure 1 del Til støtte for påstand 1 a er det sagsøgers principale standpunkt at sagsøgte overtræder ophavsretslovens  71 ved den daglige kopiering af udvalgte data fra sagsøgers database til egen database I denne forbindelse er det sagsøgers principale an bringende at sagsøgte overtræder ophavsretslovens  71 stk 1 subsidiært  71 stk 2 Under sagsøgers principale standpunkt gøres til støtte for påstand 1 b gældende at de dybe link sagsøgte etablerer på boligofir direkte til sag søgers annoncer er en overtrædelse af markedsføringslovens  1 Sagsøgers subsidiære standpunkt er at sagsøgte ved at etablere sin virksomhed boligtjenesten boligofir på den konkret foreliggende måde dvs ved den daglige kopiering i kombin ationen med tilrådighedsstillelsen af de dybe link samlet set handler i strid med god markedsføringsskik og således overtræder markedsføringslovens  1  43  Procedurens disposition er herefter 1 Hjørnesten  faktum 2 Ophavsretsloven  71 stk 1 3 Ophavsretslovens  22 4 Ophavsretslovens  71 stk 2 5 Lov om omsætning af fast ejendom  5a 6 Påstand 1b Markedsføringslovens  1 Dybe link 7 Konkurrencelovens  6 og  11 8 Subsidiære synspunkter støtte for at sagsøgte samlet set overtræder markedsføringslovens  1 9 Vederlag og erstatning 1 Hjørnesten  faktum Parterne er enige om at sagsøgte en gang i døgnet fra sagsøgers database til sagsøgtes database kopierer 13 udvalgte data opregnet i bilag R vedr alle ejendomme som er udbudt til salg af homemæglerne på homedk og at sagsøgte samtidig med kopieringen etablerer et dybt link til homedk direkte til annoncen for hver af ejendommene I forhold til homedkdatabasen føjer sagsøgte reelt ikke yderligere data til boligofirdatabasen til de data der kopieres De fire yderlige re informationer som sagsøgte tilføjer jf bilag Q nemlig bolig ID dvs sagsøgtes j nr dato dvs datoen for sagsøgtes kopiering af de pågældende data fra homedk databasen formidler ID dvs home og ejendomstype dvs villa ejerlejlighed mm er indholdsløse i den forstand at de ikke tilføjer sagsøgtes database el ler boligtjenesten boligofir noget af betydning for den besøgende Rettens udgangspunkt er derfor at sagsøgtes boligtjeneste boligofir i forhold til sagsøgers er etableret alene på grundlag af den daglige  44  kopiering fra sagsøgers database af de 13 udvalgte data samt af et dybt link til ejendommens annonce på homedk 2 Ophavsretlovens  71 stk 1 Til støtte for påstand 1a gøres det principalt gældende at sagsøgte ved sin daglige kopiering af data overtræder ophavsretslovens  71 stk 1 Bestemmelsen der blev væsentligt ændret i 1998 som følge af databasedirektivet fra 1996 udtrykker databaserettighedshaverens eneret og forbyder sagsøgte at foretage eksemplarfremstilling og til gængeliggørelse af hele eller af en væsentlig del af sagsøgers data base Parterne er enige om to væsentlige juridiske forhold nemlig at den daglige kopiering udgør eksemplarfremstilling og tilgængeliggørelse i ophavs retslovens forstand og at den til homedk knyttede database som ud gangspunkt er en database hvilket jf databasedirektivets artikel 1 vil sige en samling af værker data eller andet selvstændigt materiale der er struktureret systematisk eller metodi sk og som kan konsulteres indivi duelt ved brug af elektronisk udstyr eller på anden måde Parterne er imidlertid ikke enige om hvorvidt sagsøgers database kvalificerer sig til den såkaldte sui generis beskyttelse af databaser efter ophavsretslovens  71 og ej heller hvorvidt den del af sagsøgers database som sag søgte kopierer kan siges at udgøre en væsentlig del af sagsøgers data base Ophavsretslovens  71 indeholder to alternative betingelser for at en database kan nyde beskyttelse Begge betingelser gøres gældende at være opfyldt Vedr den første betingelse en database hvori et større antal oplysninger er sammenstillet bemærkes at formuleringen stammer fra og er enslydende med den gamle katalogregel Det gøres gældende at kravet om et større antal oplysninger er rent kvantitativt Peter Schiønning Ophavsretsloven med kommentarer 2001 side 533 og 535 Sagsø gers database består af et endda meget omfattende antal oplysninger  45  Der foreligger til stadighed informationer om ca 15000 ejendomme hvoraf ca 8000 er udbudt af homemæglere og om hver ejendom fin des gennemsnitligt ca 70 informationer Der henvises til udskrifterne af sagsøgers hjemmeside og Hanne Bran dts vidneforklaring hvorefter sag søgers database fylder 70 gigabyte homedkdatabasen opfylder således klart den første alternative be tingelse i ophavsretslovens  71 stk 1 og databasen nyder allerede af denne grund sui generisbeskyttelse efter  71 stk 1 Databasedirektivets art 7 stk 1 omtaler ganske vist ikke selve størrelsen på databasen som en mulig kvalifikation idet det alene omtales at da tabasen skal være resultatet af en væsentlig investering svarende til den anden betingelse i ophavsretslovens  71 stk 1  71 stk 1 er imidlertid helt klart formuleret og der er derfor ikke tvivl om at de to betingelser gælder alternativt Den gamle katalogregel i  71 der også omfattede databaser havde en helt tilsvarende formulering mht den kvantitative betingelse Ved harmoniseringen af  71 har det fra dansk side ikke været meningen at ændre ved den oprindelige katalogbeskyttelse Der henvises til Koktvedgaard Immaterialretten side 90 Det gøres gældende at direktivet er et minimumsdirektiv der alene for pligter medlemsstaterne til en minimumsharmonisering hvorfor strengere krav eller en beskyttelse ud over det niveau direktivet fastsætter kan bestå ved siden af det implementerede direktiv Hvorvidt der foreligger et minimums eller totalharmoniseringsdirektiv må afklares ud fra direkti vets ordlyd og formål Alle tre skan dinaviske regeringer har fundet at der er tale om et minimumsdirektiv Lisa Vogt Lorentzen NIR 2004 side 120 Den danske implementering fandt sted i 1998 Kommissionen er efter normal praksis og i øvrigt i henhold til databasedirektivets art 162  ved fremsendelse af sammenligningsske ma  utvivlsomt underrettet om de nationale forskrifter der implementere r direktivet i Danmark  og tilsva rende i Norge og Sverige og er således bekendt med at disse lande har implementeret direktivet som et mini mumsdirektiv uden at der har væ ret indledt traktatbrudsprocedure mod nogle af landene Når der er tale  46  om interessante sager vil der sædvanligvis være kendskab til en sagsbe handling længe før der på Kommissionens initiativ evt udtages stæv ning Det må når det dertil tages i betragtning at der nu er forløbet 7 år fra Danmarks implementering kunne konkluderes at Kommissionen er enig i at direktivet er et minimumsdirektiv En række elementer i direktivet pege r klart i samme retning Der henvi ses til direktivets betragtning 1 hvor efter man ved direktivet ønsker at sikre en bedre og bredere beskyttelse af databaserne idet beskyttelsen ikke var tilstrækkelig i mange af medlemsstaterne Det vil med et sådant hovedformål ikke give mening hvis di rektivet samtidig skulle begrænse beskyttelsen af databaser ved at kræve nationale regler der giver bedre beskyttelse end direktivet ophævet Der henvises endvidere til betragt ning 32 hvorefter medlemsstaterne mindst skal sikre overensstemmelse mellem deres nationale regler og direktivets bestemmelser om de op havsretlige enerettigheder Direktivet er således ikke forkert implementeret og der er derfor intet til hinder for at ophavsretslovens  71 stk 1 har bevaret den yderligere alternative mulighed at sui generisr et til en database der har en vis større volumen anerkendes Det synes heller ikke rimeligt hvis lovænd ringen skulle medføre en snævrere beskyttelse og så alene for ét af de fænomener ophavsretslovens  71 omfatter nemlig databaser samtidig med at kataloger tabeller olign fort sat skulle nyde beskyttelse blot de indeholder et vist større antal oplysninger Det gøres endvidere gældende at sagsøgers database er resultatet af en væsentlig investering  For at forstå dette begreb som ikke er nærmere defineret i 1998lovmotiverne må man se på formuleringen af direktivets art 7 stk 1 direktivets betragtnin ger samt EFdomstolens afgørelser fra november 2004 i sagerne C4602 F insk Fixtures C20302 Hill C 33802 Svenska Spel og C44402 Græsk Fixtures Ifølge direktivets art 7 skal investeringen vedrøre indsamling  kontrol eller præsentation af en databases indhold og investeringen skal være væsentlig ud fra et kvalitativt eller kvantitativt synspunkt  47  Det fremgår af direktivets betragtninger at baggrunden for direktivet er at databaser ikke er tils trækkelig beskyttet i alle medlemsstater betragt ning 1 at det er nødvendigt at vedtage beskyttelse for databaser be tragtning 6 at fremstilling af databaser kr æver betydelige ressourcer  men at databaser er lette at kopiereødelægge betragtning 7 at kraf tig vækst i Fællesskabet kræver investeringer i informationsbehandlingssystemer betragtning 10 at investeringer i informationsbehandlingssy stemer dvs informationslagrings og informationssøgningssystemer ik ke vil ske medmindre man beskytter databaserne betragtning 12 at formålet med direktivet er at beskytte databasefr emstillere mod tilegnel se af resultatet af deres investeringer betragtning 39 at formålet med direktivet videre er at sikre beskyttelse af databasefremstillers investe ring være sig i forhold til konkurrent er eller andre betragtning 42 og endelig at formålet med direktivet er at sikre databasefremstiller det ve derlag der tilkommer ham betragtning 48 Med dette udgangspunkt skal EFdomstolens udtalelser i C33802 Svenska Spel vedr forståelsen af begrebet indsamling læses jf præmis 24 og 37 de øvrige tre domme fra november 2004 er parallelle Det kan herefter udledes at meningen med sui generisretten er at yde beskyttelse til den der ud fra en mængde allerede eksisterende informa tioner fremstiller en database til lagring og søgning af disse informationer men ikke at yde beskyttelse til den der på første hånd indsamler dataene Man vil ikke beskytte investeringen i indsamlingsregistrerings processen men derimod investeringen i at skabe dvs fremstille selve databasen  informationsbehandlingssystemet Det kan også udtrykkes på den måde at hovedformålet med investeringen skal være at oprette databasen Vedr den såkaldte spinoff doktrin som sagsøgte har påberåbt sig henvises indledningsvis til Koktvedgaar d Immaterialretten Doktrinen er ikke direkte udtrykt i nogen af de fire EFdomme fra november 2004 Det gøres gældende at doktrinen og fors tåelsen af hvad der ligger i begre bet indsamling er to sider af samme sag Der henvises til Davison og Hugenholtz i EIPR 2005 side 4 Det afgørende for sui generisretten er herefter at databasefremstillers inds ats i investering i henseende til ind 48  samling angår fremskaffelse af allerede eksisterende data og at hoved formålet med den indsatsinvestering er at oprette den pågældende da tabase Det gøres gældende at sagsøger ved fremstillingen af homedkdatabasen alene har fremskaffet allerede eksisterende data og indlagt dem i databasen således at homedk databasen kun består af på forhånd eksisterende materiale som sagsøger har fremskaffet fra tredjemand Det gøres videre gældende at hovedfor målet ja det eneste formål med sagsøgers indsatsinvester ing har været at oprette informationslagrings og søgningssystemet homedkdatabasen Ved Hanne Brandts forklaring til hjælpebilaget er det dokumenteret  at sagsøgers database kassen homedk er etableret ved at sagsøger har indsamlet en række forskelligt allerede eksisterende selvstændigt materiale fra en række tredjemænd nemlig fra de enkelte homemæglere fra Nykreditmæglerne fra andre selvstændige mæglere fra OBHI fra Bureau 2000 og fra Krak kun koordinater Ingen del af dette materiale har sagsøger selv frembragt fra grunden  det forelå da sagsøger foretog indsamlingenfremskaffelsen til brug for fremstillingen af homedkdatabasen For sagsøger har det at fremstille markedsføringsværktøjet  informati onssøgningssystemet homedkdatabasen  været hovedformålet med investeringen i fremskaffelsen af de pågældende data Sagsøger har således fremstillet homedkdatabasen i overensstemmelse med forretningsgrundlaget for sagsøger dvs at fremstille og tilbyde markedsfø ringsværktøjer til ho memæglerne I denne sammenhæng er homedk databasen tillige en væsentlig indtjeningskilde idet ca 27  af sagsøgers indtjening hidrører fra mæglernes betaling for adgang til homedk Det gøres gældende at det i henseende til betingelserne om fremskaf felse af allerede eksisterende data og hovedformål med investeringen er uden betydning at nogle informat ioner er fremskaffet af sagsøger til homedkdatabasen oprindeligt dvs fra ny af og at andre er frembragt af homemæglerne i forbindelse med deres indsamling og registrering af disse informationer i deres CB system til brug for det videre salgsarbej de vedr den pågældende ejendom Det afgørende i denne sammenhæng  49  er at forholdet mellem sagsøger og de enkelte mæglere er et franchise forhold der bygger på en franchiseaftale hvor sagsøger og de enkelte homemæglere hver især er økonomis k og juridisk selvstændige parter Der kan derfor ikke ske identifikation mellem den frembringelse af nye data som den enkelte homemægler foretager og den fremskaffelse af allerede eksisterende data som sagsøger foretager i forbindelse med fremstillingen af homedk databasen Der er således ikke grundlag for at gøre spinoff doktrinen gældende Med hensyn til de to sidste beskyttels esværdige typer af indsats i direkti vets art 7 stk 1 nemlig investering i kontrol og præsentation af en da tabases indhold fremgår det af præmis 27 1 led i C33802 Svenska Spel at kontrol omfatter databasefremstillers tiltag ved oprettelsen af databasen og mens den er i drift hvorved rigtigheden og nøjagtigheden af det fremskaffede materiale sikres Der er således tale om en umiddelbart nærliggende forståelse af ordet kontrol En sådan kontrol foretager sagsøger Der henvises til Hanne Brandts forklaring i relation til sagsøgers hjælpebilag hvoraf fremgik at der på 7 steder grænseflader er etableret en kontrol af informationernes rigtighed og nøjagtighed Sagsøger har ved disse grænseflader der er ind sat af sagsøger på sagsøgers foranledning og for sagsøgers regning ud viklet programmer der checker at informationerne er korrekte Ved et enkelt sted Bureau 2000 for egår endvidere manuel kontrol Med hensyn til præsentation fremgår det af præmis 27 2 led i Svenska Speldommen at ordet omfatter strukturering af databasens bestanddele så databasen opnår en informationsbehandlingsfunktion det vil sige systematisering og indeksering af de fremskaffede informationer og den indsats der har til formål at gøre det muligt at søge i databasens infor mationer på kryds og tværs Denne forståelse af præsentation svarer måske ikke til den umiddelbare forstå else af ordet men hænger logisk sammen med databasedirektivets form ål nemlig at tilskynde til og be skytte investeringen i fremstillingen af databaserinformationssystemer  50  Det gøres gældende at sagsøger har ydet og yder en sådan indsats i henseende til præsentationen af data basens indhold Der henvises til Hanne Brandts forklaring om den interne og eksterne indsats vedr det løbende arbejde med forretningslogikken for homedkdatabasen med det formål at strukturere databasen på en sådan måde at brugeren har optimale søgemuligheder Der henvises endvidere til Hanne Brandts redegørelse for vanskelighederne med at løse de problemer der opstår med en database som homedk med så mange informationer så mange bru gere og kravet til hastighed Med hensyn til spørgsmålet om hv orvidt sagsøgers investering i fremskaffelse kontrol og præsentation af homedkdatabasens ind hold kan karakteriseres som væsentlig  gøres det indledningsvis gæl dende at der er tale om alternative indsatsmuligheder Investeringskravet kan opfyldes enten ved at investeringen i én af de nævnte typer af indsats henholdsvis indsamling kontrol eller præsentation er væsentlig eller ved at investeringen knyttet til indsamling kon trol og præsentation to og to eller tilsammen er væsentlig Der henvises til Henrik A Jensen NIR 199968 side 7374 Begrebet væsentlig investering er ik ke nærmere defineret i de danske 1998lovmotiver Af formuleringen af direktivets art 7 stk 1 fremgår at den væsentlige investering både kan være af kvantitativ og af kvalitativ art Af betragtning 40 til direktiv et fremgår at investeringen kan be stå i anvendelse af økonomiske ressourcer ogeller i brug af tid indsats og energi  Om den beskyttelsesværdige investerings karakter henvises også til betragtning 7 investering af ressou rcer af menneskelig teknisk og økonomisk art og betragtning 39 resultaterne af den økonomiske og faglige investering  Med henvisning til Svenska Spelafgørelsen præmis 28 Mads Bryde Andersen ITRetten 2 udg side 414415 og Henrik A Jensen NIR 1999 side 7778 gøres det gælden de at investeringen kan bestå i økonomisk indsats eller den kan være af ikkekvantificerbar art altså kvalitativ dvs bestå i menneskelige ressourcer som tid intellek tuel indsats og energi  51  Det gøres gældende at sagsøger har afholdt en væsentlig investering i henseende til indsamling kontrol og præsentation af indholdet af ho medkdatabasen såvel i kvantitativ økonomisk som i kvalitativ hen seende Med hensyn til sagsøgers kvantitative investering fremhæves tallene i sagens bilag 9 og Hanne Brandts forklaring herom Bilag 9 omfatter ud gifter til følgende relevante indsatser til programmet der styrer det daglige udtræk fra Base 2002 til homedk til de to programmerservices der styrer fremskaffelsenoverførslen af billedmateriale fra home MPS til homedk til det program der styrer over førselfremskaffelse af til standsrapporter og sundhedsattester fra OBHI til homedk til det pro gram der styrer overførselfremskaffelse af data fra Bureau 2000 til homedk til løbende royaltybetalinger til bureau 2002 for kommuneoplys ninger til royaltybetaling til KRAK bla fo r overførsel af koordinatoplys ninger der kan matche kort og den enkelte ejendoms adresse til at etablere og løbende gennemføre kontrol af de informationer som frem skaffes fra Base 2002 til homedk hvor der er tale om en toleddet kontrol både ved eksport af informationerne fra Base 2002 og ved import af informationerne til homedk til kontrol af de data der overføres fra home MPS til homedk således at de rigtige billeder og plantegninger knyttes til de ejendomme de hører sammen med til etablering og gen nemførelse af kontrolsystem for så vidt angår de informationer der fremskaffes fra andre mæglere både Nykreditmæglerne og andre små selvstændige mæglere til etablering og gennemførelse af kontrol i forbindel se med overførslen af rapporter og attester fra OBHI til etablering og gennemførelse og kontrol af de kommuneoplysninger der fremskaffes fra Bureau 2000  og til stadighed betydelige økonomiske udgifter til forret ningslogikken dvs til at frembringe et program med søgekriterier og sø gemuligheder som gør homedk databasen specielt brugervenlig Sagsøgers kvantitative investerin g fremgår af bilag 9 Af Hanne Brandts forklaring fremgik at de beløb der skal medregnes er 90 af de samlede udviklingsomkostninger eller 76 mio kr andel af Drift af BAS  3 mio kr hvortil kommer interne udgifterpersonale med ca 1 mio kr årligt i 8 år hv ilket udgør i alt 183 mio kr sva rende til årlige omkostninger på gennemsnitligt 23 mio kr  52  Fsv angår sagsøgers kvalitative investering fremhæves den intellek tuelle indsats og energi der er medgået internt og eksternt på sag søgers foranledning dels i forbindelse med udvikling af de mange særlige programmer der indgår i fremskaffelses og kontrolprocesserne dels i forbindelse med forretningslogikken På dette grundlag gøres det gælden de at det er dokumenteret at homedk databasen er resultatet af en væsentlig investering Det bemærkes at kravet til væsentlighed ikke antages at være særlig strengt jf Henrik A Jensen NIR 1999 side 79 Det gøres gældende at sagsøgtes kopiering af de 13 udvalgte data udgør en væsentlig del af sagsøgers database vurderet kvalitativt  og at sagsøgte dermed overtræder ophavsretslovens  71 stk 1 Direktivets betragtninger omtaler ikke direkte hvad der skal forstås ved en kvalitativ væsentlig del af en database men to betragtninger nr 39 og 42 omtaler at der skal være beskyttelse for hele databasen eller en væsentlig del af databasen og at fo rmålet med direktiv et er at beskytte databasefremstillerens investeringer Med henvisning til Henrik A Jensen NIR side 72 og 73 Thomas Riis Immaterialret og IT side 114 Mads Bryde Andersen ITretten side 418 EFDomstolens dom i sagen C20302 Hill præmis 69 og 71 gøres det gældende at selv i det tilfælde hvor udtrækket kvantitativt udgør en ringe del kan sui generisbeskyttelse opnås for en kvalitativt væsentlig del at beskyttelsen mod udtræk af en kvalitativt væsentlig  men muligt kvantitativt lille  del også er båre t af direktivets overordnede formål dvs at beskytte databasefremstillers investering i oprettelsen af databa sen herunder at beskytte databasefremstillers investering i netop de konkret kopierede data og at man også må tage karakteren af de kopie rede data i betragtning dvs om de kopierede data udgør en essentiel del i den forstand at dataene kan siges at være nødvendige og tilstrækkelige til at der på dette grundlag kan etab leres en ny database der opfylder brugerens efterspørgsel  53  Til støtte for at sagsøgtes kopiering af de 13 udvalgte data vedrører ko piering af en kvalitativt set væsentlig del af homedkdatabasen fremhæ ves Hanne Brandts forklaring til bilag R hvoraf fremgik at de 13 data udgør en essentiel del af dataene i data basen De 13 data er således alle på nær nr 15 i bilag R udbetaling søgedata i homedkdatabasen og 6 af dataene er primære søgedata Yderligere udgør alle 13 data på nær to sagsnr og Url dataene på homedks resultatliste Der er knyttet særlige investeringer for sagsøger såvel kvantitativt som kvalitativt til netop de 13 kopierede data fordi de spiller den centrale rolle dels som søgedata dels som resultatlistedata De 13 data bliver således specielt kontrolleret og de er genstand for speciel opmærksomhed i forbindelse med præsentationenforretningslogikken Endelig er disse data nødvendige og tilstrækkelige til at sagsøgtes site boligofir som udelukkende består af netop disse data fungerer som konkurrerende boligtjeneste til homedk jf også Clau s Øbirks forklaring 3 Ophavsretslovens  22 Ophavsretslovens  22 er en undt agelsesregel til den ophavsretlige eneret efter ophavsretslovens  2 og skal derfor som udgangspunkt fortolkes indskrænkende Kravet i  22 om god skik er et krav om en rimelig og hæderlig handlemåde Sagsøgtes gengivelse af sagsøgers data ikke er udtryk for en sådan handlemåde idet sagsøgte udnytter sagsøgers indsats Det er endvidere ifølge  22 kun tillad t at citere i det omfang som betin ges af formålet Denne betingelse indeholder sammen med kravet om overensstemmelse med god skik et loya litetskrav Peter Schønning Op havsretsloven side 319 Loyalitetskravet er ikke opfyldt når citeringen består i at gengive en meget omfattende del af en database med det formål at oprette en konkurrerende database For at være lovligt skal citatet normalt indgå i et andet værk og skal med andre ord udgøre en del af det der frembringes af den citerede Således er det som udgangs punkt ikke tilladt at opbygge en database udelukkende af citater Der henvises til Thomas Riis Immaterial ret og IT side 123 Peter Schønning Ophavsretsloven side 321 Mads Bry de Andersen ITretten s 419 og  54  Lars Stoltze Internet Ret side 75 Holdningen i den juridiske litteratur er at der bør vises betydelig tilbageholdenhed med hensyn til adgangen til at citere fra en database ikke mindst en digital database beskyttet i henhold til ophavsretslovens  71 Gengivelsen af data fra sagsøgers database på sagsøgtes hjemmeside omfattes ikke af ophavsretslovens  22 idet dataene udgør en for stor del af sagsøgtes database til at kunne betragtes som et citat og idet sagsøgtes gengivelse indebærer en in tensiv og vedvarende udnyttelse af sagsøgers data som ikke harmonerer med citatrettens loyalitetskrav 4 Overtrædelse af ophavsretslovens  71 stk 2 Det er sagsøgers subsidiære anbringende at sagsøgte ved sin kopiering overtræder ophavsretslovens  71 stk 2 Parterne er i relation til  71 stk 2 enige om at sagsøgte foretager en gentagen og sy stematisk eksemplarfremstilling og tilgængeliggørelse af uvæsentlige dele af homedkdatabasen Parterne er ikke enige om hvorvidt sagsøgtes kopiering jf ophavsretsloven  71 stk 2 2 led kan siges at stride mod normal udnyttelse ogeller skader sagsøgers legitime inte resser urimeligt  Denne del af  71 stk 2 stemmer overens med da tabasedirektivets art 7 stk 5  Det er tilstrækkeligt at blot den ene betingelse er opfyldt Der henvises til Lisa Vogt Lorentzen Databasevern 2002 side 100102 Henrik A Jensen NIR 1999 side 39 8399 og EFdomstolens afgørelse i C20302 Hill præmis 85 og 86 Af henvisningerne fremgår at ophavsretslovens  71 stk 2databasedirektivets art 7 stk 5 er tænkt til at hindre omgåelse af  71 stk 1art 7 stk 1 og til at imødegå den gen tagne og systematiske kopiering som ved sin ophobende virkning skader databasefremstillers investering Det fremgår videre at der i henseende til begreberne strider mod normal udnyttelse og urimeligt skader databasefremstillers legitime inte resser skal lægges vægt på om den påståede krænker er en konkur rent til databasefremstiller om den påståede krænkers formål med kopi 55  ering er at bruge dataene i en konkurrerende database om den påståede krænkers database alene består af de kopierede elementerinformatio ner om oprettelsen af den hævdede krænkers database betyder mindre udnyttelsebesøg på den oprindelige database og om de kopierede data benyttes i en sammenhæng som kan skade databasefremstillers omdømmegoodwill Netop disse fremhævede elementer foreligger i nærværende sag Der består således et konkurrenceforhold mellem parterne idet boligofir konkurrerer med sagsøgers boligtjeneste homedk Som det fremgik af Niels Bjerregaards forklaring er homedk en betydelig indtjenings kilde for sagsøger idet ca 30  af sagsøgers indtjeningnettoresul tat hidrører fra mæglerne på homedk Sagsøgtes indtjening på sin boligtjeneste består i bannerannonceindtægter Sagsøgtes site består alene af de kopierede elementer sags øgte har ikke tilføjet sin data base nyt af betydning i forhold til de elementer der er kopieret fra sagsøger Tilstedeværelsen af boligofir der etableres på baggrund af kopiering af de for brugeren essentielle data vil jf Niels Bjerregaard og Hans Trautners forklaringer på sigt betyde at der vil komme fær re besøgende på homedk hvilket måske allerede er sket Færre besøgende medfører en udhulning af boligtjenesten homedk og den enkelte mægler vil ikke være til si nds at betale en høj afgift for at kunne udnytte homedk Herved skad es sagsøgers indtjeningspotenti ale på homedk og på sigt sagsøgers investering i databasen Der er som Hans Trautner forklarede ikke tale om en fordelagtig merekspo nering af homedk Hertil kommer at den sammenhæng hvori de kopierede data optræder på sagsøgtes site er skadende for sagsøgers omdømme herunder for sagsøgers brand HOME Ved at sammenholde parternes forsider på hjemmesiderne kan det lægges til grund at sagsøger har valgt en ren og seriøs linje med en internetplatform for boligannoncer uden bannerannoncer og andre forstyrrende elementer og med stor vægt på brandet HOME mens boligofir  som sagsøger nu tvunget bliver koblet sammen med  på forsiden annoncerer for alt fra job rejser billige flybilletter billige uægte smykker og slankeråd til kontaktannoncer På sagsøgtes side søg bolig og på de følgende sider annonceres for spillere som  56  sagsøger ikke ønsker at blive forbun det med feks Lån  Finans Direkte Boligadvokater samt LynLotto Hertil kommer at den ydelse den besøgende får på boligofir mht informationer og resultatliste er dårlig og mangelfuld i forhold til den ydelse de ville få på homedk Boligofir må jf Jørgen Wittenkamps forklaring følge den laveste fælle snævner ved præsentationen bo ligofirs resultatliste Den besøgende får på boligofir langt færre oplysninger og ved ikke at han k unne få en bedre ydelse ved at be søge homedk Yderligere er den eksponering der sker på boligofir ødelæggende og undergravende for sagsøgers brandingstrategi Der henvises til Hans Trautners forklaring om den massive ensartede fælles branding af kendetegnet HOME Sagsøgers brandingstrategi splittes ad og ødelægges gradvist ved boligofirs kopiering af de 13 data og visning af informationerne i et useriøst og rodet miljø og i en mangelfuld udgave Det kan på denne baggrund konkluderes at sagsøgtes gentagne og systematiske kopiering både strider mod en normal udnyttelse og skader sagsøgers legitime interesser urimeligt 5 Lov om omsætning af fast ejendom  5a Af bemærkningerne til bestemmelsen i lov om omsætning af fast ejen dom  5a der trådte i kraft den 1 juli 2000 fremgår at det var lovgi vers ønske at der skulle ske en cent ral eksponering på internettet af alle ejendomme til salg Der blev ikke ve d bestemmelsen taget stilling til hvorledes en sådan eksponering skulle ske herunder om den skulle kunne ske på tværs af gældende regler i speciallovgivningen Bestemmelsen giver hverken sagsøgte eller andre private hjemmel til i strid med op havsretslovens  71 at oprette et sådant boligsøgesystem men giver un der visse forudsætninger hjemmel til at Erhvervs og Selskabsstyrelsen kan iværksætte fornødne tiltag her under fastsætte regler der muliggør oprettelse af et centralt søgesystem  Bestemmelsen er således irrelevant for afgørelsen af nærværende sag  57  Som forklaret af Niels Bjerregaard bevirkede  5a netop at Dansk Ejen domsmæglerforening oprettede boligsidendk hvor alle ejendomme der udbydes til salg af parter der ifølge  8 i lov om omsætning af fast ejen dom må udbyde fast ejendom er opta get Boligsiden vi ser således ikke kun ejendomme udbudt af Dansk Ejendomsmæglerforenings medlemmer men også ejendomme udbudt af andre registrerede ejendomsmæglere pengeinstitutter realkreditinstitutter forsikringsselskaber og advokater De eneste ejendomme der ikke er m ed er dem der udby des af private  netop af hensyn til forbrugerne der ik ke herved skal gives indtryk af en blåstempling fra DE Branchen har herved oprettet et acceptabelt system Korrespondancen mellem sagsøgte og Erhvervs og Selskabsstyrelsen og Pia Gjellerup kan ikke på nogen måde ses som udtryk for en officiel godkendelse af boligofir 6 Påstand 1b Markedsføringslovens  1 Dybe link Til støtte for påstand 1b gøres de t gældende at de dybe link sag søgte ubestridt foretager er i strid med markedsføringslovens  1 Dybe link deep link er et kendt og almindeligt benyttet begreb i ITverdenen Ved deeplinking etableres et direkte link til en konkret side hos tredjemand eller en konkret fil som er tilgængelig på internettet Deep refererer til at der linkes under forsideniveau i den hierarkiske struktur der ofte kendetegner websites Der henvises til Kasper Heine mfl Internetjura 2 udg 2002 side 446 Ved deeplinking ledes brugeren således direkte til det pågældende søgemål og eksempelvis uden om eventuelle bannerreklamer og bru geren bliver ikke gjort opmærksom på de øvrige ydelser websitet tilbyder Se hertil Lars Stoltze Internet Ret 2001 side 74 I denne sag medfører sagsøgtes deep link at brugeren ledes udenom homedks forside og direkte til anno ncesiden hvorved brugeren ikke præsenteres for indholdet af homedks forside  58  Internettet er ikke et retligt vakuum men underlagt de samme og i visse tilfælde skærpede regler som gælder for den almindelige er hvervsudfoldelse Lars Stoltze Internet Ret side 257 Dybe link skal ifølge litteraturen for at være i overensstemmelse med god markedsføringsskik opfylde visse betingelser For det første skal deeplinking respektere den bannerannoncering der fremtræder på den informationsleverandørs hjemmeside hvortil der linkes Mads Bryde Andersen U2000B311 side 316 For det andet skal det gøres klart over for den indirekte bruger hvordan den autentiske informationsmængde ser ud og hvem der er den autentiske formidler Mads Bryde Andersen samme sted Endvidere påvirkes bedømmelsen af om der består et konkurrenceforhold mellem de to sites imellem hvilke deeplinkingen foregår Det er i dommen i UfR 20031063S Newsbooster bekræftet at deeplinking kan udgøre en overtrædelse af markedsføringsloven Retten lagde vægt på at der bestod et konkurrenceforhold og at annonceværdien af sagsøgerens sider blev forringet som følge af deeplinkningen Det er også i udenlandsk retspraksis anerkendt at deeplinking kan udgøre en krænkelse af god markedsføringsskik Lars Stoltze Internet Ret side 76 I denne sag er kravet om at det skal gøres klart for den indirekte bruger hvordan den autentiske informationsmængde ser ud ikke op fyldt Brugeren ser ikke sagsøgtes forside og dermed ikke hele ho mes informationsmængde Forsiden er meget væsentlig for homedk Den bearbejdes til stadighed for på bedst mulig måde at introducere og informere brugeren om alle homedks funktionaliteter Sagsøgtes dybe link skader sagsøgers forretningsinteresser og om dømme Der skabes en forbindelse mellem sagsøger og sagsøgte som sagsøger klart ikke ønsker idet sagsøger som forklaret af Niels Bjerregaard finder sagsøgte useriøs Hensynet til sagsøgers forretningsinteresser og omdømme er beskyttelsesværdigt i lige så høj grad som interessen i at beskytte økonomiske indtægter i form af bannerindtægter Ved vurderingen af om de dybe link er i overens 59  stemmelse med god markedsføringsskik bør det ikke komme sagsø ger til skade at sagsøger har valgt at undlade bannerannoncering At der ved linkningen skabes flere besøgende er ikke en fordel for sag søger Parterne er konkurrenter for så vidt angår deres boligdatabasetjenester på internettet hvilket må tillægges vægt ved vurderingen Sag søger afviste efter sagsøgtes henvendelse herom at tillade dybe link til sin website men sagsøgte etablerede alligevel dybe link hvilket understreger at sagsøgte ikke har taget et rimeligt hensyn til sagsøger Sagsøgers metatags er udtryk for at sagsøger gerne vil have trafik på homedk via Google og andre fritekstsøgemaskiner Dette er ikke ensbetydende med at sagsøger ønsker trafik opstået som følge af søgemaskiner der søger inden for et specifikt afgrænset område som boligsalg som det er tilfældet med sagsøgte 7 Konkurrencelovens  6 og  11 Med hensyn til konkurrencelovens  6 gøres det gældende at der ik ke foreligger en aftale eller samordnet praksis mellem sagsøger og DE eller mellem sagsøger og andre medlemmer af DE der har til formål eller til følge at begrænse konkurrencen Med hensyn til konkurrencelovens  11 gøres det principalt gældende at sagsøger ikke indtager en dominerende stilling hverken på ejendomsmarkedet eller på markedet for salg af ejendomsannoncer s ub sidiært at der ikke foreligger et misbrug af dominerende stilling  6 forudsætter en fælles vilje hos flere parter  virksomheders sam stemmende viljeserklæring  om en konkurrencebegrænsende ad færd mens  11 finder anvendelse på en ensidig adfærd  én virksomheds misbrug af egen dominerende stilling Gældende for begge bestemmelser der skal fortolkes i overensstemmelse med henholdsvis EFtraktatens art 81 og 82 er at den der gør gældende at der foreligger en overtrædelse har en tung og omfattende bevisbyrde  60  Særlig med hensyn til overtrædelse af konkurrencelovens  6 be mærkes at to for denne sag relevante betingelser skal være opfyldt 1 Der skal foreligge en aftale samordnet praksis eller vedtagelse som 2 er konkurrencebegrænsende Begrebet aftale forudsætter konku rrenceretligt at to parter i det mindste har en samstemmende vilje Formen er ikke afgørende Samordnet praksis som det er defineret i EUpraksis omfatter en form for koordinering mellem virksomheder som uden at være udmøntet i en egentlig aftale bevids t erstatter konkurrencerisikoen med et praktisk samarbejde Der henvises til EFdomstolens dom i sag 4869 farvestofsagerne præmis 64 Parallel adfærd er ikke i sig selv samordnet praksis jf EF domstolens dom i sag C8985 mflCellulose II præmis 71 For at kunne lægge til grund at der foreligger en samordnet praksis i strid med konkurrencelovens  6 skal det jf Kirsten Levinsen Konkurrenceloven side 231  bevises at der har været en direkte eller indirekte kontakt mellem virksomheder og at der har været en fælles vilje om at samarbejde frem for at konkurrere I vurderingen af hvorvidt den anden betingelse aftalen skal være konkurrencebegrænsende er opfyldt indgår en undersøgelse af hvordan konkurrencen på det pågældende marked ville have været uden aftalen Det afgørende i de nne sammenhæng er om aftalen har en sådan indvirkning på markedsforholdene at konkurrencen påvir kes i et sådant omfang at der kan forventes eller konstateres negative indvirkninger på det pågældende marked for forbrugere ogeller konkurrenter Der er i praksis udviklet en nedre grænse for anvendelsen af for buddet i  6 En konkurrencebegræn sning skal således være mærk bar  have en vis markedspåvirkning  for at udgøre en overtrædelse af loven mærkbarhedskriteriet Der henvises til Kirsten Levinsen Konkurrenceloven side 166  61  Sagsøgte har ikke gjort noget overhovedet for at bevise at der skulle foreligge en konkurrencebegrænsende aftale eller samordnet praksis mellem sagsøger og DE eller mellem sagsøger og DEs medlemmer med det formål at afskære ikkemedlemmer adgang til robottering til sagsøgers hjemmeside De oplyste faktiske omstændigheder i sagen dokumenterer derimod klart at dette ikke er tilfældet Jørgen Wittenkamp forklarede således at der ikke forelå nogen indsigelser fra an dre mæglere hvis emner vises på bo ligofir at mæglerne er glade for den service som boligofir tilbyder  og at DE ikke afviste et samar bejde med boligofir men blot havde et skuldertræk tilovers for henvendelsen om samarbejde Dertil kommer at der på internettet fin des Boligzonen en fælles boligtjeneste oprettet af en række af de største dagblade og TV 2 hvor der på aftalt grundlag vises emner fra bla EDC Nybolig Danbolig og Realmæglerne mfl Der henvises endvidere til at sagsøgers samarbejdsaftale med Nyboligmæglerne er ikkeeksklusiv Hvis der forelå en ulovlig aftale ville aftalen være ugyldig og den skulle følgelig ophøre jf konkurrencelovens  6 stk 5 Dette ville imidlertid ikke fratage aftaleparter ne muligheden for frit at håndhæve deres immaterielrettigheder overfor tredjemand En evt ulovlig aftale eller samordnet praksis påvirker ikke lovligheden af søgsmålet der beror på håndhævelse af sagsøgers påberåbte immaterielrettighed og ikke på en i givet fald ulovlig aftale eller samordnet praksis Sagsøgtes anbringender vedrørende konkurrencelovens  6 er derfor irrele vante Påberåbelsen af  6 savner grundlag Særlig med hensyn til en overtrædelse af konkurrencelovens  11 skal to betingelser være opfyldt 1 Der skal foreligge en domineren de stilling og 2 der skal foreligge et misbrug af den dominerende stilling Det gøres gældende at sagsøger ikke har en dominerende stilling Dominansbegrebet i  11 fortolkes i overensstemmelse med EUkommissionens og EFdomstolens praksis vedr EFtraktatens art 82 Dominans siges normalt at foreligge når en virksomhed indtager en så stærk stilling på markedet at den har mulighed for at hindre at  62  der opretholdes en effektiv konkurrence inden for det pågældende markedssegment idet virksomhedens styrke giver den mulighed for uafhængig adfærd i forhold til konkurrenterne Mogens Koktved gaard Konkurrenceret side 153 Der er i konkurrenceretten en fast formodning for at der ved en markedsandel på under 4045  ikke er tale om en dominerende virk somhed og det er fast antaget at det ved en markedsandel på min dre end 25  er udelukket at tale om dominerende stilling Der henvises til Kirsten Levinsen Konkurrenceloven side 341 og Andreas Christensen mfl Konkurrenceretten i EU 2 udgave 2005 side 495 497498 For at kunne vurdere størrelsen af markedsandelen er det nødvendigt at afgrænse det relevante marked Sagsøgte har påberåbt sig to relevante markeder dels markedet for ejendomsformidling dels marke det for annoncering af fast ejendom på internettet Ifølge bilag 8 er det Konkurrencestyrelsens opfattelse at homekædens markedsandel i 2001 udgjorde 20  på markedet for ejendomsformidling Det gøres gældende at sagsøger ikke er aktør på markedet for ejendomsformidling og derfor heller ikke har en mar kedsandel Markedet er homemæglernes Derimod agerer sagsøger på markedet for annoncering af fast ejendom herunder på internettet Det bestrides ikke at der kan være en formodning for at sagsø gers andel af markedet for annoncering af fast ejendom svarer til homemæglernes andel af markedet for formidling af fast ejendom Med henvisning til Hans Trautners forklaring gøres på dette grundlag gældende at sagsøgers andel af markedet for annoncering af fast ejendom maksimalt udgør 25  også hvis markedet alene afgrænses til at udgøre annoncering af fast ejendom på internettet Når henses til markedsstrukturen i øvrigt hvor tre øvrige formidlere EDC Nybolig og Danbolig har markedsandele på internettet på henholdsvis 25  20  og 10  og det resterende marked på 20  med en række små udbydere hvoraf de største har en markedsandel  63  på 23  gøres det gældende at sagsøger entydigt ikke kan indtage den nødvendige dominerende stilling Det er i teori og retspraksis uomtvistet at den omstændighed at en virksomhed er indehaver af en immate rielrettighed ikke i sig selv er ensbetydende med at virksomheden er dominerende se EFdomstolens dom i de forenede sager C24191D og C24291D Ma gill præmis 46 Sagsøgte har ikke tilvejebragt og har heller ikke søgt tilvejebragt nogen form for dokumentation der viser sagsøgers markedsandel på markedet for ejendomsformidling eller markedet for ejendomsannon cering generelt eller for internettet alene Sagsøgte har heller ikke søgt at godtgøre at der skulle foreligge kollektiv dominans og det står ikke klart mellem hvilke parter en sådan kollektiv dominans skulle foreligge Vurderingen af hvorvidt der forligger kollektiv domi nans og hvorvidt en evt kollektivt domineret stilling er misbrugt er den samme hvad enten der er tale om en vurdering efter konkurrencelovens  11 EFtraktatens art 82 eller fusionskontrolreglerne Kirsten Levinsen Konkurrenceloven side 345 Betingelserne for at statuere kollektiv dominans fremgår af EFdomstolens dom i sag T 34299 Airtours præmis 62 Sagsøgte har ikke tilvejebragt nogen form for bevis for at disse betingelser er opfyldt Sagsøgte har ikke klart angivet hvem medlemmerne af det domine rende kollektiv er Der foreligger endvidere ingen dokumentation for at gennemsigtigheden på markedet som sagsøgte i øvrigt heller ikke har dokumenteret er tilstrækkelig til at give medlemmerne af det hævdede kollektiv mulighed for at få umiddelbart og præcist kendskab til udviklingen i de andre medlemmers adfærd med henblik på at kontrollere adfærden Det er heller ikke dokumenteret at der skulle foreligge afskrækkelsesfaktorer der tilskynder medlemmerne til ikke at fravige den hævdede fælles adfærd og endelig foreligger der ikke dokumentation for at de nuværende og potentielle konkurrenter på det relevante marked samt forbrugernes forudsigelige reaktion ikke kan så tvivl om resultatet af den kollektive adfærd  64  Skulle retten imidlertid finde at sagsøger indtager en dominerende stilling opstår spørgsmålet om konflikten mellem immaterialrettens lovbestemte enerettigheder og konkurrenceretten Mogens Koktved gaards udgangspunkt er at konflikten normalt skal løses til fordel for immaterialretten Konkurrenceretten side 228229 EFdomstolen har da også i sag 23887 VolvoVeng fastslået at nægtelse af adgang til en immaterielrettighed ikke i sig selv kan udgøre et misbrug af en dominerende stilling Magillsagen de forenede sager C24 191 og C24291 præmis 50 er den første sag hvor EFdomstolen indtog det standpunkt at en licensnægtelse vedr en eneret som udøves under særlige omstæn digheder kan udgøre misbrug af en dominerende stilling Dommen som angår en helt anden situation end den foreliggende er blevet stærkt kritiseret og senere retspraksis fra EFdomstolen viser at dommen skal betragtes som en usædvanlig sag og underlægges en snæver fortolkning Se hertil Andreas Christensen mfl Konkurrence retten i EU 2 udgave side 554 Immaterialretten er som udgangspunkt anerkendt i det konkurrenceretlige system og konkurrenceretten accepterer den eneretsposition som immaterialretten giver rettighedshaver I tilfælde af indgreb i sagsøgers immaterialret på grundlag af konkurrenceloven må det derfor kræves at sagsøgte dokumenterer at der er tale om et produkt som er absolut nødvendigt for sagsøgte for at kunne udøve sin virk somhed jf Andreas Christensen mfl Konkurrenceretten i EU 2 udgave side 555 Et sådant bevis har sagsøgte end ikke forsøgt at tilvejebringe Adgangen til databaserne vedr homemæglernes annoncer på ho medk er ikke nødvendig for udøvelsen af sagsøgtes hovedvirksomhed som internetportal med en række rubr ikannoncer feks bil båd bo lig og rejser jf princippet i EFdomstolens dom i sag T 50493 Ladbroke præmis 132 Der skal i denne sammenhæng sondres mellem essential og convenient Det v ille således være convenient for sagsøgte at have adgang til sagsøgers data men det er ikke essen tial for sagsøgtes virksomhed eller ydelser Boligsøgning er blot et  65  accessorium til sagsøgtes egentlige forretning som er at drive en stor generel internetportal med mange forskellige emner heriblandt boliger og indholdet af sagsøgers databaser dækker kun en begræn set del af de annoncerede boliger nemlig ca 25  Hertil kommer at sagsøgte ikke har dokumenteret at det ikke er muligt at drive søge tjenesten uden adgang til sagsøgers data Afslutningsvist bemærkes at betingelserne for indgreb i en immateri alret jf EFdomstolens seneste dom på området sag C41802 IMS Health heller ikke er dokumenteret opfyldt Ifølge denne dom præmis 38 skal tre kumulative betingelser være opfyldt før håndhævel sen af immaterialrettigheder kan udgøre misbrug af en dominerende stilling Af disse har sagsøgte under alle omstændigheder ikke doku menteret at den tredje betingelse er opfyldt hvilket vil sige kravet om at sagsøgers nægtelse af at give sagsøgte adgang til de omhandlede data vil medføre at der vil ske en udelukkelse af al konkurrence på markedet for internetannoncering af fast ejendom Der findes al lerede nu en række boligtjenester på markedet med forskellige udbydere bag feks Boligzonen og ofir med medierne bag DEs boligsiden med branchen bag og diverse andre sider med mæglerkæder eller franchisegivere bag 8 Subsidiære synspunkter til støtte for at sagsøgte samlet set overtræder markedsføringslovens  1 Sagsøger gør subsidiært gældende at sagsøgte ved at etablere bo ligofir ved hjælp af kopiering og deeplink samlet set overtræder markedsføringslovens  1 Det har stedse været almindeligt anerkendt i teori og praksis at mar kedsføringslovens  1 tidligere konkurrencelovens  15 kan gøres gæl dende supplerende og subsidiært til immaterialretslovgivningen Der henvises til Koktvedgaard Konkurrenceprægede immaterialretsdispositioner 1965 side 32829 og 34546 og samme Konkurrenceret side 344 Det følger heraf at markedsføringslovens  1 kan påberåbes subsi diært i forhold til ophavsretslovens specialbestemmelser og at det afgø 66  rende er at beskyttelsen og den krænkende adfærd tager en anden form ved en vurdering efter markedsføringslovens  1 Ved den markedsføringsretlige vurdering skal sagsøgtes samlede handlemåde med det formål at etablere boligofir vurderes i forhold til målestokken god markedsføringsskik De r henvises til Borcher og Bøggild Markedsføringsloven 1 udgave side 63 Sagsøgers boligsite homedk er besky ttelsesværdig efter markedsførings lovens  1 fordi der er tale om en kommerciel markedsplads en tjenesteydelse som er resultatet af en betydelig indsats i henseende til inve steringer i opbygning og markedsføring af tjenesten I denne sammen hæng er alle tal i bilag 9 relevante også omkostninger til markedsføring homedk har i kraft af de mange besøgende oparbejdet en betydelig beskyttelsesværdig position på markedet for boligtjenester Forretningskendetegnet HOME er meget velkendt og stærkt indarbejdet og sagsøger har en betydelig indtjening på home dk fra mæglerne Det er således et faktum at de to sites homedk og boligofir er konkurrerende tjenesteydelserboligtjenester hvor sagsøgte tjener på sine bannerannoncer Sagsøgte handler illoyalt og i strid med god markedsføringsskik fordi den ydelse sagsøgtes boligtjeneste boligofir stiller til rådighed for den be søgende alene består af kopierede data fra bla sagsøgers database samt det direkte link til sagsøgers annoncer uden om sagsøgers søgekri terier det vil sige uden om sagsøgers forside og resultatliste Sagsøgte tilføjer ikke sin boligtjeneste noget yderligere af betydning for den besø gende Der er tale om en intensiv og målrettet udnyttelse af sagsøgers indsats hvilket må have afgørende betydning ved vurderingen af om kravet om god markedsføringsskik i markedsføringslovens  1 er opfyldt Der henviser til Lars Stoltze Internet Ret 2001 side 77 De eneste udgifter sagsøgte har jf Jørgen Wittenkamps forklaring er til etablering og vedligeholdelse af den søgerobot der bruges til at kopiere sagsøgers data Når det er af interesse for tredjemand at betale for bannerannoncer på sagsøgtes site skylde s det jo ikke navnet ofir men der imod bla det meget velkendte navn HOME kendskabsgrad 95  Sag søgte handler i klart ond tro sagsøgte fik jo afslag fra sagsøger mht til  67  kopiering fra sagsøgers site Sagsøgte snylter på sagsøgers indsats og vil på sigt fortrænge sagsøger helt eller delvist fra det indarbejdede site ho medk og dermed ødelægge sagsøgers indtjeningsgrundlag på homedk Det gøres herefter sammenfattende gældende at forudsætningen for bo ligofirs kommercielle grundlag alene er dels kopieringen fra sagsøgers database dels de dybe link til homedk at det af boligofir ved kopiering og dybe links anvendte materiale udgør forretningsgrundlaget for sagsø gers indtjening på homedk og at boligofir vil fortrænge sagsøger fra eller i hvert fald skade homedks markedsposition Sagsøgtes handlinger er derfor klart i strid med god markedsføringsskik jf markedsføringslo vens  1 Der henvises til Mads Bryde Andersen U2000B311 side 67 Lars Stoltze Internet Ret side 76 77 og 260 samt UfR 20031063S Newsbooster 9 Vederlag og erstatning Til støtte for påstanden om vederlag og erstatning henvises til ophavsretslovens  83 og markedsføringslovens  13 Det er endnu vanskeligt at opgøre og dokumentere et økonomisk tab men ideel skade har sagsøger nok lidt ved sagsøgtes retsstridige tiltag I erkendelse af at det er vanskeligt at opgøre tabet og vederlagskravet har sagsøgte udvist beskedenhed ved opgørelsen Det gøres gældende at sagsøger i hvert fald er berettiget til det påståede beløb i vederlag og markedsforstyrrelse for den uberettigede og ulovlige udnyttelse af sagsø gers data igennem en lang årrække og til sagsøgtes egen vinding Sagsøgtes procedure 1 del Disposition 1 Indledende bemærkninger 2 Internettet som medium og parternes brug heraf 3 Det ophavsretlige grundlag Identifikation i databaseretlig henseende mellem den enkelte homeejendomsmægler og sagsøger  68  4 Ophavsretslovens  71 stk 1 Væsentlig investering 5 Ophavsretslovens  71 stk 1 Væsentligt udtræk kvalitativt set 6 Ophavsretslovens  71 stk 2 Uvæsentlig del af databasen 7 Markedsføringslovens  1 8 Erstatningvederlag 9 Konkurrencelovens  6 og  11 1 Indledende bemærkninger Parterne er enige om at den midlertidige eksemplarfremstilling der sker i forbindelse med de undersøgelseshandlinger sagsøgtes robot foretager og indekseringen er omfattet af den legale programlicens i ophavsretslovens  36 stk 2 jf  71 stk 5 Efter afsigelsen af de 4 domme fra EFdomstolen den 9 nove mber 2004 ligger det fast at un dersøgelseshandlinger ikke er i stri d med databasereglerne Der henvi ses til præmis 54 i EFdomstolens dom i sag C20302 Hill hvor det udtrykkelig siges at beskyttelsen ikke omfatter søgning i en database når fremstilleren har valgt at gøre den tilgængelig for almenheden Det te fremhæves fordi der i sagsøgers påstand indgår sætningen ved at foretage løbende og systematiske søgninger på sagsøgers hjemmeside 2 Internettet som medium og parternes brug heraf Sagsøger gør brug af internettet som markedsførings og salgskanal for sin ejendomsmæglervirksomhed Sagsøger annoncerer de ejendomme homemæglerne har i kommission på internettet Sagsøgte benytter ikke internettet til formidling af fast ejendom men driver aktivitet med rubrikannoncer herunder for salg af fast ejendom og giver alle der ønsker det mulighed for at få optaget en annonce for deres bolig på boligofir Sagsøgte st iller samtidig internetsøgefaciliteter på boligofir til rådighed for alle brugere der ønsker oplysninger om ejendomme der er udbudt til salg Boligofir kan sammenlignes med en  69  gul telefonbog og er et praktisk brugervenligt værktøj frit anvende ligt for alle altså en reel markedspla ds en vejviser en virtuel neutral chauffør til ejendomsmæglere og andre der har boliger annonceret på internettet så brugerne på en teknologisk let måde nemlig ved at klikke på et link kan komme hen til ne top den side hvor brugeren kan få flere oplysninger om den ejendom bru geren selv har fundet frem til Af bilag T om Homes profil fremgår Homekæden formidler mere end hver fjerde ejerbolighandel i Danmark Kæden er en del af Danske Bank koncernen  Udtrykket Homekæden anvendes som samlebetegnel se for hele koncernen mæglerne og sagsøger På sagsøgers hjemmeside findes i gennemsnit mere end 17000 ejendomme og sagsøger formidler mere end hver 4 bolig der i Danmark er udbudt til salg På DEs Boligsidendk var 35875 emner til salg den 27 maj 2005 Internettet er som det også fremgik af forklaringerne den primære salgskanal i dag 5075  af alle ejendomme formidles via internettet og tendensen er stigende Formålet med hjemmesiden homedk er at komme ud til så mange køberemner som muligt  at få solgt så mange boliger som mulig på den kortest mulige tid Derfor har sagsøger også indgået aftale med konku rrenterne Nybolig Schell og Orloff og Estate samt med DE om gensidig eksponerin gvisning af ejendomme på hinan dens hjemmesider med adgang til at linke direkte til de enkelte ejen domme Det er nøjagtig det samme sagsøgte gør bortset fra at sag søgte også stiller et link til ejendomsmæglernes forside til rådighed Det er derimod ikke et formålet med homedk at opnå andre indtægter fx ved bannerannoncering Det er den almindelige forretningsmodel på nettet at der ikke er bannerreklamer på hjemmesider der bruges til at markedsføre egne ydelser Uden bannere på sin hjemmeside har sagsøger ingen legitime interesser i at angribe sagsøgtes forretningsmodel som den praktiseres Sagsøgtes tjeneste er ny på et afledet marked skabt på grundlag af internettet og denne tjeneste fremmer formålet med databasedirektivet jf Mads Bryde Andersen ITretten 2001 side 495 og samme i U 2000B311 side 56  70  På internettet findes i dag uendelig mange hjemmesider med alverdens information Der kommer dagligt tusindvis af nye sider med enorme in formationsmængder til og forældede sider fjernes typisk ikke Denne information er ikke meget værd hvis man ikke kan finde den nogenlunde effektivt Det er derfor almindelig t accepteret i dag at den der læg ger information ud på internettet formodes gerne at ville have og der med acceptere at relevante brugergrupper kan finde denne information  at de der søger bolig kan finde præcis den bolig der passer de pågældende Sagsøgeren udtrykker på sin hjemmeside homedk selv at annoncering på internettet sker for at komme i kontakt med flest mu lige købere Hvis sagsøger foretrækker at brugerne kommer til sagsø ger via homedks forside må dette fremmes ved hjælp af markedsføring og en god hjemmeside  ikke ved at sagsøgeren forsøger at forhindre en brug som er hjemlet i opha vsretsloven Dette er i realiteten konkurrenceretligt set retsstridig adfærd Brug af søgemaski ner herunder intelligente søgerobotteragenter som sagsøgtes i kombination med tilrådig hedsstillelse af link herunder både link som når brugeren klikker på lin ket fører til en anden hjemmesides forside og direkte til en konkret underside der indeholder præcis den information brugeren har søgt fx hovedsiden for en bestemt fast ejen dom der er udbudt til sag hos en ejendomsmægler hører i dag til de grundlæggende og mest benyttede funktioner i forbindelse med brug af internettet Disse funktionaliteter er årsagen til at internettet overho vedet kan fungere som medie for informationsudveksling og informati onssøgning Det er både en hjælp for brugerne nemlig til at finde den information der efterspørges og en hjælp for den der udbyder og markedsfører varer eller ydelser på nettet nemlig til at få sine varer eller tjenesteydelser solgtfå informationen ud til den bredest mulige brugerkreds Søgemaskinersøgerobotte r og links er altså alene hjælpe værktøjer for brugere af internettet Markedet for de generelle søgemaskiner er afledt af internettet gene relt De specialiserede søgemaskiner er afledt af markedet for konkrete varer eller ydelser udbudt på inter nettet  i den konkrete sag markedet for boliger  71  De generelle søgemaskiner fx Yahoo Google mfl kopierer hjemme sideindhold hvorefter siderne indekse res i en database og kombineres med link og tekstcitater om hvad hjemmesidenlinket indeholder af in formation Når en bruger går ind på fx Googles hjemmeside og taster et søgeord ind i søgefeltet fremkommer en hitliste med søgeresultater i form af link  såvel link til konkrete hjemmesiders forsider som link til undersider og typisk også en kort tekstmæssig forklaring om hvad der ligger på den hjemmeside brugere kommer hen til hvis linket aktiveres af brugeren De generelle søgemaskin er bruger altså også link der går direkte til en side der ligger under forsiden Der er ingen der anfægter denne kommercielle brug i dag fordi den er helt i overensstemmelse med normal og nødvendig brug af internettet De specialiserede såkaldte intelligente søgerobotter som feks sagsøgtes er programmeret til at finde konkrete produkter eller ydelser der udbydes på nettet Disse søgemaskiner kopiererudtrækker enkelte data fra andres hjemmesider indekserer dataene i en database og stiller dem til rådighed for brugere af internettet Brugerne får endvidere typisk link stillet til rådighed link der i den konkrete sag både er til de enkelte ejendomsmægleres hjemmesiders forsider og til de ejendomme som brugeren gennem sin søgning har fundet frem til og ønsker mere information om Hvis der kun blev givet oplysning om URLadressen på den konkrete hjemmeside ville det betyde at brugeren selv skulle taste hjemmesideadressen ind på sin computer ikke blot homedk adressen på forsiden men en sådan adresse som feks fremgår af bi lag Q wwwhomedksag146E7077lynsoegtrueside1hometrue De generelle søgemaskiner og de specialiserede søgerobotters betydning for internettets funktion er og så erkendt af sagsøger der jo accep terer at konkurrenter som Nybolig Estate Schell  Orloff og andre feks DE og Danske Bank linker udenom forsiden direkte til siderne for konkrete ejendomme og endda uden at der stilles et link til sagsøgers forside til rådighed for brugeren Sagsøger har på homedk tilgængeliggjort de pågældende ejendomsda ta for almenheden Teknisk set har sagsøgte foretaget systematiske søgninger på homedk og herved fået frembragt skærmbilleder hos sag 72  søgte selv hvorfra udtrækket af de 13 data som sagen drejer sig om er sket Der er tale om objektive faktuelle oplysninger der ikke nyder nogen form for immaterialretlig beskyttelse Når brugerne klikker på linket til de enkelte mæglere vises først en side hvor det klart fremgår at brugeren nu stilles om til ejendomsmæglerens egen hjemmeside Dette er helt loyal adfærd i forhold til sagsøger Sagsøger har fravalgt at anvende tekniske hindringer for at undgå at søgemaskiner kopiererudtrækker information eller at der linkes her under udenom sagsøgers hjemmesides forside Tværtimod inviterer sagsøger robotter og giver instrukser på sin hjemmeside om hvordan disse skal opføre sig nemlig at de anbefales opdatering minimum hver 7 dag Der henvises til Jon Bing i Festskrift til Mogens Koktvedgaard 2003 side 5657 Der henvises endelig til Rapport fra Kommissionen til EuropaParlamentet Rådet og Det Europæiske Økonomiske og Sociale udvalg KOM 2003 702 endelig som er den første rapport om anvendelse af direktivet om elektronisk handel Kommissionen udtaler i afsnit 46 om internetformidlernes ansvar   besluttede visse medlemsstater at indføre begrænsninger i formid leransvaret for leverandører af hyperlinks og søgemaskiner Dette skyldes deres ønske om at skabe incitame nt for investering og innovation samt fremme ehandlens udvikling ved at etablere en yderligere rets sikkerhed for tjenesteydere Mens det ikke blev anset for nødvendigt at lade direktivet omfatte hyperlinks og søgemaskiner har Kommissionen opfordret medlemsstaterne til at udvi de retssikkerheden for internettje nesteformidlere Det er opmuntrende at medlemsstaterne i deres seneste retspraksis anerkender betydningen af linking og søgemaskiner for internet Generelt synes denne retspraksis at være i overensstemmelse med formålet med det indre marked dv s at sikre levering af grundlæg gende internettjenester som fremmer udviklingen af internet og ehandel Denne retspraksis synes derfor ikke at give anledning til pro blemer i forbindelse med det indre marked Det er interessant at Kommissionen i note 70 bla henviser til den ty ske højesteretsdom af 17 juli 2003 om internettjenesten Paperboy hvor retten netop fandt at benyttelse af links direkte til artikler på in 73  ternetavisers hjemmesider ikke udgjorde en krænkelse af eneretten til eksemplarfremstilling eller tilgæn geliggørelse Den tyske databasebe skyttelse er også baseret på databasedirektivet Sagsøgeren gjorde un der sagen gældende at virksomhedens rettigheder i medfør af databasereglerne og det der svarer til den danske markedsføringslovs  1 UWG  3 blev krænket med henvisning til at de dybe link direkte til de enkelte artikler satte brugeren i st and til at få adgang til artiklerne direkte udenom hjemmesidens forside Den tyske højesteret frifandt sagsøgte Rettens begrundelse var at brug af link ikke udgør tilgænge liggørelse idet artiklerne allerede er gjort tilgængelig e ved at blive lagt på internettet uden tekniske hindri nger og rettighedshaveren har der med accepteret at der er direkte adga ng til artiklerne for alle ved hjælp af hjemmesideadressen URLadressen  Benyttelse af dybe link herun der link udenom forsiden er som det udtales i dommen blot en teknologisk måde at skabe nemmere adgang for brugerne end hvis brugerne selv skal taste hjemmesideadressenURLadressen og ophavsretslov givningen kan som det også udtales ikke anses at indebære en eneret til oplysninger om URLadressen Den omstændighed at sagsøgeren foretog bannerannoncering kunne heller ikke ændre på resultatet i medfør af den tyske konkurrencelovs  1 idet retten udtalte at den økonomiske interesse i bannerannonc ering også kunne opnås ved at annoncere på de underliggende sider som der blev linket dybt til I den tyske sag var der tale om ophavsretsbeskyttet materiale artikler og parterne var i et konkurrenceforhold idet der i begge tilfælde var tale om nyhedsformidling Alligevel blev såvel visningen af artiklens overskrift og indholdet af artiklen som linking udenom sagsøgers forside direkte til de enkelte artikler ikke anset for at være retsstridig Der henvises generelt til Mads Bryde Andersen IT retten 2 udgave side 420431 3 Det ophavsretlige grundlag Identifikation i databaseretlig henseende mellem den enkelte homeejendomsmægler og sag søger Det gøres gældende at ophavsretslovens  71 stk 1 i dag skal fortol kes således at der implicit i større antal oplysninger ligger et krav om  74  en væsentlig investering Den efterf ølgende sætning eller som er resul tatet  tager sigte på den situation hvor der ikke er tale om et større antal oplysninger men hvor der desuagtet er foretaget en større inve stering Før gennemførelsen af databasedirektivet og tilbage til den tidligere  49 var det den almindelige opfattelse i dansk ret at et katalog ikke skulle opfylde særlige kvalitetskrav fo r at opnå beskyttelse hvis blot kataloget sammenstillede et større antal oplysninger Var dette tilfældet forelå kataloghøjde en pendant til det tidligere anvendte begreb værkshøjde Formålet med bestemmelsen var at beskytte den bety delige indsats af arbejde og kapital der kan ligge til grund for sådanne frembringelser Ifølge databasedirektivet art 7 stk 1 er beskyttelsen betinget af at den pågældende database er resultatet af en væsentlig investering  Hvad har frembringeren investeret af penge eller kreativitet i udviklin gen Investeringskravet skal måles enten kvantitativt eller kvalitativt  Fra direktivets præambel henvises til betragtning 13 7 9 12 17 19 32 39 og 40 med hensyn til investering i indsamling  kontrol eller præ sentation  Fremstilling er overbegrebet af disse 3 begreber Ordet eller skal fremhæves fordi det har som konsekvens at man ikke ved fastlæggelse af om en investering er væsentlig kan kumulere de 3 elementer jf EFdomstolens dom i sag C20302 Hill præmis 30 Der henvises endvidere til betragtning 41 42 4749  5355  Det gøres gældende at databasedirektivet er udtryk for en totalharmo nisering af beskyttelsen for databaser i EU af følgende grunde 1 Det følger af direktivets egen tekst Der henvises endvidere til præ mis 33 i generaladvokatens indstilling i sag C33802 Svenska Spel Den nye sui generisret som blev indført ved direktivet stammer fra de nordiske katalogrettigheder og den nederlandske geschriftenbescherming Denne baggrund skal dog ikke forlede nogen til at overføre de begreber der har udviklet sig indenfor teori og retspraksis ved rørende disse forløberordninger til direktivet Tværtimod skal direktivet  75  være en målestok for fortolkningen af national ret således at det også gælder for de medlemsstater hvor der allerede før direktivet gjaldt lig nende bestemmelser Også disse medlemsstater var forpligtet til at til passe de nationale bestemmelser til direktivets forskrifter 2 Der henvises endvidere til EFdomstolens fortolkning af varemærke direktivet i sag C35596 Silhoue ttedommen I dommen anføres at en fortolkning af varemærkedirektivet hvorefter dette giver medlems staterne adgang til at foreskrive konsumption i national ret ikke alene for varer som er markedsført inden for EU men også for varer der er markedsført i tredjelande er i strid med direktivet og formålet med di rektivets bestemmelser vedrørende de rettigheder  som et varemærke giver indehaveren Videre anføres at selv om det i direktivets tredje betragtning anføres at det for tiden ikke forekommer nødvendigt at foretage en fuldstændig tilnærmelse af medlemsstaternes lovgivninger om varemærker indeholder direktivet dog en harmonisering af de cen trale materielle regler på området  nemlig af reglerne vedrørende de nationale bestemmelser der har den mest direkte indvirkning på det indre markeds funktion EFdomstolen når frem til denne konklusion i Silhouettedommen på baggrund af at det i varemærkedirektivets første betragtning anføres at den lovgivning der gælder om varemærker inden for medlemssta terne indebærer forskelligheder so m kan hindre den fri bevægelighed for varer og den frie udveksling af tjenesteydelser samt fordreje konkurrencevilkårene i fællesmarkedet Tilsvarende formulering er anvendt i databasedirektivets betragtning 4 hvor det siges at ophavsretlig beskyt telse af databaser findes i forskel lig form i medlemsstaterne i henhold til enten deres lovgivning eller de res retspraksis og så længe forskelle med hensyn til rækkevidden og vilkårene for beskyttelsen vedbliver med at bestå mellem medlemssta ternes lovgivninger kan sådanne ikkeharmoniserede intellektuelle ejendomsrettigheder virke som en hindring for den frie bevægelighed for varer og tjenesteydelser inden fo r Fællesskabet Endvidere angives det i betragtning 48 at formålet med dette direktiv er at etablere et adækvat og ensartet beskyttelsesniveau for databaser  76  Under hensyn til disse betragtninger gøres det gældende at databasedi rektivet må fortolkes således at det indeholder en fuldstændig harmo nisering af de krav til beskyttelse der er knyttet til databasen nemlig de centrale materielle regler Denne fortolkning finder støtte i den om stændighed at betragtning 52 udtr ykkeligt giver de medlemsstater som har specifikke bestemmelser om en ret der er sammenlignelig med den sui generisret som direktivet fastsætter ret til at opretholde de undtagelser som traditionelt aner kendes i disse bestemmelser Med lemsstaterne gives således alene udtrykkelig hjemmel og ret til enegang for så vidt angår eksisterende undt agelser til databaserettigheder  men ikke til at foreskrive eller opretholde forskelligartede beskyttelseskriteri er og niveauer Denne fortolkning er den eneste som fuldt ud kan virkeliggøre direktivets mål der bla er at beskytte det indre markeds funktion Der vil nemlig uundgåeligt opstå hindringer for de frie varebevægelser og den fri udveksling af tjenesteydelser inden for EU i en situation hvor visse medlemsstater alene foreskriver en meget begrænset beskyttelse af databaser hvorimod det er tilladt andre at foreskrive en betydelig bre dere beskyttelse Der henvises til Lisa Vogt Lorentze ns artikel om Dat abasevern 2002 side 2831 hvor forfatteren nærmer e argumenterer for sit standpunkt at  Databasedirektivet er et uttalt harmoniseringsdirektiv På denne baggrund gøres det gældende at det for at sagsøgers database kan opnå beskyttelse efter  71 er en forudsætning at sagsøgers investering opfylder direktivets væsent lighedskrav Det er ikke i sig selv tilstrækkeligt at der i sagsøgers da tabase indgår et større antal oplys ninger Det var det heller ikke før direktivet jf Lisa Vogt Lorentzen side 46 og 56 hvor der også blev stillet krav om en vis investering men med direktivet og dets implementering er overliggeren i relation til inve steringskravet blevet hæ vet Der kræves væsentlig investering i over ensstemmelse med de nærmere kriterie r fastlagt i EFdomstolens prak sis  77  Den retspolitiske baggrund for direktivet er at omfattende investeringer i udvikling af informationssamlinger bø r beskyttes jf betragtning 39 og 40 samt Henrik A Jensen NIR 199968 side 66 og Mads Bryde Ander sen ITretten 2 udgave afsnit 8 4 Hvad der nærmere er beskyttelsens genstand og dermed hvad den væsent lige investering skal vedrøre er nu fastlagt af EFdomstolen i 4 domme af 9november 2004  C4602 Finsk Fixturessag C33802 Svenska Spel C44402 Græsk Fixtures og C20302 Hill Dommene tager stilling til hvilke elementer begrebet investering i art 7 stk 1 består af i relation til resultater af forskellige sportskampe og hestevæddeløb som alle  nøjagtig som i denne sag  kendetegnes ved at udgøre en sekundær afledet aktivitet i forhold til frembringerens primære aktivitet den pågældende sp ortsaktivitet svarende til ejendoms mæglervirksomhed i nærværende sag I dommene lægges det til grund at direktivets investeringsbegre b skal forstås således at det be tegner de midler der anvendes til fremskaffelsen af eksisterende ma teriale og til samlingen heraf og ikke de midler der anvendes til frembringelsen af de bestanddele der udgør databasens indhold I forbin delse med udarbejdelsen af et program vedrørende de pågældende sportsaktiviteter blev det derfor an taget at databasebegrebet ikke om fatter de midler der anvendes til fastsættelse af datoer klokkeslæt og kombinationerne af de hold der skal spille mod hinanden to og to med hensyn til de forskellige kampe i disse mesterskaber henholdsvis de midler der anvendes til at oprette en liste over heste der deltager i løb Hill Begrebet investering forbundet med kontrol af databasens indhold skal forstås således at det omfatter jf afgørelsens 1 led Hill de midler der med henblik på at sikre troværdigheden af den information der er indeholdt i den nævnte database anvendes til at kontrollere det fremskaffede materiales rigtighed ved oprettelsen af databasen og mens den er i drift De midler der anvendes med henblik på kontroloperationer i den fase hvor data eller materialefrembringelsen finder sted og derefter samles i en database er ikke omfattet af dette begreb Midlerne kan bestå i menneskelige finansielle eller tekniske ressourcer men skal være væsentlige ud fra et kvantitativt eller kvalitativt synspunkt  78  EFdomstolen har dermed sendt et umisforståeligt budskab om at det investeringskrav der er knyttet til databasebeskyttelse ikke er opfyldt blot ved at databasen er kommet til verden som en afledet følge af en hovedaktivitet heller ikke selvom en udefra kommende virksomhed skulle have foretaget en væsentlig investering for at frembringe en sådan database uden at drive denne hovedaktivitet Sagsøgte er derfor enig i den konklusion som Mads Bryde Andersen drager i ITretten 2 udgave side 416417 nemlig at en virksomhed der uden særlige for anstaltninger lægger sit salgskatalog ud på nettet ikke derved tilveje bringer en database der opfylder direktivets investeringskrav Dog siges det i EFdommene at det forhold at databasen er forbundet med en hovedvirksomhed ikke udelukker at den kan nyde sui generis be skyttelse præmis 35 i C20302 præm is 29 i C33802 og præmis 45 i C44402 Herom udtaler Mads Bryde Andersen ITretten side 417 I så fald må der stilles yderligere investeringskrav fx i forbindelse med den løbende fremskaffelse og kvalitet ssikring mv og beskyttelsen ræk ker da kun til de aspekter af databasen der reflekterer denne investering EFdomstolen udtaler ikke entydigt hvor stor investeringen skal være for at opfylde væsentlighedskravet men investering i indsamling kontrol og præsentation af løbsdatoer stedangivelse navne og numre for hestene opfyldte i hvert fald ikke investeringskravet Hill præmis 80 Og tilsvarende i dommen i C4602 F insk Fixtures præmis 4446 mht fodboldkampe Resultatet kan overføres direkte til nærværende sag Sagsøgeren har ikke bevist at have foretaget en selvstændig investering i relation til den til homedk knyttede database i forhold til de midler der var nødvendige for dataenes frembringelse EFdommene udtaler ikke generelt hvilke elementer der skal lægges vægt på herunder om væsentlighedsb egrebet er et relati vt eller et ab solut begreb Generaladvokaten udtaler i sin indstilling i præmis 45 i C4602 Finsk Fixtures at det følger af strukturen af art 7 stk 1 at der er tale om et relativt begreb Dette har også støtte i litteraturen jf Henrik A Jensen NIR 199968 side 8084  79  Da det må lægges til grund at invest eringskravet skal fastlægges rela tivt må konsekvensen af direktivets formål om at fremme fri konkur rence og betragtning 47 om at sui generisrettighederne ikke må udgø re et misbrug af dominerende stilling være at investeringens størrelse skal være betydelig Det skal tages i betragtning at markedet for bolig søgetjenester stort set er uden konk urrence Dette skyldes at mægler neDE har monopol på de oplysninger  som skal bruges for at kunne etablere en sådan tjeneste Det er simpelthen nødvendigt at der stilles betydelige krav til investeringens størrelse for at sikre den fri konkurrence jf Henrik A Jensen NIR 199968 side 80 Investeringen skal sættes i relation til den betydelige omsætning som genereres i Home kæden 808000000 kr i 2004 Den omstændighed at homedk og dermed også den hertil knyttede database er et biprodukt til sagsøgers virksomhed bevirker at der må stilles særlige krav til beviset for at investeringen i henseende til databa sebestemmelsen vedrører en selv stændig investering i forhold til de midler der var nødvendige til infor mationernes frembringelse salgsmaterialet Der må med andre ord konkret stilles betydelige krav til størrelsen af investeringen i fremstil lingen og til dokumentationen for at investeringen vedrører det der databaseretligt er relevant Denne bevisbyrde har sagsøgeren ikke løftet Den absolutte størrelse af databasen har ingen betydning for om der i relation til art 7 71 jf Hilldo mmen præmis 10 ca 1 mio heste er tale om en væsentlig investering En anden relevant udtalelse fra EFdomstolen i Hillsagen fremgår af præmis 47 hvor et spørgsmål om hv orvidt det påvirker retten til gen udtræk at de pågældende informationer skal benyttes i en anden database der konkurrerer med den beskyt tede blev besvaret benægtende Dermed har EFdomstolen taget afstand fra den opfattelse at der i afgrænsningen af databasebegrebet skal anlægges et integreret skøn med inddragelse af et skøn om hvorvidt parterne konkurrerer med hinanden Sagsøgte gør gældende at der ikke består et konkurrenceforhold mellem parterne der heller ikke kan siges at konkurrere om samme medieplads men nu er det efter EFdomstolens udtalelse under alle  80  omstændigheder irrelevant for den databaseretlige bedømmelse om der består et konkurrenceforhold jf også den tyske Højesteretsdom Paperboy Endvidere fremhæves fra dommen i C4602 Finsk Fixtures udover præmisserne nr 3233 34353747 sæ rlig afgørelsen der er på linie med Hilldommen I Hilldommen var der også rejst spørgsmål om hvordan et væsentligt udtrækvæsentlig del skal kvalific eres Herom udtales i afgørelsens punkt 3 Begrebet en væsentlig del af en databases indhold vurderet kvantita tivt i den forstand hvori udtrykket er anvendt i artikel 7 i direktiv 969 henviser til omfanget af de data der er udtrukket ogeller genanvendt af basen og skal bedømmes i forhold til omfanget af hele basens indhold Begrebet en væsentlig del vurderet kv alitativt af en databases indhold henviser til omfanget af denne inve stering der er forbundet med ind samling kontrol eller præsentation af indholdet af genstanden for ud trækket ogeller genanvendelsen uanset om denne genstand udgør en kvantitativt væsentlig del af den beskyttede databases generelle ind hold Omfattet af begrebet uvæsentlig del af en databases indhold er enhver del der ikke svarer til begrebet væsent lig del ud fra såvel et kvantitativt som et kvalitativt synspunkt Dommens præmisser 76 78 og 80 er særdeles relevante fordi de fast lægger kriterierne for hvad der fors tås ved et kvalitativt væsentligt ud træk Det er ikke den indre værdi af de data som udtrækket vedrører  men derimod den investering der har været forbundet med deres tilve jebringelse der er relevante  I nærværende sag foreligger ingen oplys ning om den investering der knytter sig til de 13 udtrukne data Vidnet Hanne Brandt forklarede at en sådan investering ikke kan gøres op særskilt Identifikation Den omstændighed at der er tale om forskellige juridiske personer betyder ikke at der ikke i almindelig formueretlig eller databaseretlig for 81  stand kan statueres identitet mellem sagsøger og ejendomsmæglerne Det kontraktuelle forhold mellem sagsøger og de enkelte franchisetage re er ikke oplyst men det fremgår af sagsøgers hjælpebilag at sagsø ger umiddelbart får rettighederne v ed tryk på en knap til ejendomsda taene Sagsøger har altså adgang til oplysningerne på tilsvarende vis som hvis oplysningerne var behandlet i et sagsbehandlingssystem hos sagsøger selv Da der er tale om franchise må det lægges til grund at sagsøger har sikret sig retten til at udtage igangværende arbejder og oplysninger i sagsbehandlingssystemet hvis samarbejdet med en franchisetager op hører Sagsøger stiller krav til CB systemerne og der sker fakturering fra CB direkte til sagsøger Helt generelt omtales homekæden af både direktør Bjerregaard Hanne Brandt og Hans Trautner som en enhed udadtil hvilket også ses på hjemmesiden homedk der benytter udtrykket homekæden som en enhed der indbefatter ejendomsmæglerne og sagsøger Dertil kommer at mæ glerne ikke har deres egne hjemme sider men er integreret i sagsøgers hjemmeside homedk og søgningen efter ejendommene sker gennem den af sagsøgeren ejede hjemmeside og den hertil knyttede database Udadtil optræder de enkelte ejendomsmæglere og sagsøger altså som en enhed Det afgørende er at investeringen i fremstillingen ikke bliver større eller mindre for sagsøger af at det rent juridisk er et selvstændigt forret ningssted der indsamler og behandler oplysningerne medmindre sag søger betaler et vederlag til den enkelte ejendomsmægler eller arbejdet med at indhente oplysningerne forøges ved at oplysningerne skal hentes fra et selvstændigt forretning ssteds sagsbehandlingssystem Sådan forholder det sig ikke Sagsøger betaler ikke noget vederlag til forretningsstederne for at få dataene tværtimod Betalingsstrømmen går den anden vej idet forretningsstederne både betaler en franchiseafgift og særskilt markedsføringsvederlag for at oplysningerne optages på sag søgers hjemmeside Sagsøger får ejen domsdataene gratis ved et tryk på en knap Sagsøger har ikke godtgjort at den juridiske konstruktion af homekæden bevirker nogen forskel med hensyn til investeringens størrelse  82  Der foreligger et adfærdsfuldmagtsforhold mellem sagsøger og de en kelte mæglere således som dette begreb må defineres efter dansk ret Mads Bryde Andersen Grundlæggende Aftaleret 2 udgave 2002 side 298304 Mæglerne har således ladet sagsøger disponere på en sådan måde at tredjemand får det indtryk at dispositionerne binder mæglerne Når selskabskonstruktionen bliv er tilstrækkelig uigennemskuelig tvinges retsanvendelsen til at skære igennem Der bør under de foreliggende omstændigheder statueres adfærdsfuldmagt eller identifikation i relation til sagsøgers forretningskoncept Det afgørende for om investeringskravet er opfyldt er pr imært at sagsøge ren ikke betaler for fremskaffelsen at der kun er én hjemmeside og én database for alle i kæden samt at sagsøger kun foretager kontrol og øvrige handlinger i den fase som knytter sig til selve mæglerforretningens aktivitet Forholdet er det samme som i sagerne for EFdomstolen hvor det også var en af fremstillere n af materialet uafhængig juridisk person der fik dataene udleveret De t bestrides derfor at det selskabs retlige setup har nogen betydning for den databaseretlige vurdering i relation til investeringskravet I relation til vurderingen af om parterne er konkurrenter gælder det samme Man kan ved denne vurdering ik ke bortse fra mæglerdelen idet mæglerne indgår i sagsøgers hjemmeside og sagsøger ikke som sagsøgte driver portalvirksomhed Men konkurrenceforholdene mellem fremstilleren og den der foretager udtrækket er underordnet i data baseretlig henseende 4 Ophavsretslovens  71 stk 1 Væsentlig investering Der gøres gældende at sagsøgers database hverken kvalitativt eller kvantitativt er udtryk for en så væsentlig investering i relation til fremstillingen indsamling kontrol og præsentation af eksisterende selv stændigt materiale at den nyder beskyttelse efter ophavsretslovens  71 stk 1 Af direktivets betragtning 7 fremgår at der tænkes på investering af betydelige ressourcer af menneskelig teknisk og økonomisk art Sagsø 83  geren har i bilag 9 alene opgjort hvad der kan gøres op i økonomi Hanne Brandts forklaring om to perso ner i 8 år til ca 500000 pr per son er af så diffus og udokumentere t karakter at den er uden betyd ning Det fremgår af Hilldommen præmis 30  at begrebet investering der er forbundet med indsamling kontrol eller præsentation af en databases indhold generelt skal forstås således at det betegner den investering der ligger i oprettelsen af denne database Det der vedrører den almindelige løbende drift indgår altså ikke Det samme gælder markedsføringsudgifter jf præmis 31 og Lisa Vogt Lo rentzen Databasevern 2002 side 62 Begrebet investering i art 7s forstand skal forstås således at det be tegner de midler der anvendes til fremskaffelsen af eksisterende selv stændigt materiale og samlingen heraf Det omfatter ikke de midler der anvendes til frembringelse af de bestanddele der udgør databasens indhold jf alle EFdomstolens fire afgørelser Vedrørende investering i indsamling har sagsøger ikke nogen udgifter Der sker ikke betaling til mæglerne og sagsøger har ikke dokumenteret eventuelle udgifter til det softwarepr ogram der overfører data til data basen under homedk I bilag 9 opregnes 3 kategorier af omkostninger 1 Drift af Bas 2 udvikling 3 udviklingma rkedsføring Sidstnævnte post på 4080000 kr der vedrører layout grafik mv skal der ubestridt ses bort fra i relation til ophavsretslovens  71 Om kategori 2udvikling har sagsøger oplyst at der er tale om de programmer der laver forretningslogik præsentation  og som herun der automatisk udfører de kontroller  som foranstaltes af de forskellige dataoverførsler til den database der er knyttet til hjemmesiden ho medk Men omkostningerne er ikke specificeret i en sådan grad at det på nogen rimelig måde kan adskilles hvilke omkostninger der er med 84  gået til etableringen af den database der er knyttet til homedk og sel ve hjemmesiden homedk henholdsvis hvilke omkostninger der går til de andre formål som base 2002 og billeddatabasen Home MPS og som er denne sag uvedkommende Det fremgår af sagsøgers hjælpebi lag at det vedrører omkostninger til internet generelt I det setup hjælpebilaget angiver indgår elementer der er denne sag helt uvedkommende hvilket er er erkendt af sagsøger under proceduren og det er dette forhold der har fået sagsøgeren til at reducere sine investeringsomkostninger ganske betragteligt  Men heller ikke de resterende omkostninger er databaseretlig set relevante Om forretningslogikken i kassen homedk på hjælpebilaget kan det ud ledes at der i logikken reelt er tale om 3 adskilte grupper af forretningslogiske processer Databasen er der hvor den fysiske opbevaring af de rå data i struktu reret form sker Der anvendes en Microsoft SQL server Denne database opbevarer de enkelte sager individuelt med de relevante data tilknyttet i struktureret form Individualiseringen og struktureringen af data hånd teres automatisk af databasen og in dsamlingen indebærer ikke udgifter for sagsøgeren Forretningslogikken er den programkode der styrer og håndterer funktionaliteten på hjemmesiden homedk dvs det man som bruger af hjemmesiden kan foretage sig Der er tale om en flerhed af funktioner a Funktioner der styrer søgningen i databasen og præsentationen af søgningens resultat resultatlisten hvorfra de 13 data uddrages b funktionaliteten på den individuelle boligsag på hjemmesiden c funkti oner der styrer mæglernes adgang ti l og behandling af tilstandsrappor ter d funktionaliteter der styrer hjemmesidens mange sider i brugergrænsefladen det vil sige forside undersider med film sider med er hverv med nyheder og alt det øvri ge markedsføringsmateriale der lig ger på homedk Det gøres gældende at ingen af de investeringer der knytter sig til ovenstående er relevante i databaseretlig henseende fordi der enten er tale om materiale der knytter sig til alt andet på hjemmesiden end da 85  tabasen eller som ikke opfylder EFdomstolens kriterium om at der skal være tale om investering i relation til eksisterende selvstændigt materiale Hvis det antages at der er tale om eksisterende materiale i databasedi rektivetsophavsretslovens forstand  er det kun den funktionalitet nævnt under a der styrer søgningen som databaseretligt kan henføres under begrebet præsentation og kontrol nemlig af de data der vedrører det udtræk der foretages fra den til homedk knyttede database Det er derfor  om nogen overhovedet  kun denne investering der skal medregnes i investeringen Denne investering har sagsøger ikke op gjort Brugergrænsefladen er det visuelle lag for brugeren som ikke kan udgøre en relevant investering i databaseretlig forstand Kontrol Hanne Brandt forklarede at det program der kontrollerer data mellem CBsystemet og base 2002 kontroll erer betydelig flere data end dem der anvendes i databasen under homedk Det fremgår klart af hjælpe bilaget at det ikke er alle data der kommer ind i base 2002 som eksporteres til databasen under homedk De udgifter der måtte være til kontrol er ikke databaseretligt relevante idet de vedrører kontrol i fremstillingsfasen Sagsøger er jo en del af denne proces Det gælder under alle omstændigheder de udgifter der måtte være i forbindelse med kontrol mellem base 2002 og CB syste merne Hanne Brandt angav nogle skøn over kontrolomkostningerne som andrager fra 200000 kr til 700000 kr de senere år men det er skøn som vi ikke kender grundlaget for og det er ikke dokumenteret hvilket led i processen disse skønnede udgifter relaterer sig til Det er ikke godt nok til at løfte sagsøgers bevisbyrde Også udgifterne til den kontrol der sker mellem base 2002 og basen under homedk kan der ses bort fra med samme begrundelse Udover at der er tale om kontrol i frembringelsesfasen er det ikke dokumente ret hvad kontroludgiften udgør Alt er blandet sammen efter en konto 86  plan der ikke er beregnet på doku mentation af inve steringsomkostnin ger i relation til ophavsretslovens  71 Der skal utvivlsomt ses bort fra alle udgifter der knytter sig til base 2002 Feks anvendes base 2002 til at servicere mæglere i forbindelse med udveksling af sager til udvekslin g af data mellem mæglerne og Nybolig mfl det er en fejl på hjælpebilaget når det viser at det sker fra homedk samt til statistikinfor mation vedrørende mæglerforretnin gen Herudover forklarede Hanne Brandt at der er anskaffet programmer til servicering af mæglerforretningernes behov for kort tilstandsrapporter og sundhedsattester se de 2 kasser på hjælpebilaget OBHI og KRAK Med hensyn til Home MPS billeddatabasen blev det forklaret at den også anvendes som et annonc estyringssystem primært til avis annoncering som ifølge Hans Trau tner i gennemsnit udgør 80  af markedsføringen Hanne Brandt oplyste at der udføres kvalitetskontrol på billedernes opløsning samt om det er de rigtige billeder der ligger på sagen Der er altså også her dels tale om kontrol i den fase hvor data eller materialefrembringelsen sker smh Hilldommen afgørelsens 1 led nemlig i det led der tilhører mæglerforretningsdelen og dels at billedatabasen for 80  vedrører et helt andet formål end den database som sagen her drejer sig om nemlig avisannoncering Hanne Brandt forklarede at overførsel af data mellem MPSbilleddatabasen og databasen under homedk sker ved en service der synkroniserer med nye billeder og tekster Der er altså ingen kontrol i dette led og evt omkostninger i dette led er i hvert fald ikke specificeret Der er tale om ren dataudveksling og udgifterne hertil er uoplyste men sagsøger betaler ikke for billedmateriale Bortset fra skyline vedrører billederne mæglernes kerneforretning De særlige udgifter til skyline er ikke op lyst Også udgifterne til forretningslogikpræsentation deles op i det der har med databasen under homedk at gøre og det der er uvedkommende Det må igen understreges at den forretningslogik der ligger til grund for base 2002 er sagen uvedkommende fordi det ikke klart er specificeret hvilke ressourcer der er forbundet med forretningslogikken til de formål base 2002 bruges til og som ikke har med databasen un der homedk at gøre Feks sker udveksling af data mellem de mægle 87  re Home samarbejder med fra base 2002 og ikke fra homedk som angivet på hjælpebilaget Den struktur som ligger til grund for denne udveksling er sagen uvedkommende Tilsvarende gør sig gældende i relation til de andre formål statistik mv Det kan derfor konkluderes det ikke er dokumenteret hvad udgiften til præsentation i relation til databasen under homedk er Det hele er blandet sammen i omkostninger til internet Bevisbyrden er sagsøgers og denne bevisbyrde er ikke løftet  Den relevante udgift er om der overhovedet er nogen langt mindre end angivet Vedr driftsomkostningerne i bilag 9 forklarede Hanne Brandt at der indgår diverse abonnementer Cowi Krak software teknisk drift og overvågning trafik housing over vågning billeddatabase og teknisk support hertil ved løbende drift og endvidere markedsføringsudgifter til smstjeneste Den store omkostningsstigning mht drift fra 2002 til 2004 skulle vedrøre meromkostninger i forbindelse med Krakkort De nævnte udgifter kan ikke medregnes som udgifter til fremstillingen af databasen i relation til sui generis beskyttelsen Mest oplagt er det for smstjenestens vedkommende der er ren markedsføring og housing hvori indgår leje af lokaler men også den almindelige løbende drift er helt uvedkommende og kan ikke henregnes under de databaseretlige fremstillingsomkostninger Billeddatabasen Krak og Cowi som vedrører mæglerforretningsenheden kan ikke medregnes Tilstandsrapporter er som bekendt et lovkrav Under alle omstændigheder ville der som minimum skulle ske en opdeling så det kun er det lille beløb på kr 25000 til kommuneoplysninger som ifølge forklaringerne ikke blev brugt af mæglerne Den samlede post driftsomkostninger kan sammenfattende ikke henregnes under investerings omkostninger til databasen under homedk Også her er det hele blandet sammen og der er ingen dokumentation for hvilken del af drift af BAS der udgør reelle fremstillingsudgifter eller hvilken del heraf  om nogen overhovedet  der kan henregnes til den under homedk liggende database  88  Grunden til at sagsøgeren har så store vanskeligheder med at løfte sin bevisbyrde er at der er tale om en hjemmeside hvor sagsøgerens in vestering alene går ud på at lægge sine ydelser frempræsentere ydel serne for et marked Der er ikke nogen selvstændig investering i relati on til eksisterende materiale udviklet med henblik på fx ehandel på internettet men alene annoncering med henblik på salg af fast ejendom hvor materialet allerede foreligger i form af elektroniske ejendomsoplysninger i struktureret søgbar form som sagsøgeren umiddelbart har adgang til Sammenfattende gøres det gældende at sagsøgers arbejde med at samle og kontrollere oplysningerne databaseretligt vedrører frembrin gelsen af de bestanddele der udgør databasens indhold Det er åbenbart at det kun kræver en relativt beskeden investering for sagsøger at overføre oplysninger om ejendomme til internetmediet når der er tale om materiale der foreligger i form af elektroniske salgsopstillinger mv på de enkelte forretningssteder og som sagsøger har gratis adgang til Omkostningerne er under alle omstæn digheder for minimale til at man kan kvalificere arbejdet som en væsentlig investering kvalitativt og kvantitativt i ophavsretslovens forstand og omkostningerne er konkret uoplyste og uspecificerede Sagsøgers opgørelse er for lemfældig Konkret udgør databasen i relation til de udbudte ejendomme kun et biprodukt jf Hilldommen præmis 35 hvilket stiller særlig store krav til beviset for at der foreligger en selvstændig investering Denne bevisbyrde har sagsøgeren ikke løftet Den omstændighed at sagsøgeren har monopol på oplysningerne stiller særlige krav til beviset for investeringsomkostningerne Heller ikke i denne henseende er bevisbyrden løftet Selvom dele af sagsøgerens hjemmeside i teknisk henseende udgør en database nyder den ikke beskyttelse efter sui generis reglerne Det gøres med henvisning til direktiv ets art 7 yderligere gældende at hver af udgiftsposterne skal være af væsentlig karakter jf ordet eller Der henvises til betragtning 40 jf  præmis 30 i Hilldommen der be kræfter at der er tale om alternat ive betingelser som hver især skal opfylde væsentlighedskravet Der stilles store krav til sagsøgerens do kumentation jf Henrik A Jensen  NIR68  Som en opsummering  under dette punktet må det sies at det arbeid og de kostnader som skal  89  kunne regnes som en investering i he nhold til artikkel 7 må være rime lig konkrete og knyttet til produksjonen af databasen Det er helt rimeligt at det er sådan for sui generisbeskyttelsen er en undtagelse en særlig udvidelse af det ophavsretlige værn I bilag 9 er de samlede investeringsomkostninger opgjort til ca 31800000 kr Dette beløb skal ifølge sagsøgerens egen opgørelse reduceres med kr 4080000 markedsføring Sagsøgeren nedsatte under sin procedure udviklingsomkostningerne til ca 7600000 kr svarende til 90  og fastsatte udgifterne til drift til skønsmæssigt 3000000 kr Det giver samlet 10600000 kr Herefter som en kanin op af hatten har sagsøgeren lagt et beløb på 8000000 kr til svarende til den skønsmæssige udgift til 2 medarbejdere i 8 år således at investeringen opgøres til samlet 186000 00 kr Det er ikke en seriøs bevis førelse i betragtning af de ressourcer der er lagt i denne sag Det gøres gældende at der helt skal bortses fra bilag 9 og sagsøgerens omkostningsopgørelse Hovedargumentet for at der gælder en høj tærskelværdi er at der ifølge direktivets tekst skal være foretaget en væsentlig investering før beskyttelse opstår Ved at sætte tærsklen højt tager man også hen syn til at der skal være et relativt bredt public domain for informatio ner Herved forebygges risikoen for at der skabes informationsmonopo ler hvilket er imod databasedirektivet  Denne risiko er stor i denne sag fordi mæglerne har monopol på informationerne Hertil kommer den betydelige omsætning i homekæden på 808000000 kr den omstæn dighed at der er tale om ren information som ingen har rettigheder til samt den omstændighed at der konk ret er tale om et biprodukt Konklusionen er derfor at den til homedk knyttede database ikke i ju ridisk henseende er en database fordi databasedirektivets og ophavs retslovens investeringskrav i relation til at der skal være tale om investering i eksisterende selvstændigt mate riale ikke er opfyldt respektive at sagsøgeren ikke har dokumenteret at have afholdt databaseretligt set væsentlige investeringsomkostninger  90  Måtte retten ikke være enig heri og finde at den til sagsøgers hjemme side knyttede database er omfattet af sui generisreglerne er rettighedshaveren beskyttet mod to former for udnyttelse jf ophavsretslo vens  71 stk 1 og stk 2 nedenfor pkt 5 og 6 5 Ophavsretslovens  71 stk 1 Væsentligt udtræk kvalitativt set Sagsøgers hjemmeside indeholder ca 15000 udbudte ejendomme og en række data om hver af disse ejendomme De faste kategorier af op lysninger omfatter ca 66 data bilag R eller snarere 70 jf Hanne Brandts forklaring Hertil kommer bi lleder den relativt lange præcise verbale beskrivelse af ejendommen og diverse links Det er ubestridt at det alene er 13 data vedr ejendommens pris alder størrelse belig genhed og antal værelser der kopieres til sagsøgtes database Herud over oplyses internetadressen hvorfra disse oplysninger er tilgængelige Det er et formål med art 7 jf bet ragtning 69 at undgå at en bruger ved sine handlinger skader investeringen i kvalitativ eller kvantitativ henseende Der henvises endvidere til betragtning 42 Af Hilldommen præmis 71 jf præmis 82 og selve afgørelsens 3 led fremgår at en væsentlig del af en databases indhold vurderet kvalita tivt henviser til omfanget af den investering der er forbundet med ind samling kontrol og præsentation af indholdet af genstanden for udtrækket ogeller genanvendelsen ua nset om denne genstand udgør en kvantitativ væsentlig del af den beskyttede databases generelle indhold  En kvantitativ ringe del af en data bases indhold kan med hensyn til ind samling kontrol og præsentation udgøre en væsentlig menneskelig teknisk eller finansiel investering De tte er uddybet i pr æmis 76 78 og 80 hvor det klart siges at det ikke er værdien af dataene men den investering der har været forbundet med at tilvejebringe dem der er relevant  91  EFdomstolen har altså fuldstændig forkastet at det er den indre værdi af dataene der er relevante og den litteratur som sagsøger henviser til på dette punkt HA Jensen NIR 19 9968 side 7273 er således for ældet Af bilag 9 kan der ikke udledes noget overhovedet vedrørende den investering der har været forbundet med indsamlingen kontrollen eller præsentationen af de 13 data Omkostningerne kan ikke udskilles fra de øvrige omkostninger til internet Hanne Brandt forklarede at der ikke kan siges noget om investeringen mht de 13 data Med så klar en tilkendegivelse er der ikke grundlag for at kvalificere de 13 data som kva litativt væsentlige Sagsøger her ikke gjort noget forsøg på at godtgøre investeringens størrelse i relation til disse data selvom det siden EF domstolens afgørelser i november 2004 har stået klart at et sådant bevis er nødvendigt for at komme igennem med et anbringende om at et dataudtræk er kvalitativt væsentligt Hertil kommer at både Niels Bjer regaard og Hans Trautner forklarede at der ikke er konstateret nogen skade Sagen føres fordi den er principiel Begge forklarede at Home frygter at boligofir tjenesten betyder færre besøg via homedks forside at mæglerne ikke fortsat vil bakke op om homedk og at det vil kunne skade brandet Der er altså ik ke sket nogen skade endnu Det stemmer med at der er nedlagt på stand om et meget lavt skønsmæs sigt beløb på 250000 kr  der både dækker erstatning og vederlag Det gør ikke nogen forskel at nogle af de 13 data er søgedata Det er forretningsmæssigt logisk at sagsøgte har kopieret netop de 13 data som minimum for at sagsøgte kan skabe en internetboligsøgetjeneste og dermed fremme formålet med databasedirektivet Det gøres gældende at der ikke er sket nogen skade men at sagsøgers forretning tværtimod understøttes af sagsøgte ved at brugere af bo ligofirdk kan komme til homedk blot ved at klikke på et link Ophavsretslovens  22 citatreglen der jf  71 stk 5 finder tilsva rende anvendelse på databaser påberåbes ex tuto Hvis en handling er forbudt efter  71 stk 1 og 2 kan den være tilladt efter citatreglen Det gøres gældende at de gengivelse r af faktuelle oplysninger der op 92  træder på sagsøgtes hjemmeside under alle omstændigheder er omfat tet af ophavsretslovens  22 da der er tale om korte præcise citatop lysninger til gavn og information for brugere af internettet nemlig til brug for afgørelsen af om brugeren skal aktivere linket til ejendoms mægleren Også efter denne bestemmelse er der tale om gengivelse i overensstemmelse med god skik og alene i det omfang som betinges af formålet om brugeroplysning om hvilke ejendomme der aktuelt annon ceres til salg på internettet jf lov om omsætning af fast ejendom  5a Udtrykket laveste fællesnævner om sagsøgtes produkt er både i relation til ophavsretslovens  71 og  22 positivt idet sagsøgte kun har kopieret det der er nødvendigt fo r at kunne udbyde en brugervenlig internetsøgetjeneste  altså det der er betinget af formålet Der er ale ne tale om objektiv information om ejendomme som er til salg og dermed oplysninger som der ikke er knyttet rettigheder til 6 Ophavsretslovens  71 stk 2 Uvæsentlig del af databa sen Mads Bryde Andersen udtaler i 2 udgave af ITretten side 426 Derimod ligger det nogenlunde fast at man ved at stille søgemulighe der til rådighed for almenheden genne m en søgerobot ikke bevæger sig indenfor området af stk 1 Søgerobott ens funktion er jo netop ikke at kopiere hele basen men derimod at give brugeren en enklere adgang til selv at finde frem til og kopiere ud valgte dele af den  Det springende punkt er derfor om denne anvendelse kan siges at udgøre en normal udnyttelse eller skader fremstillerens legitime interesser urimeligt jf  71 stk 2 2pkt Vurderingen af dette spørgsmål falder i hovedsagen sammen med den god skikvurdering der feks anlægges efter mfl  1  Men efter EFdommene kan det jf  Hilldommen præmisserne 8395 navnlig præmis 89 og 91 samt selve afgørelsens punkt 4 siges klart at art 7 stk 5 ophavsretslovens  71 stk 2 er en ren omgåelsesbestemmelse i relation til forbuddet i ophavsretslovens  71 stk 1 og der skal ikke foretages en god skik afvejning efter markedsføringslovens principper  93  Sagsøgtes handlinger hverken omgår eller har til hensigt at omgå  71 stk 1 idet sagsøgte ikke tilsigter at gøre hele sagsøgers database eller en væsentlig del heraf tilgængelig for offentligheden Dette er klart fremgået af bevisførelsen herunder Jørgen Wittenkamps forklaring Sagsøgte handler således ikke i  71 stk 2s forstand i strid med normal brug og skader derfor heller ikke sagsøgerens investering alvorligt Der henvises endvidere til det om sa gsøgers erstatningskrav anførte Måtte retten være uenig heri gør sagsøgte til støtte for at der ikke foreligger en krænkelse efter ophavsretslovens  71 stk 2 subsidiært tillige de god skik betragtninger gældende som følger nedenfor vedrø rende markedsføringsloven 7 Markedsføringslovens  1 Det gøres gældende at sagsøgte ikke udviser en sådan adfærd at markedsføringsloven er overtrådt Sa gsøgers bevisbyrde er ikke løftet Ophavsretslovens  71 gør op med alt der relaterer sig til udtrækket af data  71 er lex specialis og det følger af  71 stk 6 at aftaler der udvider fremstillerens ret er ugyldige jf direktivets artikel 15 Herud over henvises til betrag tning 6 hvorefter direktivet implementeres net op fordi harmonisering af medlemss taternes lovgivning vedr illoyal konkurrence endnu ikke er gennemf ørt Det er herefter sagsøgtes standpunkt at markedsføringsloven ikke kan udvide beskyttelsesområ det i relation til selve udtrækket af data Ophavsretsloven og andre immaterialretlige love fx varemærkeloven der har en anden natur end markedsføringsloven kan frit kombineres med markedsføringsloven Men netop sui generisreglerne i  71 har ikke en anden natur end markedsføringsloven Med hensyn til linkfunktionen var Mads Bryde Andersen en af de første i Danmark der beskæftigede sig med robotteknologien i relation til databasereglerne Der henvises til artiklen i U2000B311 side 5 og IT retten side 426431 konklusion side 429 Mads Bryde Andersens ana 94  lyse er mere restriktiv end den som den tyske Højesteret foretog i Pa perboysagen I nærværende sag har sagsøger ikke bannerannoncering og sagsøgte fortager linking helt loyalt det er tydeligt at der stilles om til mæglernes hjemmesider der vises ubestridt en side hvor det angives at der nu stilles om til ejendomsmæglerens side Der stilles sågar et forside link til rådighed hvorefter den videre sø gning sker på helt normal måde på sagsøgerens hjemmeside ligesom hvis brugeren var gået ind via sagsøgerens forside Det gøres gældende at etablering af et indeks som boligofir kombine ret med henvisninger i form af links i internetsammenhæng er sædvanlig og i overensstemmelse med international praksis og kutyme svarende til de bibliotekskartotekskort over bøger som informerer brugeren om hvor bøgerne kan findes og af vital betydning for informations søgning på internettet idet det er den eneste måde man som bruger kan finde den information man søger De der offentliggør oplysninger på internettet må derfor påregne og implicit siges at samtykke til at der kan og vil ske brug af materialet og henvisninger til materialet og de pågældende websteder i form af links Der består ikke nogen konkurrencerelation mellem parterne idet sagsøgers forretningsgrundlag er formidling af ejendomme mens sagsøgtes forretningsgrundlag bla er tilrådighedsstillelse af forskellige internet tjenester herunder samleoversigter over ejendomme og biler til salg homedk er et helt andet produkt med 15000 ejendomme mens boligofirdk indeholder samtlige ejendomme udbudt til salg via internettet dvs ca 40000 ejendomme Parterne er heller ikke konkurrenter i henseende til mediepladsen Sagsøgte formidler ikke ejendomme på inter nettet men stiller sin søgerobot til rådighed for brugerne så de kan finde udbydernes annoncer på internettet og giver mulighed for at private kan sætte deres ejendom til salg på nettet Sagsøgeren har ikke godtgjort hv ilke forretningsmæssige interesser som skades ved sagsøgtes link udenom sagsøgerens forside herunder ej heller hvilke interesser sagsøgeren afskæres fra at udnytte Det er  95  derimod dokumenteret at sagsøgeren har indgået aftaler med sine konkurrenter om dyb linking til sagsøgerens hjemmeside uden at der stilles et forsidelink til rådighed De t fremgik af Hans Trautners forkla ring at det handler om kontrol med markedet Af Niels Bjerregaards forklaring fremgik at sagen er princi piel at der ikke var sket skade og at problemet ikke så m eget var Ofir som det som andre kunne finde på Det lyder hult når det hævdes at boligofir kan fortrænge sagsøgers markedsposition Sagsøgers primære indtjeningsgrundlag er og bliver salg af ejendomme og da sagsøgtes boligindeks kan udbrede kendskabet til ejendommene er det snarere sandsynligt at sagsøger kan forøge sit indtjeningsgrundlag ved sagsøgtes link til sagsøgers ejendomme simpelthen fordi ejendommene  helt målrettet efter købernes individu elle søgekriterier  kan findes på ne ttet som i modsætning til aviserne opdateres dagligt Ofirdk er en seriøs portalvirksomh ed Der er almindelige kommercielle bannerannoncer på portalens forside På boligofir ser man kun annon cer som er relevante for boligofirtjenesten og som ingen kan have nogen legitim indsigelse imod Tjenesten er jo gratis og finansieringen tilvejebringes gennem reklameindtægter Det er en bevidst politik fra sagsøgtes side at bannerannoncerne skal passe til indholdet Specialiserede søgemaskiner som bolig ofir er helt sædvanlige alminde ligt anerkendte og udbredte på internettet og understøtter almene sam funds og forbrugerhensy n samt hensynet bag lov om omsætning af fast ejendom  5a Sagsøgeren har ikke implementeret nogen teknisk foranstaltning for at hindre robottering Tværtimod Sagsøgeren opfordrer alle robotter til at komme forbi og blive opdateret min hver 7 dag Al tekst skrives i ren tekst og de enkelte mægleres logotypes anvendes ikke Der sker løbende opdateringer så dataene er korrekte og ajourførte Sagsøgte har sin helt egen profil hvorfor der ikke skabes en forbindelse mellem sagsøgeren og sagsøgte ved sagsøgtes handlinger Hvis ejendomssælgerne blev spurgt om de var interesseret i så mange ind 96  gange som muligt til deres ejendo mme ville de utvivlsomt svare be kræftende Der foreligger åbenbart ikke nogen sn yltning eller profilering på bekost ning af sagsøgeren eller anden adfæ rd i strid med god skik Resultatet af en søgning på sagsøgtes søgetjeneste er netop at brugeren opnår information som brugeren gennem sin søgning selv har fremkaldt Bru geren har mulighed for at klikke sig vi dere til fx sagsøger der ejer den hjemmeside hvorfra ejendommen udbydes til salg hvilket i givet fald kun kan resultere i større eksponering og i bedste fald en handel til fordel for mægleren Sagsøgte bidrager dermed til at sagsøgeren opnår sagsøgerens erklærede formål med hjemmesiden kontakt til flest muli ge køberemner og hurtigere salg Sagsøgerens henvisning til at sagsøgtes handlinger er ødelæggende for sagsøgerens strategi er et skinargument Strategi ikke er en rettighed Som erhvervsdrivende må man tilpasse sin strategi efter retsudviklingen og markedet Sagsøgte har med sin søgetjeneste for det første skabt et helt nyt produkt et samleværk som adskiller sig væsentligt fra de eksisterende søgetjenester på markedet Dette prod ukt er et stykke selvstændigt ud viklet software Sagsøgte var first mover i kapløb med boligsøgetjene sten Kapow Forestiller man sig at hver ejendomsmægler har en bog eller et katalog over salgsemner gør boligofir det muligt at søge i indholdsfortegnelserne i alle disse bøger på ét sted  samtidig For det andet er tjenesten unik idet visningen på boligofir foregår ud fra objektive kriterier Foretager brug eren en søgning på ejerlejligheder mellem 15 og 2 mio kr vises resultaterne fortløbende fra den billigste lejlighed til den dyreste  ingen mæglere favoriseres eller forfordeles Foretages samme søgning hos sagsøgeren fremkommer resultaterne derimod først med de lejligheder sagsøgeren har til salg og herefter med resultaterne fra sagsøgerens aftalepartnere Boligofir giver som nævnt alle  ejendomsmæglere private advokater etc  mulighed for at lægge boligannoncer ind i databasen Dette er ikke muligt hos homedk eller andre af de store ejendomsmæglere  97  Boligofir er således et værktøj der adskiller sig fra de eksisterende in ternetsøgetjenester og som er til st or nytte for brugerne 1 det er gra tis og nedsætter den tid brugeren skal afsætte til at foretage boligsøg ning væsentligt 2 det giver brugeren et hurtigt overblik over samtlige salgsemner på markedet og 3 det er med til at skabe et overblik og gennemsigtighed på boligmarkedet som boligrapporten jf lov om omsætning af fast ejendom  5a netop opfordrer til Der henvises til sagsøgtes opgørelse over investering i forbindelse med skabelsen af boligofir bilag Z og Jørgen Wittenkamps forklaring Af bemærkningerne til lovforslaget vedr  5a i lov om omsætning af fast ejendom fremgår at formålet med loven er at gøre det nemmere og billigere at handle bolig Hensynene bag  5a må derfor indgå i den markedsføringsretlige vurdering Sa gsøgte gør gældende at disse hen syn netop tilgodeses af sagsøgtes tjeneste boligofir Dansk Ejendoms mæglerforenings boligsidendk opfylder ikke dette formål da den ikke er et komplet indeks fordi den ikke er tilgængelig for privates annoncering Særlig mht Newsboosterdommen UfR 20031063 S bemærkes at der er tale om en udeblivelsesdom i forbindelse med en justifikations sag anlagt efter et nedlagt fogedfor bud Afgørelsen er forkert efter EF domstolens afgørelser fra november 2004 men der er under alle omstændigheder klare forskelle i faktum i forhold til nærværende sag Dels var der tale om ophavsretsbeskyttet materiale i form af nyhedsartikler dels var der bannerannoncer på internetavisernes forside og et konkurrenceforhold mellem parterne 8 Erstatning vederlag Sagsøgers erstatnings og vederlagskrav er fuldstændig udokumenteret og må ikke mindst i lyset af sagsøgers egne vidneforklaringer afvises Det kan hverken efter markedsføringslovens  13 eller ophavsretsloven  83 komme på tale at yde erstatning for ideel skade Begge bestem melser er investeringsværn og forudsætter et rent økonomisk tab  98  9 Konkurrencelovens  11 og  6 Databasedirektivet fastslår klart bet ragtning 47 og artikel 16 stk 3 at sui generisretten ikke må udnyttes på en sådan måde at konkurren cen begrænses og at sådanne begrænsninger skal imødegås konkur renceretligt Måtte det antages at sagsøgers data base nyder sui generisbeskyttelse indtager sagsøger en dominerende stilling Dette skyldes at sagsøger respektive DE så vil være den eneste kilde til de informationer som det er nødvendigt at robottere og linke til for at sagsøgte kan udbyde ofirdk Et forbud mod at robottere og linke til sagsøgers hjemmeside vil derfor indebære et de facto monopol som gør det muligt for sagsøger at hindre effektiv konkurrence på markedet for boligsøgetjenester på internettet Med henvisning til EFdomstolens do m af 6 april 1995 i de forenede sager C24191 P og C24291 Magill præmis 46 og 47 kan retten lægge til grund at sagsøger indtager en dominerende stilling Det følger endvidere af EFdomstolens praksis særligt Magill og C48101 IMS at sagsøger misbruger sin dominerende stilling ved at modsætte sig robottering og linkning Magillsagen modificerer det konkurrenceretlige udgangspunkt hvoref ter licensnægtelse normalt ikke udgør misbrug af dominerende stilling Spørgsmålet i sagen var om det udgjorde misbrug at nogle tvselskaber som udgav hver deres tvprogramblad for deres egne tv kanaler påberåbte sig ophavsret til deres egne programoversigter for at forhindre at forlaget Magill udgav en komplet tvguide dvs en samlet programoversigt for alle tvkanaler Domstolen besvarede spørgsmålet bekræftende af 4 grunde For det første var tvstationerne de eneste kilder til de oplysninger  som var absolut nødvendige for at Magill kunne udgive en samlet pro 99  gramoversigt præmis 53 Denne betingelse er opfyldt fordi sagsøgte ikke via alternative kanaler kan få adgang til sagsøgers boliginformatio ner som er nødvendige for at sagsøger kan udbyde ofirdk For det andet hindrede tvstationernes li censnægtelse at der blev skabt et nyt produkt  en komplet programoversigt  som tv stationerne ikke selv udbød og som der var en potentiel efterspørg sel efter fra forbrugernes side præmis 54 Denne betingelse er op fyldt fordi sagsøgte som den første i Danmark udbød en generel boligsøgetjeneste på internettet som derfor var et nyt produkt som der har været en dokumenteret stor efterspørgsel efter Det er ikke en relevant omstændighed at sagsøger via Da nsk Ejendomsmæglerforening udby der Boligsidendk fordi denne søgetjeneste er etableret længe efter boligofir Som det tredje var tvstationernes licensnægtelse ikke begrundet i sær lige forhold vedrørende tvvirksomhed eller udgivelsen af programblade præmis 55 Denne betingelse giver ikke anledning til bemærkninger Som det fjerde udelukkede tvstationernes licensnægtelse enhver kon kurrence på det afledte marked for ugentlige tvprogrambalde som tv stationerne derved forbeholdt sig selv præmis 56 Også denne betin gelse er opfyldt fordi et forbud mod robottering og linkning vil have som konsekvens at boligofir reelt udelukkes fra at eksponere Danmarks suverænt største ejendomsportef ølje udbudt til salg på internet tet og derfor afskæres fra at give et samlet øjebliksbillede af alle ejen domme som udbydes på markedet Fra et forbrugersynspunkt er det en nødvendig forudsætning for boligofirs troværdighed og værdi som boligsøgetjeneste at man kan få dette samlede overblik og at brugerne kan anvende tjenesten som et effektivt søgeværktøj Det understreges at sagsøger  vi a Dansk Ejendomsmæglerforening  er til stede på markedet for udbud af boligindeks og internetsøgetjenester og at sagsøger derfor forbeholder dette  afledte  marked for sig selv og Dansk Ejendomsmæglerforenings øvrige medlemmer  100  Afgørende for om Magillkriterierne er opfyldt  herunder det centrale nyhedskriterium  er forholdene på det tidspunkt hvor licensen nægtes første gang dvs det tidspunkt hvor sagsøger første gang gjorde indsi gelse mod sagsøgtes robottering og linking EFdomstolens dom i IMSsagen cementerer dette tidsperspektiv og præciserer kriterierne i Magillsagen idet den fastslår at en licen s til at udøve en bestemt aktivitet kun vil udgøre misbrug af dominerende stilling når 3 kumulative betin gelser er opfyldt Nægtelsen hindrer fremkomsten af et nyt produkt som der er en potentiel efterspørgsel på fra forbrugernes side  Denne betingelse er opfyldt jf vedr Magill Nægtelsen vil udelukke enhver konk urrence på et afledt marked  Denne betingelse er også opfyldt jf vedr Magill Nægtelsen er ikke objektivt begrun det  Også denne betingelse er op fyldt Sagsøger er på intet tidspunkt fremkommet med nogen saglig grund til at forbyde sagsøgte at robottere og linke Dette illustreredes af direktør Niels Bjerregaard forklaring hvoraf fremgik at det værste ikke var Ofir men at alle andre også kan gø re det og at vidn et ikke bryder sig om konkurrence  Samlet set efterlades ingen rimelig tv ivl om at sagsøgers strategi er at udelukke enhver konkurrence på markedet for udbud af boligindeks og internetsøgetjenester for derved effektivt at afskærme markedet for formidling af salg af boliger for indtrængende konkurrence fra private Henset til at sagsøger og Dansk Ejendomsmæglerforening har en sammenfaldende interesse i at modarbejde sagsøgtes søgetjenester  for derved også at vanskeliggøre privates konkurrerende udbud af ejen domme  kan det ikke afvises at denne konkurrencebegrænsning beror på en konkurrencebegrænsende aftale vedtagelse eller samordnet praksis i strid med konkurrencelovens  6 Det hele forstærkes af at Danske Bank der ejer sagsøgeren valgte både at sagsøge sagsøgte og boligsøgetjenesten Kapow der udbød en lignende tjeneste for derefter  101  at opkøbe Kapow og dermed overtage og eliminere tjenesten Se Mads Bryde Andersen U2000B311 side 6 Alligevel har visse større ejendomsmæglerfirmaer modsat sig robotte ring af deres hjemmesider muligvis ud fra en interesse i at holde mar kedets opmærksomhed fokuseret på de res men ikke på andre ejen domsudbyderes hjemmesider En sådan interesse i at holde andre ude af et marked kan ikke betegnes so m legitim sml om konkurrencebe grænsende aftaler konkurrencelovens  6 stk 2 nr 2 Det kan i den forbindelse nævnes at  5a i lov om omsætning af fast ejendom nu gi ver Erhvervs og Selskabsstyrelsen hjemmel til  medmindre andre gør det  at oprette et søgesystem med central indgang til alle ejendomme der udbydes via et offentligt tilgængeligt elektronisk medie Sagsøgers søgsmål mod sagsøgte tjener i konsekvens af ovenstående et ulovligt formål og er i strid med konkurrencelovens  6 og  11 fordi sagsøger ved rettens mellemkomst sø ger at håndhæve en konkurrence begrænsning som angiveligt beror på en aftale eller vedtagelse med Dansk Ejendomsmæglerforening og dens øvrige medlemmer og som er et led i en samlet strategi om at etablere adgangsbarrierer for indtrængende konkurrence på markedet for udbud af boligindeks og internetsø getjenester et marked der er afledt af markedet for formidling af salg af boliger med det overordnede form ål at afskærme markedet for for midling af salg af boliger for indtrængende konkurrence fra udbydere som ikke er medlemmer af Dansk Ejendomsmæglerforening herunder private Det er sagens egentlige kern e Alt om databasereglerne er et røgslør Med hensyn til sagens omkostninger bemærkes at det må tages i be tragtning at sagsøgeren burde have hævet sagen efter at EFdom stolen med de 4 domme fra november 2004 udstak klare retningslinier Sagsøgers procedure 2 del  replik Sui generisrettens natur Det bestrides at sui generisretten skulle være noget helt særligt i forhold til øvrige immaterialrettigheder ved alene at være udtryk for en ren investeringsbeskyttelse og ikke nogen ideel ret Sui generis  102  betyder egen art At rettigheden er af egen art skal ses i sam menhæng med at sui generisretten er indsat i ophavsretsloven Som den eneste af immaterialrettighederne er ophavsretten båret af visse ideelle hensyn til ophavsmanden specielt ophavsmandens droit moral rettigheder For immaterialrettighederne  patenter brugsmodeller varemærkerettigheder designrettigheder samt til dels ophavsrettighederne  gælder at de også bæres af økonomiske interesser og in vesteringsmæssige beskyttelseshensyn Det er således almindelig an erkendt at man ved udmålingen af den tidsbegrænsede beskyttelse for immaterialrettighederne netop har afvejet på den ene side hensy net til opfinderen frembringeren mv der skal have beskyttet sin investering i udviklingen frembringelsen mv af den pågældende eneret og den samfundmæssige interesse i ved hjælp af eneretten at skabe et incitament til at fremme den teknologiske udvikling overfor på den anden side det almene hensyn at konkurrencen ikke fast låses således at tredjemand i hvert fald på et vist tidspunkt frit får adgang til at udnytte opfindelser frembringelser mv Investeringsbeskyttelsen og investeringsincitamentet gælder således som et bærende hensyn bag såvel sui generisretten som de øvrige immaterialrettigheder Når sui generisretten er af sin egen art i ophavsretsloven er det fordi retten ikke i øvrigt er båret af ideelle interesser for databasefremstiller således som det er tilfældet med almindelige ophavsretligt beskyttede værker Internettet Sagsøgtes holdningsbaserede betragtninger hvorefter internettet ik ke skulle kunne fungere hvis sa gsøgte dømmes kan ikke tillægges nogen juridisk betydning ved vurderingen af nærværende sag der netop påkalder sig en afgørelse af hvor grænsen for det tilladte og det ikke tilladte går Der henvises ti l Lars Stoltze Internet Ret side 260  103  Ved hjælp af søgerobotter er det mu ligt for konkurrerende websites at tage interessante elementer ud af de sites robotten anvendes på Dette kan feks dreje sig om bolig eller jobdatabaser på konkurrerende sites hvortil der linkes ved hjælp af links genereret af en søge robot eller ved at resultaterne lægges ind på modtagersitet gennem framing Det må antages at sådan udnyttelse af konkurrerende sites databaser ud over at være i strid med god markedsføringsskik vil være en overtrædelse af ophavsretslovens  71 vedr beskyttelse af databaser samt i visse tilfælde ophavsretten til indholdet af sitet Det er klart at nogle former for robottering og nogle former for link ning er fuldt tilladt men det er li ge så klart at der findes robotte ringsformer og former for deeplinking som ikke er og ikke skal være tilladt Kapow Det korrekte faktum vedr Kapow er at sagsøger anlagde sag mod Ka pow og Egmont vedr boligtjenesten boligagenten samtidig med nær værende sag den 15 oktober 1999 Sagen mod Kapow blev efter fuld skriftveksling forligt og hævet i dec ember 2002 efter Danske Banks op køb i 2002 af Kapow Baggrunden for opkøbet var at banken var interesseret i Kapows avancerede søgerobot til brug for oprettelse af tjenester vedr bil båd mv således at banken herved kunne få kontakt til et bre dere privatkundesegment Databasedirektivet  totalharmon iseringsdirektiv eller mini mumsdirektiv Med henvisning til Generaladvokatens udtalelse i præmis 33 i den svenske Fixtures sag Svenska Spel der er identisk med præmis 49 i den græske Fixtures sag C44402 gøre s det gældende at der i Generalad vokatens udtryk forpligtet til at tilpasse  de nationale lovgivninger ikke kan indfortolkes et krav om totalharmonisering Mere interessant er det imidlertid hvad EFdomstolen udtaler og især ikke udtaler i Svenska Spelsagen I dommens præmis 8 redegøres for  104  svensk ret dvs den tilrettede svenske katalogregel der ligner den dan ske I præmissen udtales Efter ændringen af ophavsretslovens  49 gives der ligesom hidtil en beskyttelse af samlinger af et stort antal data men desuden også en be skyttelse af arbejder som er resultat et af en væsentlig investering Op havsrettens beskyttelsesgenstand er således bredere end den beskyttel sesret der er indeholdt i sui generisretten i henhold til direktivet Den manglende adressering af den svenske harmonisering  der svarer til den danske  støtter uanset at EFdomstolen ikke havde spørgsmålet om direktivets karakter til afgørelse klart sagsøgers synspunkt om at databasedirektivet er et minimumsdirektiv at Danmark ikke har imple menteret direktivet forkert og at sui generisret i henhold til de gælden de danske regler derfor må anerkend es blot databasen i mængde består af et stort antal data At udtrykket et større antal oplysninger i ophavsretslovens  71 stk 1 implicit skulle indeholde et krav om en væsentlig investering savner og så grundlag i den foreliggende danske litteratur Det samme er tilfældet mht synspunktet om at ordene i øvrigt skulle indfortolkes i bestem melsen i  71 stk 1 Silhouettedommen har ikke har relevans for vurderingen Varemærkedirektivet og databasedirektivet er vidt forskellige direktiver båret af for skellige hensyn Hertil kommer at det i Silhouettesagen var en absolut nødvendighed at statuere totalharmo nisering idet konsumptionsprincip pet ellers ville miste sin virkning De fire domme fra EFdomstolen  overordnet De faktiske omstændigheder i de 4 EUsager fra 2004 er på helt afgørende punkter forskellige fra nærværende sags omstændigheder I EU sagerne påberåbte databasefremstiller sig investeringer knyttet til frem bringelse af data det vil sige indsamli ng af nye data og ikke investerin ger knyttet til fremskaffelse af data dvs indsamlingen af allerede eksi sterende data Det er derfor ganske underordnet om der i disse sager var tale om meget store databaser og betydelige investeringer I den  105  eneste sag Hillsagen hvor der fra databasefremstillers side også var tale om investeringer i forbindelse med fremskaffelse af allerede eksiste rende data fandt domstolen at det ikke var muligt at adskille disse om kostninger fra de omkostninger der relaterede sig til frembringelsen af nyt materiale Af denne årsag blev det underkendt at investeringskravet var opfyldt I nærværende sag påberåber sagsøger som databasefremstiller sig inve steringer knyttet til fremsk affelsen af allerede eksisterende data og altså ikke investeringer knyttet til frembr ingelsen af data og der foreligger derfor ikke en sammenblanding af investeringer som i Hillsagen Af den efter de fire domme skrevne litteratur fremgår at der endnu udestår en række uafklarede spørgsmål som dommene ikke har berørt bla forståelsen af begrebet væsentlig investering Af Davison  Hugenholtz Mads Bryde Andersen ITRetten 2 udgave samt Koktvedgaard Immaterialrette n fremgår at dommene afklarede visse kernespørgsmål i direktivet således at man ikke vil beskytte inve stering i indsamling af data fra ny men alene investeringer der relaterer sig til fremskaffelse og efterfølgende behandling af allerede eksisterende data at domstolen accepterer den også forud for dommene i teori og praksis drøftede spinoff teori samt at man ved vurderingen af spørgs målet om krænkelse ikke ser på den økonomiske værdi af de tilegnede data Spørgsmålet om identifikation mellem sagsøger og homemæglerne Spørgsmålet om identifikation er afgørende for om kravet til investering i indsamling  dvs fremskaffelse af allerede eksisterende data  kravet om at hovedformålet med investeringen skal være oprettelsen af den påbe råbte database spinoff doktrinen og kravet til at investeringen skal være væsentlig kan anses for opfyldt Det er ikke korrekt at det kontraktuelle forhold mellem sagsøger og mæglerne ikke er oplyst Niels Bjer regaard forklarede at homekæden  106  bygger på et traditionelt franchiseforhold og at de enkelte mæglere i for hold til sagsøger er økonomisk og juridisk uafhængige og selvstændige parter der hver for sig driver deres virksomhed for egen regning og risi ko hvilket er det afgørende for spørgsmålet om identifikation Sagsøgtes synspunkter om adfærdsfuldmagt er helt uvedkommende Ej heller EFdomstolens afgørelser i Fixturessagerne støtter identifikati onssynspunktet I Fixturessagerne havde databasefremstillerne der havde rettighederne til databasen in dgået aftale med Fixtures hvorved Fixtures opnåede retten til at repræs entere databasefremstillerne også i tilfælde af håndhævelse af rettigheder til databasen I de nationale sager der ligger til grund for EFdommene havde Fixtures anlagt sag mod udnyttere af databasen om krænkelse af databasefremstillernes rettigheder Fixtures mellemmandsvirksomhed består således alene i at Fixtures optrådte som repræsentant for databasefremstillerne et forhold EF domstolen i øvrigt ikke tillagde betydn ing og et forhold der er usam menligneligt med franchiseforholdet i denne sag Såfremt retten måtte give sagsøger medhold i at der ikke er grundlag for at statuere identifikation er det en automatisk følge at sagsøgtes syns punkter om at sagsøger ikke har foretaget en investering i fremskaffelse af allerede eksisterende materiale og at sagsøgers database blot er et biprodukt et spinoff af mæglernes indsamling af data til brug for deres salg af fast ejendom i det hele kan afvises For fuldstændighedens skyld må det ti l præmis 44 i den finske Fixtures sag fremhæves at denne præmis netop ikke gælder når der ikke kan ske identifikation Præmissen ville have været gældende hvis der var identifikation mellem sagsøger og homemæglerne eller hvis det havde været homemæglerne selv der havde fremstillet den påberåbte data base Væsentlig investering Sagsøger har ved bilag 9 og den supplerende afhøring af Hanne Brandt ført bevis for sin investering Ideelt set var sagsøger kommet med detal 107  jerede revisorattesterede opgørelser men sådan er virkeligheden ikke og kan ikke være i disse sager EFdomstolens krav i de fire afgørelser fra 2004 til investeringen i indsamling kontrol og præsentation afspejler jo ikke en regnskabsmæssig virkelighed  og da slet ikke mht databaser fremstillet før afgørelserne Det gøres gældende at det ikke er muligt at foretage dokumentationen på anden måde og at dette ikke skal kunne komme sagsøger til skade Bilag 9 og Hanne Brandts forklaring skal belyse både de omkostninger der er relevante for vurderingen af kravet til væsentlig investering i henhold til ophavsretslovens  71 og de omkostninger der er relevante i henseende til beskyttelsen efter markedsføringslovens  1 Bla derfor er der flere omkostninger med i bilag 9 end dem der alene er relevante for investeringskravet i ophavsretslovens  71 Bilag 9 er jf Hanne Brandts forklaring blevet til ved at Hanne Brandt på grundlag af sagsøgers interne regnskabsmateriale har udarbejdet den totale oversigt over omkostninger ti l Internet Uddybende til opgørelsen i bilag 9 har Hanne Brandt så godt som det er muligt redegjort for de enkelte posters skønsmæssige fordeling på de for ophavsretslovens  71 og markedsføringslovens  1 relevante poster Der er ingen belæg for at drage hverken bilag 9 eller Hanne Brandts forklaring i tvivl Af bilag 9 og Hanne Brandts forklaring kan udledes at sagsøger har haft betydelige udgifter til fremskaffelse og kontrol af de allerede foreliggende data Fremskaffelsen og kontrollen er hovedsagligt håndteret af EDB programmer der er bekostet udviklet af sagsøger Omkost ningerne hertil indgår i posten Drift af BAS og andrager over årene i alt kr 3 millioner Nemlig ca 200000 kr årligt 199799 ca 300000 kr årligt i 2000 og 2001 ca 500550000 kr årligt i 2002 og 2003 og ca 600700000 kr i 2004 Det er uden betydning at sagsøger ikke betaler mæglerne for dataene Omkostningerne relateret til fremskaffelse af data udgøres af de udgifter og den interne tid der er medgået til udvikling af de EDB programmer og services der håndtere r fremskaffelsen af data Endvidere  108  indgår abonnementer til Krak for en lille del og betaling til Bureau 2000 i posten Drift af BAS og i det omtalte beløb på 3 mio kr Sagsøgers udgifter til forretningslogikken udgøres af ca 90  af posten udvikling i bilag 9 og dermed over årene i alt 76 millioner kr Udgifterne i bilag 9 er sagsøgers eksterne udgifter men også intern tid som er en helt forventelig og sædvanlig post skal som det frem går af databasedirektivet medregnes i investeringen Der har i gen nemsnit været 2 personer fuldtids beskæftiget med databasen i hen seende til indsamling kontrol og pr æsentation af data dvs med ma nuelle kontrolopgaver opgaver vedr udvikling af EDBprogrammerne og services til brug for fremskaffelse og kontrol af data og opgaver vedr etablering og løbende udvikling af forretningslogikken for databasen De samlede omkostninger til denne interne tid var ca 1 mio kr årligt Det præciseres at omkostninger t il billeddatabasen home MPS ikke gøres gældende i forbindelse med ophavsretslovens  71  men alene de omkostninger der relaterer sig til etableringen af de servicesEDBprogrammer der fremskaffer og kontrollerer billeder til sagsøgers ejendomsdatabase Det samme gælder i relation til OBHI Det eneste der er medregnet i sagsøgers investering er sagsøgers omkostninger til servicenEDBprogrammet indsat mellem OBHI og sagsøgers database til fremskaffelse og kontrol af data Da de fire afgørelser fra EFdomstolen ikke udtaler sig om væsentlig hedskravet fastholdes relevansen af citatet fra Henrik A Jensen side 79 hvorefter investeringskravet må antages at være lavt Hjælpebilaget støttet af Hanne Brandts forklaring samt de fremlagte udskrifter fra sagsøgers boligsøgetjenesteejendomssøgesystem do kumenterer og illustrerer enkelt og overskueligt den ejendomsdatabase sagsøger hævder beskyttelse for nemlig sagsøgers database med informationerne om de til enhver tid på homedk til salg udbudte ejendomme Hjælpebilaget og Hanne Brandts forklaring viser hvorfra informationerne til sagsøgers ejendomsdatabase kommer og hvor indsatsen i henseende til fremskaffelse og kontrol af data sker  109  Kvalitativt væsentligt udtræk De af sagsøgte påberåbte præmisser 7678 samt domskonklusionen pkt3 2 led i Hillsagen har ikke supplerende relevans ved siden af sagsøgers henvisninger til direktiv ets betragtning 39 og 42 præmis 69 og 71 i Hillsagen samt citaterne fra litteraturen herunder Mads Bryde Andersens ITretten 2 udg der er skrevet efter de fire EF domme Præmis 76 siger således ikke andet end præmis 71 og udtalelserne i præmis 77 er strikt knyttet til Hillsagens faktum som er afgørende anderledes end faktum i nærværen de sag Mht præmis 78 bemær kes at sagsøger ikke gør gældende at de af sagsøgte kopierede da tas indre værdi for sagsøger er af betydning for sagens vurdering på dette punkt Nok kan sagsøger ikke opgøre den præcise investering i de 13 kopierede data men det fremgik klart af Hanne Brandts forklaring at en væsentlig del af den i øvrigt væsentlige investering i henseende til fremskaffelse kontrol og præsentation af dataene i sagsøgers ejen domsdatabase netop er knyttet til de 13 data Der henvises til Mads Bryde Andersen ITretten 2 udgave side 418 hvorefter  71 stk 1 først og fremmest rammer kopieringshandlin ger der har til hovedformål at genskabe den funktionalitet den op rindelige database tilbyder Dette er netop resultatet af sagsøgtes kopiering i nærværende sag Der kan i bestemmelsen ikke indfortolkes et yderligere krav om skade Ophavsretslovens  71 stk 2 Det fastholdes på grundlag af teori og præmis 8586 i Hillsagen at ophavsretslovens  71 stk 2art 7 stk 5 er tænkt til at hindre om gåelse af  71 stk 1art 7 stk 1 i den form hvor den gentagne og systematiske kopiering medfører at hele den oprindelige database eller en væsentlig del af den oprindelige database genskabes samt  110  hvor den gentagne og systematiske kopiering ved sin ophobende virkning skader databasefremstillers investering alvorligt Det er net op den ophobende virkning af sagsøgtes gentagne og systematiske kopiering der skader sagsøgers investering i databasen alvorligt Denne ophobende virkning består i at sagsøgte ved sin kopiering skaber en database der har den samme nøglefunktionalitet som sagsøgers database og som derved flytter besøgende fra sagsøgers da tabase til sagsøgtes database med den følge at sagsøger ikke vil kunne bevare sin indtjening på mægl ernes adgang til at få emner på databasen Sagsøger mister altså sit vederlag på databasen smh direktivets betragtning 48 og sagsøgers investering i databasen ska des EFdomstolen har ikke i de fire domme taget stilling til hvad der lig ger i de to alternative betingelser i  71 stk 2 strid med normal udnyttelse og urimelig skade på databasefremstillerens legitime in teresser og den citerede litteratur af Lisa Vogt Lorentzen og Henrik Jensen er derfor ikke forældet  71 stk 2 er båret af god skikbetragtninger og det er af væsentlig betydning at der er tale om et konkurrenceforhold mellem parter ne Præmis 47 i Hillsagen som skal læses i sammenhæng med de forudgående præmisser er i fuld overensstemmelse med direktivets betragtning 42 hvorefter sui generisretten ikke forudsættes kun at kunne ramme en påstået krænker der fremstiller en konkurrerende database eller en database af samme størrelse som den kopierede det afgørende er om databasefremstillers investering skades og skade kan jf såvel betragtning 42 som præmis 47 i Hillsagen også ske selvom krænkeren ikke opretter en konkurrerende database et piratprodukt Mads Bryde Andersen ITretten 2udgave side 426 er altså helt på rette vej Anvendelsen af disse regler forudsætte r ikke at der først skal være ind truffet en alvorlig skade før en databasefremstiller kan gribe ind overfor en krænker Ophavsretslovens  71 stk 2 kan naturligvis bruges til at imødegå krænkelser for at afværge og begrænse en skade  111  Det er ikke korrekt at sagsøger aner kender ikke at have lidt en skade Den økonomiske skade i form af færre besøgende udhulningen af grund laget for databasen og dermed sagsøgers afkast på databasen kommer snigende og er i gang men er meget vanskeligt at opgøre i eksakte tal derfor det beskedne økonomiske krav i påstand 2 Det afgørende er sag søgers udsigt til det ultimative tab hvis sagsøgte ikke standses idet sagsøger i så fald berettiget må fryg te at sagsøger ikke kan opretholde mæglernes betaling for adgang til databasen hvorved sagsøger ikke får det vederlag for databasen der tilkommer sagsøger smh direktivets betragtning 48 Hertil kommer det tab sagsøger løbende lider dels i form af skade på sagsøgers brandingstrategi dels i form af imagetab ved at få sin forretning sammenkædet med sagsøgtes Sagsøgtes fremhævning med henvisning til domskonklusion 3 og 4 i Hillsagen af at det kvalitativt væsentlige dataudtræk alene skal vurderes ud fra de omkostninger der er forbundet med indsamling kontrol eller præsentation af de kopierede data er ikke korrekt Sagsøger er enig i at investeringen knyttet til indsamling kontrol og præsentation af de kopierede data er relevant men dataenes essentielle rolle er også relevant i den forstand at de kopierede data netop sætter sagsøgte i stand til at etablere en database med samme kernefunktionalitet som sagsø gers database Deeplinking Paperboydommen se Mads Bryde An dersens omtale ITretten side 423 er ikke relevant for denne sag Sagen drejede sig for det første om spørgsmålet om tilladeligheden i henhold til den tyske ophavsretslov af deeplinking til et ophavsretligt beskytt et værk et  2værk hvor op havsmanden ikke overfor linkeren ha vde tilkendegivet at han ikke øn skede linking Sagen drejede sig herefter blandt andet om i hvilket om fang ophavsmanden måtte anses for at have givet et stiltiende samtykke til linkingen hvilket retten nåede frem til var tilfældet Disse faktiske omstændigheder svarer netop ikke til nærværende sag hvor sagsøger fra starten udtrykkelig overfor sagsøgte frabad sig deeplinkingen Rettens vurdering i Paperboydommen efter de tyske konkurrenceregler kan ikke tillægges nogen betydning Den dans ke markedsføringslov og de tilsva 112  rende regelsæt i de øvrige medlemssta ter  i det omfang sådanne regler findes  er netop ikke udtryk for harmonisering men er rent nationale regler med rod i den tradition for go d erhvervsmæssig skik og brug der gælder i den enkelte medlemsstat og som kan være forskellige fra land til land Mht Kommissionens rapport der angår Ehandelsdirektivet og ikke data basedirektivet bemærkes at Kommissionens udtalelser ikke er fremsat i nogen for denne sag relevant sammenhæng Markedsføringslovens  1  til su bsidiær støtte for påstand 1 a og b under ét Det bestrides at sagsøgers synspu nkter indebærer at markedsfø ringsloven bruges til at udvide databaseretten efter ophavsretslovens  71 Der er tale om en anden rettighed når sagen skal vurderes efter markedsføringsloven nemlig den af sagsøger oparbejdede markedsposition for homedk og det er en anden krænkelseshandling der skal vurderes nemlig sagsøgtes samlede handlinger og ikke kun datakopieringen Der ikke er nogen forskel på sui generisretten og de øvrige immaterielrettigheder mht beskyttelsesformålet der også for så vidt angår de traditionelle immaterielrettigheder er af økonomisk art og tillige har til formål at begunstige og fr emme den teknologiske udvikling Der henvises til Koktvedgaard Immaterialretten Kapitel I Denne sag adskiller sig derfor ikke fra de traditionelle immaterialretssager hvor det stedse har været anerkendt at markedsføringsloven kan anven des supplerende eller evt subsidiært til immaterialretslovene Op havsretsloven  71 stk 6 er på dette grundlag uden relevans Sagsøgte har intet tilføjet til boligofir og sagsøgte har ikke dokumenteret at have brugt mange penge på udviklingen af boligofir Det havde været interessant at få belyst udgift er til selvstændige nye funktionalite ter hos boligofir og udgifterne til selve robotten men sagsøgte har alene fremlagt en internt udarbejdet opstilling bilag Z med nogle samlede ud 113  giftsposter og direktør Jørgen Wittenkamp var ikke i stand til at redegøre for posternes sammensætning eller tilb livelse Der er derfor ikke ført be vis for nogen form for relevant egeninvestering i boligofir Sagsøger driver ikke virksomhed med at sælge ejendomme men ved som franchisegiver bla at udvikle og mod betaling stille markedsføringsværktøjer som boligtjenesten homedk til rådighed for mæglerne som franchisetagere hvor disse kan få annonceret de ejendomme de har til salg Op mod 30  af sagsøgers årlige nettoindtjening stammer fra mæglernes betaling herfor Boligofir yder nøjagtig den samme tjeneste som homedk i henseende til at være en plads på internettet for annon cering af ejendomme til salg Der består på dette grundlag oplagt en konkurrencerelation mellem parterne i henseende til boligofir og homedk og det er uden betydning at sagsøgtes indtjening ikke stammer fra de annoncerende men fra bannerannoncer Konkurrencelovens  6 og  11 Når det af betragtning 47 følger at immaterialrettigheder ikke må udnyttes på en måde der letter et konkurrenceretligt misbrug af en dominerende stilling svarer det til hvad der altid har været antaget Sui generisretten skal således ko nkurrenceretligt behandles som an dre immaterialrettigheder Særlig vedr konkurrencelovens  6 bemærkes at sagsøgtes anbrin gende om at det såfremt sagsøgte dømmes i sagen vil føre til at der foreligger en overtrædelse af bestemmelsen ikke har juridisk støtte For at komme ind under  6 skal der konkret være påvist en aftale en samordnet praksis eller en vedtagelse der er konkurren cebegrænsende  6 kan ikke bruges ti l at tage stilling til fremtidige hypotetiske situationer Der henvis es til Kirsten Levinsen Konkurren celov side 164 Sagsøgte har end ikke forsøgt at dokumentere at der i dag skulle foreligge en konkurrencebegrænsende aftale samordnet praksis eller indforståelse med sagsøger som part  114  Sagsøgtes synspunkter til konkurrencelovens  11 lider af to meget væsentlige mangler For det første tager sagsøgte igen udgangspunkt i at der vil blive tale om en overtrædelse af  11 dvs foreligge misbrug af en dominerede stilling hvis sagsøger får medhold Men også  11 finder alene an vendelse på en konkret foreliggende eksisterende situation og ikke på et hypotetisk fremtidigt forhol d og retten kan derfor allerede på dette grundlag se bort fra sagsøgtes synspunkter Sagerne Magill og IMS Health II er ikke relevante i det foreliggende tilfælde hvilket først og fremmest skyldes den anden meget væsent lige mangel ved sagsøgtes indlæg Sagsøgte har ikke defineret det relevante marked og sagsøgte har ikke påvist at sagsøger indtager en dominerende position på et sådant marked I sit første procedureindlæg lancerede sagsøgte begrebet de facto monopol tilsyneladende forstået således at det relevante marked nu skal defineres som udgørende alene annoncerne for ejendomme sat til salg af homemæglere ved annoncering på homedk Men de facto monopol er ikke et anbringende men i bedste fald en beskri velse af en markedssituation Sagsøgte har i øvrigt først gjort dette synspunkt gældende under sin procedure og synspunktet kan derfor ikke tages i betragtning ved sagens afgørelse Det vides med andre ord ikke hvilket marked sagsøgte mener er det relevante og endvidere ikke hvilken markedsandel sagsøger skulle indtage på dette marked Det er således ikke muligt at vurdere om der foreligger dominans og konkurrencelovens  11 kan følge lig ikke bringes i anvendelse En domfældelse af sagsøgte vil ikke ændre på sagsøgers andel af markedet for annoncering af ejendomme på internettet som sagsøger gør gældende i givet fald er det relevante marked På dette marked vil sagsøger fortsat have en markedsandel på ca 25  Der kan kun blive tale om misbrug af en do minerende stilling i dette marked hvis alle konkurrenterne agerer ens  115  mht til rettighedshåndhævelse til de omhandlede immaterielle rettig heder Det er dokumenteret at dette ikke er tilfældet Om der ved en domfældelse i fremtiden vil kunne blive tale om et de facto monopol vides ikke men det har formodningen imod sig i forhold til konkurrenternes kendte ager en i dag Der henvises herved til boligsøgetjensten boligzonen og det faktum at ingen andre ejen domsmæglere hvorfra sagsøgte i dag kopierer data har rejst indsi gelse overfor sagsøgte Magilldommen er blevet stærkt kritis eret Den er afløst af IMS Health II der opstiller betydelig mere kval ificerede og strengere betingelser for at en håndhævelse af immaterielle rettigheder kan udgøre en overtrædelse af konkurrencelovens  11 EFTraktatens artikel 82 Kommentarer til den nationale en gelske afgørelse af 13 juli i Hillsagen Med hensyn til den nationale afgørelse i Hillsagen efter EFdomstolens dom bemærkes at BHBs advokat forsøgte at forklare den engelske domstol at EFdomstolen har misforstået sagens fakta og at EFdomstolens resultat således ikke finder anvendel se Den engelske domstol blev imid lertid ikke overbevist dommens pkt 2527 og udtaler derfor at der er tale om frembringelse af data i overensstemmelse med det af EFdomstolen anførte Dette er ikke ove rraskende henset til at den natio nale domstol har pligt til at træffe afgørelser i overensstemmelse med EFdomstolens fortolkninger af EUretten Det andet spørgsmål den engelske dommer behandler er spørgsmålet om dekonstruktion hvor dommeren anfører at det kun er BHB der kan levere databasen og at der derfor ikke kan være tale om fremskaffelse af allerede eksisterende data Når det forholder sig anderledes i næ rværende sag skyldes det at sag søgeren kan lave databasen fordi sagsøgeren har den pågældende aftale med mæglerne Hvis tredjemand havde tilsvarende aftale med mægler ne kunne tredjemand således have opre ttet databasen Dette er en af 116  gørende faktuel forskel på Hillsagen og den foreliggende sag hvorfor heller ikke dekonstruktionssynspunkterne kan finde anvendelse i nærvæ rende sag Det er helt afgørende at fastslå at den engelske dommers udtalelser om dekonstruktion kun har relevans for nærværende sag i det omfang der statueres identifikation mellem sagsøger og de enkelte mæglere I Hillsagen blev det gjort gældende at der gennem en række trin oprettes en database Det er korrekt at databasen i nærværende sag også oprettes gennem en række trin Forskellen er dog at det i nær værende sag ikke er den samme der foretager de forskellige handlinger på de forskellige trin I nærværende sag er det mæglerne der foretager frembringelsen mens sagsøgeren foretager fremskaffelsen Betragtninger om sagen set fra oven Sagsøgte prøver at blæse sin interesse i sagen op til og tilsløre sagen med at det skulle være afgørende for sagsøgte at få adgang til de omhandlede data uanset at realiteten er at sagsøgte kan drive sin internetportalvirksomhed med alt fra jobannoncer billige rejsetilbud og bilannoncer til kontaktannoncer mm uden at det har nogen kommerciel betydning for sagsøgtes virksomhed om sagsøgte måtte være forhindret i på boligofir at kunne annoncere de af home ejendomsmæglerne på homedk annoncerede ejendomme Der henvi ses til direktør Wittenkamps forklaring om at sagsøgte har en meget lille indtjening på boligofir Heroverfor står at sagsøger med nærværende sag ønsker at bruge sine lovhjemlede rettigheder i henhold ti l ophavsretsloven og markedsførings loven til at sikre sin investering i og sit afkast af det markedsføringsværktøj i form af den påberåbte ejendomsdatabase som sagsøger har bekostet udviklet vedligeholdt markedsført og etableret på markedet over en årrække mod den meget in tensive målrettede skadende og uretmæssige udnyttelse sagsøgte dagligt foretager ved kopieringen af data og etableringen af dybe link til ejendomsannoncer på homedk  117  Sagsøgtes procedure 2 del  duplik Sagsøger må i relation til database reglerne og markedsføringsloven be tragtes som én ejendomsmæglervirksomhed  homekæden og sagsø ger skal i databaseretlig henseende identificeres med de enkelte mæglere og disses aktiviteter Udover det fælles brand homekæden at sagsøger ejer alle lejemål og inventar og at sagsøger forhandler ITkontrakter CB Krak mfl og foretager gennemfakturering er det afgørende at sagsøger lader mæg lerne udnytte sin goodwill at sagsøger har interesse i at aftaler opfyl des og at undgå at tredjemands kr edittab belaster sagsøgers goodwill at mæglerne ikke har egen hjemmeside men er integrerede i sagsøgers hjemmeside homedk at sagsøgers formål er at drive mæglervirksomhed gennem franchisetagere understøtte de nne aktivitet og bidrage aktivt til processen med at skabe databasen ved at frembringe korrekte informationer om ejendommene at sagsøger får alle data gratis til fri benyttelse og at det er sagsøger der giver dataene det endelige autorisationsstem pel bestående i at dataene efter en række interne processer offentliggø res på sagsøgers hjemmeside Sagsøgte er en ren medievirksomh ed der driver portalvirksomheden ofirdk hvori internetsøgetjenesten boligofir indgår Boligofir er en tje neste der er baseret på allerede eksisterende materiale i databasedirektivets forstand nemlig uvæsentlige udtræk af enkelte data fra andre ejendomsmægleres hjemmesider Tjen esten ligger derfor i kerneområdet for sui generisbeskyttelsen i modsætning til sagsøgers database der ikke i direktivets forstand er basere t på allerede eksisterende materiale Sagsøgte har i modsætning til sagsøgeren ingen produkter til salg ingen ejendomme eller job der formidles Sagsøgte kan sammenlignes med en elektronisk gul telefonbog Selvom der i sagsøgtes tjeneste indgår data fra andres hjemmesider er sagsøgtes virksomhed skabt gennem egen indsats i såvel teknisk mennesk elig som finansiel henseende  118  Søgetjenesten boligofir er nemlig ud viklet af sagsøgte fra bunden Selve robotten er et avanceret stykke egenudviklet ophavsretligt beskyttet software Gennem denne indsats har sags øgte ubestridt skabt en helt ny tjenesteydelse Boligofir er ikke et plagiat af nogen dele af homedk den til homedk knyttede database eller af nogen anden tredjemands produkt eller tjeneste Væsentlig investering Sagsøger har ikke løftet sin bevisbyrde for at der er præsteret en væ sentlig investering i det der efter databasedirektivet og ophavsretsloven er relevant for at opnå beskyttelse efter  71 stk 1 nemlig i indsamling kontrol eller præsentation af allerede eksisterende selvstændigt materiale jf Hilldommen afgørelsens punkt 1 jf præmis 31 og præmisserne 40 og 41 Den engelske Court of Appeal der havde forelagt Hillsagen for EFdomstolen har nu afgjort appelsagen  Den engelske første instans havde givet fremstilleren af databasen BH B medhold i at Wilhelm Hill krænke de BHBs databaserettigheder herunder at der forelå en væsentlig inve stering i BHBs database hvorfor databasen var omfattet af sui generisbeskyttelsen Ved Court of Appeals dom af 13 juli 2005 er 1 instansafgørelsen blevet ændret selvom dommerne oprindeligt var indstillet på at stadfæste den idet retten som EFdomstolen er nået frem til at BHB ikke har ført bevis for at der er foretaget en væsentlig investering i databasedirektivets forstand Om sagens omstændigheder fremgår af dommens pkt 44  48 at der er tale om en omfattende database med oplysninger om mere end 1 mio heste løbsprogrammer med 1209 væddeløbsmøder på 59 baner på 327 dage i år 2000 med i alt 7800 galopl øb mv Opdatering sker løbende og hvert år foretages 800000 nye registreringer eller ændringer i registre ringer ligesom der gennemføres en omhyggelig kontrol af at data er  119  korrekte Virksomheden Weatherbys havde til opgave på vegne BHB at føre og udvikle databasen 80 medarbejdere var beskæftiget med proces serne som involverer omfattende software og hardware De årlige udgif ter forbundet med at indsamle kontrollere og præsentere databasens indhold beløber sig til 4 mio GBP dvs ca 40 mio kr pr år Dette svarer til lidt mere end ¼ af de samlede omkostninger på 15 mio GBP som BHB har med sin aktivitet BHBs advokat oplyste under sagen hvordan den endelige database bliver til i en række trin hvilket næsten fuldstændig svarer til skabelsen af sagsøgers database under homedk der sker i en række trin mæglerne indsamler oplysningerne trykker på en knap hvorefter oplysningerne kommer ind i base 2002 hvorefter sagsøgeren kontrollerer oplysningerne sender forkerte data tilbage til retning hos mæglerne og når de er korrekte sender nogle af dataene videre fra base 2002 til databasen under homedk BHBs advokat gjorde gældende at de enkelte trin i processen fandt sted på baggrund af et allerede eksister ende løbsprogram og at den investe ring der er forbundet med en database kan opdeles i 2 dele nemlig en investering som i det væsentlige er en samling registrering og kontrol af allerede eksisterende data og en investering som i sig selv er kreativ Han gjorde herefter gældende at alt hvad BHB gør i det væsentlige er at investere i indsamling kontrol og præsentation af allerede eksisterende materiale samt at der også selv om dette ikke måtte være alt hvad BHB gør i hvert fald var tale om en væsentlig investering i samlingen registreringen og kontrollen af sådanne eksterne data BHBs advokat gjorde endvidere gældende at EFd omstolen havde misforstået sagens omstændigheder at den kun kunne tage st illing til retlige og ikke faktiske forhold samt at BHBdatabasen hvis man anvendte afgørelsens kerne på sagens omstændigheder ikke var en der var skabt ved frembringel se men ved samling og kontrol af selvstændigt materiale og derfor omfattet af art 7 stk1 Court of Appeal afviste disse anbringender med den begrundelse at ret ten dels ikke anså det for sandsynlig t at EFdomstolen havde misforstået sagens omstændigheder eller indladt sig på noget som EFdomstolen  120  ikke var berettiget til og at anbr ingenderne involverede en dekonstrukti on som EFdomstolen har afvist Retten begrunder i punkterne 21 27 baggrunden for at EFdomstolen ikke kan anses at have gjort sig skyldig i en misforståelse af faktum I punkterne 2837 begrundes tilbagevisningen af BHBs øvrige anbringender Dommeren Jacob konstaterer i pkt 28 at BHBs advokat begynder med begyndelsen af processen og arbejder si g frem til den endelige offentlig gjorte liste over deltagende ryttere og heste og gør gældende at der gennem en række trin frembringes data baser der er omfattet af art 7 stk 1 ved en indsamlings og kontrolproces Sagsøgers advokat gør præcis det samme i nærværende sag Der startes med indsamlingen hos mæglerne overførslen til base 2002 og videreoverførslen til databasen under homedk med de tilhørende kontroller i begge led som Hanne Brandt har forklaret om Sagsøgeren konstaterer herefter at da mæglerne er juridisk selvstændige enheder ja så er der i relation til dataene tale om allerede eksisterende materiale i ophavsrets lovens og direktivets forstand Dette er forkert Dommeren i BHBsagen konstaterer nemlig i pkt 29 at EFdomstolen har afvist denne argumentationsmåde idet EFdomstolen fokuserer på den endelige database  den database som i sidste ende bliver offentlig gjort Videre udtales det at den adskiller sig fra alt muligt andet der er gået forud herfor fordi den bærer BHBs autoritetsstempel Kun BHB kan levere en sådan officiel liste og kun ud fra denne kan man vide hvem der er de accepterede erklærede tilmeldte Ingen andre ville kunne gennemføre en lignende proces for at lave den officielle liste og derfor er konklusionen at BHBs database ikke kan siges at bestå af allerede eksi sterende materiale i databasedirektivets forstand Det samme er tilfældet i nærværende sag Der er kun én officiel alment tilgængelig database nemlig den til hjemmesiden homedk knyttede database På denne hjemmeside udbyder alle homekædens ejendomsmæglere deres ejendomme til salg og fra denne hjemmeside har bruge re adgang til at søge informationer i sagsøgers database Hanne Brandt har forklaret hvordan sagsøger bi står de enkelte ejendomsmæglere med  121  at kontrollere og processe de enkelte data i flere led og hvilken udveks ling der er af data som sagsøgeren konstaterer er forkerte Der sker her en tilbagesendelse til mæglerne med henblik på tilretning inden et ud valg af de modtagne data overføres ti l den endelige officielle alment til gængelige database nemlig den til homedk knyttede database Først i det øjeblik dataene overføres til databa sen knyttet til homedk får disse data sagsøgers godkendelsesstempel Ingen andre kan gennemføre en lignende proces og lave den officielle samling af ejendomme udbudt til salg gennem den til homedk knyttede database Konsekvensen heraf er at sagsøgers database på samme måde som BHBs database ikke kan siges at bestå af allerede eksisterende selvstændigt materiale i database direktivets og ophavsretslovens forstand Dommeren refererer under punkt 31 EFdomstolens præmisser 3741 Således fremhæves det at EFdomstolen i præmis 38 udtaler  De investeringer der med henblik på tilrettelæggelsen af hestevædde løb er forbundet med udvælgelsen af de heste der kan deltage i det pågældende løb vedrører imidlertid oprettelsen af data som listerne vedrø rende disse løb består af og som findes i BHBs database De kan ikke sidestilles med en investering der er forbundet med indsamling af en databases indhold De kan derfor ikke tages i betragtning ved vurderin gen af om der er tale om en væsentlig investering der er forbundet med oprettelsen af denne base Og præmis 40  Den forudgående kontrol finder imidlertid sted i den fa se hvor den omhandlede liste over løb oprettes Den udgør derfor en investering der er forbundet med frembringelse af data og ikke med kontrol af en databases indhold Herefter konkluderes det i præmis 41  at de anvendte midler ikke udgør en investering der er forbundet med indsamling og kontrol af indholdet af den database hvori denne liste findes I pkt 35 konkluderer dommeren For så vidt som BHBs database består af de officielt identificerede navne på deltagende ryttere og heste er den ikke omfattet af sui generisretten i direktivets artikel 7 stk 1 Og jeg er  122  af den opfattelse at samme argument ation finder anvendelse på de til fælde store løb hvor BHB offentliggør en liste over foreløbigt delta gende heste forud for de endelige erklær inger Igen er karakteren af det der bliver offentliggjort forskellig fra en liste der blot indeholder indsamlede oplysninger Det er en liste over de heste som BHB har accepteret som opfyldende kravene for at deltage i løbet for så vidt som disse er korrekt og faktisk tilmeldt Nøjagtig det samme gælder i nærværende sag Ejendomsmæglerne indsamler oplysningerne om ejendommene og tilføjer data om pris og vilkår mv Samtlige oplysninger videresendes til base 2002 ved tryk på en knap Derefter behandles og kontrolleres dataene i base 2002 Der fore går en kontrol rettelses og udskilningsproces Opdagede mangler korrigeres af mæglerne og kun nogle af de indgåede data videresendes til databasen under homedk mens øvrige data alene bruges i intern sammenhæng fx købers navn De invester inger der er forbundet med disse processer vedrører ligesom i Hillsagen oprettelsen af data og det gæl der egentlig uanset om sagsøger og mæglerne databaseretligt betragtes som en enhed eller separate enheder idet sagsøger har så aktiv og be stemmende en rolle i hele processen at sagsøger derved er med i selve skabelsen af databasen Processerne og investeringerne frem til dataenes overførsel til databasen under homed k vedrører altså oprettelsen af de data som findes i databasen under homedk Disse data kan ikke sidestilles med en investering der er forbundet med indsamling af en databases indhold  helt i modsætning til boligofir hvis database netop be står af indsamlede data fra andres databaser De to øvrige dommere i Court of Appeal tilslutter sig dommer Jacob Fra dommer Pills udtalelse i pkt47 48 fremhæves Den skelnen som jeg forstår at EFdomstolen har foretaget i sin dom er en skelnen mellem på den ende side databasen som sådan præmis 30 og databasens indhold præmis 3337 og 40 og på den anden side oprettelsen af lister over tilmeldte præmis 40 som udgør selvstændigt materiale der er frembragt efterfølgende Denne skelnen foretages i præmis 31  123  I den forbindelse skal begrebet inve stering der er forbundet med ind samling af en databases indhold  forstås således at det betegner de midler der anvendes til fremskaffelsen af eksisterende selvstændigt ma teriale og dets samling i denne database idet der ikke skal tages hensyn til midler der bliver anvendt til selve frembringelsen af det selvstændige materiale Formålet med beskyttelsen ved sui generisretten der er ind ført ved direktivet er nemlig at stimulere oprettelsen af lagrings og be handlingssystemer for eksisterende info rmationer og ikke frembringelsen af materiale der senere kan samles i en database I pkt 48 udtaler denne dommer Midler der anvendes til at frembringe hvilket indbefatter kontrollere listern e over tilmeldte anvendes med en omskrivelse af præmis 40 ikke til at indsamle eller kontrollere databasens indhold som defineret i artikel 7 Domstolens konklusion i præmis 41 er en logisk og uundgåelig følge af denne fremgangsmåde Heraf følger at de midler der anvend es til oprettelse af en liste over heste der deltager i et løb og til de kontrolforanstaltninger der er for bundet hermed ikke udgør en investering der er forbundet med indsamling og kontrol af indholdet af den database hvori denne liste findes Den engelske domstol har således taget EFdomstolens afgørelse til efter retning og når i en sag med et helt parallelt faktum i forhold til nærvæ rende sag frem til at der ikke foreligger en væ sentlig investering i ind samling af selvstændigt allerede ek sisterende materiale Investeringen fra BHBs side vedrører investering i frembringelse af dataene hvilket ikke er formålet med databasedire ktivet jf BHBdommen præmis 31 sidste afsnit Det er det Mads Bryde Andersen ITretten 2 udgave side 416417 udtrykker på denne måde EFDomstolen har hermed sendt et klart signal om at det investerings krav der skal være opfyldt for at opnå databasebeskyttelse efter sui ge nerisreglerne ikke er opfyldt alene i og med at databasen er kommet til verden som en afledet følge af en hovedaktivitet selvom en udefra kommende virksomhed ville have skullet foretage en væsentlig investering for at bringe en sådan database til verden uden også at drive denne hovedaktivitet Denne konklusion inde bærer at en virksomhed der uden  124  særlige foranstaltninger blot lægger sit salgskatalog ud på nettet ikke dermed tilvejebringer en database der opfylder direktivets krav Det er præcis det sagsøger gør Det er homekædens salgskatalog der lægges ud på internettet Hvis retten ikke er enig heri gøres det gældende at det i hvert fald kun er de direkte til databasen under ho medk knyttede omkostninger til ind samling kontrol og præsentation der kan komme i betragtning som en relevant investering Der henvises til første punkt i Hillafgørelsen Væsentlighedskravet gælder selvstændigt i relation til henholdsvis ind samling kontrol og præsentation altså hver for sig jf ordet eller i art 7 stk 1 Da det ligger fast at sa gsøger ikke har om kostninger med hen syn til indsamlingen idet oplysninger ne tilflyder sagsøger gratis ved mæglernes tryk på en knap er væsentlighedskravet allerede af denne grund ikke opfyldt Mht sagsøgtes henv isning til at EFdomstolen i Hill dommen anvender udtrykket indsamling kontrol og præsentation be mærkes at der er tale om en oversættelsesfejl jf den engelske udgave hvoraf fremgår at præmis 71 anven der ordet or både i anden og sidste linie Totalharmonisering Sagsøgerens argument om at EFdomstolen eller generaladvokatens undladelse af Svenska Spelsagen at gøre bemærkning om at data basedirektivet er et totalharmoniseri ngsdirektiv i relation til den svenske ophavsretslov der i henhold til præmis 7 har samme indhold som  71 skulle have til konsekvens at der ikke er tale om et totalharmoniserings direktiv kan ikke stå for en nærmere prøve Svenska Spel sagen var så ledes ikke en traktatbrudssag hvort il kommer at det af præmis 20 frem går at der kun er stillet spørgsmål i relation til begrebet væsentlig inve stering Det er rigtigt at generaladvokaten i præmis 8 udtaler at den svenske lov har et bredere beskyttelsesområde men dette skal sammenholdes med at generaladvokaten i præmis 33 udtrykkelig udtaler at det ikke skal  125  forlede nogen til at overføre de begreber der har udviklet sig indenfor teori og retspraksis vedrørende disse forløberordninger til direktivet Tværtimod skal direktivet være en må lestok for fortolkningen af national ret således at det også gælder fo r de medlemsstater hvor der allerede før direktivet gjaldt lignende bestemmelser Også disse medlemsstater var forpligtet til at tilpasse de nationale lovgivninger til direktivets bestemmelser  Rettens bemærkninger Rettens præmisser følger systematikken i sagsøgerens hovedprocedure Ophavsretslovens  71 stk 1 og 2 Påstand 1a Det må anses for at være et hovedformål med den beskyttelse af databa ser der fremgår af det i dansk ret implementerede databasedirektiv fra 1996 at stimulere oprettelsen af sø gnings lagrings og behandlingssy stemer for eksisterende informationer med henblik på udveksling af dis se men ikke processen med at frembringe materiale der senere kan samles i en database Tilvejebringelsen af de oplysninger som om hver enkelt af de af homeejendomsmæglerne til enhver tid på internettet udbudte faste ejendomme forefindes på den til sagsøgerens hjemmeside knyttede database homedkdatabasen hvorfra sagsøgte for hver af ejendommene kopierer 13 data til boligofir sker efter det fremkomne på den måde at ejen domsmæglerne på deres C  Bsagsbehandlingssystem for hver ejendom frembringer en oplysningsmængde ved at sammenstykke indsamle de faktuelle oplysninger feks om ejendommens areal antal rum be liggenhed etc og tilføjede oplysninger feks pris udbetaling alternativ finansiering mv Ved en enkel manøvre et tryk på en knap overføres en del af oplysningerne i struktureret fo rm til sagsøgerens interne database Base 2002 hvorfra der efter kontrol og evt fejlretning af oplysninger ne hvilket i givet fald sker i et samspil med den pågældende ejendoms mægler foretages et udtræk af nogle af disse til slutdatabasen ho medkdatabasen I denne database forefindes også andre overførte da 126  ta feks koordinater efter aftale me d Krak samt data fra billeddataba sen Home MPS Det produkt der herefter vises på sagsøgerens hjem meside på internettet er udover oplysninger om andre ejendomsmæg lerfirmaers ejendomme i henhold til særskilt aftale herom en samlet af sagsøgeren bearbejdet og godkendt ov ersigt et salgskatalog over ho meejendomsmæglernes aktuelt udbudte ejendomme præsenteret på en af sagsøgeren udviklet måde med en række af sagsøgeren udvalgte op lysninger af faktuel informativ og illustrativ karakter om hver enkelt ejendom Den samlede mængde af slutdata om de af homeejendomsmæglerne udbudte ejendomme i homedkdatabasen må under disse omstændighe der anses i væsentlig grad at være tilvejebragt i en trinvis frembringelses og udvælgelsesproces sluttende med dataoverførslerne til homedkdatabasen som udtryk for sagsøgerens endelige godkendelse af de således frembragte data som egnede til at indgå i præsentationen af de en kelte ejendomme på sagsøgerens hjemmeside Efter oplysningerne om relationerne mellem sagsøgeren og de godt 190 homeejendomsmæglerforretninger der om end de ubestridt hver især alle i juridisk og forretningsmæssi g henseende er selvstændige enheder i et aftalekompleks hvis nærmere indhol d ikke er dokumenteret for retten er forpligtet til hinanden på væsentlige juridiske økonomiske funktionsmæssige og strategiske herunder markedsføringsmæssige områder er det rettens opfattelse at også den fr embringelse af data der foretages af mæglerforretningerne og som den enkelte ejendomssag i mæglernes C  Bsystem består af må indgå i vurderingen af det omtvistede spørgsmål om hvorvidt sagsøgerens database består af indsamlet allerede ek sisterende materiale I det foreliggen de franchisekoncept er det således bla en væsentlig funktion for sagsøgeren på sin egen hjemmeside at forestå de udbydende ejendomsmægler es markedsføring og annoncering på internettet af de af dem udbudte ejendomme for hvilken ydelse mæglerne der ikke har egne internethj emmesider betaler nærmere aftalte styk og omsætningsafgifter til sags øgeren Franchiseparterne findes så ledes i det hele at være forretningsmæssigt tæt forbundne med hver de res funktioner i det fælles ejendomsmæglerkædekoncept homekæden og de oplysninger der udgør de endeligt oprettede i homedkdatabasen  127  har ingen andre end sagsøgeren haft mulighed for at oprette hvortil fø jes at sagsøgerens adgang til data ene i CBsystemerne hvis funktion sagsøgeren definerer krav til og hv is abonnementsfaktu rering sker via sagsøgeren efter det oplyste må antages at være fri og uhindret Under de anførte omstændigheder finder retten ikke at homedkdatabasen hvis oprettelse i det væsentlige må anses at være afledet af homekædens hovedvirksomhed salg af fast ejendom til brug for an noncering og præsentation af de udbudte ejendomme i databaseretlig henseende består af indsamlet allerede eksisterende materiale og den ved databasedirektivet art 7 stk 1 etablerede databasebeskyttelse jf ophavsretslovens  71 stk 1 der må forstås i overensstemmelse her med omfatter derfor ikke denne database Der er herefter ikke anledning for rett en til at tage de øvrige omtvistede punkter i relation til ophavsretslovens  71 stk 1 under påkendelse ligesom spørgsmålet om sagsøgtes evt overtrædelse af ophavsretslovens  71 stk 2 databasedirektivets art 7 stk 5 ikke kommer på tale Markedsføringslovens  1 Påstand 1 b dybe link Indledningsvis bemærkes at sagsøgtes oprettelse af en boligsøgetjene ste i 1998 nu boligofir med et landsdækkende boligindeks med lige adgang for alle udbydere til at få deres udbudte ejendomme med i indekset modsvarede intentionerne bag regelen i lov om omsætning af fast ejendom  5a der blev indført med virkning fra 1 juli 2000 på grundlag af Boligrapporten afgivet af den af Erhvervsministerie t i 1996 nedsatte idégruppe  jf lov nr 227 af 21 april 1999  1 Det må efter oplysningerne om homeejendomsmæglernes markedsandel antages at ville indebære en væsentli g forringelse af kvaliteten ved bo ligofirs boligindeks med en reduktion i besøgstallet til følge såfremt sagsøgte afskæres fra at optage homemæglernes ejendomme i indekset Det bemærkes endvidere at boligofir hvis profil på internettet ikke fremtoningsmæssigt ligner sagsøgerens boligtjeneste efter det frem komne præsenterer udbydernes ejendomm e ca 40000 i alt på en ens 128  artet og loyal måde i ren tekst uden anvendelse af logotypes Det er de af brugerne i søgeprocessen konkret valgte faktuelle data om de enkelte ejendomme som er afgørende for præsentationsrækkefølgen ingen ud byder har præference frem for andre Uanset at de omhandlede hjemmesider hver især er platformemarkedspladser for udbudte faste ejendomme til salg på internettet er det endvi dere rettens opfattelse at der ikke i noget væsent ligt omfang består et direkte konkurrenceforhold mellem parterne Sagsøgerens forretningsgrundlag i internetsammenhæng er baseret på homeejendomsmæglernes betaling som franchisetagere for sagsøgerens salgspræsentation som franchisegiver af mæglernes ejendomme på homedk og sagsøge ren har ikke indtægter fra bannerannoncering Sagsøgtes ydelse i denne sammenhæng er en hjemmeside med en boligsøgetjeneste og et landsdækkende boligindeks med gratis deltagelse for alle herunder private udbydere af fast ejendom og sagsøgtes indtjening består udelukkende i indtægter fra annoncørers bannerannoncering på hjemmesiden Driften af sagsøgtes boligtjeneste indebærer ikke risiko for tilegnelse af mar kedsandele fra sagsøgeren og den om sætning som måtte udspringe af et ejendomssalg efter en henvisning fra boligofir oppebæres af den udbydende homeejendomsmægler og til fordel tillige for sagsøgeren i form af den som følge af den genererede omsætning afledte afgift som ejendomsmægleren skal betale til sagsøgeren Sagsøgtes omsætning derimod er upåvirket af det konkrete salg Retten bemærker herefter Søgetjenester der af forskelligt tilsni t må antages at blive stadig mere almindelige på internettet må anses som ønskværdige som værende nødvendige for funktionen af dagens internet som medie for søgning og udveksling af en uhyre omfangsrig og stadig stigende mængde af infor mationer Den databasebeskyttelse som er et sigte med databasedirektivet afspejler også disse forhold Det må anses for almindeligt at der på søgetjenester stilles dybe link til rådi ghed hvorved brugeren på en effek tiv måde kan komme direkte til de ønskede oplysninger hvilket som in ternettet er indrettet og fungerer gennemgående må antages at være i overensstemmelse med de interesser der forfølges af dem der vælger at  129  benytte internettet til tilgængeliggøre lse af oplysninger for offentlighe den Aktører herunder udbydere på internettet må således påregne at der fra søgetjenesterne etableres link til de oprettede sider uanset disses opbygning og indbyrdes sammenhæng dvs også til undersider som sagsøgerens ejendomsannoncesider Når det til det anførte yderligere tages i betragtning at boligofirs bruge re  der kan vælge omstilling enten til forsiden eller ved brug af dybe link direkte til ejendomsannoncesiden på sagsøgerens hjemmeside hvor der ikke gøres brug af bannerannoncer  før omstilling til ejendomsannoncesiden effektueres ved fremkomsten af et skærmbillede oplyses om den forestående omstilling finder retten ikke at sagsøgte overtræder markedsføringslovens  1 ved på boligofir at stille dybe link til rådighed for brugerne Markedsføringslovens  1 som sagsøgerens subsidiære anbrin gende Under henvisning til rettens betragtninger i det foregående afsnit og idet der ikke i øvrigt er anført omstændi gheder der giver grundlag for en an den vurdering herunder hverken det anførte om de skadelige virkninger for sagsøgerens brandingstrategi og karakteren af boligofirs banneran noncering som den er eksemplifice ret for retten eller den omstændig hed at sagsøgte ikke tilføjer egne data til de kopierede kan retten ikke tiltræde sagsøgerens subsidiære anbringende i relation til markedsfø ringslovens  1 Påstand 2 og konkluderende bemærkninger Da sagsøgte som en følge af det anførte frifindes for så vidt angår sagsø gerens påstande 1a og 1b er der ikke grundlag for at pålægge sagsøgte at betale hverken erstatning eller v ederlag hvorfor sa gsøgte yderligere frifindes for sagsøgerens påstand 2 Der er herefter ikke anledning for re tten til at behandle parternes anbrin gender vedr ophavsretslovens  22 og konkurrencelovens  6 og  11  130  T h i k e n d e s f o r r e t Sagsøgte OFIR a s frifindes for de af sagsøgeren home as nedlagte påstande Sagsøgeren betaler inden 14 dage 150000 kr i sagsomkostninger til sagsøgte Claus Forum Petersen Claus Thorsgaard Larsen Claus Jepsen Sign ___ ___ ___ Udskriftens rigtighed bekræftes Pjv Sø og Handelsretten den Spam Act 2003 A practical guide for business When reviewing your business practices and the contents of your commercial electronic messages for compliance with the Spam Act there are three key elements you should consider 1  CONSENT Only send commercial electronic messages with the addressees consent  either express or inferred consent 2  IDENTIFY Include clear and accurate information about the person or business that is responsible for sending the commercial electronic message 3  UNSUBSCRIBE Ensure that a functional unsubscribe facility is included in all your commercial electronic messages Deal with unsubscribe requests promptlyOVERVIEW  THE 3 STEPS TO FOLLOWSpam Act 2003 A practical guide for business February 2004 ISBN Print 1 74082 046 0 ISBN Online 1 74082 047 9 Disclaimer Please note This guide has been prepared by NOIE to provide information to business in relation to the sending of commercial electronic messages While every effort has been made to ensure that the document is accurate no warranty guarantee or undertaking is given regarding the accuracy completeness or currency of the document This guide should not be relied upon as legal advice Users are encouraged to seek independent advice relevant to their own particular circumstances Links to other websites are inserted for convenience only and do not constitute endorsement of material at those sites or any associated organisation product or service This guide provides practical information to businesses that send electronic messages It explains the main requirements of the Spam Act 2003 the SpamAct and outlines business practices that comply with the legislation The guidehas been developed in consultation with key industry stakeholders to provide aclear explanation of the legislations requirements The three key steps you should follow are 1 Consent Only send commercial electronic messages with the addressees consent  either express or inferred consent 2 Identify Include clear and accurate information about the person or business that is responsible for sending the commercialelectronic message 3 Unsubscribe Ensure that a functional unsubscribe facility is included in all your commercial electronic messages Deal with unsubscriberequests promptly About this document  2 The Spam Act  what does it say 4 3 steps to follow  6 1 Consent 7 2 Identify  11 3 Unsubscribe 13 The Australian Communications Authority  the Spam Acts watchdog15International laws 17 More Information 18 Glossary of terms  19 Overview  the 3 steps to follow back cover 1TABLE OF CONTENTSINTRODUCTION The National Office for the Information Economy NOIE has prepared this guide in consultation with the business community to provide practical information about the Spam Act and guidance on stepsthat may be taken to assist in complying with it Italicised terms appear in the glossary on page 19  WHAT IS SPAM The Spam Act refers to spam as unsolicited commercial electronic messaging Electronic messaging covers emails instant messaging SMS and other mobile phone messaging but does not cover normal voicetovoice communication by telephone To be covered by the Spam Act the message must be commercial in nature  for instance offering a commercial transaction or directing the recipient to a location where a commercial transactioncan take place There are a large number of commercial electronic messages that can be sent legitimately They are only considered to be spam if they are sent without the prior consent of the recipient  as unsolicited messages A single message may be spam The message does not need to be sent in bulk or received in bulk The Spam Act makes no reference to bulk messaging  a single unsolicited commercial electronicmessage could be spam PURPOSE OF THE SPAM ACT 2003 The Spam Act was developed in response to the problems caused by the growing volume of unsolicited commercial electronic messages  or spam Spam threatens the viability and efficiency of electronic messaging It damages consumer confidence obstructs legitimate business activities andimposes many costs on users The legislation prohibits unsolicited commercial electronic messages  There are however many legitimate uses for electronic messaging  it is an important tool for business It allows simple and low cost communication with consumers who are increasingly usingsuch technologies to access information The Spam Act includes rules aimed at preservinglegitimate business communication activities and encouraging the responsible use of electronicmessaging The Act says that commercial electronic messages must accurately identify their sender and include a way for the recipient to unsubscribe from future such messages if they want to ABOUT THIS DOCUMENT 2Spam Act 2003  A practical guide for business120 DAY GRACE PERIOD The Spam Act became law on 12 December 2003 with a proviso that its penalty provisions would come into effect 120 days later This grace period was included to ensure that people could learnabout the requirements of the Spam Act and ensure that their business practices satisfy thoserequirements All provisions of the Spam Act are in effect from 10 April 2004 THE PRIVACY ACT AND THE NATIONAL PRIVACY PRINCIPLES Businesses need to comply with the provisions of the Spam Act when sending commercial electronic messages Equally importantly businesses should make sure that their practices are in accordance with the National Privacy Principles available from wwwprivacygovau  in all activities where they deal with personal information Personal information includes customers contact details NOIE The National Office for the Information Economy is responsible for providing information and education material about the Spam Act during its implementation Additional material about the Spam Act is available from NOIE at wwwnoiegovau  THE ACA The Australian Communications Authority is responsible for enforcing the provisions of the Spam Act  Additional information about the Spam Act and the ACAs role is available from wwwacagovau  The ACAs enforcement role is discussed further in the section starting on page 15  3SPAM PROHIBITED The Spam Act says that unsolicited commercial electronic messages must not be sent Messages should only be sent to an address when it is known that the person responsible for that address has consented to receive it There is discussion of consent and what it means on page 7  ADDRESS HARVESTING SOFTWARE HARVESTED ADDRESS LISTS Businesses must not use electronic address harvesting software  or lists which have been generated using such software for the purpose of sending unsolicited commercial electronic messages  There is a description of address harvesting software and harvested lists on page 10  The same section provides some guidance when using contact lists supplied by a third party RULES FOR SENDING COMMERCIAL ELECTRONIC MESSAGES Commercial electronic messages must contain  Accurate information about the sender of the message A functional way for the messages recipients to indicate that they do not wish to receive such messages in the future  that they wish to unsubscribe  MESSAGES COVERED BY THE ACT The Spam Act covers commercial electronic messages that are sent using applications such as  email short message service SMS multimedia message service MMS and instant messaging iM MESSAGES NOT COVERED BY THE ACT The following examples are notcovered by the Spam Act  Nonelectronic messages such as ordinary mail paper flyers etc Voice to voice telemarketing The majority of pop up windows that appear on the internet they are usually an intrinsic part of a webpage that has been accessed rather than a message sent to the recipient address and  Messages without any commercial content that do not contain links or directions to a commercial website or location THE SPAM ACT  WHAT DOES IT SAY 4Spam Act 2003  A practical guide for businessMESSAGES WITH AN AUSTRALIAN LINK The provisions of the Spam Act cover commercial electronic messages  originating in Australia that are sent to any destination and originating overseas that are sent to an address accessed in Australia FINANCIAL PENALTIES ASSOCIATED WITH A BREACH OF THE SPAM ACT The maximum penalties under the Spam Act are substantial  A business that is found to be in breach of the Spam Act may be subject to a Court imposed penalty of up to 220000 for a single days contraventions If after that finding the businesscontravenes the same provision they may be subject to a penalty of up to 11 million  The Spam Act specifies a number of options that are available to enforce the legislation depending on which is the most appropriate response to the contravention that has occurred The range of possible activities includes formal warnings infringement notices similar to aspeeding ticket and court actions INDUSTRY CODES AND STANDARDS Industry codes of practice are likely to be developed by industry organisations such as the Australian Direct Marketing Association ADMA and the Internet Industry Association IIA The codes areintended to provide relevant and achievable standards and procedures developed by groupsrepresenting industry sectors for their member organisations to assist compliance with the ActThese codes are likely to be presented to the ACA for registration 5When reviewing your business practices and the content of your commercial messages to ensure you comply with the Spam Act you should consider the following three steps STEP 1  CONSENT Your commercial messages should only be sent when you have consent  This may be express consent from the person you wish to contact  a direct indication that it is okay to send the message or messages of that nature It is also possible to infer consent based on a business or other relationship with the person and their conduct The concept of consent is discussed further in the section starting on page 7  STEP 2  IDENTIFY Your commercial messages should always contain clear and accurate identification of who is responsible for sending the message and how they can be contacted It is important for people to know who is contacting them and how they can get in touch in return This will generally be the organisation that authorises the sending of the message ratherthan the name of the person who actually hits the send button Identification details that are provided must be reasonably likely to be accurate for a period of 30 days after the message is sent This would be a consideration if the business was about to change address The concept of identification is discussed further in the section starting on page 11  STEP 3  UNSUBSCRIBE Your commercial messages should contain an unsubscribe facility  allowing people to indicate that such messages should not be sent to them in future All commercial electronic messages must contain a functional unsubscribe facility allowing people to optout from receiving future messages Such a request must be honoured The Spam Act specifies that the persons consent has been withdrawn within five working days from the date that the unsubscribe request was sent in the case of electronic unsubscribe messages or delivered in the case of unsubscribe messages sent by post or other means Similar to the identification of the messages sender step 2 above the unsubscribe facility must be reasonably likely to remain accurate and functional for a 30 day period The concept of the unsubscribe facility is discussed further in the section starting on page 13  3 STEPS TO FOLLOW 6Spam Act 2003  A practical guide for businessSTEP 1  CONSENT Your commercial messages should only be sent when you have consent  Only send commercial electronic messages with the addressees consent  either express or inferred consent TYPES OF CONSENT There are two forms of consent Express consent from the person you wish to contact  a direct indication that it is okay to send the message or messages of that nature Inferred consent based on a business or other relationship with the person and their conduct WHAT IS EXPRESS CONSENT You have received express consent from an addressee if that person has specifically requested messages from you Examples of this include when  the addressee has subscribed to your electronic advertising mailing list  the addressee has deliberately ticked a box consenting to receive messages or advertisements from you or  the addressee has specifically requested such material from you over the telephone WHAT IS INFERRED CONSENT Consent may be inferred when the person you wish to contact has not directly instructed you to send them a message but it is still clear that there is a reasonable expectation that messages will be sent You may be able to reasonably infer consent after considering both the conduct of the addressee and their relationship with you For example if the addressee has an existing relationship with youand has previously provided their address then it would be reasonable to infer that consent hasbeen provided Other examples of where consent may be inferred are  when purchasing goods or services an addressee has provided their electronic address in the general expectation that there will be followup communications  when an addressee has provided their address with the understanding that it would be used in daytoday transactions such as online banking or business and may be used for additionalcommunications for example notification of related services or products  online registration of a product or a warranty 71  CONSENTccoonnsseenntt when an addressee has conspicuously published their electronic address  In such a case the Spam Act permits commercial electronic messages to be sent to the addressee if the message relates to the addressees published employment function or role If a plumber advertises theiremail address it is okay to send them offers of work or of plumbing supplies but not to sendan offer unrelated to their work such as cheap pharmaceuticals If the published address isaccompanied by a statement saying that it should not be used for such messages such as thewords no spam then it cannot be used to infer consent to a message being sent  similarly when an addressee has provided a business card containing their electronic address  it would be a reasonable expectation on both sides that relevant messages would be sent tothat electronic address  For example if the business card was provided for work purposes then it would not be reasonable to infer that the addressee consented to receiving messages fromyou which are unrelated to their work WHAT IS AN EXISTING RELATIONSHIP It will be possible for you to infer consent based on the status of your relationship with the addressee as long as it is consistent with the reasonable expectations of the addressee and theirconduct The National Privacy Principles available from wwwprivacygovau  and particularly Privacy Principle 2 provides guidance on such communications An existing business or otherrelationship may for example be a relationship that was initiated by a commercial activityincluding provision for a fee or free of charge of information goods or of services or othercommunication between you and potential addressee The following are examples that might suggest that a business or other relationship exists from which you may reasonably infer consent  persons who have purchased goods or services which involves ongoing warranty and service provisions  shareholders magazine and newspaper subscribers subscribers to a service registered users of online services  utility or rate payers ie in a business relationship with utility companygovernment body subscribers to informationadvisory services financial members of a club professional association members members of frequent flyer or buyer clubs bank account holders superannuation subscriber employers and employees or contractors 8Spam Act 2003  A practical guide for businessCIRCUMSTANCES WHEN AN EXISTING RELATIONSHIP CANNOT BE ASSUMED Consent will not always be inferred where there is a preexisting relationship between you and a person For example it would not be reasonable to infer that a person consented to receiving commercial electronic messages from you simply because of a transaction along the lines of any oneoff purchase Transactions such as the purchase of a tshirt or groceries from a shopattendance at a concert performance or movie would not be a good basis for inferring consent or assuming that there is a preexisting relationship THE PRIVACY ACT AND THE NATIONAL PRIVACY PRINCIPLES The National Privacy Principles available from wwwprivacygovau  should always be followed by businesses when handling personal information including customers contact details You shouldbe aware of your obligations under the privacy legislation WHAT ABOUT MY OLD CONTACT LISTS Commercial electronic messages must only be sent with consent It does not matter when the contact list was gathered or how it has been used You should be able to look at the addresses on yourcontact list and be certain that you have either express or inferred consent to contact each addressee When you are satisfied that your existing list of addressees have consented to receiving commercial electronic messages  you should ensure that the collection of future addresses is also based on consent To do so you may wish to consider amending any forms letters or even invoices to seekconsent from a person to send them commercial electronic messages  WHAT IF IM NOT SURE WHETHER CONSENT HAS BEEN GIVEN To remove any uncertainty about whether you have the consent of the potential addressee you should seek confirmation from that addressee that you can send commercial electronic messages to them DOUBLE OPTIN PROCESS A double optin process sometimes also referred to as a closedloop confirmation can be used to validate that an addressee has consented to receiving commercial electronic messages and provides the evidence that you have the consent of the addressee The steps typically involved are 1 Your business receives a message saying that an electronic address email SMS or similar should be added to your contact list for commercial messages or company newsletters 2 Your business sends a message to that address requesting confirmation that messages should be sent there in future The message also contains a notification that they will only be added toyour contact list if they send a positive confirmation within 14 days 9ccoonnsseenntt3 After 14 days there are 3 choices  There has been a positive confirmation  the address is added to the contact list or There has been a negative response  the address is notadded to the contact list for future messages  There has been no response  the address is notadded to the contact list for future messages While not a legislated requirement you are encouraged to consider implementing a double optin process whether it is an automated system or a manual procedure for instances where it is difficultto validate whether the potential addressee has actually consented These instances can occur whendealing with online subscriptions requests from third parties and other occasions where consenthas not been given at the time of a personal communication or transaction CAN SOMEONE SUBSCRIBE ON ANOTHER PERSONS BEHALF Sometimes you may receive a request from a person to send commercial electronic messages to another person In this case the addressee themselves did not submit the request and as a resultthe consent requirements of the Act may not be met If you receive a request like this you should contact the addressee and seek confirmation of the request that was made and ensure that they consent to you sending commercial electronic messages to them When doing this it may be useful to provide information on whom requested the initial subscription on their behalf or how the subscription request was submitted WHAT ABOUT ADDRESSHARVESTING SOFTWARE Addressharvesting software and harvestedaddress lists are often used for legitimate purposes such as collecting data for research marketing or maintaining websites but they are also often used tocreate distribution lists for sending spam The legislation bans the use of addressharvesting software and harvestedaddress lists  for the purpose of sending spam You should ensure that the use of such software and lists are for purposesother than for sending unsolicited commercial electronic messages  Lists generated manually for example by reviewing websites are not prohibited However if addressees have included a statement adjacent to their electronic address indicating the addressee does not wish to receive commercial messages this must be respected CAN I USE PURCHASED CONTACT LISTS You may use a purchased or rented list of contacts but you should be careful to ensure that the requirements of the Spam Act have been met ie consent has been obtained 10Spam Act 2003  A practical guide for business2  IDENTIFY STEP 2  IDENTIFY People who receive your commercial messages should be able to read them and know who you are and how to get in contact with you This means including accurate sender details and contactinformation Include clear and accurate information about the person or business that is responsible for sending the commercial electronic message  WHAT IDENTIFICATION DO I NEED TO PROVIDE To comply with the Spam Act you should ensure that accurate information identifying your business is provided in all commercial electronic messages you have authorised to be sent This information should include details that clearly identify your business for example the business name and detailsabout how the addressee may contact you This may be as simple as amending templates that are used for electronic letters quotes invoices and other messages that are sent to existing and potential customers HOW ABOUT WHEN IM USING A THIRD PARTY TO SEND THE MESSAGE Sometimes you might use another organisation a third party to send commercial electronic messages on your behalf This third party must include accurate information about your business for example name address and contact details When instructing the third party to send messages on your behalf you should ensure that you provide your sender information and authorise its inclusion in messages to be sent The Spam Act does not require the third partys information to be included in the message  you may decide whether it would be appropriate or not WHAT IF THERE ARE LIMITATIONS ON THE AMOUNT OF INFORMATION I AM ABLE TO SEND The content of electronic messages may depend on the size and capacity of different technologies For example more information is able to be sent by email than by SMS In most cases it is unlikely that detailed sender information and detailed unsubscribe information will be able to be provided inan SMS message 11iiddeennttiiffyyIn these circumstances your sender information might be brief for example your business name and contact number You might also include an additional link to more information about yourbusiness a free information number or an internet address FOR HOW LONG MUST THIS INFORMATION REMAIN ACCURATE Sender information must be reasonably likely to be accurate for a period of 30 days after the day on which you send your message This requirement ensures that addressees have a reasonablechance of being able to contact you If you are planning on changing premises within that period you could include postal information and phone contacts for both addresses and the date when the transfer will occur or alternativelyyou could make arrangements for communications that go to the old premises to be redirected toyour new premises for a period of time 12Spam Act 2003  A practical guide for businessSTEP 3  UNSUBSCRIBE You need to provide people the choice to opt out or unsubscribe  from your future commercial electronic messages  It needs to be a clearly presented and easy to use Ensure that a functional unsubscribe facility is included in all your commercial electronic messages  Deal with unsubscribe requests promptly WHAT FORM SHOULD THE UNSUBSCRIBE FACILITY TAKE An unsubscribe facility is basically an electronic address that messages can be sent to and a clear conspicuous statement that the address can be used to opt out from future messages The form ittakes can vary as long as these basic requirements are met In relation to email messages this could be in the form of a link that creates an automatically addressed email to be sent in reply Alternatively a link could take the addressee to your websitewhere they can fill in their details and send them to you An accompanying note along the lines ofClick here to unsubscribe would satisfy the requirement Alternatively a message saying If youwish to opt out from future messages send a reply email with the subject UNSUBSCRIBE iscommonly used In relation to SMS the facility might provide a number that addressees can SMS their request to unsubscribe or alternatively provide an email address for the person to contact with their opt outrequest You might also consider providing additional ways for addressees to unsubscribe  Alternatives might include acceptance of requests through telephone calls to your existing business numberOtherwise you could use a dedicated line such as a 1800 number accepting requests by facsimileor through your business email address FOR HOW LONG MUST THE UNSUBSCRIBE FACILITY REMAIN WORKING In terms of the Act the unsubscribe facility must be reasonably likely to be functional for a period of 30 days after the day on which your message was sent You should however endeavour tohave a permanent facility available to addressees HOW QUICKLY MUST I ACTION REQUESTS TO UNSUBSCRIBE The Spam Act states that a request to withdraw consent will be considered to have taken effect after five working days from the date on which the request was sent for electronic unsubscriberequests or delivered in the case of unsubscribe messages sent by post or other means 133  UNSUBSCRIBEuunnssuubbssccrriibbeeAny commercial electronic message sent after this five day period contrary to an unsubscribe request may be considered to be in breach of the legislation You are strongly encouraged to ensure that your unsubscribe facilities and business processes are set up to support this requirement Options for doing this could be Setting up a sameday unsubscribe regime so that optout requests have a 24 hour turn around or  Change your process for sending out electronic messages so that the addresses that have unsubscribed are always removed from your contact list just before any messages are sent You also should consider keeping unsubscribe requests for a specified period in order to check addresses against future message mailouts 14Spam Act 2003  A practical guide for businessTHE ACA The ACA is responsible for regulating telecommunications and radiocommunications including licensing spectrum management compliance with codes and standards performance monitoringand consumer safeguards The Australian Communications Authority is responsible for enforcing the provisions of the Spam Act INDUSTRY CODES AND STANDARDS Industry codes of practice are likely to be developed by industry organisations such as the ADMA and the IIA The codes will aim to provide relevant and achievable standards and proceduresdeveloped by groups representing industry sectors for their member organisations to assistcompliance with the Act These codes are likely to be presented to the ACA for registration ENFORCEMENT OF THE SPAM ACT Under the Spam Act the ACA is concerned with unsolicited commercial email and other electronic messages whether or not the content is itself legal or illegal However much email also carriescontent which is itself illegal under other lawsfor example it is fraudulent offensive or carries acomputer virus The ACA will be working closely with other regulators and law enforcementagencies on the problem of illegal messages In addition to working on industry codes and standards the Spam Act gives the ACA the ability to pursue a number of options in enforcing the legislation FORMAL WARNINGS The ACA may choose to issue a formal warning rather than issue an infringement notice or initiate a full court proceeding This would typically be done where the ACA was satisfied that thecontravention was largely inadvertent and would not be repeated or in other cases where awarning would suffice to change the contravening behaviour INFRINGEMENT NOTICES The ACA may choose to issue infringement notices for contraventions of the legislation instead of initiating a full court proceeding A person who receives an infringement notice may refuse to paybut could then be subject to a court action where if the contravention was proven they could bepenalised at a higher rate than the infringement notice 15THE AUSTRALIAN COMMUNICATIONS AUTHORITY  THE SPAM ACTS WATCHDOGCOURT ACTIONS The ACA may initiate a court action in respect of a contravention of the legislation If a contravention is found to have occurred the ACA may apply to the court to order the person or organisationinvolved to pay a penalty and additionally to surrender any financial benefit they gained in thecourse of their contravening activity Any person who has suffered loss or damages from someoneelse contravening the Spam Act or the ACA on their behalf may apply to the court to make anorder for compensation 16Spam Act 2003  A practical guide for businessCOVERAGE OF AUSTRALIAS SPAM ACT The legislation is intended to prohibit  spam originating in Australia being sent to any destination  spam originating overseas being sent to an address accessed in Australia Enforcement of the penalties relating to overseas sourced spam will be problematic until international arrangements are in place Australia is actively seeking partnerships with othercountries and organisations in the fight against spam The legislation ensures that there is an appropriate enforcement regime in place to deal with overseas spammers as soon as international arrangements are in place The Spam Act includesprovisions that anticipate Australias entry into such arrangements with other countries concernedabout spam This will enable regulations to be made giving effect to these agreements once in place OTHER COUNTRIES LAWS Australias legislation is currently one of the worlds best examples of an antispam legislative regime The number of countries that have passed or are considering passing national legislationagainst spam is growing Often the requirements of these laws vary subtly from country to countryand if you are planning to send commercial electronic messages to addressees outside of Australia you should find out about the specific requirements of their antispam laws 17INTERNATIONAL LAWSCHECK YOUR ISPS POLICIES It should be noted that many businesses may have existing agreements with their Internet Service Providers ISPs on Acceptable Use Policies AUPs which specify a higher level of consent than isprovided for in the spam legislation For example they may require express consent or require theuse of double optin methodologies for confirming consent They do this to protect their businessreputation and to avoid problems with spam blocking groups on the Internet The spam legislationdoes not overrule cases where a higher standard is required in an AUP Businesses should pay closeattention to their AUPs to avoid difficulties with their ISP THE PRIVACY ACT 1998 AND THE NATIONAL PRIVACY PRINCIPLES NPP The Office of the Federal Privacy Commissioner wwwprivacygovau  provides a comprehensive range of information on the requirements of the Privacy Act and on the National Privacy Principles In addition to the requirements of the Spam Act you should always be in compliance with the provisions of the National Privacy Principles OTHER SOURCES OF INFORMATION Additional information in relation to the Spam Act and preventative measures is available from the ACA and NOIE websites located at the following addresses wwwacagovau and wwwnoiegovau  LINKS Many industry organisations also offer advice about the Spam Act and about spam in general This information can be found from the following website addresses  Australian Direct Marketing Association ADMA wwwadmacomauaspindexasp   Coalition against Unsolicited Bulk Email CAUBE wwwcaubeorgau   Internet Industry Association IIA wwwiianetau   Internet Society of Australia ISOC wwwisocauorgau   Public Relations Institute of Australia PRIA wwwpriacomauhomephp   Small Enterprise Telecommunications Centre SETEL wwwsetelcomau  and  Presidian Legal Publications wwwpresidiancomau  MORE INFORMATION 18Spam Act 2003  A practical guide for businessAdditional definitions can be found in the Spam Act 2003 and its accompanying Explanatory Memorandum  Both are available from httpscalepluslawgovau  120 DAY GRACE PERIOD Time between Royal Assent enactment and penalty provisions of the Act coming into force This provision was designed to allow time for the review of business practices to ensure conformity with the Act ACA Australian Communications Authority ACCOUNTHOLDER The person responsible for the electronic address  When an organisation provides email addresses for its employees both the organisation and the employee may consent to messages being sent to that address ADDRESSHARVESTING SOFTWARE Addressharvesting software is a computer program that is designed to automatically collect electronic address es from the Internet The software searches public areas such as from web pages newsgroups chat rooms and other online directories to compile or harvest lists of addresses ADMA Australian Direct Marketing Association COMMERCIAL ELECTRONIC MESSAGE An electronic message for example an email or a text message for example that offers or advertises the supply of goods or services land business or investment opportunity For more information please see the fact sheet on commercial electronic messages CONSPICUOUS PUBLICATION Prominent display of an address to which electronic messages can be sent 19GLOSSARY OF TERMSELECTRONIC ADDRESS The means for contacting a particular person through a communications medium So an email address for emails telephone number for mobile phone messaging and user identity number forinstant messaging ENFORCEABLE UNDERTAKING Where an organisation submits a formal commitment that certain behaviour or activities will be done or will not be done HARVESTEDADDRESS LISTS A harvestedaddress list is a collection of electronic addresses that has been compiled through the use of addressharvesting software often without the consent or knowledge of the addressee The use of these types of software or address lists is only prohibited if the purpose of their use is to send unsolicited commercial electronic messages  IIA Internet Industry Association INJUNCTION A court based order requiring a person to do or stop doing something PENALTY AMOUNTS The amount of monies fined UNSOLICITED COMMERCIAL ELECTRONIC MESSAGE An electronic message for example an email or a mobile phone text message that is commercial in nature and has not been consented to UNSUBSCRIBE To cause an address to be removed from a mailing or distribution list 20Spam Act 2003  A practical guide for businessSpam Act 2003 A practical guide for business February 2004 ISBN Print 1 74082 046 0 ISBN Online 1 74082 047 9 Disclaimer Please note This guide has been prepared by NOIE to provide information to business in relation to the sending of commercial electronic messages While every effort has been made to ensure that the document is accurate no warranty guarantee or undertaking is given regarding the accuracy completeness or currency of the document This guide should not be relied upon as legal advice Users are encouraged to seek independent advice relevant to their own particular circumstances Links to other websites are inserted for convenience only and do not constitute endorsement of material at those sites or any associated organisation product or service This guide provides practical information to businesses that send electronic messages It explains the main requirements of the Spam Act 2003 the SpamAct and outlines business practices that comply with the legislation The guidehas been developed in consultation with key industry stakeholders to provide aclear explanation of the legislations requirements The three key steps you should follow are 1 Consent Only send commercial electronic messages with the addressees consent  either express or inferred consent 2 Identify Include clear and accurate information about the person or business that is responsible for sending the commercialelectronic message 3 Unsubscribe Ensure that a functional unsubscribe facility is included in all your commercial electronic messages Deal with unsubscriberequests promptly Spam Act 2003 A practical guide for business When reviewing your business practices and the contents of your commercial electronic messages for compliance with the Spam Act there are three key elements you should consider 1  CONSENT Only send commercial electronic messages with the addressees consent  either express or inferred consent 2  IDENTIFY Include clear and accurate information about the person or business that is responsible for sending the commercial electronic message 3  UNSUBSCRIBE Ensure that a functional unsubscribe facility is included in all your commercial electronic messages Deal with unsubscribe requests promptlyOVERVIEW  THE 3 STEPS TO FOLLOW Breaking Fraud  Bot Detection SolutionsMayank DhimanStealth Security AgendaArchitectural OverviewThreat ModelIssues  AttacksTakeawaysFraud DetectionDefend against fraudulent logins payments etcLook for anomalies in activity of a user given past activity Bot DetectionDefend against bots trying to test credential dumps scraping etcBot detection solutions look for anomalies across entire populations and time periods Account Take Over Fake Accounts PII  PHI Theft Cloud Deployment MitigatorService Provider Client BrowserWeb Server Web Request 1Fingerprintjs2 34 Form Submission4 5 Risk Score5 6 Block66 Allow6Inline Deployments Inline Device Client BrowserWeb Server AllowBlock 2 Web Request 1 3 4 4 Fingerprintjs2Threat ModelAttacker has full control over the browserAttacker can craft requests and modify responses according to the responses from the web server Fundamental Issue IAttacker can reverse engineer the entire sensorBrowser Fingerprinting httpspanopticlickefforgBrowser FingerprintingHardwareCPUArchitecture  Device MemoryGPU Canvas FingerprintingAudio Stack FingerprintingSoftwareUserAgentOS VersionStorageLocalStorageSessionStorageDisplayColor DepthScreen SizeBrowser CustomizationsFontsPluginsCodecsMime TypesTime zoneUser LanguageMiscFloating point calculationsAdd behaviorcallbacksobjects to DOM to check a real JS execution engine Browser Fingerprinting Fingerprintjs2 httpsgithubcomValvefingerprintjs2User BehaviorMouseCoordinates of where the move movedCoordinates of clicksKeyboardStream of key pressesTouchpadCoordinates of where the screen was touched User BehaviorDevice Orientation3D angle of device whenever the orientation changesDevice PositionRecord speed of change of devices position Timing information along with event type can be used to create a very accurate picture of what interactions took place on the webpageAntiTampering  AntiReversingJavaScript ObfuscationXOR based packed codeRandomize namelocation of the JavaScript file to loadDynamic FieldsPayloadPayload Encoding Base64Symmetric Encryption DESCustom Encryption Schemes Fundamental Issue IIThere are no guarantees of the correct execution of JavaScriptHeadless BrowsersBrowser without a GUI often used for automation and testing Either render full JS or run JS in a virtual DOM Stripping Attack MitigatorService Provider Client BrowserWeb Server Web Request 1Fingerprintjs2 34 Form Submission4 5 Risk Score5 6 Block66 Allow6Stripping Attack MitigatorService Provider Client BrowserWeb Server Web Request 1Fingerprintjs2 34 Form Submission4 5 Risk Score5 6 Block66 Allow6Stripping Attack Inline Device Client BrowserWeb Server AllowBlock 2 Web Request 1 3 4 4 Fingerprintjs2Stripping Attack Inline Device Client BrowserWeb Server AllowBlock Web Request 1 4 4 Fingerprintjs2 Form POST3MITM ProxyReplay AttacksNo check on freshness of payload Dynamic TokensA dynamic token is generated which is derived from the timestampSame logic can be replicated in a scriptFundamental Issue IIIThere are no guarantees of the legitimacy of the data collected by the JavaScript sensors Forging Browser FingerprintsFPRANDOM Modified browser which introduces noise during browser fingerprintOpenWPMWeb Privacy Measurement software Database of Normal FingerprintshttpsgithubcomplaperdrfprandomhttpsgithubcomcitpOpenWPMForging Browser Fingerprints Bad Guys Are Already Doing thisAntiDetect 399 in the underground httpskrebsonsecuritycom201503antidetecthelpsthieveshidedigitalfingerprintsUser BehaviorReplay with changed timestampsAdd ripples and disturbancesUse MITM Proxy Fundamental Issue IVJavaScript cant protect all flowsFundamental Issue VThe mitigativeaction acts as an oracle for the attacker Other IssuesFraudBot Detection Solutions are themselves FingerprintableSimilar issues exist for mobile app SDK based solutionsTakeawaysImplementation and Architectural Issues in multiple deploymentsJavaScript runs in an attacker controlled environmentUnderstand the limitations of such solutionsProtect all flowsQuestions , Web Scraping 101 Tools Techniques and Best PracticesAnthony HeathFollowPublished inGeek Culture14 min readMar 22ListenShareSo whats this web scraping thing everyone is talking aboutLets imagine the internet as the worlds largest data center Have you ever wondered how you could extract useful insights from it Finding and copypasting individual data would take too much time for largescale workThe answer lies in the art of web scraping which involves automated data extraction from websites and databasesWeb scraping is one of the most popular and powerful internet research tools for numerous purposes such as competitor analysis data mining content aggregation and market research You can extract necessary web resources such as photos text links or any other data based on your requirementsIts an exciting field and this article will provide a detailed overview of web scraping its essential tools techniques and best practices to bring you up to speed So lets buckle up and explore the interesting field of data scrapingWhat is Web ScrapingWeb scraping is an automated process for extracting data such as codes links images or any other structured data from websitesIf you still dont understand it think about it like this Imagine that youre catching fish looking for valuable data in the ocean on the web You would use a big net or a fishing rod to catch themWeb scraping is that net or fishing rod Its a tool to extract what you need and store it somewhere for analysis or your use caseIn the real world its used for monitoring product prices lead generation sentiment analysis content aggregation academic research etc Some Artificial Intelligence programs also use web scraping techniques to analyze and provide resultsSome exciting examples of web scraping includeExtracting price information from different ecommerce websites comparing prices from the dataset and selecting the best dealMonitoring your brand or product on social media and responding to your possible customersScraping stock market data from various websites analyzing this data and making decisions based on realtime data It can be an excellent tool for stock market traders and investorsCollecting data from different weather forecast websites analyzing the data and providing uptodate weather forecasts for specific locationsCollecting uptodate news from various news portals and creating a single platform that shows the latest newsNow you might be thinking Damn Thats so cool But how do I do thatGood question There are many tools and technologies available for web scraping Most programming languages like Python or R have specific libraries or extensions that allow you to extract data efficientlyBeautiful Soup Scrapy Selenium and Octoparse are the most widespread web scrapers In the next section well explore these popular web scraping tools Lets dive right inOverview Of Popular Web Scraping ToolsWeb scraping tools are software applications that allow you to extract data from websitesBelow weve listed some of the most popular web scraping tools and their pros and cons Lets choose the best one for your project1 Beautiful SoupBeautifulSoup is a Python parsing library that extracts data from HTML and XML files It is easy to use and can navigate through HTML and XML documents This tool extracts data from web pages such as images texts links etcBeautifulSoup mainly works by parsing HTML or XML files and generating a parse tree that it can traverse to locate specific elements It also includes various functions for searching and filtering the parse treeCode snippet from bs4 import BeautifulSoup sample  BeautifulSouppSomebexample ofiHTML printsampleprettifyhtmlbodypSomebexample ofiHTMLibpbodyhtml samplefindtextexampleexample sampleiiHTMLi2 ScrapyScrapy is a Pythonbased framework aimed at extracting data from internet resources It contains a rich set of web crawling data extraction and processing functionality making it a powerful and flexible tool for web scrapersOne of the major advantages of Scrapy is its performance It is fast efficient and able to extract a large amount of data in a short amount of time It can also format the results in several formats including CSV JSON XML and othersCode snippetfrom pathlib import Pathimport scrapyclass mySpiderscrapySpidername  examplestart_urls  httpsexampletoscrapecompage1 httpsexampletoscrapecompage2def parseself responsepage  responseurlsplit2 filename  fexamplepagehtmlPathfilenamewrite_bytesresponsebody3 SeleniumSelenium focuses on browsers which means it can be slower and requires a browser unlike other web scraping tools However Seleniums flexibility and versatility make it an effective and powerful tool for scraping dynamic pagesSelenium is compatible with popular programming languages like Python Java and C It can access the HTML of the web page and extract data It also contains builtin methods for accessing specific elements from the web page using element IDs and classesCode snippetimport pytestfrom selenium import webdriverimport sysfrom seleniumwebdriverchromeoptions import Optionsfrom seleniumwebdrivercommonkeys import Keysfrom time import sleepsaf_capabilities  build Sample Selenium Grid Chrome name  Sample for Selenium Grid Chromeplatform  Windows 10browserName  Chrome version  1404 OctoparseOctoparse is a web scraping tool perfect for anyone who needs to extract data from websites but wants to save time learning to code With Octoparse you can scrape data using a simple visual pointandclick interface which means you dont need any programming knowledge to get startedOctoparse can organize the result in various formats such as Excel CSV JSON and more It also provides a cloudbased scraping solution that enables users to run it on their server Octoparse has a builtin data extraction engine that can automatically identify and extract the data you need from web pages so you dont have to waste time manually selecting data fieldsOverview of Popular Web Scraping TechniquesHave you ever found yourself in a situation where you need to extract data from a website but copying and pasting each piece of information is too tedious and timeconsumingWell data scraping techniques are here to save the dayWith web scraping techniques like DOM parsing regular expressions and XPath you can extract the exact data you need from a websites HTML codeLets discuss a few of the most popular data scraping techniques and their pros and cons1 DOM ParsingDOM parsing is a web scraping technique that involves analyzing the HTML structure of a web page to extract specific data elements like headings paragraphs images links etcThe Document Object Model DOM is a treelike structure that represents the HTML structure of a web page Think of it as a treasure hunt for data from numerous sourcesDOM parsing requires a good understanding of HTML structure and can be done using libraries like Beautiful Soup For example if youre scraping an ecommerce website with multiple pages of products you can use DOM parsing to extract data from each product page by analyzing the HTML structureCode snippethtmlbodyp idexamplepscriptvar Sampletext parser xmlSampletext  bookstorebook  titleDunetitle  authorFrank Herbertauthor  year1965yearparser  new DOMParser xml  parserparseFromStringSampletext SampletextxmldocumentgetElementByIdexampleinnerHTML xmlgetElementsByTagNametitle0childNodes0nodeValuescriptbodyhtml2 Regular ExpressionRegular expressions or regex for short are a powerful technique used in web scraping to identify and extract specific patterns in the text of a web page Its like having a superpower that allows you to find and extract information based on a specific set of rulesFor example you need to extract all the phone numbers from a website With regex you can create a pattern that matches phone numbers in a specific format such as 5555555 and then use that pattern to extract all phone numbers from the web pageRegex is also useful for extracting structured data like email addresses URLs and postal codesCode snippetimport requestsfrom bs4 import BeautifulSoupimport repage  requestsgethttpsbookstoscrapecomsoup  BeautifulSouppagecontent htmlparserdata  soupfind_allclass_product_titledata  strdatare_titles  rtitletitles_list  refindallre_titles datare_prices  pprice_list  refindallre_prices datawith openoutputtxt w as ffor title price in ziptitles_list price_list fwritetitle  t  price  n3 XPathXPath is a language that lets you navigate through the elements of an HTML document and select specific elements or attributes You can use it with libraries like lxml or Scrapy to scrape data from websitesSo why is XPath so great It can easily handle even the most complicated web pagesAnd even if the structure of a web page changes you can still use XPath to extract the desired elementsNow that were armed with the capabilities of these powerful tools its time for us to keep certain best practices in mindComparison of Different Web Scraping Tools and TechnologiesWhich web scraping library is the bestIt depends on your specific use case and proficiency with code Heres a quick guideBeautiful Soup Its great for scraping data from static websites or web pages with a simple structure  a good choice for beginnersSelenium Selenium is ideal for automating web browser interactions such as clicking buttons filling out forms and navigating between pages Selenium is more complex than Beautiful SoupOctoparse Octoparse is a userfriendly web scraping tool for scraping data from multiple pages with similar content It doesnt require any coding knowledge making it accessible to beginnersScrapy Scrapy is ideal for scraping large amounts of data from complex websites Scrapy requires coding knowledge and is more complex than Beautiful Soup or Octoparse its a powerful tool for scraping data from advanced websitesAs for web scraping techniques wed recommend learning all of them but some are more useful in specific cases likeXPath is best suited for extracting specific elements or attributes from websites that use XML or HTML with complex structures XPath may not be the best option for web scraping beginnersOn the other hand regular expressions are ideal for extracting structured data and are highly versatile as they can be applied to any text data With a basic understanding of RegEx syntax you can use them with many programming languagesDOM parsing is a popular technique for extracting data from websites with complex HTML structures Beginners can use DOM parsing techniques with the help of libraries like Beautiful Soup lxml or jsoup While understanding HTML and CSS is helpful when working with DOM parsing techniques it is not strictly necessarySo lets face it there is no best technique for web scrapingBy understanding the strengths of each technique you can choose the most appropriate technique for your specific use caseBest Practices for Web ScrapingWeb scraping can be a powerful tool for extracting valuable data from websitesHowever it is essential to follow best practices to ensure the scraping process is legal ethical and efficientHere are some best practices for web scrapingTechniques for Maintaining Data Quality in Web ScrapingData quality is super important when it comes to web scraping especially if youre using the data for important business decisions or analysesHere are some useful techniques for maintaining data quality in web scrapingChoose your sources wisely Before you start scraping ensure youre pulling data from reputable sources If youre scraping from a site known for inaccurate or unreliable data youre likely to end up with inaccurate or unreliable data yourselfCheck for duplicates One common issue with web scraping is that you can end up with duplicates of the same data To avoid this check for copies before you analyze or use the dataUse regular expressions Regular expressions are a powerful datacleaning tool that can help you quickly identify and fix any issues with your scraped data They can also help you extract specific information from your scraped dataHandle missing values Its common to encounter missing values when scraping data from the web Make sure to handle these missing values appropriately by filling them in with an appropriate value or removing the incomplete data altogetherClean and standardize your data One of the biggest challenges with web scraping is that the data you pull can often be messy and inconsistent To combat this cleaning and standardizing your data before analyzing it is important This might involve removing special characters converting data types or reformatting textCommon Mistakes to Avoid in Web ScrapingLets be careful and understand the restrictions and things to look out for during our web scraping journeyBe Respectful with the Robotstxt FileIn case youre wondering what a robotstxt file is heres the answerIt is a text file that tells search engines how to crawl and index pages restricted pages and files and provides other instructions for web crawlers to crawl the website Check it before extracting data from a websiteYou may ask Why should I care about thisThis file contains a list of rules and instructions for web crawlers to interact with the website For example a link containing confidential data might not be available for crawlersAnother important thing is that this file defines some intervals to hit the website making it a toppriority best practiceOffPeak Hour ScrapingYou might think What are offpeak hoursOffpeak hours are when website traffic is considerably less than at any other timeIt helps to improve the crawling rate and avoid extra loads from spider requests So running your crawler during offpeak hours can be good practiceTaking Responsibility for the DataIt is your responsibility to ensure the correct use of the data Its pretty straightforward Just go through the Terms of Services page before starting scrapingIf the website owner doesnt allow republishing or copying of their data just avoid it because breaking copyright laws may lead to legal issuesData WarehousingWhen you start web scraping youll have to deal with a ton of data which can be a nightmare to manageThats where data warehousing comes in Its a technique for managing and organizing large amounts of data from multiple sources in one centralized placeOne of the great things about data warehousing is that it stores data optimally for analysis and reporting making extracting valuable insights from all that information much easier Once the data is stored in the warehouse you can analyze it using various techniques such as data mining and business analysisIt can help you achieve scalability fault tolerance and high availability making it easier to work with all that data and get the insights you need to make informed decisionsRotating IPs and Proxy ServicesSometimes your spider might be locked when trying to crawl a website frequentlyHow can you fix this The easiest way would be by rotating IPs and Proxy Services during crawling Rotating means changing the IPs and Proxy Services so the server doesnt block the spiderAnother easy way to bypass certain website restrictionsdetections is to use GoLogin as it provides advanced features giving you control over cookies browser agents online fingerprints and moreIn our next section well discuss managing a web scraping project Lets go through itHow to Manage Your Web Scraping ProjectManaging web scraping projects can be challenging hence it is essential to approach web scraping with a strategic plan and carefully manage your project from start to finishBy taking a thoughtful approach to web scraping and following best practices for project management you can ensure that your project runs smoothly and that you can get the highquality data you needSo if youre ready to dive into your web scraping project look at the following tips and tricks to manage it betterIdentify your data requirements such as what kind of data you are willing to deal with and how you will use itSelect the best web scraping tool for your project You can reference the list of popular web scraping tools abovePrepare your scraping code and test it Testing is crucial as it will help you fix bugs and issues affecting data qualityIf any errors or exceptions occur handle them strategically such as retrying failed requests or using proxies to avoid blocking by the serverOnce you have obtained your data successfully organize it You can find practical techniques for organizing data in the Best Practices sectionLastly visualize and analyze your dataUse Cases and Examples of Web ScrapingPrice Monitoring for EcommerceRetailers can track the prices of competitors products in real time by scraping their websites allowing them to adjust their prices accordingly and stay competitiveSocial Media Monitoring for Market ResearchSocial media platforms can be scraped for marketing purposes to gather data on consumer behavior including sentiment analysis of brand mentions and tracking of hashtags related to their industryRecruitmentHRs can utilize web scraping to collect data on potential candidates from LinkedIn profiles job portals and other sources allowing them to build a robust talent pool and streamline their recruitment processReal EstateWeb scraping can help gather property listings including pricing location and amenities allowing them to make more informed decisions when buying and selling propertiesWeather ForecastingDifferent weather forecast companies can use web scraping to combine information from various sources such as weather websites sensors and satellites and analyze it to generate more accurate and reliable weather predictionsThese are just a few examples of successful web scraping projects By leveraging the power of web scraping businesses across industries can gather valuable data and insights to inform their decisionmaking and improve their operationsConclusionWeb scraping is a powerful technique for extracting data from the internet and using it for various purposes from business analysis and research to marketing and moreThroughout this article weve introduced you to some tools and techniques used for data scraping and how to scrape data ethically Weve also discussed the importance of testing and monitoring your scraping process and managing your web scraping projectIf you still find things difficult to understand feel free to try out GoLogin a powerful and professional privacy tool designed to make your web scraping experience easier and more efficient Check out this expert article on how GoLogin is used with Playwright to scrape websites with advanced protection like CloudflareHopefully this article has equipped you with the basic knowledge of web scraping With the right approach web scraping can help you unlock valuable insights and information that can help you make better decisions and achieve your goalsOr maybe web scraping is your next careerDownload GoLogin here and scrape even the most protected websites with our free plan ","https://en.wikipedia.org/wiki/Web_scraping, https://medium.com/geekculture/web-scraping-101-tools-techniques-and-best-practices-417e377fbeaf",Data Handling,12360,61233
Data Visualization in Web,How To Use Data Visualization In Web DesignNam Le Thanh Web DesignerFollow7 min readJul 16ListenShareThe human brain processes visual information much faster than text This is why data visualization has become increasingly popular in web design From infographics and charts to maps and timelines data visualization can help your website communicate complex information in a simple and engaging way Its important to use the right tools and design techniques to create visually appealing graphics that convey a clear message to your audience In this blog post well explore the benefits of data visualization in web design and share some tips on how to effectively incorporate it into your website So whether youre a web designer or just interested in improving your websites visual appeal read on to learn how to use data visualization to tell your story in a way that your audience will remember1 Introduction to data visualization in web designData visualization is the art of representing data in a visually appealing and understandable manner As web design becomes more datadriven data visualization has become an essential tool for web designers Data visualization helps designers to communicate complex data sets analysis and insights to users in a simple and effective wayWeb designers are increasingly using data visualization to provide users with a better understanding of the datadriven insights that underpin their products and services By using visual representations of data designers can turn dry numbers into engaging and attractive visualizations that tell a story and make sense to the user2 Why data visualization is important for web designData visualization is an essential component of web design because it helps to communicate complex information in an easytounderstand format The human brain processes visual information much faster than text making data visualization an effective way to convey information quickly and efficiently Designers can use various data visualization techniques such as charts graphs and infographics to present data in a visually appealing and engaging wayBy using data visualization designers can help users analyze and interpret data more effectively Users are more likely to engage with a website that presents information in an organized and visually appealing manner For example an ecommerce website can use data visualization to display popular products most viewed items and toprated products This information helps users make informed decisions while shopping and encourages them to make a purchase3 Types of data visualization used in web designIn web design there are several types of data visualization that can be used to effectively communicate information to the userOne popular type of data visualization is charts and graphs which can be used to display numerical data in a visually appealing way Bar charts pie charts and line graphs are all common types of charts that are used in web design to present data in an easytounderstand wayAnother type of data visualization that is used in web design is infographics Infographics are a combination of text images and charts or graphs that are used to convey complex information in a visually appealing way They are often used to present statistics trends or other types of data in a way that is easy to understandMaps are also a common type of data visualization used in web design They can be used to display geographical information such as the location of a business or the distribution of a particular product or service Maps can be interactive allowing users to zoom in and out or to click on specific locations to get more information4 How to choose the right type of data visualization for your websiteWhen deciding which type of visualization to use consider the type of data you are presenting and the story you want to tell If you are presenting numerical data such as sales figures or survey results a bar or line chart might be the best option If you are presenting geographical data such as population or income data a map might be more appropriateYou should also consider the complexity of the data you are presenting If you are presenting a lot of data an infographic might be the best option Infographics can be used to display a lot of complex information in a visually appealing and easytounderstand wayAnother important consideration is the design of the visualization When designing a data visualization make sure it is visually appealing easy to read and accurately represents the data You can use color typography and other design elements to make your data visualization more visually appealing and engaging to your audience5 Best practices for incorporating data visualization into web designIncorporating data visualization into web design can be a powerful tool for improving user experience and making complex information easier to understand But there are some best practices you should follow to make sure the data visualization is effective and enhances the overall designFirstly keep it simple Complex graphs and charts can be overwhelming and confusing for users Stick to simple easytounderstand visualizations that clearly convey the information you want to presentSecondly make sure the visualization is relevant to the content on the page Dont add a chart or graph simply because it looks good  it should serve a purpose and help the user better understand the informationThirdly use color and typography effectively to guide the users attention to the most important information Use color sparingly and consistently and choose fonts that are easy to read and complement the overall designFourthly make sure the data visualization is responsive and looks good on all screen sizes This is particularly important as more and more users access websites on mobile devicesFinally test the data visualization with users to ensure its effective and easy to understand This feedback can help you make tweaks and improvements to ensure the visualization is serving its intended purpose6 Tips for creating effective data visualizationsWhen it comes to creating effective data visualizations there are a few key tips to keep in mind First its important to choose the right type of visualization for the data youre trying to convey Bar charts line graphs and pie charts are all common options but there may be other visualizations that work better for your specific data setAnother important factor to consider is color Choose colors that are easy on the eyes and provide sufficient contrast to make the data easy to read Avoid using too many colors as this can be overwhelming and distracting Stick to a simple color palette that complements your brand and makes the data easy to understandWhen it comes to displaying labels and annotations be sure to use a font that is easy to read and legible at the size you plan to use If your visualization includes a lot of data points or labels consider using interactive features to allow users to zoom in and explore the data in more detailFinally its important to consider the context in which your data visualization will be viewed Will it be displayed on a large screen or a small mobile device Will users be interacting with it on a touch screen or with a mouse These factors can influence how you design and present your visualization to ensure it is effective in conveying your message to your audience7 Tools and resources for creating data visualizations in web designOne of the most popular tools for creating data visualizations is Tableau Tableau is a powerful data visualization tool that allows you to easily create interactive dashboards and charts It also has a large community of users who share their visualizations and provide support for othersAnother great tool for data visualization is D3js D3js is a JavaScript library for creating dynamic and interactive data visualizations in web browsers Its a bit more complex than Tableau but it gives you more control and customization optionsIf youre looking for a more userfriendly option you might want to try out Google Charts Google Charts is a free tool for creating simple charts and graphs that can be easily embedded in your websiteIn addition to these tools there are many resources available to help you learn more about data visualization in web design Websites like Data Visualization Society and Flowing Data provide inspiration and tutorials on how to create effective data visualizations8 How to measure the effectiveness of your data visualizationsThere are several ways to measure the effectiveness of your data visualizations including1 Analyzing user engagement Monitoring user engagement with your data visualizations can provide valuable insights into their effectiveness You can track metrics such as the time spent on the page the number of clicks and the number of shares to determine how engaged users are with your visualizations2 Conducting user surveys Surveys can help you understand how users perceive your data visualizations You can ask questions such as Did you find the data visualization helpful Did the visualization help you understand the data better and Would you like to see more data visualizations in the future3 Analyzing the impact on website metrics You can also track website metrics such as bounce rate conversion rate and time on site to determine the impact of your data visualizations on user behavior4 AB testing AB testing involves creating two versions of a web page with different data visualizations and measuring which version performs better This can help you determine which types of visualizations are most effective for your audienceConclusionI hope you enjoyed our blog on data visualization in web design Designing websites with data visualization in mind can help you communicate complex information in a clear and concise way I covered the benefits of using data visualization in web design as well as some tips for incorporating it into your own designs By keeping these suggestions in mind you can create stunning and effective designs that are sure to impress your clients and users So keep on experimenting with different data visualization techniques and let me know which ones worked the best for youOriginal blog post ,https://medium.com/@namtheartist95/how-to-use-data-visualization-in-web-design-6801667ef5c6,Data Visualization,483,1644
Animation and Motion in Web Design, Animation in Web Design All a Client Needs to Know Published Dec 13 2021  8 min read UI Design Animation has always served to help breathe soul into the pages of your website make it more lively and understandable for the user and improve their experience Even primitive animation the simplest GIFs and flashing images are often used for decorative purposes They may entertain the user and simply distinguish your website from competitors One of Our Works From the first glance moving pictures and gifs are nothing serious more like fun But lets see what web animation can bring for the website owner and the business as a whole 7 Types of Animations Animation in web design may vary Nowadays animation effects are made functional They improve the websites usability and increase engagement More recently its become an integral part of great UX  UI design which makes the user comfortable Lets check out what basic types of animated website design you may come across Hover CSS hover effects are applied for images buttons hovering over links blocks etc Very often on websites you could see a change in the design of links or buttons on hover A special pseudoclass hover in CSS allows implementing this task These layout techniques are applied to Effect buttons and links Hover images CSS library included separately These are the most exciting and widely applied hover effects you may ever notice in web design Page Motion Whole page animation as an effect may usually mean the slight movements of the entire website background No wonder Motion is type of animation apps which is easy to use Using page motion graphics may help you to enhance your website in many ways The major thing here will be not to overdo Keep it a harmony Scrolling Here the principle is still the same what you need to draw the attention of the visitor to goes in the first place and is highlighted while scrolling up and down So if you think its time to add some animation to your page when a visitor scrolls go ahead Backgrounds In traditional animation background layouts are more like line drawings of the background for a scene So in web design its instead an environment on your website where the users get The animation effect is added to provide more visual interest to your website background and the interaction Attracting attention Of course if you apply some Fast animations in your website design they are more likely to attract your users attention when they happen outside the users focus The motion added to motionless areas is the first to grab your attention and engage to spend some more time on Navigation and Menus While using animation effects here when the menu items appear the screen overlaps When you click on the menu elements a smooth transition of the underline may be used for the active link etc Transforms and animations are also used in navigation with the transition property Loading Animations Lets see how HubSpot defines loading animations Loading animations are notifications that reassure users that the system is still handling their request Some animations have progress bars that indicate how long it will take for data or content to load This gives users a realtime update  or distraction  that makes waiting more bearable 5 Animation Techniques No matter which type of animated web page design you prefer for your website design you may achieve these effects with the help of a range of animation techniques Lets revise some of them Progression If we take the Loading animation that may influence your users perception of time we can make it seem less than it is by applying this technique One of the UX principles is to make waiting comfortable if you cannot shorten the line in some other way Even if the load time is short the animation will add so much fun and engage the viewer better Skeleton screens Another technique applied that may be found anywhere humans are forced to wait throughout the websites is Skeleton screens They are found in different sections shapes and sizes are seemingly everywhere across the web and apps The pattern was introduced to mitigate focus on the loading process versus the actual content that is loading Wroblewski Transition without hard cuts The most basic form of transition is the hard cut or move from the end of one scene to the beginning of the next without any changes or effects To transit without such hard cuts smoothly is the aim of this essential motion design technique Visual feedback In other words this is an animated response to the users action Good interaction design provides feedback which communicates the results of any encounter Sometimes people do not know what elements are interactive which frustrates them Visual feedback makes everything visible and understandable Galleries and slideshows And finally you can animate text pictures shapes tables other graphic objects for your web galleries and slides Indeed a presentation that has a bit of animation engages and delights viewers more than anything When You Should Use Animation Highquality and appropriate animation of web pages brings aesthetics and helps in work by visualizing needful information This is one of the foundations of web design UX today The interaction of users with modern websites is heavily tied to animation techniques So any of them you may use in a range of cases Data loading animation Animated reaction to user actions Attracting attention with animation Navigation Creative effects and so much more Animation is also used to enable reporting on specific page states focusing the users attention Animation helps the user to see the result of his actions and can influence their behavior Do you want to create your own animation  Feel free to contact us Therefore when designing pages it is necessary from the very beginning to remember the interactive nature of the webspace and incorporate animated objects as a natural part of that space If you need video for your business make sure you know what to do Good luck Conclusion Your website animation design should be more than set of phrases of data visualization languages Great website animation manages the interaction between the user and the web page As a result the animation plays a significant role in conveying information in the most appropriate way Similiar articles of our explainer video blog Project Management Tools for Video Production Dec 27 2021  6 min read Brand Storytelling Trends Every Marketing Leader Should Know in 2024  Explain Ninja Mar 29 2020  6 min read 7 Best Interactive Videos of All Time Mar 02 2023  13 min read What are you waiting for Just leave us a note well respond faster than Flash would do Contact Us ,https://explain.ninja/blog/animation-in-web-design-all-a-client-needs-to-know/,UI/UX Design,512,1127
Typography in Web Design, The Role Of Typography In Web Design Tips And Best Practices antarticastdShutterstockcom Level 2 By Ashish Kumar Tiwari August 11 2023 7 minutes to read 2 Comments Summary Typography is the art and technique of arranging type to create visual impact In web design typography plays a vital role in communicating information effectively and enhancing the overall User Experience How Text Can Enhance Your eLearning Websites User Experience Do you notice why some websites become your favorite for reading and catch your attention on the first visit It is because of their texts The text element is a critical component for grabbing the visitors attention on a website Thus if you want to build a blogging site or services profiles then your text is a significant factor in attracting the audiences attention Many experts believe that typography in web design is more than just a text font they can use it to enhance their website design In this article we discuss with some specialized web designers and developers to learn everything about typography in web design So to grab the information stick to the end What Is Typography In Website Design In web designing there are many factors you need to consider and typography is one of them The typography generally related to the typefaces or fonts designed on the webpages is very appealing readable and communicative It involves the selection placement and styling of typefaces as well as other elements such as spacing line length line spacing and alignment In the context of good website design typography refers to the thoughtful and deliberate selection arrangement and implementation of typefaces and typographic elements to enhance a websites visual appeal readability and User Experience Top Key Factors You Need To Consider For Your Web Typography Typography contrast in web design refers to the intentional variation and juxtaposition of different typographic elements to create visual interest and hierarchy and to enhance readability Here are some critical considerations for typography in good website design 1 Readability To Attract Readers The primary goal of typography in website design is to ensure that the content is easily readable and accessible to users This involves choosing legible typefaces appropriate font sizes and suitable line spacing leading to prevent eye strain and enable effortless reading 2 Contrast Enhance Your Elements Contrast is crucial in guiding users attention and making the content stand out It involves selecting a suitable combination of typefaces font weights and sizes to create a visual hierarchy and emphasize important information Contrasting the headline and body text can help establish a clear distinction between different content levels 3 Consistency Is Good For You Consistency in typography helps create a cohesive and harmonious visual experience across a website It involves consistently using a limited set of typefaces and styles throughout the site ensuring that headings subheadings body text and other elements maintain a uniform typographic appearance 4 Responsive Design To Engage Your Audience With the proliferation of various devices and screen sizes responsive typography is crucial for ensuring that text adapts and remains legible across different devices Implementing techniques such as fluid typography and media queries allows the typography to adjust dynamically based on the available screen space 5 Hierarchy And Information Organization Typography aids in establishing a clear visual hierarchy allowing users to understand the organization and importance of content By varying font sizes weights and styles designers can guide users attention making it easier for them to navigate and consume information on the website 6 Alignment And Spacing Proper alignment and spacing contribute to the overall aesthetics and readability of a website Aligning text elements consistently and using appropriate margins padding and line lengths can enhance readability and prevent a cluttered appearance 7 Branding And Personality Typography can also be used to convey the personality and brand identity of a website Selecting typefaces that align with the websites tone style and target audience helps establish a coherent brand image and create a memorable User Experience 8 Follow Accessibility Standards Consideration should be given to accessibility standards and guidelines when designing typography for a website Ensuring sufficient color contrast between text and background providing alternative text for images with typography and allowing users to adjust font sizes are some practices that promote accessibility for users with visual impairments or other disabilities In a nutshell typography in good website design focuses on creating a visually appealing readable and accessible User Experience by carefully selecting and implementing typefaces organizing content hierarchically and maintaining consistency throughout the site Remember typography contrast should be used intentionally to enhance the overall design and User Experience Strive for a balance between legibility visual appeal and brand consistency to create a harmonious and effective typographic system for your web design Best Practices Of Typography For Developing Amazing Web Design To develop a fantastic web design with typography consider the following best practices These are the experts recommended tactics for building an incredible web design with the help of typography 1 Select Appropriate Typefaces Choose typefaces that align with the websites purpose target audience and overall design style Opt for legible fonts with a range of weights and styles to create visual contrast and hierarchy 2 Limit Typeface Choices Stick to a limited number of typefaces typically two to three to maintain visual consistency and coherence throughout the website Too many typefaces can result in a cluttered and confusing design 3 Establish A Hierarchy Use typographic variations in font size weight and style to establish a clear visual hierarchy Important headings should stand out and be distinguishable from subheadings and body text 4 Pay Attention To Readability Ensure the text is easy to read by using an appropriate font size and maintaining adequate contrast between the text and the background Avoid using tiny font sizes that strain the eyes and ensure sufficient color contrast for readability especially for users with visual impairments 5 Use White Space Incorporate ample white space also known as negative space between lines paragraphs and elements to enhance readability and create a clean balanced design White space provides visual breathing room and helps direct the users focus 6 Mindful Alignment Align text elements consistently to create a cohesive and organized appearance Choose from leftaligned rightaligned centered or justified alignments based on the designs needs but avoid excessive justification as it may negatively impact readability 7 Consider Responsive Typography Implement responsive typography techniques to ensure text adjusts appropriately on different devices and screen sizes Fluid typography and media queries can help maintain optimal legibility and readability across various viewing contexts 8 Use Typographic Hierarchy Tools Employ typographic hierarchy tools such as headings subheadings bullet points and lists to structure and organize content This aids in scannability and comprehension making it easier for users to navigate and understand the information presented 9 Maintain Consistency Establish and maintain typographic consistency throughout the website Ensure consistent use of fonts sizes spacing and other typographic elements across all pages to create a unified and professional look 10 Test For Accessibility Ensure that typography choices meet accessibility standards and guidelines Verify color contrast ratios provide alternative text for nontext elements and allow users to adjust font sizes if needed Remember that typography is a powerful visual tool and its implementation should support the websites goals enhance readability and contribute to an overall pleasing User Experience With the help of these practices you can build a unique web design FAQ As you read about typography in web design here are some frequently asked questions These FAQs related to typographic considerations in website design Q1 What Are The Key Factors To Consider When Choosing Typefaces For A Website A When selecting typefaces consider factors such as readability legibility appropriateness for the websites purpose and target audience visual hierarchy and brand consistency Q2 How Many Typefaces Should I Use In My Website Design A Limiting the number of typefaces is generally recommended to maintain visual consistency Two to three typefaces eg one for headings and another for body text are commonly used ensuring a cohesive design without overwhelming the user Q3 How Can I Create A Visual Hierarchy With Typography A Visual hierarchy can be established through font size weight and style variations Use larger and bolder fonts for headings subheadings or essential elements to make them stand out from the body text Q4 How Can I Ensure Good Readability In My Websites Typography A To ensure readability consider using an appropriate font size maintaining adequate contrast between text and background using a legible typeface and paying attention to line spacing leading and paragraph spacing Q5 What Is The Role Of White Space In Typographic Design A White space or negative space is crucial for typographic design It provides a visual breathing room enhances readability and creates a balanced layout Use white space effectively to separate content and improve overall aesthetics Q6 How Can I Make My Typography Responsive Across Different Devices A Responsive typography can be achieved through fluid typography and media queries These approaches allow text to adapt and resize based on the screen size and ensure optimal readability on various devices Q7 Is It Important To Maintain Typographic Consistency Across All Website Pages A Yes maintaining typographic consistency is essential Consistent use of fonts sizes spacing and other typographic elements throughout the website ensures a unified and professional look enhancing the overall User Experience Q8 What Are Some Accessibility Considerations For Typographic Design A Accessibility is essential for inclusive design Ensure sufficient color contrast between text and background provide alternative text for nontext elements and allow users to adjust font sizes easily Q9 How Can I Effectively Use Typography For Content Organization A Typography helps in content organization through the use of headings subheadings bullet points and lists These elements create visual structure aid in scannability and improve the User Experience Q10 Are Any Tools Or Resources Available For Typography In Website Design A Yes there are various typography tools and resources available online Some popular ones include Google Fonts Adobe Fonts Typekit and Font Awesome These platforms provide a wide range of typefaces and resources to enhance your websites typography Remember that typography plays a crucial role in web design impacting aesthetics and usability Consider these FAQs as a starting point to help you make informed decisions and create visually appealing and userfriendly typographic designs for your website Read Also Typography In eLearning 5 Key Tips For eLearning Professionals 9 Online Resources To Learn Web Design 4 Tips And Examples Of Great WebStyle eLearning Using CRAP Web Design For eLearning Finding Your Type Fonts And Their Influence On Learning ,"https://elearningindustry.com/role-of-typography-in-web-design-tips-and-best-practices#:~:text=The%20primary%20goal%20of%20typography,strain%20and%20enable%20effortless%20reading.",UI/UX Design,595,1766
Color Theory for Web, About the author Alina Khazanova Product Designer  ElementorAlina is a product designer at Elementor Her passion is to bring valuable and satisfying product experience to the users Color theory is a huge field of knowledge It includes rules and guidelines about various color combinations and their uses Apart from the basic terminology and classifications such as color schemes it also taps into other considerations such as human perception cultural associations color psychology and moreLearning about color theory can help you create effective smart designs Understanding the basics is a must for any professional in the fieldThis article will guide you through the fundamentals of color theory that every web designer should know Well also show you how it works in practice Lets jump in Table of Contents Why Color Matters In Web Design A Brief Look Into Color History 7 Key Color Theory Terms You Should Know How To Apply An Effective Color Scheme How to Use Color Psychology and Meaning to Influence Emotions Things to Consider When Using Color Psychology Introducing Elementor Global Color How to Use Color Theory On Your Website Why Color Matters In Web Design The most apparent advantage of using the right color combinations in web design is that they help users understand and navigate the site Colors can improve visitors online experiences enabling them to find the information they need and respond to your Call to Action CTAHowever there are other vital benefits of understanding color When used effectively in web design it plays a significant role in branding and product messaging In fact research has found that color plays a huge role in customers decisions about purchasing a product with a staggering 926 percent of viewers putting high importance on the items visual factorsThe right color scheme can also make or break the success of a marketing campaign According to a study conducted by the University of Loyola Maryland colors can increase overall brand recognition by a staggering 80 percentThis subject fascinates many researchers worldwide who are keen to examine the effect of color on brand recognition customer satisfaction and overall product success Colors are crucial in both physical and digital environments as they help guide the users through your website and improve the overall experience Therefore every web designer needs to become fluent in color theory A Brief Look Into Color History Colors have played vital roles in art and culture for centuries However the scientific approach to color theory started in the 17th century when Sir Isaac Newton created the first color wheelAround that time colors were considered a mixture of light and dark Newton believed this approach was flawed so he examined the properties of white light in his famous prism experiment Dispersive Prism separating white light into the colors of the spectrum as discovered by Newton Newton discovered a visible spectrum of light which consisted of many colors He mapped them into classifications that became known as the color wheel His experiment also led to the discovery that all secondary colors can be created by mixing primary colors Newtons discoveries have influenced the work of artists designers and scientists up to this day 7 Key Color Theory Terms You Should Know With over 16 million colors to choose from when designing a website its easy to become overwhelmed Having such a vast array of options gives you nearinfinite possibilities Understanding the most basic color characteristics and terms can help you make effective design decisions 1 Color Wheel A color wheel is a powerful tool that can help you visualize relationships between colors in a standard schematic way The basic color wheel consists of 12 colors Primary colors form the basis of all others Although traditional theory lists these as Red Blue and Yellow recent research suggests that Magenta Cyan and Yellow are more accurate descriptors of how we perceive these colors Mixing primary colors gives you Orange Green and Purple These are known as secondary colors You can also combine primary and secondary colors to create tertiary colors such as yellowgreen bluegreen and so on 2 Color Relationships When working on a project designers often rely on fundamental color relationships also known as color schemes The four main types includeMonochrome Consisting of various tints shades and saturation of the same colorComplementary Based on two colors from opposite sides of the color wheelAnalogous Featuring three colors that are next to each other on the color wheelTriadic Using three colors that are at the points of a triangle drawn within the color wheelComplementary and analogous color schemes are the easiest to work with for many designers The first is excellent if you want to achieve a high contrast effect while the latter produces more subtle results Learn More About Website Color Schemes 3 Color Warmth In a nutshell colors can be either cool or warm Hues that contain higher amounts of yellow and red are considered warm colors They evoke a sense of passion happiness and heat but can also seem aggressive and bring feelings of danger Thats why theyre often used in alert messagesCool colors on the other hand contain higher amounts of blue and purple These colors are reminiscent of chilly climates crystal clear waters or the sky They are considered more soothing and relaxing than warm colors However they can also carry connotations of formality and sadness Adding neutral colors such as white black and gray can help you achieve a harmonious palette They can balance out your color scheme and add contrast to your designs 4 Color Systems RGB CMYK and HEX The three standard color systems are RGB Red Green Blue CMYK Cyan Magenta Yellow Black and HEXThe RGB color system is based on light All colors in this system are a combination of Red Green and Blue Each value is represented by a number from 0 black to 255 white Its easy to understand once you remember Newtons experiments the maximum value of all basic colored lights produces white light and zero color or zero light is black or darkness CMYK is used in print design These are also the standard cartridges for most color printers Unlike RGB the zero value of all colors in the CMYK system 0000 will produce white while the maximum value 100100100100 will be black However the standard black used in print is defined as 0 0 0 100Finally the HEX color system uses a sixdigit threebyte hexadecimal description of each color such as 000000 black or ffffff white Every two characters represent a color value For instance the famous Facebook blue 3b5998 includes a red hue described as 3b 5 Tints and Shades You can create tints by adding white to a color Higher levels of white will produce lighter tints Similarly if you add black you will produce a different shade The darker the shade the more black it contains You can combine tints and shades of a base color to achieve a monochromatic color scheme However it can be more difficult to make important elements stand out in such a design 6 Hue Saturation and Lightness Hue describes the degree of similarity between colors The point of reference is usually a color such as red green blue or yellow For instance when you describe a color as yellowgreen youre thinking of it as having two huesSaturation on the other hand refers to color intensity Increasing it will make the color more vibrant and darker while decreasing it will make the color appear faded and pale Finally lightness defines how bright a color is compared to pure white Changing only the lightness parameter in graphic editing software will produce different tints and shades 7 Contrast Contrast is a crucial element of any website especially when it comes to background color and text If the contrast is too low users are more likely to have trouble differentiating between elements For the sake of readability its best to use a white background and dark text color to keep pages clean and organized On the flip side you can also experiment with reversing the colors and using a light text over a dark background These two combinations have become a trend in web design with many templates and apps offering a Dark Theme or a Light Theme Contrast is vital not only for readability but content hierarchy as well A prime example is Aviaja Dance which uses high contrast elements on its website to showcase essential details Host  Build Your Website with Elementor Hosting Explore Plans Join Our Global Web Creator Community Join Now Feel the Community Spirit in Our Hub Join Now Connect With Fellow Web Creators Find Meetups How To Apply An Effective Color Scheme A wellselected color scheme will help you achieve a balanced design Colors that work well together create harmony and contribute to a pleasant User Experience UX However clashing colors can cause negative impressions with feelings of chaos and disharmony resonating from the design This is why its crucial to develop your ability to craft effective color schemes that wont put off your visitorsBelow are a few examples of different color schemes that are visually pleasing We Are OSMs excellent monochromatic color scheme uses different tints and shades of green for its About section Our own color scheme applies analogous hues for the main banner on the home page Using colors that stand next to each other on the color wheel creates a soothing gradient effect Instinct Studio boasts vibrant elements in orange and turquoise which are complementary colors These colors stand on opposite sides of the color wheel and produce a sharp contrast when used together However note that this technique can start to feel aggressive if used excessively How to Use Color Psychology and Meaning to Influence Emotions Color psychology is a fascinating field of study that examines the influence of colors on peoples behaviors and moods Different colors are often associated with particular meanings or senses they provide to a perceiving person To create a successful design you need to be aware of the color meanings and understand how a color choice can influence your users by generating a specific emotional responseMany industries benefit from color psychology especially marketing and design Wellselected colors can convince users to take action and purchase products or sign up for your mailing list In other words the knowledge of color theory can help improve your conversion rateBelow are examples of Elementorbased websites and templates that successfully employ color meaning in their designs Red Red is a strong energetic color It can symbolize many emotions and ideas both positive and negative Users can associate it with love and passion but it can also signal danger or anger Elementors Portfolio kit uses an inviting tint of red which resonates energy and confidence Red can be a bold statement color if you want to draw users immediate attention In fact many food and beverage companies use red to evoke feelings of hunger and desire Orange Orange is a warm and happy color that reminds many users of friendliness enthusiasm and motivation As seen in Suited  Booted using a bold orange background for your websites navigation screen can give off a creative and adventurous vibe Using orange as a key player in your color scheme can result in a highly memorable site that leaves visitors with positive first impressions Yellow Yellow is another warm color that symbolizes joy happiness and sunlight When used strategically on your website you can easily inject confidence and inspiration in your design Lùleka Experience has used this color particularly well strategically adding bits of yellow to create a happy feeling on its homepage That said too much yellow can tire the eyes and even create anxiety so its best to keep it as an accent color Green Green is a positive and calm color widely associated with nature ecology and renewing energy Elementors Travel kit employs beautiful dark green elements to compliment the images of greenery This color is pleasant and refreshing to look at and its often used for environmentallyconscious brands Blue Blue is a popular choice for many corporate brands as it symbolizes trust and reliability Its a calm soothing color that can easily create a sense of freshness when highly saturated Elementors Digital Agency kit is a classic example of blue used in a business context Its vibrant and energetic and evokes trust and confidence Blue can also look distant and sad when pale so its essential to strike a thoughtful balance with this color Purple Purple has long been associated with royalty luxury and wealth but its also a mysterious and magical color Combining the energy of red and blue it can be an excellent option if you want to convey a message of power and trustworthiness For example Proxy employs a stunning purple palette to create a sophisticated and mystical nighttime look Purple can be relaxing as it reminds many people of the dream sphere However a high concentration may also distract users Pink Pink is a youthful and romantic color reminding users of everlasting love Its widely associated with sensitivity and femininity and it can also be a bold statement color As seen in this striking design by the Komini agency you can use pink typography to create strong accents on your website It can take a fair bit of confidence to pull off a pinkheavy color scheme However when used wisely it makes for striking and memorable designs Black Black has many meanings and can evoke different feelings when used in combination with other colors Western cultures will sometimes associate it with evil and death while in the East it symbolizes strength and wisdom Elementors Photography kit employs a rich black background to emphasize the stunning imagery and create an elegant look Black can be tragic and mysterious or serious and modern Its excellent for website backgrounds as it sets a sharp contrast with lighter typography White White is a popular choice for modern minimalist websites as it increases readability and pairs well with any color The use of white space creates a feeling of cleanliness and light In this example Jason Blackeye uses crisp white and light grey to make his portfolio projects stand out White can inspire new ideas as it reminds users of a blank page so its not surprising its such a popular choice for a background color However too much white can also look empty and isolated Things to Consider When Using Color Psychology As seen in our examples colors can have many meanings that resonate differently with each user Therefore its crucial to have your target audience in mind when choosing color palettes for web designA users perception of color depends on factors such as their age gender culture and even religious beliefs The same color can have opposite effects in different parts of the world For instance white is considered a pure and positive color in the US and Western Europe However Asian cultures associate it with death and sadnessColor psychology is a complex subject so make sure to study your target audience and learn about their preferences Rely on the power of user testing ask the right questions and gather as much relevant data as possible so you can make informed decisions Introducing Elementor Global Color Once youve created an effective color scheme its smart to apply it across the entire website for brand consistency Manually copying and pasting HEX codes to implement your chosen palette can be timeconsuming Using tools such as the Elementor Color Picker enables you to save your preferred color combinations and apply them to your projects faster However If you want to manage a color scheme globally throughout your website our new Global Color functionality will make your life easier Global color comes with the launch of Elementor Core 30 and is an additional layer of Theme Style It helps you build your design with useful blocks that you can place where appropriate This feature is perfect for making changes to a websites color scheme without having to touch any code or CSS files all from one place within the editor How to Use Color Theory On Your Website Now weve covered the basics of color theory you should be able to implement it in your next project To recap here are the main points to considerColor choices are vital for satisfactory user experience An effective color scheme can make a massive difference to your customers and contribute to your websites successRely on color theory to come up with harmonious palettes and find the right color combinationsColor psychology is a powerful technique that can convey a variety of messages to users You should always research your target audience and test their color preferencesDont be afraid to perform additional testing to establish whether your choice of color scheme is optimal on all devicesFinally you can use the Elementor Global Color feature to ensure consistency and harmony throughout your websites design Enhance Your Web Design Skills With Color Theory Color theory is a broad subject offering insight into the science of color and the depths of human emotion While its a complex field getting a grasp on the basics can significantly boost your success as a web designerIn this article weve given you an overview of the fundamentals of color theory for web designers From basic terminology and classifications to color psychology and cultural considerations you should now have the tools to put this strategy into practiceDo you have any questions about Color Theory and how to apply it in web design Let us know in the comments section below Host  Build Your Website with Elementor Hosting Explore Plans Join Our Global Web Creator Community Join Now Feel the Community Spirit in Our Hub Join Now Connect With Fellow Web Creators Find Meetups  Dispersive Prism Yellow Primary Yellow Green Tertiary Yellow Orange Orange Green Secondary Secondary Orange Red Blue Green Tertiary Tertiary Red Blue Primary Primary Red Purple Blue Purple Purple Secondary Complementary Analogous color combinations color combinations RGB CMYK Additive Substractive Used for Web and Digital design Used for Print design Tints Add White to a color to create Tints Shades Add Black to a color to create Shades x jue Saturation 0 100 Lightness  Brightness 100  AVIAJSA  CONTACT nasoaviiadancecom Empower Web Creators Globally  Locally Apply Now Grow Your Business With Experts Network Explore Now TD  wo50  ABOUT US Our software solutions are not made for you they are made for your clients and customers stiidie  At t stud io k  ane AD Tm Alex Daniels A Freelance UXUI Designer L SB About Services Work Sustainability Resources Contact ble QD Expertence UNCONVENTIONAL TRAVEL AGENCY PROXY scut Pricing Process FAQ ay Elerentor Mork With Us KEEP THE WEB BEAUTIFUL We craft unbelievably modern easytouse Elenentor  WordPress websites Kreativ reklambyra med fokus pa Webb Vatkommen tt Komi Moat Rosdantyr i Gotaborg Wildlife Nature ROBERT ORTEGA PHOTOGRAPHY Pets WE ARE OUR CHOICES Empower Web Creators Globally  Locally Apply Now Grow Your Business With Experts Network Explore Now TD  wo50   elementor A  Create a hero layout for a 3D design studio Our Latest AI Innovation Container Layouts elementor HOSTING Elementor Hosting 6 Reasons Why to Offer It to Clients ,https://elementor.com/blog/color-theory-web-design/,UI/UX Design,1138,3199
User Authentication and Authorization, September 29 2022  Authentication Authentication vs Authorization  Whats the Difference Grant Weatherston When youre starting out in web development youll likely hear the terms authentication and authorization all the time And it doesnt help that theyre both usually abbreviated auth so its very easy to get the two confusedIn this article you will learnThe differences between authentication and authorizationHow each of these processes workExamples of authorization and authentication in everyday lifeOk lets get startedWhat is AuthenticationAuthentication is the the process of verifying the credentials a user provides with those stored in a system to prove the user is who they say they are If the credentials match then you grant access If not you deny itMethods of AuthenticationSingle Factor authenticationThis is often used as the authentication process for lower risk systems You only need a single factor to authenticate with the most common being a password so its more vulnerable to phishing attacks and key loggers In addition to this a recent article by DataProt showed that 78 of GenZ people utilize the same password for multiple services This means that if an attacker gained access to one user account they have a high probability of gaining access to others by simply using the same password2Factor AuthenticationThis method is more secure as it comprises two factors of authentication  typically something you know for example username and password  plus something you have  own for example a phone SMS or a security token For 2factor authentication you would enter a onetime SMS password sent to your device or perhaps a linked authenticator app code and provide an everchanging access codeAs you can imagine this is a lot more secure than simply entering a password or a single authentication credential You would need to know the login credentials as well as have access to the physical device for the second part2factor authentication has become very common amongst online services in recent years and with many large companies it is the default authentication method Many require that you setup 2factor auth in order to even utilize the serviceMultiFactor AuthenticationGoing one step further to make your authentication process even more secure is having 3 or more factors This form of authentication usually works on the premise ofsomething you know username  password or a username  security question and answersomething you have mobile phone sms authenticator app USB keysomething you are like a fingerprint  face recognitionFor these reasons multifactor authentication offers the most protection as you would need to compromise multiple factors and these factors are a lot more difficult to hack or replicate The downside to this method of authentication and the reason its not utilized in many average systems is it can be cumbersome to setup and maintain So the data  system youre protecting really has to justify the need for such securitySo How Much Information Do You Need to AuthenticateThis question comes up at many security architecture meetings and the answer is it dependsIt is not unusual for companies to combine various authentication methods to increase security based on the nature of applicationFor example take a banking app It contains very sensitive information and could have a huge financial and reputational impacts should it be obtained by the wrong person The bank may combine personal questions to be answered along with a customer number and complex passwordOn the other hand for a social media site you might only require a username and password which is then checked and verified before allowing accessIts all about the level of risk involved and what information someone can access once theyre in the application This helps determine the level of authentication you needIf you or your team underestimates the level of authentication your app needs you could be prosecuted for not securing the data within your system adequately So companies employee security specialists to advise on best practices and appropriate solutionsHow Does Authentication Work in the Real WorldLets take an example of a social media account You choose your favorite social media site which is hosted on a server The server will ask you to provide credentials to access the site via a sign in page Here you would type in your username and password that you used when creating the accountImage showing the authentication processThese details are then sent to the server and the authentication process begins The details you provided are verified and checked in the servers database and if they match the details on record you are authenticated Then youre provided with a form of identification data for example a cookie or Json Web Token JWT tokenSuccess You have accessed the site and are given entryYou can learn more about JWT tokens in another FreeCodeCamp article by Beau Carnes hereNext lets look at authorizationWhat is AuthorizationAuthorization is the process of verifying that youre allowed to access an area of an application or perform specific actions based on certain criteria and conditions put in place by the application You may also hear it called access control or privilege controlAuthorization can either grant or deny permission to carry out tasks or access areas of an applicationLets look at an exampleWeve gained access to the social media site but what were allowed to do there depends on what were authorized to to doIf we try to access someones profile that were not friends with theyve not accepted our connection request were not authorized to view their profile This means that we are denied permission to view their shared postsImage of authorization flowHow to Implement AuthorizationThere are many ways you can implement authorization depending on the frameworks you are usingWithin the NET framework for example you could use rolebased access control or claimsbased access controlRolebased access control is centered around the ideology that each user within your system is assigned a role These roles have predefined permissions associated with them Being granted a role means that user will automatically inherit all these permissions The roles are assigned at time of user creation and setupThe endpoint or site simply then checks if the current loggedin user has the role of Admin when attempting to access the admin areaThe downside to this approach is that sometimes users are granted too many permissions that they dont need or shouldnt haveFor example giving a user the role of Admin may mean they would have been givenAdvanced Create Edit Delete and View user privileges Whereas you may want to only give them View and Basic Create permissionsClaimsbased access control can allow for finer tuning of a specific users permissions The application can either check that the claim simply exists on a user or whether a particular value is assigned to the claimAs an example a claim called CreateUser could be given to a user and this is checked when creating a user Or you could assign a value of Advanced to the same claim and then have different actions and user interface available depending whether the value was Advanced or BasicWhats the Difference between Authentication and AuthorizationSo now that we have a better understanding of the terms lets look at a scenario you may be familiar with that involves both processesAt a dinner party with an exclusive guest list each guest is given a nickname and a secret passwordUpon arrival a security guard asks you for your nickname and secret password They then authenticate your credentials against the list they have If your credentials match you are handed an envelope showing youve been allowed inOnce inside you are allowed to access the party and public areas of the venue as these require no authorization everyone has the permission to enjoy the party However you then want to visit the VIP areaAs you approach another security personnel asks to open your envelope your permissions and roles They take a look but unfortunately you do not have the VIP role and therefore are not authorized to accessPut as simply as possible authentication verifies the identity of a user or service allowing access whereas authorization determines what they can do once theyre inWhy Should You Implement Both Authentication and AuthorizationAs you can see although authentication and authorization are very different each plays an integral part in the security and integrity of the application or systemThese processes go hand in hand and without one the other is kind of meaningless If you can gain access to the Admin area but do whatever you want once in there it could lead to big problemsOn the other hand you cant authorize individuals without knowing who they are Which is why authentication always comes before authorizationClosing ThoughtsI hope this has been insightful and you now have a clearer understanding of the differences between Authorization and Authentication and how to use themRememberAuthenticate  Verifies the identity of a user or processAuthorize  Determines if the user  system has permission to use a resource or carry out an actionFeel free to get in touch via Twitter if you wish to discuss this article in more detail gweaths ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT Grant Weatherston Consultant and Application Development Specialist with over 9years of experience within the development industry If you read this far thank the author to show them you care Say Thanks Learn to code for free freeCodeCamps open source curriculum has helped more than 40000 people get jobs as developers Get started ADVERTISEMENT Authorisation Authentication Whats The Difference GWeaths freeCodeCamp 4 Username gWeaths Password    1 i t Lz _ client accesses server F Server server informs the client to retum credentials Verify the provicledt credentials Server against user store user submits username and  _ password to server J Zz a  Server   Lo i  O  ys Device server sends identification data cookie token etc  Server every subsequent request the user will send this identification token as pact of the request  Server User is authorised to access Admin Area f       4 es       Ills    _ _v _   User tries to  soe  Retrieve users permissions Compare users permissions access admin area 7 claims  rol  tees claims  roles with required permissions User is not authorised No Entry ,https://www.freecodecamp.org/news/whats-the-difference-between-authentication-and-authorisation/,Security,668,1672
File Upload and Management, Media Guides Image Effects Video effects Image formats Wordpress Plugin AI Marketing Videos Live Streaming Video Video Formats UserGenerated Content ECommerce Platform Web Performance Digital Asset Management FrontEnd Development Bulk Image Resize Responsive Images Automatic Image Cropping FrontEnd Development 6 Ways to Stretch a Background Image with CSS Auto Cropping for Images and Video Features  Best Practices FLAC vs WAV 4 Key Differences and How to Choose Converting Audio to Video A Practical Guide FLAC vs AIFF 5 Key Differences and How to Choose FLAC vs MQA 5 Key Differences and How to Choose Converting WAV Files To OGG The Ultimate Guide On Converting OGG Files To WAV Sound Choices FLAC vs MP3 AAC vs MP3  The Future of Audio Files All about AIFF and how it compares to WAV and MP3 Integrating Cloudinary with Netlify Integrating Cloudinary with Svelte and SvelteKit Integrating Cloudinary with Nuxt Integrating Cloudinary with Gatsby File Upload as a Service How It Works and 5 Leading Solutions Native Mobile App Development Creative Uses for CSS Inner Border and 3 Ways to Set a Border Integrating Cloudinary with Nextjs FrontEnd Development The Complete Guide File Upload as a Service How It Works and 5 Leading Solutions What Is File Upload File upload refers to the process of transferring digital files from a local device to a remote server or storage location using a network connection It allows users to share and distribute files such as documents images videos and other multimedia content across the internet File uploads can be initiated through various methods such as web browsers mobile apps or FTP File Transfer Protocol clients The uploaded files can then be accessed and downloaded by authorized users from the remote server or storage location In this article What Are Cloud Storage Services Adding File Upload to Your Website DIY Approach Cloud Storage Cloud Services That Provide File Upload as a Service Cloudinary Dropbox Amazon S3 Microsoft Azure Blob Storage Google Cloud Storage Additional Cloud Storage Services and Tools What Are Cloud Storage Services Cloud storage services are a type of online storage solution that enables users to store and access their digital files and data on remote servers maintained by a thirdparty provider Major cloud storage services include Dropbox Google Drive Microsoft OneDrive Amazon S3 and iCloud These services offer various use cases such as file sharing and collaboration nearline storage backup and disaster recovery Users can share files with others collaborate in realtime store frequently accessed data for quick retrieval backup critical data for data protection and recover data in case of an unexpected disaster or loss Adding File Upload to Your Website Do it Yourself DIY Approach The DIY approach to adding file upload functionality to your website involves creating a custom solution using frontend and backend technologies Heres a breakdown of how this approach works Frontend clientside Design a user interface with an HTML form containing a file input field This allows users to browse and select files from their local devices to upload Optionally use JavaScript for clientside validation such as checking file types or sizes before the file is uploaded to the server When the user submits the form the selected file and any additional form data are sent to the server for processing Backend serverside Choose a serverside programming language eg PHP Nodejs Python or Ruby to handle the file upload process Create a serverside script that receives the uploaded file and any additional form data from the client Validate the received file on the serverside checking for file types sizes and any other security measures necessary to ensure only valid files are accepted Process the uploaded file as needed which might include resizing images generating thumbnails or converting file formats Save the file to a designated storage location on your server or another storage system such as a database or cloud storage service Store any additional form data eg title description or tags in a database or other data storage system along with a reference to the uploaded files location Return a response to the client indicating the success or failure of the file upload process This might include displaying a confirmation message or providing a link to the uploaded file Learn more in our detailed guides to PHP file upload Nodejs file upload Data storage and retrieval Depending on your requirements you may store the uploaded files on your servers file system in a database or using a cloud storage service When users request to view or download an uploaded file your serverside script retrieves the file from its storage location and serves it to the client By following the DIY approach you have complete control over the file upload process allowing for customization and integration with your existing website architecture and backend systems However this approach requires development effort technical expertise and ongoing maintenance to ensure the security reliability and scalability of the file upload feature Cloud Storage When adding file upload functionality to your website using a cloud storage approach you leverage thirdparty cloud storage services to handle file storage and processing Heres a breakdown of how this approach works Frontend Some cloud storage services provide readymade widgets you can add to your site with no development effort If not you will need to go through the following steps Design a user interface with an HTML form containing a file input field allowing users to browse and select files from their local devices to upload Optionally use JavaScript for clientside validation such as checking file types or sizes before the file is uploaded to the cloud storage service Integrate the cloud storage providers API or SDK into your frontend code which will enable direct uploading of files from the client to the cloud storage service This bypasses the need to send files to your server first reducing server load and bandwidth usage Backend If required create a serverside script to handle any additional form data such as title description or tags and store this information in a database or other data storage system along with a reference to the uploaded files location in the cloud storage service Use the cloud storage providers API to interact with uploaded files such as retrieving file metadata generating download URLs or deleting files Data storage and retrieval The cloud storage service stores the uploaded files handling the file storage and processing tasks on your behalf This ensures that your files are stored securely and reliably with the ability to scale as your storage needs grow When users request to view or download an uploaded file your serverside script or frontend code depending on the cloud storage providers API capabilities retrieves the files URL from the cloud storage service and serves it to the client By using the cloud storage approach you can reduce the development effort required to implement file upload functionality and leverage the scalability security and reliability features provided by the cloud storage service However note that this approach might offer less customization than a DIY solution Top 5 Cloud Services That Provide File Upload as a Service Cloudinary Cloudinary is a cloudbased media management platform that provides file upload storage and delivery services for images videos and other digital assets It simplifies the process of handling media files by offering onthefly manipulation optimization and transformation capabilities through a dynamic URL structure Cloudinary provides a prebuilt file upload widget you can easily add to your site Developers can also integrate Cloudinary into web and mobile applications using its APIs SDKs and prebuilt UI components Cloudinarys features include automatic format selection responsive image breakpoints face detection and contentaware cropping which help optimize the visual quality and performance of media assets across various devices and network conditions It also supports secure uploads access controls and integration with popular content management systems and eCommerce platforms Learn more about file upload with Cloudinary Dropbox Dropbox is a cloudbased file storage and synchronization service that allows users to store share and access their files from anywhere with an internet connection Dropbox can be used as a file upload service for your website or application by leveraging its APIs and SDKs This allows users to upload files directly to your Dropbox account where they can be stored managed and shared Amazon S3 Amazon S3 is a highly scalable durable and secure object storage service offered by Amazon Web Services AWS It enables developers to store and retrieve files using a REST API or AWS SDKs in various programming languages S3 provides features like versioning lifecycle policies serverside encryption and access control through bucket policies and IAM roles S3 supports multiple storage classes including S3 Standard S3 IntelligentTiering S3 One ZoneInfrequent Access and S3 Glacier to optimize costs based on the access patterns and durability requirements of the stored data Microsoft Azure Blob Storage Azure Blob Storage is a scalable object storage service from Microsoft that allows developers to store and manage unstructured data such as text binary data or images Blob Storage is suitable for various scenarios including serving images or documents to a website storing large files for distributed access and streaming video or audio It offers features like automatic data tiering with hot cool and archive storage tiers access control through Shared Access Signatures SAS or Azure Active Directory and integration with other Azure services such as Azure Functions and Azure CDN Blob Storage also supports snapshots soft delete and lifecycle management to optimize data storage and retention Google Cloud Storage Google Cloud Storage is a versatile object storage service offered by Google Cloud Platform GCP It allows developers to store and manage files in the cloud using REST APIs and Google Cloud SDKs Google Cloud Storage provides finegrained access controls serverside encryption and integration with other Google Cloud services such as Cloud Functions and BigQuery Users can choose from four storage classes  Standard Nearline Coldline and Archive  based on their data access frequency and storage duration needs Google Cloud Storage also supports object versioning lifecycle management and data transfer from other cloud providers or onpremises systems Additional Cloud Storage Services and Tools Filescom A cloud storage service offering secure file sharing and collaboration features ExaVault A service focusing on business file sharing with robust FTP and SFTP support Filestack A platform that provides developers with tools for file uploading transformation and delivery Transload Another tool that assists in uploading and processing files useful for web and app developers Incorporating these services and tools can offer additional flexibility and functionality to meet diverse file management needs Conclusion In conclusion file upload as a service has become an essential aspect of digital asset management collaboration and data storage By employing either the DIY approach or leveraging thirdparty cloud storage services like Cloudinary Dropbox Amazon S3 Microsoft Azure Blob Storage or Google Cloud Storage developers can add file upload functionality to their websites and applications with varying levels of customization and complexity Cloud storage services can provide increased efficiency improved security and reduced infrastructure and maintenance costs while providing users with a seamless and reliable file sharing experience Back to top ,https://cloudinary.com/guides/front-end-development/file-upload-as-a-service-how-it-works-and-5-leading-solutions,Back-End Development,607,1847
Custom Web Components,Using custom elementsOne of the key features of web components is the ability to create custom elements that is HTML elements whose behavior is defined by the web developer that extend the set of elements available in the browser This article introduces custom elements and walks through some examplesTypes of custom elementThere are two types of custom element Customized builtin elements inherit from standard HTML elements such as HTMLImageElement or HTMLParagraphElement Their implementation customizes the behavior of the standard element Autonomous custom elements inherit from the HTML element base class HTMLElement You have to implement their behavior from scratch Implementing a custom elementA custom element is implemented as a class which extends HTMLElement in the case of autonomous elements or the interface you want to customize in the case of customized builtin elements Heres the implementation of a minimal custom element that customizes the p element jsclass WordCount extends HTMLParagraphElement  constructor  super   Element functionality written in here  Heres the implementation of a minimal autonomous custom element jsclass PopupInfo extends HTMLElement  constructor  super   Element functionality written in here  In the class constructor you can set up initial state and default values register event listeners and perhaps create a shadow root At this point you should not inspect the elements attributes or children or add new attributes or children See Requirements for custom element constructors and reactions for the complete set of requirementsCustom element lifecycle callbacksOnce your custom element is registered the browser will call certain methods of your class when code in the page interacts with your custom element in certain ways By providing an implementation of these methods which the specification calls lifecycle callbacks you can run code in response to these events Custom element lifecycle callbacks include connectedCallback called each time the element is added to the document The specification recommends that as far as possible developers should implement custom element setup in this callback rather than the constructor disconnectedCallback called each time the element is removed from the document adoptedCallback called each time the element is moved to a new document attributeChangedCallback called when attributes are changed added removed or replaced See Responding to attribute changes for more details about this callback Heres a minimal custom element that logs these lifecycle events js Create a class for the element class MyCustomElement extends HTMLElement  static observedAttributes  color size constructor   Always call super first in constructor super  connectedCallback  consolelogCustom element added to page  disconnectedCallback  consolelogCustom element removed from page  adoptedCallback  consolelogCustom element moved to new page  attributeChangedCallbackname oldValue newValue  consolelogAttribute name has changed   customElementsdefinemycustomelement MyCustomElement Registering a custom elementTo make a custom element available in a page call the define method of WindowcustomElements The define method takes the following arguments name The name of the element This must start with a lowercase letter contain a hyphen and satisfy certain other rules listed in the specifications definition of a valid name constructor The custom elements constructor function options Only included for customized builtin elements this is an object containing a single property extends which is a string naming the builtin element to extend For example this code registers the WordCount customized builtin element jscustomElementsdefinewordcount WordCount  extends p  This code registers the PopupInfo autonomous custom element jscustomElementsdefinepopupinfo PopupInfo Using a custom elementOnce youve defined and registered a custom element you can use it in your code To use a customized builtin element use the builtin element but with the custom name as the value of the is attribute htmlp iswordcountp To use an autonomous custom element use the custom name just like a builtin HTML element htmlpopupinfo  content of the element  popupinfo Responding to attribute changesLike builtin elements custom elements can use HTML attributes to configure the elements behavior To use attributes effectively an element has to be able to respond to changes in an attributes value To do this a custom element needs to add the following members to the class that implements the custom element A static property named observedAttributes This must be an array containing the names of all attributes for which the element needs change notifications An implementation of the attributeChangedCallback lifecycle callback The attributeChangedCallback callback is then called whenever an attribute whose name is listed in the elements observedAttributes property is added modified removed or replaced The callback is passed three arguments The name of the attribute which changed The attributes old value The attributes new value For example this autonomous element will observe a size attribute and log the old and new values when they change js Create a class for the element class MyCustomElement extends HTMLElement  static observedAttributes  size constructor  super  attributeChangedCallbackname oldValue newValue  consolelog Attribute name has changed from oldValue to newValue    customElementsdefinemycustomelement MyCustomElement Note that if the elements HTML declaration includes an observed attribute then attributeChangedCallback will be called after the attribute is initialized when the elements declaration is parsed for the first time So in the following example attributeChangedCallback will be called when the DOM is parsed even if the attribute is never changed again htmlmycustomelement size100mycustomelement For a complete example showing the use of attributeChangedCallback see Lifecycle callbacks in this pageCustom states and custom state pseudoclass CSS selectors Built in HTML elements can have different states such as hover disabled and read only Some of these states can be set as attributes using HTML or JavaScript while others are internal and cannot Whether external or internal commonly these states have corresponding CSS pseudoclasses that can be used to select and style the element when it is in a particular state Autonomous custom elements but not elements based on builtin elements also allow you to define states and select against them using custom state pseudoclasses The code below shows how this works using the example of an autonomous custom element that has an internal state collapsed The collapsed state is represented as a boolean property with setter and getter methods that is not visible outside of the element To make this state selectable in CSS the custom element first calls HTMLElementattachInternals in its constructor in order to attach an ElementInternals object which in turn provides access to a CustomStateSet through the ElementInternalsstates property The setter for the internal collapsed state adds the dashed identifier hidden to the CustomStateSet when the state is true and removes it when the state is false The dashed identifier is just a string preceded by two dashes in this case we called it hidden but we could have just as easily called it collapsed jsclass MyCustomElement extends HTMLElement  constructor  super this_internals  thisattachInternals  get collapsed  return this_internalsstateshashidden  set collapsedflag  if flag   Existence of identifier corresponds to true this_internalsstatesaddhidden  else   Absence of identifier corresponds to false this_internalsstatesdeletehidden     Register the custom element customElementsdefinemycustomelement MyCustomElement After adding mycustomelement to the HTML we can use the dashed identifier added to the CustomStateSet prefixed with  as a custom state pseudoclass for selecting the element state For example below we select on the hidden state being true and hence the elements collapsed state using the hidden selector and remove the border cssmycustomelement  border dashed red  mycustomelementhidden  border none  There is are more complete live example in CustomStateSetExamplesIn the rest of this guide well look at a few example custom elements You can find the source for all these examples and more in the webcomponentsexamples repository and you can see them all live at httpsmdngithubiowebcomponentsexamplesAn autonomous custom elementFirst well look at an autonomous custom element The popupinfo custom element takes an image icon and a text string as attributes and embeds the icon into the page When the icon is focused it displays the text in a pop up information box to provide further incontext information See the example running live See the source code To begin with the JavaScript file defines a class called PopupInfo which extends the HTMLElement class js Create a class for the element class PopupInfo extends HTMLElement  constructor   Always call super first in constructor super  connectedCallback   Create a shadow root const shadow  thisattachShadow mode open   Create spans const wrapper  documentcreateElementspan wrappersetAttributeclass wrapper const icon  documentcreateElementspan iconsetAttributeclass icon iconsetAttributetabindex 0 const info  documentcreateElementspan infosetAttributeclass info  Take attribute content and put it inside the info span const text  thisgetAttributedatatext infotextContent  text  Insert icon let imgUrl if thishasAttributeimg  imgUrl  thisgetAttributeimg  else  imgUrl  imgdefaultpng  const img  documentcreateElementimg imgsrc  imgUrl iconappendChildimg  Create some CSS to apply to the shadow dom const style  documentcreateElementstyle consolelogstyleisConnected styletextContent   wrapper  position relative  info  fontsize 08rem width 200px display inlineblock border 1px solid black padding 10px background white borderradius 10px opacity 0 transition 06s all position absolute bottom 20px left 10px zindex 3  img  width 12rem  iconhover  info iconfocus  info  opacity 1    Attach the created elements to the shadow dom shadowappendChildstyle consolelogstyleisConnected shadowappendChildwrapper wrapperappendChildicon wrapperappendChildinfo   The class definition contains the constructor for the class which always starts by calling super so that the correct prototype chain is established Inside the method connectedCallback we define all the functionality the element will have when the element is connected to the DOM In this case we attach a shadow root to the custom element use some DOM manipulation to create the elements internal shadow DOM structure  which is then attached to the shadow root  and finally attach some CSS to the shadow root to style it We dont do this work in the constructor because an elements attributes are unavailable until it is connected to the DOM Finally we register our custom element in the CustomElementRegistry using the define method we mentioned earlier  in the parameters we specify the element name and then the class name that defines its functionality jscustomElementsdefinepopupinfo PopupInfo It is now available to use on our page Over in our HTML we use it like so htmlpopupinfo imgimgaltpng datatextYour card validation code CVC is an extra security feature  it is the last 3 or 4 numbers on the back of your cardpopupinfo Referencing external stylesIn the above example we apply styles to the shadow DOM using a style element but you can reference an external stylesheet from a link element instead In this example well modify the popupinfo custom element to use an external stylesheet See the example running live See the source code Heres the class definition js Create a class for the element class PopupInfo extends HTMLElement  constructor   Always call super first in constructor super  connectedCallback   Create a shadow root const shadow  thisattachShadow mode open   Create spans const wrapper  documentcreateElementspan wrappersetAttributeclass wrapper const icon  documentcreateElementspan iconsetAttributeclass icon iconsetAttributetabindex 0 const info  documentcreateElementspan infosetAttributeclass info  Take attribute content and put it inside the info span const text  thisgetAttributedatatext infotextContent  text  Insert icon let imgUrl if thishasAttributeimg  imgUrl  thisgetAttributeimg  else  imgUrl  imgdefaultpng  const img  documentcreateElementimg imgsrc  imgUrl iconappendChildimg  Apply external styles to the shadow dom const linkElem  documentcreateElementlink linkElemsetAttributerel stylesheet linkElemsetAttributehref stylecss  Attach the created elements to the shadow dom shadowappendChildlinkElem shadowappendChildwrapper wrapperappendChildicon wrapperappendChildinfo   Its just like the original popupinfo example except that we link to an external stylesheet using a link element which we add to the shadow DOM Note that link elements do not block paint of the shadow root so there may be a flash of unstyled content FOUC while the stylesheet loads Many modern browsers implement an optimization for style tags either cloned from a common node or that have identical text to allow them to share a single backing stylesheet With this optimization the performance of external and internal styles should be similarCustomized builtin elementsNow lets have a look at a customized built in element example This example extends the builtin ul element to support expanding and collapsing the list items See the example running live See the source code First of all we define our elements class js Create a class for the element class ExpandingList extends HTMLUListElement  constructor   Always call super first in constructor  Return value from super is a reference to this element self  super  connectedCallback   Get ul and li elements that are a child of this custom ul element  li elements can be containers if they have uls within them const uls  ArrayfromselfquerySelectorAllul const lis  ArrayfromselfquerySelectorAllli  Hide all child uls  These lists will be shown when the user clicks a higher level container ulsforEachul   ulstyledisplay  none   Look through each li element in the ul lisforEachli    If this li has a ul as a child decorate it and add a click handler if liquerySelectorAllullength  0   Add an attribute which can be used by the style  to show an open or closed icon lisetAttributeclass closed  Wrap the li elements text in a new span element  so we can assign style and event handlers to the span const childText  lichildNodes0 const newSpan  documentcreateElementspan  Copy text from li to span set cursor style newSpantextContent  childTexttextContent newSpanstylecursor  pointer  Add click handler to this span newSpanaddEventListenerclick e    next sibling to the span should be the ul const nextul  etargetnextElementSibling  Toggle visible state and update class attribute on ul if nextulstyledisplay  block  nextulstyledisplay  none nextulparentNodesetAttributeclass closed  else  nextulstyledisplay  block nextulparentNodesetAttributeclass open    Add the span and remove the bare text node from the li childTextparentNodeinsertBeforenewSpan childText childTextparentNoderemoveChildchildText     Note that this time we extend HTMLUListElement rather than HTMLElement This means that we get the default behavior of a list and only have to implement our own customizations As before most of the code is in the connectedCallback lifecycle callback Next we register the element using the define method as before except that this time it also includes an options object that details what element our custom element inherits from jscustomElementsdefineexpandinglist ExpandingList  extends ul  Using the builtin element in a web document also looks somewhat different htmlul isexpandinglist  ul You use a ul element as normal but specify the name of the custom element inside the is attribute Note that in this case we must ensure that the script defining our custom element is executed after the DOM has been fully parsed because connectedCallback is called as soon as the expanding list is added to the DOM and at that point its children have not been added yet so the querySelectorAll calls will not find any items One way to ensure this is to add the defer attribute to the line that includes the script htmlscript srcmainjs deferscript Lifecycle callbacksSo far weve seen only one lifecycle callback in action connectedCallback In the final example customsquare well see some of the others The customsquare autonomous custom element draws a square whose size and color are determined by two attributes named size and color See the example running live See the source code In the class constructor we attach a shadow DOM to the element then attach empty div and style elements to the shadow root jsconstructor   Always call super first in constructor super const shadow  thisattachShadow mode open  const div  documentcreateElementdiv const style  documentcreateElementstyle shadowappendChildstyle shadowappendChilddiv  The key function in this example is updateStyle  this takes an element gets its shadow root finds its style element and adds width height and backgroundcolor to the style jsfunction updateStyleelem  const shadow  elemshadowRoot shadowquerySelectorstyletextContent   div  width elemgetAttributesizepx height elemgetAttributesizepx backgroundcolor elemgetAttributecolor    The actual updates are all handled by the lifecycle callbacks The connectedCallback runs each time the element is added to the DOM  here we run the updateStyle function to make sure the square is styled as defined in its attributes jsconnectedCallback  consolelogCustom square element added to page updateStylethis  The disconnectedCallback and adoptedCallback callbacks log messages to the console to inform us when the element is either removed from the DOM or moved to a different page jsdisconnectedCallback  consolelogCustom square element removed from page  adoptedCallback  consolelogCustom square element moved to new page  The attributeChangedCallback callback is run whenever one of the elements attributes is changed in some way As you can see from its parameters it is possible to act on attributes individually looking at their name and old and new attribute values In this case however we are just running the updateStyle function again to make sure that the squares style is updated as per the new values jsattributeChangedCallbackname oldValue newValue  consolelogCustom square element attributes changed updateStylethis  Note that to get the attributeChangedCallback callback to fire when an attribute changes you have to observe the attributes This is done by specifying a static get observedAttributes method inside the custom element class  this should return an array containing the names of the attributes you want to observe jsstatic get observedAttributes  return color size  Found a content problem with this pageEdit the page on GitHubReport the content issueView the source on GitHubWant to get more involved Learn how to contributeThis page was last modified on Dec 26 2023 by MDN contributorsclass WordCount extends HTMLParagraphElement  constructor  super   Element functionality written in here  class PopupInfo extends HTMLElement  constructor  super   Element functionality written in here   Create a class for the element class MyCustomElement extends HTMLElement  static observedAttributes  color size constructor   Always call super first in constructor super  connectedCallback  consolelogCustom element added to page  disconnectedCallback  consolelogCustom element removed from page  adoptedCallback  consolelogCustom element moved to new page  attributeChangedCallbackname oldValue newValue  consolelogAttribute name has changed   customElementsdefinemycustomelement MyCustomElement customElementsdefinewordcount WordCount  extends p  customElementsdefinepopupinfo PopupInfo p iswordcountp popupinfo  content of the element  popupinfo  Create a class for the element class MyCustomElement extends HTMLElement  static observedAttributes  size constructor  super  attributeChangedCallbackname oldValue newValue  consolelog Attribute name has changed from oldValue to newValue    customElementsdefinemycustomelement MyCustomElement mycustomelement size100mycustomelement class MyCustomElement extends HTMLElement  constructor  super this_internals  thisattachInternals  get collapsed  return this_internalsstateshashidden  set collapsedflag  if flag   Existence of identifier corresponds to true this_internalsstatesaddhidden  else   Absence of identifier corresponds to false this_internalsstatesdeletehidden     Register the custom element customElementsdefinemycustomelement MyCustomElement mycustomelement  border dashed red  mycustomelementhidden  border none   Create a class for the element class PopupInfo extends HTMLElement  constructor   Always call super first in constructor super  connectedCallback   Create a shadow root const shadow  thisattachShadow mode open   Create spans const wrapper  documentcreateElementspan wrappersetAttributeclass wrapper const icon  documentcreateElementspan iconsetAttributeclass icon iconsetAttributetabindex 0 const info  documentcreateElementspan infosetAttributeclass info  Take attribute content and put it inside the info span const text  thisgetAttributedatatext infotextContent  text  Insert icon let imgUrl if thishasAttributeimg  imgUrl  thisgetAttributeimg  else  imgUrl  imgdefaultpng  const img  documentcreateElementimg imgsrc  imgUrl iconappendChildimg  Create some CSS to apply to the shadow dom const style  documentcreateElementstyle consolelogstyleisConnected styletextContent   wrapper  position relative  info  fontsize 08rem width 200px display inlineblock border 1px solid black padding 10px background white borderradius 10px opacity 0 transition 06s all position absolute bottom 20px left 10px zindex 3  img  width 12rem  iconhover  info iconfocus  info  opacity 1    Attach the created elements to the shadow dom shadowappendChildstyle consolelogstyleisConnected shadowappendChildwrapper wrapperappendChildicon wrapperappendChildinfo   customElementsdefinepopupinfo PopupInfo popupinfo imgimgaltpng datatextYour card validation code CVC is an extra security feature  it is the last 3 or 4 numbers on the back of your cardpopupinfo  Create a class for the element class PopupInfo extends HTMLElement  constructor   Always call super first in constructor super  connectedCallback   Create a shadow root const shadow  thisattachShadow mode open   Create spans const wrapper  documentcreateElementspan wrappersetAttributeclass wrapper const icon  documentcreateElementspan iconsetAttributeclass icon iconsetAttributetabindex 0 const info  documentcreateElementspan infosetAttributeclass info  Take attribute content and put it inside the info span const text  thisgetAttributedatatext infotextContent  text  Insert icon let imgUrl if thishasAttributeimg  imgUrl  thisgetAttributeimg  else  imgUrl  imgdefaultpng  const img  documentcreateElementimg imgsrc  imgUrl iconappendChildimg  Apply external styles to the shadow dom const linkElem  documentcreateElementlink linkElemsetAttributerel stylesheet linkElemsetAttributehref stylecss  Attach the created elements to the shadow dom shadowappendChildlinkElem shadowappendChildwrapper wrapperappendChildicon wrapperappendChildinfo    Create a class for the element class ExpandingList extends HTMLUListElement  constructor   Always call super first in constructor  Return value from super is a reference to this element self  super  connectedCallback   Get ul and li elements that are a child of this custom ul element  li elements can be containers if they have uls within them const uls  ArrayfromselfquerySelectorAllul const lis  ArrayfromselfquerySelectorAllli  Hide all child uls  These lists will be shown when the user clicks a higher level container ulsforEachul   ulstyledisplay  none   Look through each li element in the ul lisforEachli    If this li has a ul as a child decorate it and add a click handler if liquerySelectorAllullength  0   Add an attribute which can be used by the style  to show an open or closed icon lisetAttributeclass closed  Wrap the li elements text in a new span element  so we can assign style and event handlers to the span const childText  lichildNodes0 const newSpan  documentcreateElementspan  Copy text from li to span set cursor style newSpantextContent  childTexttextContent newSpanstylecursor  pointer  Add click handler to this span newSpanaddEventListenerclick e    next sibling to the span should be the ul const nextul  etargetnextElementSibling  Toggle visible state and update class attribute on ul if nextulstyledisplay  block  nextulstyledisplay  none nextulparentNodesetAttributeclass closed  else  nextulstyledisplay  block nextulparentNodesetAttributeclass open    Add the span and remove the bare text node from the li childTextparentNodeinsertBeforenewSpan childText childTextparentNoderemoveChildchildText     customElementsdefineexpandinglist ExpandingList  extends ul  ul isexpandinglist  ul script srcmainjs deferscript constructor   Always call super first in constructor super const shadow  thisattachShadow mode open  const div  documentcreateElementdiv const style  documentcreateElementstyle shadowappendChildstyle shadowappendChilddiv  function updateStyleelem  const shadow  elemshadowRoot shadowquerySelectorstyletextContent   div  width elemgetAttributesizepx height elemgetAttributesizepx backgroundcolor elemgetAttributecolor    connectedCallback  consolelogCustom square element added to page updateStylethis  disconnectedCallback  consolelogCustom square element removed from page  adoptedCallback  consolelogCustom square element moved to new page  attributeChangedCallbackname oldValue newValue  consolelogCustom square element attributes changed updateStylethis  static get observedAttributes  return color size  ,https://developer.mozilla.org/en-US/docs/Web/API/Web_components/Using_custom_elements,Front-End Development,741,3493
GraphQL, From Wikipedia the free encyclopedia Data query language developed by Facebook This article relies excessively on references to primary sources Please improve this article by adding secondary or tertiary sources Find sources GraphQL  news  newspapers  books  scholar  JSTOR March 2023 Learn how and when to remove this template message GraphQLOriginal authorsFacebookDevelopersOpen sourceInitial releaseSeptember 14 2015 20150914Stable releaseOctober 2021 2021101 RepositorygithubcomgraphqlgraphqlspecWritten inImplementations in Java JavaScript Ruby Scala othersWebsitegraphqlorg GraphQL is an opensource data query and manipulation language for APIs and a query runtime engine GraphQL enables declarative data fetching where a client can specify exactly what data it needs from an API Instead of multiple endpoints that return separate data a GraphQL server exposes a single endpoint and responds with precisely the data a client asked for2 Because a GraphQL server can fetch from separate data sources and present the data in a unified graph it isnt tied to any specific database or storage engine Historyedit Facebook started GraphQL development in 2012 and released it as open source in 20153 In 2018 GraphQL was moved to the newly established GraphQL Foundation hosted by the nonprofit Linux Foundation45 On 9 February 2018 the GraphQL Schema Definition Language SDL became part of the specification6 Many popular public APIs adopted GraphQL as the default way to access them These include public APIs of Facebook GitHub Yelp Shopify and Google Directions API7 Designedit GraphQL supports reading writing mutating and subscribing to changes to data realtime updates  commonly implemented using WebSockets8 A GraphQL service is created by defining types with fields then providing functions to resolve the data for each field The types and fields make up what is known as the schema definition The functions that retrieve and map the data are called resolvers9 After being validated against the schema a GraphQL query is executed by the server The server returns a result that mirrors the shape of the original query typically as JSON10 Type systemedit The root type of a GraphQL schema Query by default contains all of the fields that can be queried Other types define the objects and fields that the GraphQL server can return There are several base types called scalars to represent things like strings numbers and IDs Fields are defined as nullable by default and a trailing exclamation mark can be used to make a field nonnullable required A field can be defined as a list by wrapping the fields type in square brackets for example authors String11type Query  currentUser User  type User  id ID name String  Queriesedit A GraphQL query defines the exact shape of the data needed by the client query CurrentUser  currentUser  name age   Once validated and executed by the GraphQL server the data is returned in the same shape currentUser  name Yash Bhavsar age23   Mutationsedit A GraphQL mutation allows for data to be created updated or deleted Mutations generally contain variables which allow data to be passed into the server from the client The mutation also defines the shape of the data that will be returned to the client after the operation is complete mutation CreateUsername String age Int  createUseruserName name age age  name age   The variables are passed as an object with fields that match the variable names in the mutation name Han Solo age 42  Once the operation is complete the GraphQL server will return data matching the shape defined by the mutation data  createUser  name Han Solo age 42    Subscriptionsedit GraphQL also supports live updates sent from the server to client in an operation called a subscription Again the client defines the shape of the data that it needs whenever an update is madesubscription  newPerson  name age   When a mutation is made through the GraphQL server that updates the associated field data is sent to all subscribed clients in the format setup through the subscription newPerson  name Jane age 23   Comparison to other query languagesedit GraphQL does not provide a fullfledged graph query language such as SPARQL or even in dialects of SQL that support transitive closure For example a GraphQL interface that reports the parents of an individual cannot return in a single query the set of all their ancestors Testingedit GraphQL APIs can be tested manually or with automated tools issuing GraphQL requests and verifying the correctness of the results Automatic test generation is also possible12 New requests may be produced through searchbased techniques due to a typed schema and introspection capabilities13 Some of the software tools used for testing GraphQL implementations include Postman GraphiQL Apollo Studio GraphQL Editor and Step CI14 See alsoedit Query by Example OpenAPI Specification Microservices The Graph Referencesedit  GraphQL October 2021 Release Notes GitHub  Learn GraphQL Fundamentals with Fullstack Tutorial wwwhowtographqlcom Retrieved 25 April 2023  GraphQL A data query language 14 September 2015  Facebooks GraphQL gets its own opensource foundation TechCrunch Retrieved 7 November 2018  The Linux Foundation Announces Intent to Form New Foundation to Support GraphQL  The Linux Foundation The Linux Foundation 6 November 2018 Retrieved 17 March 2023  GraphQL SDL included in Github repository GitHub  Popular public APIs that use GraphQL Frontendengdev  GraphQL facebookgithubio Facebook Archived from the original on 18 July 2018 Retrieved 4 July 2018  Introduction to GraphQL  GraphQL graphqlorg Retrieved 25 April 2023  Execution  GraphQL graphqlorg Retrieved 25 April 2023  GraphQL specgraphqlorg Retrieved 25 April 2023  Vargas D M Blanco A F Vidaurre A C Alcocer J P S Torres M M Bergel A Ducasse S 2018 Deviation Testing A Test Case Generation Technique for GraphQL APIs 11th International Workshop on Smalltalk Technologies IWST 19  Karlsson Stefan Causevic Adnan Sundmark Daniel May 2021 Automatic Propertybased Testing of GraphQL APIs 2021 IEEEACM International Conference on Automation of Software Test AST Madrid Spain IEEE pp 110 arXiv201207380 doi101109AST52587202100009 ISBN 9781665435673 S2CID 229156477  GraphQL IDE Monorepo GraphQL 25 April 2023 retrieved 25 April 2023The Apollo Studio Explorer Apollo Docs Retrieved 25 April 2023GraphQL Editor API Console GraphQL Editor Docs Retrieved 2 September 2023Testing GraphQL APIs Step CI Documentation Retrieved 8 January 2023 External linksedit Official website GraphQL The Documentary on YouTube vteQuery languagesIn current use QL ALPHA CQL Cypher DAX DMX Datalog GraphQL Gremlin ISBL LDAP LINQ MQL MDX OQL OCL QUEL SMARTS SPARQL SQL XQuery XPath YQL Proprietary YQL LINQ Superseded CODASYL vteComputer scienceNote This template roughly follows the 2012 ACM Computing Classification SystemHardware Printed circuit board Peripheral Integrated circuit Very Large Scale Integration Systems on Chip SoCs Energy consumption Green computing Electronic design automation Hardware acceleration Computer systems organization Computer architecture Embedded system Realtime computing Dependability Networks Network architecture Network protocol Network components Network scheduler Network performance evaluation Network service Software organization Interpreter Middleware Virtual machine Operating system Software quality Software notations and tools Programming paradigm Programming language Compiler Domainspecific language Modeling language Software framework Integrated development environment Software configuration management Software library Software repository Software development Control variable Software development process Requirements analysis Software design Software construction Software deployment Software engineering Software maintenance Programming team Opensource model Theory of computation Model of computation Formal language Automata theory Computability theory Computational complexity theory Logic Semantics Algorithms Algorithm design Analysis of algorithms Algorithmic efficiency Randomized algorithm Computational geometry Mathematics of computing Discrete mathematics Probability Statistics Mathematical software Information theory Mathematical analysis Numerical analysis Theoretical computer science Information systems Database management system Information storage systems Enterprise information system Social information systems Geographic information system Decision support system Process control system Multimedia information system Data mining Digital library Computing platform Digital marketing World Wide Web Information retrieval Security Cryptography Formal methods Security hacker Security services Intrusion detection system Hardware security Network security Information security Application security Humancomputer interaction Interaction design Social computing Ubiquitous computing Visualization Accessibility Concurrency Concurrent computing Parallel computing Distributed computing Multithreading Multiprocessing Artificial intelligence Natural language processing Knowledge representation and reasoning Computer vision Automated planning and scheduling Search methodology Control method Philosophy of artificial intelligence Distributed artificial intelligence Machine learning Supervised learning Unsupervised learning Reinforcement learning Multitask learning Crossvalidation Graphics Animation Rendering Photograph manipulation Graphics processing unit Mixed reality Virtual reality Image compression Solid modeling Applied computing Quantum Computing Ecommerce Enterprise software Computational mathematics Computational physics Computational chemistry Computational biology Computational social science Computational engineering Computational healthcare Digital art Electronic publishing Cyberwarfare Electronic voting Video games Word processing Operations research Educational technology Document management Category Outline WikiProject Commons Retrieved from httpsenwikipediaorgwindexphptitleGraphQLoldid1188729924 Categories Query languagesData modeling languagesGraph data structuresHidden categories Articles with short descriptionShort description matches WikidataArticles lacking reliable references from March 2023All articles lacking reliable referencesUse dmy dates from October 2019 This article relies excessively on references to primary sources Please improve this article by adding secondary or tertiary sources Find sources GraphQL  news  newspapers  books  scholar  JSTOR March 2023 Learn how and when to remove this template message 0 This article relies excessively on references to primary sources Please improve this article by adding secondary or tertiary sources Find sources GraphQL  news  newspapers  books  scholar  JSTOR March 2023 Learn how and when to remove this template message ,https://en.wikipedia.org/wiki/GraphQL,Back-End Development,733,1477
Block Chain, Navigation Blockchain For Beginners What Is Blockchain Technology A StepbyStep Guide BeginnersBlockchain 101Blockchain for BusinessBlockchain for IntermediateBlockchain for Investors Home  Guides  Blockchain 101 Author Nick Darlington Updated on October 18th 2022 This content has been FactChecked Back to Guides Contents ToggleBlockchain 101 Blockchain For BeginnersTypes of Blockchains1 Public Blockchains2 Private Blockchains3 Hybrid Blockchains or Consortiums4 SidechainsHistory of BlockchainWho Invented BlockchainWho Owns Blockchain TechnologyWho Founded BitcoinWho Sent and Received the First Bitcoin TransactionHow Does a Public Blockchain Work StepbyStepProof of Work PoW vs Proof of Stake PoSBlockchain or Scalability Trilemma Decentralization Security and ScalabilityWhat Is the Difference Between Bitcoin and Ethereum BlockchainsBitcoin BasicsEthereum BasicsEthereum vs Bitcoin BlockchainsWhat Are the Benefits of Blockchains Over Traditional FinanceWhat Are the Disadvantages of Blockchains1 Environmental Impact2 Personal Responsibility3 Growing Pains4 False NarrativesPromising Blockchain Use Cases and Killer ApplicationsHow to Invest in Blockchain TechnologyBlockchain Companies to Invest in 2021Traditional Finance and Blockchain Investment StrategiesOverview of 10 Major Investment StrategiesHow can businesses benefit from blockchainBlockchain Is the Present and the Future What is blockchain technology What makes it so important Imagine a world where you can send money directly to someone without a bank  in seconds instead of days and you dont pay exorbitant bank fees Or one where you store money in an online wallet not tied to a bank meaning you are your own bank and have complete control over your money You dont need a banks permission to access or move it and never have to worry about a third party taking it away or a governments economic policy manipulating it This is not a world of the future it is a world that an avid but growing number of early adopters live in right now And these are just a few of the important blockchain technology use cases that are transforming the way we trust and exchange value Well get into the rest later on Yet for many blockchain technology is still a mysterious or even intimidating topic Some even remain skeptical that well use this technology in the future This skepticism that exists today is understandable because were still very early in the development and widespread adoption of blockchain technology 2021 is to blockchain what the late 1990s were to the internet And like the internet blockchain technology is anything but a fad its here to stay and if youre reading this youre early too This post demystifies blockchain technology This is your intro to blockchain technology 101 A complete easytounderstand step by step beginners blockchain breakdown Youll learn everything from what blockchain is and why it matters to how blockchain works step by step and what today  tomorrows  most promising blockchain applications may be Youll also walk away from this post confident and well on your way to making informed independent blockchain technology investment decisions And youll be no slouch if you want to hold your own in conversations with family and friends too So lets dive in Contents ToggleBlockchain 101 Blockchain For BeginnersTypes of Blockchains1 Public Blockchains2 Private Blockchains3 Hybrid Blockchains or Consortiums4 SidechainsHistory of BlockchainWho Invented BlockchainWho Owns Blockchain TechnologyWho Founded BitcoinWho Sent and Received the First Bitcoin TransactionHow Does a Public Blockchain Work StepbyStepProof of Work PoW vs Proof of Stake PoSBlockchain or Scalability Trilemma Decentralization Security and ScalabilityWhat Is the Difference Between Bitcoin and Ethereum BlockchainsBitcoin BasicsEthereum BasicsEthereum vs Bitcoin BlockchainsWhat Are the Benefits of Blockchains Over Traditional FinanceWhat Are the Disadvantages of Blockchains1 Environmental Impact2 Personal Responsibility3 Growing Pains4 False NarrativesPromising Blockchain Use Cases and Killer ApplicationsHow to Invest in Blockchain TechnologyBlockchain Companies to Invest in 2021Traditional Finance and Blockchain Investment StrategiesOverview of 10 Major Investment StrategiesHow can businesses benefit from blockchainBlockchain Is the Present and the Future Blockchain 101 Blockchain For Beginners Blockchain technology is the concept or protocol behind the running of the blockchain Blockchain technology makes cryptocurrencies digital currencies secured by cryptography like Bitcoin work just like the internet makes email possible The blockchain is an immutable unchangeable meaning a transaction or file recorded cannot be changed distributed digital ledger digital record of transactions or data stored in multiple places on a computer network with many use cases beyond cryptocurrencies Immutable and distributed are two fundamental blockchain properties The immutability of the ledger means you can always trust it to be accurate Being distributed protects the blockchain from network attacks Each transaction or record on the ledger is stored in a block For example blocks on the Bitcoin blockchain consist of an average of more than 500 Bitcoin transactions The information contained in a block is dependent on and linked to the information in a previous block and over time forms a chain of transactions Hence the word blockchain Types of Blockchains There are four types of blockchains 1 Public Blockchains Public blockchains are open decentralized networks of computers accessible to anyone wanting to request or validate a transaction check for accuracy Those miners who validate transactions receive rewards Public blockchains use proofofwork or proofofstake consensus mechanisms discussed later Two common examples of public blockchains include the Bitcoin and Ethereum ETH blockchains 2 Private Blockchains Private blockchains are not open they have access restrictions People who want to join require permission from the system administrator They are typically governed by one entity meaning theyre centralized For example Hyperledger is a private permissioned blockchain 3 Hybrid Blockchains or Consortiums Consortiums are a combination of public and private blockchains and contain centralized and decentralized features For example Energy Web Foundation Dragonchain and R3 Take note There isnt a 100 percent consensus on whether these are different terms Some make a distinction between the two while others consider them the same thing 4 Sidechains A sidechain is a blockchain running parallel to the main chain It allows users to move digital assets between two different blockchains and improves scalability and efficiency An example of a sidechain is the Liquid Network History of Blockchain Blockchain isnt just a database its a new technology stack with digital trust that is revolutionizing the way we exchange value and information across the internet by taking out the gatekeepers from the process For a complete and more detailed deep dive check out our article A Concise History of Blockchain Technology Blockchain history goes back farther than you might imagine but weve condensed it by answering four critical questions Who Invented Blockchain The first blockchainlike protocol was proposed by cryptographer David Chaum in 1982 Later in 1991 Stuart Haber and W Scott Stornetta wrote about their work on Consortiums But it was Satoshi Nakamoto presumed pseudonym for a person or group of people who invented and implemented the first blockchain network after deploying the worlds first digital currency Bitcoin Cryptography is a deep and fascinating discipline with a history that goes back further than blockchain For a richer understanding of how cryptography helps blockchain technology check out Why Cryptography Makes Blockchain Unstoppable Who Owns Blockchain Technology Because blockchain technology is the technology behind the blockchain it cannot be owned Its like the internet But anyone can use the technology to run and own their own blockchains Who Founded Bitcoin Satoshi Nakamoto Who Sent and Received the First Bitcoin Transaction Nakamoto sent ten bitcoins to Hal Finney who built the first reusable proofofwork system in 2004 How Does a Public Blockchain Work StepbyStep For a more indepth account of the next section check out the thorough discussion in What is Blockchain Technology and How Does it Work Lets start with an oversimplification As a society we created ledgers to store informationand they have a variety of applications For example we use ledgers in real estate to store a houses records such as when alterations were made or the house was sold We also use ledgers in bookkeeping to record all the transactions a company makes Bookkeeping mostly relies on doubleentry accounting to store transactions Although this is a stepup from singleentry accounting that lacks transparency and accountability doubleentry accounting also has its pitfalls Entries are accounted for separately making it difficult for one counterparty to verify the others records Records stored using traditional ledgers are also easy to tamper with meaning you can easily edit remove or add a record As a result youre less likely to trust that the information is accurate Public blockchains solve both these problems  and the way we trust  by evolving the traditional bookkeeping model to tripleentry bookkeeping transactions on a blockchain are cryptographically sealed by a third entry This creates a tamperproof record of transactions stored in blocks and verified by a distributed consensus mechanism These consensus mechanisms also ensure new blocks get added to any blockchain An example of a consensus mechanism is proofofwork PoW often referred to as mining Mining isnt universal to all blockchains its just one type of consensus mechanism currently used by Bitcoin and Ethereum though Ethereum plans to move to anotherproofofstake PoS by 2022 Heres how this process works with Bitcoin When sending Bitcoin you pay a small fee in bitcoin for a network of computers to confirm your transaction is valid Your transaction is then bundled with other transactions pending in a queue to be added to a new block The computers nodes then work to validate this list of transactions in the block by solving a complex mathematical problem to come up with a hash which is a 64digit hexadecimal number Once solved the block is added to the networkand your fee combined with all other transaction fees in that block is the miners reward Its that simple Each new block added to the network is assigned a unique key via cryptography To obtain each new key the previous blocks key and information are inputted into a formula As new blocks are continually added through the ongoing mining process they become increasingly secure and harder to tamper with Anyone caught trying to edit a record will simply be ignored All future blocks then depend on information from prior blocksand this dependency from one block to the next forms a secure chain the blockchain You can see this depicted below for house records stored on the blockchain For example Block 2 provides a key after taking all the information from Block 1 into account including the key and inputting it into a formula Block 3 in turn provides a new key after taking all the information from Block 1 and Block 2 into account including the key and inputting it into a formula And so the process repeats itself indefinitely Now lets dig deeper exploring proofofwork PoW vs proofofstake PoS and the blockchain trilemma which are fundamental to the public blockchains functioning Proof of Work PoW vs Proof of Stake PoS A public blockchain functions through consensus mechanisms the process for validating transactions without a third party like a bank PoW and PoS are two such mechanisms While their goalto reach a consensus that a transaction is validremains the same how they get there is a little different What Is PoW PoW the technical term for mining is the original consensus mechanism It is still used by Bitcoin and Ethereum as of writing but as mentioned Ethereum will move to PoS by 2022 PoW is based on cryptography which uses mathematical equations only computers can solve The example in the previous section of how blocks get added to the Bitcoin Blockchain explains this system The two big problems with PoW are that it uses a lot of electricity and can only process a limited number of transactions simultaneously seven for Bitcoin Transactions typically take at least ten minutes to complete with this delay increasing when the network is congested Though compared to the dayslong wait required to wire money across the globe or even to clear a check Bitcoins tenminute delay is quite remarkable Other consensus mechanisms were created to solve these PoW problems the most popular being PoS What Is PoS PoS still uses cryptographic algorithms for validation but transactions get validated by a chosen validator based on how many coins they hold also known as their stake Individuals arent technically mining and theres no block reward Instead blocks are forged Those participating in this process lock a specific number of coins on the network The bigger a persons stake the more mining power they haveand the higher the chances theyll be selected as the validator for the next block To ensure those with the most coins arent always selected other selection methods are used These include randomized block selection forgers with the highest stake and lowest hash value are chosen and coin age selection forgers are selected based on how long theyve held their coins The results are faster transaction times and lower costs The NEO and Dash cryptocurrencies for example can send and receive transactions in seconds Blockchain or Scalability Trilemma Decentralization Security and Scalability Most blockchain projects are built around three core properties decentralization scalability and security Developers are constantly trying to balance these aspects so one isnt compromised But they often have to sacrifice one for the others The blockchain trilemma concept was first coined the scalability trilemma by Ethereum founder Vitalik Buterin Lets look at these concepts in more detail and explore the tradeoffs Decentralization Decentralization means theres no central point of control Instead decisions are made via consensus over a distributed network of computers There is however one significant tradeoff speed Sending transactions takes longer because multiple confirmations are required to validate a transaction Hence why Bitcoin is slow Scalability Scalability is the ability of the system to cope with a growing number of transactions Scalability is crucial for mass adoption because any system needs to operate efficiently as more people use it Below is a rough breakdown of how many transactions Ethereum Bitcoin and credit card companies can process per second Bitcoin seven per second Ethereum 30 per second Credit cards 5000 credit card transactions per second with the ability to process much more if needed Visa for example can process up to 24000 transactions per second But achieving scalability often comes at the expense of decentralization EOS for example promises a maximum of 4000 TPS but has come under criticism for being too centralized Security Security is the ability of a blockchain to be protected from attacks Unfortunately exchanges and source code have been hacked on many occasions suggesting that many developers focus on scalability and decentralization at the expense of security What Is the Difference Between Bitcoin and Ethereum Blockchains Bitcoin and Etherum are the two biggest cryptocurrencies and blockchains so discussing and comparing them makes sense Bitcoin Basics The Bitcoin network is a public decentralized peertopeer payment network that allows users to send and receive bitcoins without a bank getting involved The digital currency or bitcoin token uses the ticker symbol BTC and is the only cryptocurrency traded on the Bitcoin network Transactions are recorded using a digital ledger and nodes ensure the PoW consensus mechanism is followed or that mining happens For many Bitcoin seems complicated but it isnt when you view it as a combination of three things A peertopeer payment system You can send money BTC from one person or company to another without the need for a bank Sending money this way is faster more secure and cheaper than using traditional methods A decentralized system like the internet so its not controlled by one entity and cannot be stopped by a third party A store of value like gold often called digital gold but much easier to transfer than gold Ethereum Basics In 2013 after traveling meeting with bitcoin developers and discovering Bitcoins limitations Vitlaik Buterin decided to improve upon the Bitcoin blockchain and built Ethereum The Ethereum network is a public decentralized peertopeer network Like Bitcoin it uses nodes and allows users to send and receive cryptocurrencyin this case Ether The network is much more than a payment systemit was primarily created to deploy decentralized applications dapps and smart contracts Dapps are simply decentralized apps or computer programs that interact with the Ethereum blockchain Smart contracts however operate on the Ethereum blockchain and are contracts that automatically execute without an intermediary once certain conditions written into computer code are met For example a smart contract could be programmed to send a designated person a portion of your Bitcoin when you die Ethereum vs Bitcoin Blockchains In summary Bitcoin and Ethereum networks are public decentralized peertopeer networks with their own tokens bitcoins and Ether Both rely on cryptography and both use digital ledger technology For a complete Ethereum vs Bitcoin match up check out our deep dive post Ethereum Vs Bitcoin Whats the Difference But they differ significantly in purpose and capability Bitcoin is a decentralized payment system and a store of value Its blockchain is a database of all bitcoin transactions and tracks their ownership Ethereum is more than a payment system and allows smart contracts and apps to be built on it making it a more sophisticated blockchain What Are the Benefits of Blockchains Over Traditional Finance Trustless The blockchain is immutable and automates trusted transactions between counterparties who do not need to know each other Transactions are only executed when programmed conditions are met by both parties Unstoppable Once the conditions programmed into a blockchain protocol are met an initiated transaction cannot be undone changed or stopped Its going to execute and nothing  no bank government or third party  can stop it Immutable Records on a blockchain cannot be changed or tampered with  Bitcoin has never been hacked A new block of transactions is only added after a complex mathematical problem is solved and verified by a consensus mechanism Each new block has a unique cryptographic key resulting from the previous blocks information and key being added into a formula Decentralized No single entity maintains the network Unlike centralized banks decisions on the blockchain are made via consensus Decentralization is essential because it ensures people can easily access and build on the platform and there are multiple points of failure Lower Cost In the traditional finance system you pay third parties like banks to process transactions The blockchain eliminates these intermediaries and reduces fees with some systems returning fees to miners and stakers PeertoPeer Cryptocurrencies like Bitcoin let you send money directly to anyone anywhere in the world without an intermediary like a bank charging transaction or handling fees Transparent Public blockchains are opensource software so anyone can access them to view transactions and their source code They can even use the code to build new applications and suggest improvements to the code Suggestions are accepted or rejected via consensus Universal Banking 2 Billion people globally do not have a bank account Because anyone can access the blockchain to store money its a great way to bank the unbanked and protect against theft that can happen due to holding cash in physical locations What Are the Disadvantages of Blockchains Public open source blockchains are not without their hazards and challenges Here is a list of the top concerns 1 Environmental Impact Blockchain networks like Bitcoin use a lot of electricity to validate transactions leading to environmental concerns For example Bitcoin consumes more electricity than a small mediumsized European country and Bitcoin mining is threatening Chinas climate change goals However many would argue that Bitcoin is held to higher environmental standards than anyone and anything This may be true especially if you consider that the blockchain and Bitcoin are an alternative to the traditional finance system that uses much more electricity and has a much larger environmental impact A study by Galaxy Digital suggests Bitcoin energy consumption is less than half that of the traditional banking system If anything you could argue that Bitcoin is a step in the right direction for the environment No one is saying that making strides to lowering the carbon footprint shouldnt be on the agenda this is already happening with some mining farms shifting to renewable energy sources like solar panels and the El Salvadoran President calling for a plan to use geothermal energy volcanoes to mine Bitcoin But its crucial to maintain a balanced view when viewing the cost environmental impact and blockchain benefits 2 Personal Responsibility One of blockchains and cryptocurrencies most significant advantages is also its biggest weakness When you invest in public opensource blockchains by mining or buying cryptocurrencies and store it in your cryptocurrency wallet your wallet is like your bank account except only you can access it and have the passwords only you control your money You are your own bank and this is great But if you lose your seed phrases  the list of words that give you access to recover your wallets  there is no recourse compared to banks where you can reset your password Your money is lost forever Unsurprisingly a large portion of Bitcoin remains permanently lost According to some estimates 20 or 37 million of the currently minted Bitcoin is probably lost forever 3 Growing Pains Even though public blockchains remain more efficient than traditional banking systems decentralization comes at the cost of scalability Trying to grow blockchain networks to global capacity in turn is the root cause of speed inefficiencies Its why as we saw Bitcoin and Ethereum can only process a maximum of seven and 30 transactions respectively compared to Visas 24000 Luckily solutions are being built to improve scalability and the speed of transactions For example the lightning network allows transactions to happen off the Bitcoin blockchain to speed up transactions On Ethereum many innovative Layer 2 L2 solutions are being developed to improve scalability and speed including rollups zeroknowledge proofs and side chains 4 False Narratives Some cryptocurrencies are undoubtedly used in unlawful activity The most famous example is Silk Road people laundered money and bought drugs on the platform using Bitcoin However this is no different from the illegal activity that constantly happens when people use other currencies like the Dollar This false narrative that cryptocurrencies are only or mainly used for illicit activities only delays their inevitable adoption which can hugely benefit everyone including the financial system Promising Blockchain Use Cases and Killer Applications For an even more indepth discussion of the most interesting and disruptive blockchain use cases as of 2021 check our guide Disruptive Blockchain Technology Use Cases 2021 Blockchain technology is currently used across various industries like supply chain healthcare retail media and advertising financial services insurance travel and transportation oil and gas and gaming Here are some promising use cases Cryptocurrencies The killer app of blockchains today is internet money Cryptocurrencies let you transfer value faster and cheaper across borders without a bank Besides Bitcoin and Ethereum other digital currency examples include Polkadot DOT NEO Cardano ADA Tether USDT Binance Coin BNB and Litecoin LTC Smart Contracts These blockchain applications are contracts that automatically execute without an intermediary once conditions written into the computer code are met Decentralized Banking The use of blockchain technology is also proliferating in banking For example many banks like Barclays Canadian Imperial Bank and UBS are interested in how blockchain can make their backoffice settlement systems more efficient Video GamesArt You may have heard Crypto Kittiesa game launched on the Ethereum blockchain One of the virtual pets in the game was sold for over 100000 Peertopeer Energy Trading People buy or sell energy directly without an intermediary Supply chain and logistics tracking Blockchain is being used to track precious metals origins and foods For example Walmart and IBM worked together to create a food traceability system based on opensource ledger technology making it easier to trace contaminated food Healthcare process optimization Blockchain can speed up the time required to pay health insurance payments to patients and store and securely share medical data and records Real estate processing platform Property ownership records can be securely stored and verified on the blockchain These records cannot be tampered with so you can trust theyre accurate and more easily verify property ownership NFT marketplaces These are marketplaces that allow you to buy nonfungible tokens NFTs digital tokens of things like paintings and clothing Music royalties tracking Blockchain can trace music streams and immediately pay those who contributed to a song Antimoney laundering tracking system Authorities can more easily track the original source of money because every transaction on the blockchain is recorded and leaves behind a tamperproof trail Personal identity security Traditional systems for storing identities are insecure and fragmented Blockchain provides a unified immutable and interoperable infrastructure so you can store and manage records securely and efficiently New insurance distribution methods For example peertopeer insurance parametric insurance and microinsurance Automated Advertising Campaigns Advertisers can use smart contracts to automate advertising campaigns eg an audience is only shown an ad when specific criteria are met How to Invest in Blockchain Technology With blockchain offering some promising use cases helping many companies become more efficient and attracting big companies like Amazon and Tesla it can be an attractive investment But there are risks Its a new technology and many projects will not pan out So invest only what you can afford to lose do your own research to determine if the project or initial coin offering is worth investing in and decide what level of exposure you want For example you can get more exposure by investing in cryptocurrencies directly instead of an exchangetraded fund ETF That being said here are a variety of ways you can invest in the blockchain depending on your goals and risk tolerance Buy shares in companies using blockchain eg Visa Walmart and Siemens on traditional stock exchanges like the NYSE You can buy shares by using an online broker such as Vanguard and Betterment US Invest in companies with Bitcoin on their balance sheet eg Square WeWork MicroStrategy and Tesla Again use an online broker to buy shares Buy cryptocurrencies like Bitcoin or Ethereum directly on Centralized Finance CeFi or Decentralized DeFi exchanges Centralized exchanges were the norm in the crypto world until decentralized exchanges arrived With centralized exchanges you dont have your own private keys and the exchange is the custodian for storing your funds Decentralized exchanges are peertopeer and theres no intermediary Examples of CeFi exchanges include Binance Kraken Bittrex Bitfinex Luno and Coinbase Examples of DeFi exchanges include Uniswap Compound KyberSwap Airswap IDEX SushiSwap Balancer and Totle Invest in crypto exchangetraded funds ETFs ETFs are a basket of securities that track an asset or index you can buy or sell on an exchange throughout the day For example many traditional ETFs will include bonds currencies commodities and stocks and track the SP 500 Index In the crypto space you get a variety of ETFs you can invest in such as a Bitcoin ETF that tracks the price of Bitcoin Each ETF will differ depending on who issues it Companies that offer ETFs include Grayscale Galaxy Digital and Gemini Invest in crypto mining companies such as Riot Hive and Marathon Many mining companies let investors participate indirectly by offering equity in their companies To invest in Riot use an Americanbased online broker like Robinhood To invest in Hive and Marathon use a Canadianbased broker like Questrade TD Direct Investing or BMO InvestorLine Buy crypto hardware and mine cryptocurrency yourself While Bitcoin mining requires a large capital outlay there are other tokens you can mine for a reasonably low barrier to entry For example Helium miners cost roughly 500 and mint HNT using the proof of coverage consensus protocol to verify new blocks Get started with cryptocurrency mining by reading our short guide on Bitcoin mining Invest in mining pools An alternative to mining cryptocurrency yourself is to join a mining pool Mining pools pool together the computational power of others on the network to improve the chances of mining a block The rewards for all blocks mined are shared among miners in the pool Slush Pool is a popular mining pool Blockchain Companies to Invest in 2021 If youre looking to get started with crypto investing weve created a comprehensive stepbystep guide you can follow to get started here How To Invest in Cryptocurrencies The Ultimate Beginners Guide Here is a comprehensive list of public blockchain companies to invest in We have segmented them based on these categories banking supply chain health care energy insurance travel real estate exchanges and mining These public companies are either using blockchain have cryptocurrency on their balance sheets allow you to trade cryptocurrency or are mining cryptocurrency Technically Binance is not a public company but you can invest in it by purchasing their own digital currency BNB You can use their currency to pay for transaction and trading fees on the exchange This is also true for DeFi exchanges like Uniswap 1inch and PancakeSwap Traditional Finance and Blockchain Investment Strategies In some ways the process of investing in shares and cryptocurrencies is the same First you can buy cryptocurrencies on exchanges like you can buy shares through an online broker Second you are also able to apply traditional investment principles to investing in cryptocurrencies and the blockchain For example you can invest the same amount of money into Bitcoin each month regardless of price dollarcost averaging to remove any emotion out of the investment process But there are also investment strategies that are unique to the blockchain and cryptocurrencies like yield farming Read on to learn about ten common traditional finance and blockchain investment strategies you can use when investing in public blockchain companies and cryptocurrencies Overview of 10 Major Investment Strategies Growth Investing Investors look for companies that demonstrate aboveaverage growth Investors using this strategy will often still invest in shares even if they seem expensiveTo narrow down your search focus on industries currently doing well or have historically performed With the blockchain technology market expected to grow in size there are bound to be several companies with strong growth potential Value Investing Investors look for undervalued companies eg their price doesnt fully reflect their value Successful value investing often requires that you hold your shares for the long term Dividend Growth Investing Investors invest in companies that have a history of paying out dividends You can look at a companys financial statements to see if they pay out dividends Look for a yield of between 26 Indexing This is more of a cautious and passive investment strategy but indexed investors often outperform more active investors These investors typically invest in an index fundAn index fund consists of pooled funds from investors is managed by a fund manager and automatically invests in the companies of a specific index like the SP 500 to effectively track against the indexs performanceIt is different from an ETF in that you can only buy or sell index funds at the end of the day and not throughout An example of a cryptocurrency index fund is the Bitwise 10 Crypto Index Fund BITW Day Trading Day trading is a more active and aggressive shortterm trading strategy Investors frequently trade throughout the day to capitalize on small market movements to make a profit Day traders will use technical analysis to develop trade ideas around how the market will move Day trading cryptocurrency is equally lucrative and risky due to highly volatile assets Algorithmic Trading Also known as automatic trading this investment strategy involves using computer programs to execute trades based on preprogrammed instructions such as price time etc A large portion of the American market consists of algorithmic trading AlgoTrader is an automated trading program you can use for Bitcoin trading Contrarian Investing Contrarian investors purposely go against the market sentiment They buy when people are selling and sell when people are buyingBy following the Bitcoin Fear and Greed Index you can get a good idea of the prevailing sentiment in the Bitcoin market and then do the opposite buy when people are fearful and sell when theyre greedy see Fear  Greed Index below Arbitrage This strategy involves taking advantage of price differences of the same asset between markets You buy the asset in one market and then sell it for a higher price in anotherBecause cryptocurrencies like Bitcoin often differ in price between countries there are great opportunities to profit from this strategyIn a nutshell traders will buy cryptocurrency on an overseas exchange for a lower price and then transfer it to a local exchange and sell it for a higher priceAs Business Tech reports you can make 24 per trade using the right investment platform Just make sure you follow local exchange control laws because there are usually limits to how much local currency you can move beyond the borders Yield Farming This blockchainspecific investment strategy involves lending your cryptocurrency to someone else via smart contractsThe lendee pays you a fee for your services Yield farmers often move their cryptocurrency between different lending platforms to maximize returns A few yield farming platforms include Compound Finance Aave and MarketDAO Learn more about DeFi yield farming Diversification Spread your risk and invest in different assets and companies to limit your overall downside while exposing you to more opportunities to make money Diversification is more than just an investment strategy its a smart way to invest that most financial experts and brokers encourageThis strategy works well for traditional finance and cryptocurrencyIn traditional markets you can spread risk across bonds money markets and shares and even diversify your share portfolio by investing across industriesFor cryptocurrencies and blockchain you can invest in different public blockchain companies and also cryptocurrencies with different use cases like Bitcoin payments Ethereum smart contracts Monero privacy and XRP cross border paymentsIf you really want to prioritize diversification you should invest across traditional and crypto markets and rebalance your portfolio as needed How can businesses benefit from blockchain Lets look at the businessspecific advantages of blockchain technology  As mentioned above the blockchain is a great way to build trust among entities that have never worked together As such it is an excellent way for businesses to work together without requiring a trusted third party  The blockchain can help create a consortium of businesses and provide an operational structure with no central leader This can allows multiple businesses to interact effectively and share information  The fact that all data stored within blockchains are immutable has gamechanging security implications Its no longer possible for malicious centralized parties to tamper with crucial data  By removing the need for trusted third parties the overall organizational costs go down significantly Plus taking away these intermediaries drastically increases operational speeds For example Walmart used blockchain to trace the source of sliced mangoes in seconds Normally this process would take a week  The blockchain is a major boon for companies that rely on or operate supply chains The blockchains transparency helps fix a majority of the issues present in traditional supply chain structures For example not only has Walmart successfully applied blockchain in their supply chain via IBM but the medical industry is actively using the tech in their crackdown on counterfeit medication Blockchain Is the Present and the Future With many promising realworld use cases like faster crossborder payments and smart contracts blockchain technology is here to stay As more companies realize how the blockchain can help them theyll commit more resources money and time into the technologyand even more use cases will emerge While we understand that blockchain technology will remain a complex topic for many it really doesnt have to be for you We hope this guide gave you the confidence to have conversations with friends and acquaintances about the blockchain and that it demystified and simplified an often scary topic Refer to it whenever you need to brush up on any blockchain concepts Most importantly we hope it lit a small fire in you to learn even more about a technology thats fundamentally changing the way we trust and exchange value Nick Darlington Like what you read Give us one like or share it to your friends and get 16 60 newest oldest most voted Crystal To6219A very informative guide Thank you so much Blockgeeks for your hard work I will certainly use it from time to time Its gonna be so great if Blockgeeks offers regular updates on the current state of the mentioned projects using blockchain Once again thank you so much Vote Up17Vote Down 4 years ago M Mike Nahounou7000Without a doubt this is the single most important article written on Blockchain Technology since Bitcoins Genesis Block Well done Vote Up3Vote Down 4 years agoBlockNut6974This beginners guide is structured in the best way possible from the most basic concept of what blockchain is to the future of business through the various applications thereof Well written and presented Whether you are an absolute newbie or an expert on blockchain this guide will suffice for your need to grow within the Blockchain space Thank you Blockgeeks  Vote Up3Vote Down 4 years ago B Ben Fox6763Thanks for this Vote Up2Vote Down 4 years agoRobert Kroos6706The article was completely helpful for beginners and newbies With the drastic implementation of Blockchain Technology most of the industries such as Hospital banking finance has reaped profits You can check more about this here Vote Up2Vote Down 4 years agoMark Silen6594Great articlethanx  Vote Up4Vote Down 4 years ago Tiffany Mccullar6543This was such a simple way of explaining this technology I enjoyed reading this Vote Up4Vote Down 4 years ago LISS6497Great introduction I have a much clearer understanding of blockchain now Vote Up4Vote Down 4 years agoMarko Ceki6446Thank you for creating easy to understand education on blockchain technology Your article helped me gain a deeper understanding of blockchain and has benefited me greatly on my journey of studying crypto All the best Vote Up5Vote Down 4 years ago F FUK VEW6054I can find out how it works Vote Up4Vote Down 4 years ago F FUK VEW6053how it works Vote Up2Vote Down 4 years ago Karthik Shanmugam6035Really Impressive Writing I myself being working in one of the leading Blockchain development companyZab Technologies I was able to identify all my queries with your answers  Vote Up3Vote Down 4 years ago Nazeh Abel6012I love how things are outlined here for easier understanding love this guide its my first reading for blockchain Vote Up10Vote Down 4 years ago httpstwittercomSashaBaksht6034So much more to LEarn Vote Up5Vote Down 4 years ago F Fenglian Xu6011Nice article its a bit unclear on how a change in block 3 will cause the entire backward block chain changed Vote Up5Vote Down 4 years ago httpstwittercomSashaBaksht6033The hash of block 3 is included in block 4 and so on Vote Up4Vote Down 4 years agoธณวฒน ประวนตา6008Thankâ Flowâ youâ Vote Up4Vote Down 4 years agoCrystal To5985Thank you so much for the work the article has so much information in it Its gonna be even better if the team can point out the key points for beginners to have a clearer mind Thank you so much Vote Up3Vote Down 4 years ago Kevin Wright5984This is a good comprehensive introductory guide to blockchain I have looked for something that provides a good summary of blockchain to use as an example for those new to the technology This might be a bit too much information to digest all at once for people but it covers a lot of good ground Vote Up2Vote Down 4 years agoSandra Douglas5946I never knew Id be able to make profits after losing so much Mrs Rose helped me to recover all that I lost trading on my own I really dont think I can be able to thank her enough shes a lifesaver Vote Up3Vote Down 4 years agoGeorge Walker5945Thanks for sharing this great information I will contact Mrs Rose Parker to get started Vote Up5Vote Down 4 years agoeclature technologies5942This is a very nice article on Blockchain Thanks for sharing this article I understand that Blockchain authenticates digital transformation but is it a trusted approach Vote Up8Vote Down 4 years ago pravinrrwltzgmailcom5872Nice blog We are also working in blockchain development and blockchain is having a great futurehttpbitly2KjUNUj Vote Up4Vote Down 4 years agoeclature technologies5850Thank you for the blog post The need to implement blockchain has drastically risen over the years and ee eclaturetechnologiesgmailcom know the value of having blockchain services Vote Up2Vote Down 4 years ago D Daniel Pereira5848Hi Ive enjoyed reading this stepbystep guide Thanks Vote Up9Vote Down 4 years agoSphinx Solution5771Blockchain in simple language is a database based and managed on a peertopeer network of computers often referred as nodes You can also call it as a distributed ledger which is a decentralized way of documenting transactions in chronological order Every participant in the blockchain has uninterrupted access to the blockchain and its history Vote Up9Vote Down 4 years agoWebcom Systems5764Very helpful blog post Thanks for sharing valuable information I am a blockchain developer at webcom systems and understand the importance of blockchain technology and how it works Videos are as good as the content of the blog Vote Up8Vote Down 4 years ago httpstwittercomSashaBaksht5802Thanks Webcom Vote Up4Vote Down 4 years ago N Neelima d5714Good course Vote Up5Vote Down 4 years ago t t z5683Keep in mind that Bitcoin blockchain does not use encryption The security is provided by digital signatures and hashing algorithms ECDSA and SHA256 httpsbitcoinstackexchangecomquestions81493isencryptionreallyneededforblockchaintowork Vote Up5Vote Down 4 years ago R Rama Ranabothu5578Good one Vote Up4Vote Down 4 years ago P Purnima Ratra5576Nice One Vote Up5Vote Down 4 years ago E Edwin Qi5572cool Vote Up4Vote Down 4 years ago F Firozsha Makandar5565Cool Vote Up4Vote Down 4 years agoNoor Khan5557Thank you for sharing this detailed article with us I love the way you cover the topic with expert opinion Great article and I love to get engage with such an article Im learning blockchain technology Really curious about blockchain technology Keep posting Vote Up4Vote Down 5 years ago B Britney Jolie5538Useful and interesting intro to blockchain I have a few thoughts 1 Distributed ledgers dont all the nodes get swamped with all the data as it is updated every ten minutes and that could mean lots and lots of storage space required 2 What happens as with peers in torrents when some nodes are offline Every node has to have a copy of all the information I guess this is another storage space question 3 Blockchain is advantageous because it is secure yet hacking has been mentioned a couple of times Human error and bad intent are also present with other technologies The public and private keys can be stolen 4 Criminal activity in a free decentralized system reputation is the only force keeping people honorable Can reputation be smeared ok just thinking of the different things that happen in the world Safeguards protections Very exciting concepts I have heard the terms cryptocurrency and blockchain thrown around but never really looked at it Very interesting Thank you for the information Vote Up4Vote Down 5 years ago s saranya balasubramanian5518informative article Vote Up4Vote Down 5 years ago R Rajesh Puli5491Good article its useful everyone Vote Up4Vote Down 5 years ago J Jay Suguru5478Nice one Vote Up4Vote Down 5 years ago S Sreenivas Aghoramurthy5475Pretty interesting the cases and applicability that Don Tapscott spoke through and available on TED helped realize that our everyday lives are significantly influenced by middlemenoperators who probably have been doing great but now we have faster approaches based on the blockchain technology Vote Up4Vote Down 5 years ago r ritesh soni5473Useful Vote Up4Vote Down 5 years ago R Rajesh Murugiah5455Its great to learn Vote Up4Vote Down 5 years ago S Sangeetha Pandimeyyappan5444Good and useful Vote Up4Vote Down 5 years ago Neil James5439Indeed a very informative article for beginner to advance level crypto lover Vote Up4Vote Down 5 years ago B Banupriya RamakrishnaYoganandhan5427It was useful Vote Up4Vote Down 5 years ago R Roman Gernovski5347This is going to come off rude but may I suggest you perform some basic proofreading of your article prior to publication to fix all the grammatical errors of which there are many if you wish to teach your audience something new without insulting their intelligence by forcing them to fix your illstructured sentences to clarify your own writing Vote Up4Vote Down 5 years ago M Michael Kelem5353Yes And this was written two years ago updated in Sept 2018 and they still havent found or corrected any errors Its painful to read at times Informative yes Painful also yes Vote Up4Vote Down 5 years ago Bardia Pourvakil5360Roman Hi thanks for the feedback can you please give us some details as we are currently going over the guide to fix any outstanding grammatical errors Vote Up3Vote Down 5 years ago j jay rickaba5415I would like to second the motion that some time be spent cleaning up the grammar Great opportunities to educate about great topics can be squandered through inattention to the quality of presentation Ive tried reading this several times and have to agree that its quite painful to get throughnot because its inaccurate but simply because its garbled in critical spots One suggestion is to let a skilled copy editor review text prior to its release Sites that dont proofread their content run the risk of being dismissed as less than reliable Often I want to refer others interested in learning about CC to specific information sites but cant yet recommend this one Vote Up3Vote Down 5 years ago I IKENNA MICHAEL5336The summary was informative Blockchain technology is the future and I really hope all the value creations listed above will help developing countries such as mine Vote Up3Vote Down 5 years ago J Joshua Ntsioa5320This seems to be a much better platform to transect and share documents over the internet Is there anyone who can share their experience of implementing this and the use thereof Vote Up3Vote Down 5 years ago S Sean Brunnock5293The image has a bunch of typos legder partipates permision Vote Up4Vote Down 5 years ago httpstwittercomSashaBaksht5295Good find Sean Vote Up3Vote Down 5 years ago q qwerty12343 5242n called âœdigPotential Vote Up3Vote Down 5 years ago q qwerty12343 5241Is blockchain technology the new internetMain Topic Vote Up3Vote Down 5 years ago L Lehman Heaviland5237Is this similar to dropbox only in a much more complex way I was wondering if this could be used in language learningteaching format some how Vote Up3Vote Down 5 years ago Nathaniel Oamhen5233Excellent breakdown I have learnt so much from this article Welcome to the decentralized future Vote Up3Vote Down 5 years ago J Jamal 5188shared documents analogy is a powerful oneThis analogy may not be as accurate Google Docs are still maintained centrally Blockchain on the other hand is completely decentralized Vote Up3Vote Down 5 years ago Load More Comments Have a question Ask our Community 60 20160918 215317 Have questions We have built an incredible community of blockchain enthusiasts from every corner of the industry If you have questions we have answers Ask community 1  Q What is a Blockchain 1 1  Q What is a Blockchain asked 20190815 Ameer Rosic 1 answers 1 votes 1 A A blockchain is an immutable timestamped series record of data that is distributed and managed by cluster of computers Answer Link answered 20190815 Blockgeeks 2  Q Who controls the blockchain 1 2  Q Who controls the blockchain asked 20190815 Ameer Rosic 1 answers 1 votes 1 A An open blockchain network has no central authority  it is the very definition of a democratized system Since it is a shared and immutable ledger the information in it is open for anyone and everyone to see Answer Link answered 20190815 Blockgeeks 3  Q What are the 3 pillars of blockchain technology 1 3  Q What are the 3 pillars of blockchain technology asked 20190815 Ameer Rosic 1 answers 1 votes 1 Decentralization Transparency Immutability Answer Link answered 20190815 Blockgeeks 4  Q What is Blockchain used for 1 4  Q What is Blockchain used for asked 20190815 Ameer Rosic 1 answers 1 votes 1 A Initially used for Bitcoin and other cryptocurrencies blockchain has now found use cases in several industries including finance real estate and health Answer Link answered 20190815 Blockgeeks Like what youre reading Join our community and get access to over 50 free video lessons workshops and guides like this No credit card needed Get Started Related Guides Ameer Rosic What is Cryptoeconomics The Ultimate Beginners Guide 1380 Ameer Rosic What is Bitcoin The Most Comprehensive StepbyStep Guide 1310 Ameer Rosic What is Cryptocurrency Everything You Need To Know 12466 Ameer Rosic What is Ethereum The Most Updated StepbyStepGuide 1158 Andrew Zapotochny What are Smart Contracts 1210 Hungry for knowledge New guides and courses each week Looking to invest Market data analysis and reports Just curious A community of blockchain experts to help Get started today Join Blockgeeks Already have an account Sign In Blockchain Technology How it works law  BR  ow The requested transaction is broadcast to P2 ome Validation network consisting one someone requests __etwork consisting The network of nodes  gryptocurrency a transaction i known as nodes validates the transaction or other information and the users status using known algorithms Once verified the transaction is combined with o_ o__ Sere oneentions to create a new The new block is then added to the ecece ane the ledger a Bj The transaction existing blockchain in a way that is is complete permanent and unalterable oe  Cryptocurrency Cryptocurrency is a medium of exchange created and stored electronically in the blockchain using encryption techniques to control the creation of monetary units and to verify the transfer of funds Bitcoin is the best known example XO Has no Has no physical Its supply is not value in that it isnot form and exists only determined by a central redeemable for in the network bank and the network is Oo Blockgeeks another commodity completely decentralized such as gold 5 Fear  Greed Index Multifactorial Crypto Market Sentiment Analysis Now Greed alternativeme Last updated Dec 27 2023 pay pay   5 e228 pay o pay  Or Vhat is Cryptocurrency What is  Block 0 ,https://blockgeeks.com/guides/what-is-blockchain-technology/,Infrastructure,2194,8299
Internet Protocols and Standards," From Wikipedia the free encyclopedia Standard published by the Internet Engineering Task Force This article relies excessively on references to primary sources Please improve this article by adding secondary or tertiary sources Find sources Internet Standard  news  newspapers  books  scholar  JSTOR November 2015 Learn how and when to remove this template message In computer network engineering an Internet Standard is a normative specification of a technology or methodology applicable to the Internet Internet Standards are created and published by the Internet Engineering Task Force IETF They allow interoperation of hardware and software from different sources which allows internets to function1 As the Internet became global Internet Standards became the lingua franca of worldwide communications2 Engineering contributions to the IETF start as an Internet Draft may be promoted to a Request for Comments and may eventually become an Internet Standard An Internet Standard is characterized by technical maturity and usefulness The IETF also defines a Proposed Standard as a less mature but stable and wellreviewed specification A Draft Standard was an intermediate level discontinued in 20113 A Draft Standard was an intermediary step that occurred after a Proposed Standard but prior to an Internet Standard As put in RFC 2026 In general an Internet Standard is a specification that is stable and wellunderstood is technically competent has multiple independent and interoperable implementations with substantial operational experience enjoys significant public support and is recognizably useful in some or all parts of the Internet Overviewedit An Internet Standard is documented by4 a Request for Comments RFC or a set of RFCs A specification that is to become a Standard or part of a Standard begins as an Internet Draft and is later usually after several revisions accepted and published by the RFC Editor as an RFC and labeled a Proposed Standard Later an RFC is elevated as Internet Standard with an additional sequence number when maturity has reached an acceptable level Collectively these stages are known as the Standards Track and are defined in RFC 2026 and RFC 6410 The label Historic is applied to deprecated Standards Track documents or obsolete RFCs that were published before the Standards Track was established Only the IETF represented by the Internet Engineering Steering Group IESG can approve Standards Track RFCs The definitive list of Internet Standards is maintained in the Official Internet Protocol Standards Previously STD 1 used to maintain a snapshot of the list5 History and the purpose of Internet Standardsedit Internet standard is a set of rules that the devices have to follow when they connect in a network Since the technology has evolved the rules of the engagement between computers had to evolve with it These are the protocols that are in place used today Most of these were developed long before the Internet Age going as far back as the 1970s not long after the creation of personal computers TCPIP The official date for when the first internet went live is January 1 19836 The Transfer Control ProtocolInternet Protocol TCPIP went into effect ARPANETAdvanced Research Projects Agency Network and the Defense Data Network were the networks to implement the Protocols These protocols are considered to be the essential part of how the Internet works because they define the rules by which the connections between servers operate They are still used today by implementing various ways data is sent via global networks IPsec Internet Protocol Security is a collection of protocols that ensure the integrity of encryption in the connection between multiple devices The purpose of this protocol is to protect public networks According to IETF Datatracker the group dedicated to its creation was proposed into existence on 25 November 19927 Half a year later the group was created and not long after in the mid 1993 the first draft was published HTTP HyperText Transfer Protocol is one of the most commonly used protocols today in the context of the World Wide Web HTTP is a simple protocol to govern how documents that are written in HyperText Mark LanguageHTML are exchanged via networks This protocol is the backbone of the Web allowing for the whole hypertext system to exist practically It was created by the team of developers spearheaded by Tim BernersLee BernersLee is responsible for the proposal of its creation which he did in 1989 August 6 1991 is the date he published the first complete version of HTTP on a public forum8 This date subsequently is considered by some to be the official birth of the World Wide Web HTTP has been continually evolving since its creation becoming more complicated with time and progression of networking technology By default HTTP is not encrypted so in practice HTTPS is used which stands for HTTP Secure TLSSSL TLS stands for Transport Layer Security which is a standard that enables two different endpoints to interconnect sturdy and privately TLS came as a replacement for SSL Secure Sockets Layers was first introduced before the creation of HTTPS and it was created by Netscape As a matter of fact HTTPS was based on SSL when it first came out It was apparent that one common way of encrypting data was needed so the IETF specified TLS 10 in RFC 2246 in January 19999 It has been upgraded since Last version of TLS is 13 from RFC 8446 in August 2018 OSI Model The Open Systems Interconnection model began its development in 197710 It was created by the International Organization for Standardization It was officially published and adopted as a standard for use in 1979 It was then updated several times and the final version It took a few years for the protocol to be presented in its final form ISO 7498 was published in 1984 Lastly in 1995 the OSI model was revised again satisfy the urgent needs of uprising development in the field of computer network UDP The goal of User Datagram Protocol was to find a way to communicate between two computers as quickly and efficiently as possible UDP was conceived and realized by David P Reed in 198011 Essentially the way it works is using compression to send information Data would be compressed into a datagram and sent point to point This proved to be a secure way to transmit information and despite the drawback of losing quality of data UDP is still in use Standardization processedit Becoming a standard is a twostep process within the Internet Standards Process Proposed Standard and Internet Standard These are called maturity levels and the process is called the Standards Track If an RFC is part of a proposal that is on the Standards Track then at the first stage the standard is proposed and subsequently organizations decide whether to implement this Proposed Standard After the criteria in RFC 6410 is met two separate implementations widespread use no errata etc the RFC can advance to Internet Standard The Internet Standards Process is defined in several Best Current Practice documents notably BCP 9 currentlyupdate RFC 2026 and RFC 6410 There were previously three standard maturity levels Proposed Standard Draft Standard and Internet Standard RFC 6410 reduced this to two maturity levels Proposed Standardedit RFC 2026 originally characterized Proposed Standards as immature specifications but this stance was annulled by RFC 712712 A Proposed Standard specification is stable has resolved known design choices has received significant community review and appears to enjoy enough community interest to be considered valuable Usually neither implementation nor operational experience is required for the designation of a specification as a Proposed Standard Proposed Standards are of such quality that implementations can be deployed in the Internet However as with all technical specifications Proposed Standards may be revised if problems are found or better solutions are identified when experiences with deploying implementations of such technologies at scale is gathered Many Proposed Standards are actually deployed on the Internet and used extensively as stable protocols Actual practice has been that full progression through the sequence of standards levels is typically quite rare and most popular IETF protocols remain at Proposed Standard13 Draft Standardedit In October 2011 RFC 6410 merged the second and third maturity levels into one Draft Standard Existing older Draft Standards retain that classification The IESG can reclassify an old Draft Standard as Proposed Standard after two years October 2013 Internet Standardedit An Internet Standard is characterized by a high degree of technical maturity and by a generally held belief that the specified protocol or service provides significant benefit to the Internet community Generally Internet Standards cover interoperability of systems on the Internet through defining protocols message formats schemas and languages An Internet Standard ensures that hardware and software produced by different vendors can work together Having a standard makes it much easier to develop software and hardware that link different networks because software and hardware can be developed one layer at a time Normally the standards used in data communication are called protocols All Internet Standards are given a number in the STD series The series was summarized in its first document STD 1 RFC 5000 until 2013 but this practice was retired in RFC 7100 The definitive list of Internet Standards is now maintained by the RFC Editor14 Documents submitted to the IETF editor and accepted as an RFC are not revised if the document has to be changed it is submitted again and assigned a new RFC number When an RFC becomes an Internet Standard STD it is assigned an STD number but retains its RFC number When an Internet Standard is updated its number is unchanged but refers to a different RFC or set of RFCs For example in 2007 RFC 3700 was an Internet Standard STD 1 and in May 2008 it was replaced with RFC 5000 RFC 3700 received Historic status and RFC 5000 became STD 1 The list of Internet standards was originally published as STD 1 but this practice has been abandoned in favor of an online list maintained by the RFC Editor15 Organizations of Internet Standardsedit The standardization process is divided into three steps Proposed standards are standards to be implemented and can be changed at any time The draft standard was carefully tested in preparation for riverside to form the future Internet standard Internet standards are mature standards There are five Internet standards organizations the Internet Engineering Task Force IETF Internet Society ISOC Internet Architecture Board IAB Internet Research Task Force IRTF World Wide Web Consortium W3C All organizations are required to use and express the Internet language in order to remain competitive in the current Internet phase Some basic aims of the Internet Standards Process are ensure technical excellence earlier implementation and testing perfect succinct as well as easily understood records Creating and improving the Internet Standards is an ongoing effort and Internet Engineering Task Force plays a significant role in this regard These standards are shaped and available by the Internet Engineering Task Force IETF It is the leading Internet standards association that uses welldocumented procedures for creating these standards Once circulated those standards are made easily accessible without any cost Till 1993 the United States federal government was supporting the IETF Now the Internet Societys Internet Architecture Board IAB supervises it It is a bottomup organization that has no formal necessities for affiliation and does not have an official membership procedure either It watchfully works with the World Wide Web Consortium W3C and other standard development organizations Moreover it heavily relies on working groups that are constituted and proposed to an Area Director IETF relies on its working groups for expansion of IETF conditions and strategies with a goal to make the Internet work superior16 The working group then operates under the direction of the Area Director and progress an agreement After the circulation of the proposed charter to the IESG and IAB mailing lists and its approval then it is further forwarded to the public IETF It is not essential to have the complete agreement of all working groups and adopt the proposal IETF working groups are only required to recourse to check if the accord is strong Likewise the Working Group produce documents in the arrangement of RFCs which are memorandum containing approaches deeds examination as well as innovations suitable to the functioning of the Internet and Internetlinked arrangements In other words Requests for Comments RFCs are primarily used to mature a standard network protocol that is correlated with network statements Some RFCs are aimed to produce information while others are required to publish Internet standards The ultimate form of the RFC converts to the standard and is issued with a numeral After that no more comments or variations are acceptable for the concluding form17 This process is followed in every area to generate unanimous views about a problem related to the internet and develop internet standards as a solution to different glitches There are eight common areas on which IETF focus and uses various working groups along with an area director In the general area it works and develops the Internet standards In Application area it concentrates on internet applications such as Webrelated protocols Furthermore it also works on the development of internet infrastructure in the form of PPP extensions IETF also establish principles and descriptions for network processes such as remote network observing For example IETF emphasis the enlargement of technical standards that encompass the Internet protocol suite TCPIP The Internet Architecture Board IAB along with the Internet Research Task Force IRTF counterpart the exertion of the IETF using innovative technologies The IETF is the standards making organization concentrate on the generation of standard stipulations of expertise and their envisioned usage The IETF concentrates on matters associated with the progress of current Internet and TCPIP knowhow It is alienated into numerous working groups WGs every one of which is accountable for evolving standards and skills in a specific zone for example routing or security People in working groups are volunteers and work in fields such as equipment vendors network operators and different research institutions Firstly it works on getting the common consideration of the necessities that the effort should discourse Then an IETF Working Group is formed and necessities are ventilated in the influential Birds of a Feather BoF assemblies at IETF conferences Internet Engineering Task Forceedit The Internet Engineering Task Force IETF is the premier internet standards organization It follows an open and welldocumented processes for setting internet standards The resources that the IETF offers include RFCs internetdrafts IANA functions intellectual property rights standards process and publishing and accessing RFCs18 RFCsedit Documents that contain technical specifications and notes for the Internet The acronym RFC came from the phrase Request For Comments  this is not used anymore today and is now simply referred to as RFCs19 The website RFC Editor is an official archive of internet standards draft standards and proposed standards20 Internet Draftsedit Working documents of the IETF and its working groups21 Other groups may distribute working documents as InternetDrafts Intellectual property rightsedit All IETF standards are freely available to view and read and generally free to implement by anyone without permission or payment22 Standards Processedit The process of creating a standard is straightforward  a specification goes through an extensive review process by the Internet community and revised through experience23 Publishing and accessing RFCsedit InternetDrafts that successfully completed the review process Submitted to RFC editor for publication Types of Internet Standardsedit There are two ways in which an Internet Standard is formed and can be categorized as one of the following de jure standards and de facto standards24 A de facto standard becomes a standard through widespread use within the tech community A de jure standard is formally created by official standarddeveloping organizations24 These standards undergo the Internet Standards Process Common de jure standards include ASCII SCSI and Internet protocol suite20 Internet Standard Specificationsedit Specifications subject to the Internet Standards Process can be categorized into one of the following Technical Specification TS and Applicability Statement AS25 A Technical Specification is a statement describing all relevant aspects of a protocol service procedure convention or format25 This includes its scope and its intent for use or domain of applicability However a TSs use within the Internet is defined by an Applicability Statement An AS specifies how and under what circumstances TSs may be applied to support a particular Internet capability An AS identifies the ways in which relevant TSs are combined and specifies the parameters or subfunctions of TS protocols An AS also describes the domains of applicability of TSs such as Internet routers terminal server or datagrambased database servers25 An AS also applies one of the following requirement levels to each of the TSs to which it refers Required Implementation of the referenced TS is required to achieve interoperability For example Internet systems using the Internet Protocol Suite are required to implement IP and ICMP25 Recommended Implementation of the referenced TS is not required but is desirable in the domain of applicability of the AS Inclusion of the functions features and protocols of Recommended TSs in the developments of systems is encouraged For example the TELNET protocol should be implemented by all systems that intend to use remote access25 Elective Implementation of the referenced TS is optional The TS is only necessary in a specific environment For example the DECNET MIB could be seen as valuable in an environment where the DECNET protocol is used25 Common Standardsedit Web Standardsedit TCP IP Model  associated Internet Standards Web standards are a type of internet standard which define aspects of the World Wide Web They allow for the building and rendering of websites The three key standards used by the World Wide Web are Hypertext Transfer Protocol HTML and URL26 Respectively they specify the transfer of data between a browser and a web server the content and layout of a web page and what web page identifiers mean Network Standardsedit Network standards are a type of internet standard which defines rules for data communication in networking technologies and processes Internet standards allow for the communication procedure of a device to or from other devices In reference to the TCPIP Model common standards and protocols in each layer are as followscitation needed The Transport layer TCP and SPX Network layer IP and IPX Data Link layer IEEE 8023 for LAN and Frame Relay for WAN Physical layer 8P8C and V92 The future of Internet Standardsedit This article possibly contains original research Please improve it by verifying the claims made and adding inline citations Statements consisting only of original research should be removed May 2022 Learn how and when to remove this template message The Internet has been viewed as an open playground free for people to use and communities to monitor However large companies have shaped and molded it to best fit their needs The future of internet standards will be no different Currently there are widely used but insecure protocols such as the Border Gateway Protocol BGP and Domain Name System DNS27 This reflects common practices that focus more on innovation than security Companies have the power to improve these issues With the Internet in the hands of the industry users must depend on businesses to protect vulnerabilities present in these standards27 Ways to make BGP and DNS safer already exist but they are not widespread For example there is the existing BGP safeguard called Routing Public Key Infrastructure RPKI It is a database of routes that are known to be safe and have been cryptographically signed28 Users and companies submit routes and check other users routes for safety If it were more widely adopted more routes could be added and confirmed However RPKI is picking up momentum As of December 2020 tech giant Google registered 99 of its routes with RPKI28 They are making it easier for businesses to adopt BGP safeguards DNS also has a security protocol with a low adoption rate DNS Security Extensions DNSSEC Essentially at every stage of the DNS lookup process DNSSEC adds a signature to data to show it has not been tampered with29 Some companies have taken the initiative to secure internet protocols It is up to the rest to make it more widespread See alsoedit Internet portal Standardization Web standards Referencesedit  Leiba Barry January 2008 An Introduction to Internet Standards IEEE Internet Computing 12 1 7174 doi101109MIC20082 ISSN 10897801 S2CID 26168365 Archived from the original on 20220209 Retrieved 20220204  Cath Corinne Floridi Luciano April 2017 The Design of the Internets Architecture by the Internet Engineering Task Force IETF and Human Rights Science and Engineering Ethics 23 2 449468 doi101007s119480169793y ISSN 13533452 PMID 27255607 S2CID 3613408  Russell Housley Dave Crocker Eric W Burger 11 October 2011 Reducing the Standards Track to Two Maturity Levels IETF doi1017487RFC6410 RFC 6410  Huitema C Postel J Crocker S 1995 Not All RFCs are Standards IETF Request for Comments RFC Pages  Test ISSN 20701721 Archived from the original on 20180320 Retrieved 20180320  RFC 7100 Retirement of the Internet Official Protocol Standards Summary Document  A Brief History of the Internet wwwusgedu Archived from the original on 20020218 Retrieved 20211208  IP Security Protocol ipsec  datatrackerietforg Archived from the original on 20190913 Retrieved 20211208  Evolution of HTTP  HTTP  MDN developermozillaorg Archived from the original on 20230327 Retrieved 20211208  Transport Layer Security TLS  MDN Web Docs Glossary Definitions of Webrelated terms  MDN developermozillaorg Archived from the original on 20211208 Retrieved 20211208  Alani Mohammed M 2014 OSI Model Guide to OSI and TCPIP Models SpringerBriefs in Computer Science Cham Springer International Publishing pp 517 doi1010079783319051529_2 ISBN 9783319051512 retrieved 20211208  What Is UDP  DiverseNet Inc Archived from the original on 20211208 Retrieved 20211208  Characterization of Specifications Characterization of Proposed Standards IETF January 2014 sec 3 doi1017487RFC7127 RFC 7127 Retrieved March 11 2016  IETF Review of Proposed Standards Characterization of Proposed Standards IETF January 2014 sec 2 doi1017487RFC7127 RFC 7127 Retrieved March 11 2016  Official Internet Protocol Standards Archived from the original on 20180315 Retrieved 20180319  RFC 7100  Ma D Mandelberg D Bruijnzeels T August 2018 Simplified Local Internet Number Resource Management with the RPKI SLURM doi1017487rfc8416 RFC 8416  Knieps Günter September 2015 Entrepreneurial Traffic Management and the Internet Engineering Task Force Journal of Competition Law and Economics 11 3 727745 doi101093joclecnhv018 ISSN 17446414  Society Internet Engineering Task Force Internet 2005 IETF journal Internet Society OCLC 746928702  RFCs IETF Archived from the original on 20211206 Retrieved 20211208  a b Internet Official Protocol Standards May 2008 doi1017487rfc5000 RFC 5000  Farrel A April 2014 Handling of InternetDrafts by IETF Working Groups doi1017487rfc7221 RFC 7221  Intellectual Property Rights in IETF Technology March 2005 doi1017487rfc3979 RFC 3979  Hovey R Bradner S October 1996 The Organizations Involved in the IETF Standards Process doi1017487rfc2028 RFC 2028  a b Nickerson Muehlen 2006 The Ecology of Standards Processes Insights from Internet Standard Making MIS Quarterly 30 467488 doi10230725148769 JSTOR 25148769  a b c d e f Bradner S October 1996 The Internet Standards Process  Revision 3 doi1017487rfc2026 RFC 2026  Comer Douglas 2015 Computer networks and Internets Sixth ed Boston MA ISBN 9780133587937 OCLC 870649960cite book CS1 maint location missing publisher link  a b Sherman Justin 1 October 2020 Mapping Private Sector Influence on the Internet Starting with Internet Protocols The Politics of Internet Security Private Industry and the Future of the Web Report Atlantic Council pp 47 JSTOR resrep266615  a b Newman Lily Hay A Broken Piece of Internet Backbone Might Finally Get Fixed Wired ISSN 10591028 Retrieved 20211208  DNSSEC An Introduction The Cloudflare Blog 20141007 Archived from the original on 20211206 Retrieved 20211208 External linksedit RFC Editor Retrieved from httpsenwikipediaorgwindexphptitleInternet_Standardoldid1183126917 Category Internet StandardsHidden categories CS1 maint location missing publisherArticles with short descriptionShort description is different from WikidataArticles lacking reliable references from November 2015All articles lacking reliable referencesArticles containing potentially dated statements from 2011All articles containing potentially dated statementsAll articles with unsourced statementsArticles with unsourced statements from June 2023Articles that may contain original research from May 2022All articles that may contain original researchPages using div col with small parameter This article relies excessively on references to primary sources Please improve this article by adding secondary or tertiary sources Find sources Internet Standard  news  newspapers  books  scholar  JSTOR November 2015 Learn how and when to remove this template message 0 This article relies excessively on references to primary sources Please improve this article by adding secondary or tertiary sources Find sources Internet Standard  news  newspapers  books  scholar  JSTOR November 2015 Learn how and when to remove this template message This article possibly contains original research Please improve it by verifying the claims made and adding inline citations Statements consisting only of original research should be removed May 2022 Learn how and when to remove this template message 0 This article possibly contains original research Please improve it by verifying the claims made and adding inline citations Statements consisting only of original research should be removed May 2022 Learn how and when to remove this template message, Ramotion Blog MVC Architecture Simplifying Web Application DevelopmentWeb App DevelopmentMVC Architecture Simplifying Web Application DevelopmentThe ModelViewController MVC architecture is a popular approach for building web applications Learn how it simplifies development and improves scalabilityWritten by RamotionMay 2 202310 min readLast updated Aug 22 2023Table of ContentsIntroductionMVC ArchitectureAdvantages of MVCDisadvantages of MVCPopular MVC FrameworksMVC ExamplesConclusionIntroductionWeb apps are everywhere these days Every company wants an online presence There are a lot of them Amazon Google and Twitter The MVC architecture is a popular way to build web applications that allow companies the benefits of scalability reusability and maintainability  something thats very important for the success of any online business The purpose of this article is to provide you with a brief history of web applications to give an overview of how MVC architecture alleviates some scalability issues and to provide specific examples of how MVC architecture can help complex web applications operate more smoothly than with other approachesWhat is the MVC pattern for web applicationsMVC stands for ModelViewController this pattern was developed in the mid1990s to help web developers create web applications that were not only userfriendly but also easy to maintain This pattern is still used today and can be seen in many common web frameworks such as Ruby on Rails Laravel and ASPNET MVCThe MVC pattern is a software design pattern for web applications The MVC framework separates an application into three main components models views and controllers Models are used to store data and business logic views display data from a model on the screen and controllers manage user interactions with these two components Brief history of MVC Framework The history of web applications is a long one but it began with the introduction of the first web browser in 1993 This was Netscape Navigator which provided users with an easy way to access information on the Internet without having to know how to code HTML or any other language As more and more people started accessing the web and interacting online companies began noticing that they needed new ways to build their websites to make them more userfriendly This led to the introduction of the ModelViewController MVC framework which provided a simple way for web developers to create complex applications The MVC framework was first introduced by Trygve Reenskaug in 1979 as a way to manage interactions between users and computers and is still used todayMVC ArchitectureHighlevel overview of the MVC architecture The MVC framework is a software architecture that separates the user interface UI data storage and business logic into three separate components This allows developers to work on each component independently without affecting the other two parts of the application The MVC framework consists of three main components ModelThe model represents the data logic and data that is stored in your application This can be a simple data structure like an array or dictionary or it can be a complex data set with properties and methods The model typically stores information about what happened in one or more events such as user input or database queries The model also provides a way to access data from the UI This includes storing user input retrieving data from the database and performing other tasks that are necessary for your applications functionality ViewThe view is where your applications user interface lives and this is what the user sees It takes the data provided by the model and displays it on screen in a way that users can interact with The view typically contains HTML markup CSS styles and JavaScript code that provides interactive functionality like form validation or draganddrop interactions It is important to note that the view does not contain any logic It only displays data and handles user input ControllerThe controller is a component that sits between the model and the view It is responsible for handling user interaction with the view as well as performing any logic necessary to prepare data for display For example if a user clicks on a button in your applications UI this will trigger an event in JavaScript which will be handled by the controllerin turn it can use this information to retrieve data from the database or perform other tasks A diagram of MVC architecture in a web applicationAdvantages of MVCThe MVC pattern is a proven popular way to structure your code MVC architecture helps you to organize your web application and make it more manageable It allows you to separate business logic from presentation logic which makes it very easy to add new features or change existing ones without affecting the whole application Clean and organized code MVC helps you to write clean and organized code When you use the MVC architecture the controller handles all requests and responses This means that it will be responsible for retrieving data from a database or performing other tasks which will be handled by the controllerin turn it can use this information to retrieve data from the database or perform other tasks This makes it very easy to maintain and extend the application It also helps you to write clean code as there is no need to write code that will handle data retrieval or perform other tasks which will be handled by the controller Easy to test and debug When you use the MVC design pattern its easy to test and debug your application This is because the controller can be easily isolated from other components in your application You can write tests for the controller without having any dependencies on other parts of the system Improved scalability and flexibility MVC pattern helps you to build scalable and flexible applications This is because the model view and controller components can be shared across multiple applications So if you have a set of requirements that are similar to those used in another project you dont have to spend a lot of time writing new code for them again Improved team productivity and collaboration MVC pattern is a great way to improve team productivity and collaboration because it enables you to divide the work among different teams who can then work in parallel For example one team could focus on writing code for the model component and another team could take care of coding for the view component By dividing the work among different teams you can improve team productivity and collaboration This is because you dont have to wait for one team to finish before starting work on another component of your application You can also easily add more teams if there are too many tasks that need to be completed in parallelDisadvantages of MVCIncreased complexity The main disadvantage of MVC is increased complexity As your application grows the number of files that need to be maintained increases as well This makes it difficult for developers to keep track of every file and ensure that they are always uptodate with the latest changes in the codebase In practice this means that developers will have to spend more time navigating between different files and trying to find out where specific code is being used You also need a lot of experience with MVC frameworks in order to create applications that are highly maintainable Steep learning curve The learning curve for MVC is quite steep This can be a problem if you are trying to create an application with a small team or one that has only recently started using this technology It takes time for developers to learn how all the different pieces fit together including routing controllers and views Potential performance issues MVC applications can suffer from performance issues when they are not built correctly If the code is not wellwritten it can cause rendering problems and slow down your entire application Limited control over the user interface MVC is not very flexible when it comes to the user interface You have very little control over how the application looks and feels which can be problematic if you have a specific look and feel in mind for your projectPopular MVC FrameworksRuby on Rails Ruby on Rails is an opensource web development framework written in Ruby programming language created by David Heinemeier Hansson It provides a number of features that make it easy to develop and maintain complex web applications Its built on top of the objectoriented programming language Ruby and follows the modelviewcontroller MVC architectural pattern Rails are MVC based which means it separates all the UI components into three different parts Model View and Controller Django Django is a free and opensource web application framework written in Python It follows MVC architecture and provides an integrated set of components for the rapid development of complex databasedriven websites Django is developed by the Django Software Foundation DSF and its licensed under the Apache License version 20 Laravel Laravel is a free opensource PHP framework for web development It was created by Taylor Otwell and intended for developing and designing web applications following the modelviewcontroller MVC architectural pattern primarily using the PHP programming language Laravel aims to make the development process a pleasing one for developers who use it Spring MVC The Spring MVC framework is an opensource Java web application framework that provides a robust set of features for developing enterprisegrade MVC applications Its designed to be easy to use highly testable and extensible Spring MVC enables you to build web applications in Java without having to worry about the plumbing code that makes up the middle tier the controller It handles all of this for you leaving you free to concentrate on your application logic It also provides support for internationalization i18n and localization l10n so you can easily display content in multiple languagesMVC ExamplesBasic CRUD application using MVC architecture A basic CRUD Create Read Update Delete application using MVC architecture would involve creating a model for the data a view for the user interface and a controller to handle user input and data operations The user would be able to create new records read existing ones update them and delete them through the interface with the controller handling the interactions between the view and the model This architecture provides a structured and modular approach to web application development making it easier to manage and scale the application over time Sample code snippet demonstrating MVC implementation Heres a sample code snippet demonstrating the implementation of the MVC architecture in Ruby on Rails Modelclass User  ApplicationRecord validates name presence true validates email presence true uniqueness true end CopyViewh1Usersh1 table thead tr thNameth thEmailth tr thead tbody  userseach do user  tr td username td td useremail td tr  end  tbody table CopyControllerclass UsersController  ApplicationController def index users  Userall end def new user  Usernew end def create user  Usernewuser_params if usersave redirect_to users_path notice User created successfully else render new end end private def user_params paramsrequireuserpermitname email end end CopyThis code defines a User model with name and email attributes an index view to display all users and actions in the UsersController that allow us to create new users or see them listed by nameConclusionIn this article we explored the ModelViewController MVC architecture in web applications which separates an application into three interconnected components the model view and controller The model represents the data and business logic the view handles the user interface and the controller acts as the intermediary between the two handling user input and data operations We also looked at a sample implementation of the MVC architecture in Ruby on Rails which demonstrated how the three components work together to create a structured and modular web application Overall the MVC architecture is a popular approach for building web applications due to its modularity scalability and maintainability It provides a clear separation of concerns making it easier to manage and modify the different components of an application However it can be challenging to implement correctly and requires careful planning and design By using MVC architecture web developers can create more organized and efficient applications that are easier to maintain and scale over time As technology continues to evolve it will be interesting to see how the MVC architecture evolves as well to meet the changing needs of web developmentShareRelated postsMay 1 2023Web App DevelopmentUnderstanding MVVM ModelViewViewModel Architecture ExplainedMVVM is a popular design pattern used in modern software development This article explains what MVVM is how it works and its benefits10 min readApr 6 2022Web App DevelopmentWeb Application Architecture  Modern GuideDiscover the application architecture best practices and learn what the web app architecture consists of Find new opportunities today16 min readRamotionRamotion is an award winning design agency with more than 10 years of experience in the industry The team designed Firefox logo Bitmoji by Snapchat and lot of other famous brands In addition to brand identity design Ramotion provides UIUX develop websites and appsLinkedInTwitterInstagramFacebookPartner with usUnlock your business potential with our committed team driving your successContact usPopularAgencyWeb Developer PortfoliosWhat is Web ApplicationHire developers for StartupResponsive Web App DevelopmentWeb App Development AgencyWeb App Development Agency for StartupsWeb App Development Agency in San FranciscoWeb App Development Agency in Los AngelesWeb App Development Agency in New YorkUnlock your business potential with usEmpower your business with tailored strategy innovative design and seamless development Ready to take your company to the next levelContact us class User  ApplicationRecord validates name presence true validates email presence true uniqueness true end h1Usersh1 table thead tr thNameth thEmailth tr thead tbody  userseach do user  tr td username td td useremail td tr  end  tbody table class UsersController  ApplicationController def index users  Userall end def new user  Usernew end def create user  Usernewuser_params if usersave redirect_to users_path notice User created successfully else render new end end private def user_params paramsrequireuserpermitname email end end ","https://en.wikipedia.org/wiki/Internet_Standard, https://www.ramotion.com/blog/mvc-architecture-in-web-application/",Networking,2053,6412
MVC Architecture in Web Development,Ramotion Blog MVC Architecture Simplifying Web Application DevelopmentWeb App DevelopmentMVC Architecture Simplifying Web Application DevelopmentThe ModelViewController MVC architecture is a popular approach for building web applications Learn how it simplifies development and improves scalabilityWritten by RamotionMay 2 202310 min readLast updated Aug 22 2023Table of ContentsIntroductionMVC ArchitectureAdvantages of MVCDisadvantages of MVCPopular MVC FrameworksMVC ExamplesConclusionIntroductionWeb apps are everywhere these days Every company wants an online presence There are a lot of them Amazon Google and Twitter The MVC architecture is a popular way to build web applications that allow companies the benefits of scalability reusability and maintainability  something thats very important for the success of any online business The purpose of this article is to provide you with a brief history of web applications to give an overview of how MVC architecture alleviates some scalability issues and to provide specific examples of how MVC architecture can help complex web applications operate more smoothly than with other approachesWhat is the MVC pattern for web applicationsMVC stands for ModelViewController this pattern was developed in the mid1990s to help web developers create web applications that were not only userfriendly but also easy to maintain This pattern is still used today and can be seen in many common web frameworks such as Ruby on Rails Laravel and ASPNET MVCThe MVC pattern is a software design pattern for web applications The MVC framework separates an application into three main components models views and controllers Models are used to store data and business logic views display data from a model on the screen and controllers manage user interactions with these two components Brief history of MVC Framework The history of web applications is a long one but it began with the introduction of the first web browser in 1993 This was Netscape Navigator which provided users with an easy way to access information on the Internet without having to know how to code HTML or any other language As more and more people started accessing the web and interacting online companies began noticing that they needed new ways to build their websites to make them more userfriendly This led to the introduction of the ModelViewController MVC framework which provided a simple way for web developers to create complex applications The MVC framework was first introduced by Trygve Reenskaug in 1979 as a way to manage interactions between users and computers and is still used todayMVC ArchitectureHighlevel overview of the MVC architecture The MVC framework is a software architecture that separates the user interface UI data storage and business logic into three separate components This allows developers to work on each component independently without affecting the other two parts of the application The MVC framework consists of three main components ModelThe model represents the data logic and data that is stored in your application This can be a simple data structure like an array or dictionary or it can be a complex data set with properties and methods The model typically stores information about what happened in one or more events such as user input or database queries The model also provides a way to access data from the UI This includes storing user input retrieving data from the database and performing other tasks that are necessary for your applications functionality ViewThe view is where your applications user interface lives and this is what the user sees It takes the data provided by the model and displays it on screen in a way that users can interact with The view typically contains HTML markup CSS styles and JavaScript code that provides interactive functionality like form validation or draganddrop interactions It is important to note that the view does not contain any logic It only displays data and handles user input ControllerThe controller is a component that sits between the model and the view It is responsible for handling user interaction with the view as well as performing any logic necessary to prepare data for display For example if a user clicks on a button in your applications UI this will trigger an event in JavaScript which will be handled by the controllerin turn it can use this information to retrieve data from the database or perform other tasks A diagram of MVC architecture in a web applicationAdvantages of MVCThe MVC pattern is a proven popular way to structure your code MVC architecture helps you to organize your web application and make it more manageable It allows you to separate business logic from presentation logic which makes it very easy to add new features or change existing ones without affecting the whole application Clean and organized code MVC helps you to write clean and organized code When you use the MVC architecture the controller handles all requests and responses This means that it will be responsible for retrieving data from a database or performing other tasks which will be handled by the controllerin turn it can use this information to retrieve data from the database or perform other tasks This makes it very easy to maintain and extend the application It also helps you to write clean code as there is no need to write code that will handle data retrieval or perform other tasks which will be handled by the controller Easy to test and debug When you use the MVC design pattern its easy to test and debug your application This is because the controller can be easily isolated from other components in your application You can write tests for the controller without having any dependencies on other parts of the system Improved scalability and flexibility MVC pattern helps you to build scalable and flexible applications This is because the model view and controller components can be shared across multiple applications So if you have a set of requirements that are similar to those used in another project you dont have to spend a lot of time writing new code for them again Improved team productivity and collaboration MVC pattern is a great way to improve team productivity and collaboration because it enables you to divide the work among different teams who can then work in parallel For example one team could focus on writing code for the model component and another team could take care of coding for the view component By dividing the work among different teams you can improve team productivity and collaboration This is because you dont have to wait for one team to finish before starting work on another component of your application You can also easily add more teams if there are too many tasks that need to be completed in parallelDisadvantages of MVCIncreased complexity The main disadvantage of MVC is increased complexity As your application grows the number of files that need to be maintained increases as well This makes it difficult for developers to keep track of every file and ensure that they are always uptodate with the latest changes in the codebase In practice this means that developers will have to spend more time navigating between different files and trying to find out where specific code is being used You also need a lot of experience with MVC frameworks in order to create applications that are highly maintainable Steep learning curve The learning curve for MVC is quite steep This can be a problem if you are trying to create an application with a small team or one that has only recently started using this technology It takes time for developers to learn how all the different pieces fit together including routing controllers and views Potential performance issues MVC applications can suffer from performance issues when they are not built correctly If the code is not wellwritten it can cause rendering problems and slow down your entire application Limited control over the user interface MVC is not very flexible when it comes to the user interface You have very little control over how the application looks and feels which can be problematic if you have a specific look and feel in mind for your projectPopular MVC FrameworksRuby on Rails Ruby on Rails is an opensource web development framework written in Ruby programming language created by David Heinemeier Hansson It provides a number of features that make it easy to develop and maintain complex web applications Its built on top of the objectoriented programming language Ruby and follows the modelviewcontroller MVC architectural pattern Rails are MVC based which means it separates all the UI components into three different parts Model View and Controller Django Django is a free and opensource web application framework written in Python It follows MVC architecture and provides an integrated set of components for the rapid development of complex databasedriven websites Django is developed by the Django Software Foundation DSF and its licensed under the Apache License version 20 Laravel Laravel is a free opensource PHP framework for web development It was created by Taylor Otwell and intended for developing and designing web applications following the modelviewcontroller MVC architectural pattern primarily using the PHP programming language Laravel aims to make the development process a pleasing one for developers who use it Spring MVC The Spring MVC framework is an opensource Java web application framework that provides a robust set of features for developing enterprisegrade MVC applications Its designed to be easy to use highly testable and extensible Spring MVC enables you to build web applications in Java without having to worry about the plumbing code that makes up the middle tier the controller It handles all of this for you leaving you free to concentrate on your application logic It also provides support for internationalization i18n and localization l10n so you can easily display content in multiple languagesMVC ExamplesBasic CRUD application using MVC architecture A basic CRUD Create Read Update Delete application using MVC architecture would involve creating a model for the data a view for the user interface and a controller to handle user input and data operations The user would be able to create new records read existing ones update them and delete them through the interface with the controller handling the interactions between the view and the model This architecture provides a structured and modular approach to web application development making it easier to manage and scale the application over time Sample code snippet demonstrating MVC implementation Heres a sample code snippet demonstrating the implementation of the MVC architecture in Ruby on Rails Modelclass User  ApplicationRecord validates name presence true validates email presence true uniqueness true end CopyViewh1Usersh1 table thead tr thNameth thEmailth tr thead tbody  userseach do user  tr td username td td useremail td tr  end  tbody table CopyControllerclass UsersController  ApplicationController def index users  Userall end def new user  Usernew end def create user  Usernewuser_params if usersave redirect_to users_path notice User created successfully else render new end end private def user_params paramsrequireuserpermitname email end end CopyThis code defines a User model with name and email attributes an index view to display all users and actions in the UsersController that allow us to create new users or see them listed by nameConclusionIn this article we explored the ModelViewController MVC architecture in web applications which separates an application into three interconnected components the model view and controller The model represents the data and business logic the view handles the user interface and the controller acts as the intermediary between the two handling user input and data operations We also looked at a sample implementation of the MVC architecture in Ruby on Rails which demonstrated how the three components work together to create a structured and modular web application Overall the MVC architecture is a popular approach for building web applications due to its modularity scalability and maintainability It provides a clear separation of concerns making it easier to manage and modify the different components of an application However it can be challenging to implement correctly and requires careful planning and design By using MVC architecture web developers can create more organized and efficient applications that are easier to maintain and scale over time As technology continues to evolve it will be interesting to see how the MVC architecture evolves as well to meet the changing needs of web developmentShareRelated postsMay 1 2023Web App DevelopmentUnderstanding MVVM ModelViewViewModel Architecture ExplainedMVVM is a popular design pattern used in modern software development This article explains what MVVM is how it works and its benefits10 min readApr 6 2022Web App DevelopmentWeb Application Architecture  Modern GuideDiscover the application architecture best practices and learn what the web app architecture consists of Find new opportunities today16 min readRamotionRamotion is an award winning design agency with more than 10 years of experience in the industry The team designed Firefox logo Bitmoji by Snapchat and lot of other famous brands In addition to brand identity design Ramotion provides UIUX develop websites and appsLinkedInTwitterInstagramFacebookPartner with usUnlock your business potential with our committed team driving your successContact usPopularAgencyWeb Developer PortfoliosWhat is Web ApplicationHire developers for StartupResponsive Web App DevelopmentWeb App Development AgencyWeb App Development Agency for StartupsWeb App Development Agency in San FranciscoWeb App Development Agency in Los AngelesWeb App Development Agency in New YorkUnlock your business potential with usEmpower your business with tailored strategy innovative design and seamless development Ready to take your company to the next levelContact us class User  ApplicationRecord validates name presence true validates email presence true uniqueness true end h1Usersh1 table thead tr thNameth thEmailth tr thead tbody  userseach do user  tr td username td td useremail td tr  end  tbody table class UsersController  ApplicationController def index users  Userall end def new user  Usernew end def create user  Usernewuser_params if usersave redirect_to users_path notice User created successfully else render new end end private def user_params paramsrequireuserpermitname email end end ,https://www.ramotion.com/blog/mvc-architecture-in-web-application/,Back-End Development,700,2280
Web Application Security Threats,10 Web Application Security Threats and How to Mitigate ThemStackHawkMarch 1 2023Delve into 10 common web application security threats their consequences how web apps are vulnerable to them and how to mitigate themWeb application security is crucial to ensuring the safety and security of online systems and their users As more and more daily activities and transactions move online the importance of securing web applications becomes increasingly clear Daily reports of breaches and alwayschanging security threats mean that security is a top priority for every organizationIn this article well explore ten common web application security threats the consequences of these threats how web applications are vulnerable to them and how to mitigate them10 Web Application Security ThreatsHere are the ten common web application security threats we will cover in this articleSQL injectionCrosssite scripting XSSCrosssite request forgery CSRFInsecure direct object referencesRemote code executionInsufficient logging and monitoringInsecure cryptographic storageFailure to restrict URL accessCrossorigin resource sharing CORS misconfigurationUsing components with known vulnerabilities1 SQL InjectionA SQL injection attack is executed when an attacker injects malicious code into an applications database through user input fields These types of attacks can accomplish many different things Two of the most common outcomes include allowing the attacker to gain unauthorized access to sensitive data stored in the database Depending on what data the database is storing the attack could get access to passwords financial information and personal data The second outcome could be the manipulation or deletion of data For instance a user may be able to execute a DROP TABLE or DROP DATABASE commandYou can mitigate this with the following stepsValidate user inputUse output encoding which involves converting special characters such as  and  into their HTML entity equivalents to prevent them from being interpreted as HTML codeUse prepared statements parameterized queries or stored procedures instead of dynamic SQL whenever possibleMost languages and frameworks have recommended ways of handling form input By combing frontend and backend standards to prevent SQL injection from happening your application can increase its security against this type of threat2 CrossSite Scripting XSSCrosssite scripting XSS attacks involve injecting malicious code or a malicious script into a website The website then executes the script allowing the attacker to steal sensitive user data like session tokens and cookies or perform other actionsThere are two main types of XSS attacks reflective and stored Reflective XSS attacks involve injecting malicious code into a website that is immediately executed Stored XSS attacks involve injecting malicious code into a website that is stored and executed at a later timeIf successful a crosssite scripting attack can result in the theft of user session IDs website defacement and redirection to malicious sites thereby enabling phishing attacksYou can mitigate this with the following stepsValidate user inputUse output encoding techniquesUse autosanitization libraries such as OWASP AntiSamyImplement a content security policySimilar to the recommendation for SQL injection using modern web frameworks generally tends to steer developers towards secure coding practices to avoid XSS and similar attacks3 CrossSite Request Forgery CSRFCrosssite request forgery CSRF is a type of attack that involves tricking a victim into performing an action on a website without their knowledge This can be done by injecting a malicious link or form into a website that the victim is already authenticated onWhen the victim clicks the link or submits the form the action is performed on their behalf potentially leading to data loss or unauthorized accessYou can mitigate this with the following stepsLeverage CSRF protections already built into the framework you are using if applicableUse CSRF tokens These are unique randomized values associated with a users session and are included in forms and links to verify the authenticity of the requestUse SameSite cookies These are a type of cookie that is only sent with requests to the same origin as the cookies creation This can help prevent attackers from being able to send requests on behalf of a victim as they would not have access to the victims SameSite cookies4 Insecure Direct Object References IDORInsecure Direct Object References or IDOR occur when an application exposes direct object references such as URLs or database keys that allow attackers to access restricted data by manipulating these referencesFor example an application may allow users to access their account information by entering their account number in a URL such as wwwexamplecomaccount123 An attacker could potentially access other users account information by changing the account number in the URLYou can mitigate this with the following stepsImplement proper access controls and session management This involves setting up mechanisms to ensure that only authorized users have access to certain resources or data The OWASP cheat sheets on authorization and authentication can be helpful resources for reviewing best practices in these areasValidate user input To help prevent attackers from manipulating direct object references to accessrestricted data ensure that user input is the correct type length and formatAvoid using predictable references Instead consider using globally unique identifiers GUIDs to prevent attackers from guessing the direct object references they need to access restricted dataAs noted in the mitigation steps above IDORbased vulnerabilities dont occur on their own These vulnerabilities must be coupled with other vulnerabilities to become an effective attack vector5 Remote Code Execution RCERemote Code Execution RCE attacks allow attackers to execute arbitrary code on a server potentially leading to full system compromise and unauthorized access to sensitive dataRCE attacks can occur through a variety of means such as exploiting vulnerabilities in code libraries or injecting malicious code through user input fieldsA successful RCE attack can have several consequences These include Denial of Service DoS attacks exposure of sensitive data illicit cryptocurrency mining and execution of malware In some cases a successful RCE attack can even give full control over the compromised machine to the attackerYou can mitigate this with the following stepsSanitize user inputImplement secure memory management RCE attackers can potentially take advantage of memory management flaws such as buffer overflows Conducting regular security vulnerability scans on your applications can help you identify buffer overflow and memoryrelated vulnerabilities that an attacker could exploitAlways keep your operating system and your thirdparty software up to date to ensure that you have the latest security patchesLimit the attackers ability to move through a network y implementing network segmentation access management and a zerotrust security strategyRCE attacks have been a major source of breaches in the last few years many leading to worldwide security emergencies One that many people will remember is the Log4j fiasco discovered in 2021 where multiple RCE vulnerabilities were discovered in Log4j These RCE vulnerabilities allowed attackers to exploit vulnerable applications to execute Cryptojacking attacks and other malware on compromised servers6 Insufficient Logging and MonitoringInsufficient logging and monitoring refer to a lack of proper logging and monitoring processes in place to detect and respond to security threats This can allow attackers to go unnoticed and continue to compromise the system potentially leading to data loss and financial lossIts also important to be aware of what is being logged If secure information such as credit card numbers or passwords are being written to logs attackers who gain access to the logs could use this information maliciously Fraudulent credit card charges or unauthorized access to a system could be easily executedYou can mitigate this with the following stepsEnable logging for key events and actions in your application and monitor logs regularlyUse log analysis tools These can help automate the process of reviewing logs and identify potential security issues or anomalies more quickly and efficientlySet up alerting systems to notify administrators of any potential security issues in real time allowing them to respond more quickly to potential threatsEnsure that sensitive information is either not included in logs or is properly masked7 Insecure Cryptographic StorageInsecure cryptographic storage refers to the improper handling of cryptographic keys such as storing them in plain text or using weak keys This can allow attackers to gain access to sensitive data through compromised cryptographic keysYou can mitigate this with the following stepsUse strong cryptographic algorithms such as AES or RSA to secure stored dataImplement key management best practices such as regularly rotating keys and securely storing them to help prevent unauthorized access to encrypted dataUse secure storage solutions such as hardware security modules or encrypted storage devices to help further protect encrypted dataOne suggestion is also to audit the data that you need to store in an encrypted state The best way to protect data is to simply not store it at all If sensitive data is being stored without need it may be best to forego the storage of this data to lessen the data that potential attackers have access to8 Failure to Restrict URL Access  Broken Access ControlFailure to restrict URL access refers to a lack of proper access controls that allow unauthorized users to access restricted pages and resources This can allow attackers to access sensitive data and potentially compromise the systemThis security threat is mostly similar and related to the IDOR vulnerabilities we discussed earlier The core differentiating factor between the two is that IDOR tends to give the attacker access to information in the database while failure to restrict URL access allows the attacker access to special functions and features that should not be available to any typical userYou can mitigate this with the following stepsImplement proper access controls by setting up authentication and authorization processes to ensure that only authorized users have access to certain resources or functionsUse rolebased authorization The enforcement mechanism should deny all access by default requiring explicit grants to specific users and roles for access to every pageImplement adequate authorization measures at relevant stages of user web app useMany routing libraries and routing mechanisms built into modern web frameworks tend to protect against this by default By making sure that the application routing is set up correctly these types of vulnerabilities can be completely avoided9 CrossOrigin Resource Sharing CORS MisconfigurationCrossOrigin Resource Sharing CORS is a security feature that allows a web server to specify which domains are allowed to access its resources However if CORS is misconfigured it can allow attackers to access restricted resources from a different origin This could potentially expose data through services that can be used without authorizationYou can mitigate this with the following stepsProperly configure CORS headersUse CORS libraries that provide an easytouse interface for configuring CORS headers to help you configure CORS properlyMany serverside frameworks and platforms can aid developers in properly configuring CORS for their services Developers should be aware of how CORS can be configured in the framework of their choosing One common reason for CORS security misconfiguration is that when developers are creating applications locally they will set an entirely open CORS policy for easier development Ensuring that these policies do not get checked into production code is crucial10 Using Components with Known VulnerabilitiesUsing components with known vulnerabilities refers to the use of outdated code libraries frameworks or other components with known vulnerabilitiesMany websites today are built using complex components which can make it difficult for development teams to understand their internal workings This can create potential vulnerabilities if a component contains known security issues that are not properly addressedYou can mitigate this with the following stepsKeep track of component versions You can address any vulnerabilities by regularly checking for updates and staying up to date with the latest versions of componentsUse security scanners to help you identify known vulnerabilities in components and alert developers to potential issuesUsing tools like Dependabot can help keep your dependencies up to date automatically By using scanning tools and automation keeping dependencies secure and uptodate is easy to do as part of the development processWhat Is the Biggest Security Threat to a Web ApplicationIts difficult to determine the single biggest threat to a web application This is because it depends on the specific web application and its unique vulnerabilitiesHowever the most common application security threats according to the OWASP Top 10 are broken access control cryptographic failures and injection including SQL injection and crosssite scripting By using the latest tools for security scanning and monitoring as well as the latest secure coding practices developers and their organizations can limit their exposure ConclusionWeb applications are an integral part of modern life and as such theyre a common target for attackers By understanding common security threats and implementing proper mitigation techniques web application developers and administrators can help protect their systems and users To assist with this process consider using a security platform like StackHawk to automate and improve your application security testingWith StackHawk developers can add Dynamic Application Security Testing directly into their CICD pipelines StackHawk scans the running application for vulnerabilities that are outlined in the OWASP Top 10 and more Developers are then able to view reports for each test that is executed uncover vulnerabilities and be guided on fixes The best part all of this can happen before the application hits production To see the benefits of StackHawk for yourself sign up today for a free trialLearn moreRead on to see how StackHawks CSO Scott Gerlach talks about Shift Left being more than just a buzzword here Check out why Omdias On the Radar report highlights StackHawk as an interesting alternative to most other DAST tools hereGetting started with StackHawk Check out Advice and Answers from the amazing StackHawk team here StackHawk  March 1 2023Read MoreAdd AppSec to Your CircleCI Pipeline With the StackHawk OrbApplication Security is Broken Here is How We Intend to Fix ItUsing StackHawk in GitLab Know Before You Go Live ,https://www.stackhawk.com/blog/10-web-application-security-threats-and-how-to-mitigate-them/,Security,811,2241
Cross-Origin Resource Sharing (CORS),CrossOrigin Resource Sharing CORSCrossOrigin Resource Sharing CORS is an HTTPheader based mechanism that allows a server to indicate any origins domain scheme or port other than its own from which a browser should permit loading resources CORS also relies on a mechanism by which browsers make a preflight request to the server hosting the crossorigin resource in order to check that the server will permit the actual request In that preflight the browser sends headers that indicate the HTTP method and headers that will be used in the actual request An example of a crossorigin request the frontend JavaScript code served from httpsdomainacom uses fetch to make a request for httpsdomainbcomdatajson For security reasons browsers restrict crossorigin HTTP requests initiated from scripts For example fetch and XMLHttpRequest follow the sameorigin policy This means that a web application using those APIs can only request resources from the same origin the application was loaded from unless the response from other origins includes the right CORS headers The CORS mechanism supports secure crossorigin requests and data transfers between browsers and servers Browsers use CORS in APIs such as fetch or XMLHttpRequest to mitigate the risks of crossorigin HTTP requestsWhat requests use CORSThis crossorigin sharing standard can enable crossorigin HTTP requests for Invocations of fetch or XMLHttpRequest as discussed above Web Fonts for crossdomain font usage in fontface within CSS so that servers can deploy TrueType fonts that can only be loaded crossorigin and used by websites that are permitted to do so WebGL textures Imagesvideo frames drawn to a canvas using drawImage CSS Shapes from images This is a general article about CrossOrigin Resource Sharing and includes a discussion of the necessary HTTP headersFunctional overviewThe CrossOrigin Resource Sharing standard works by adding new HTTP headers that let servers describe which origins are permitted to read that information from a web browser Additionally for HTTP request methods that can cause sideeffects on server data in particular HTTP methods other than GET or POST with certain MIME types the specification mandates that browsers preflight the request soliciting supported methods from the server with the HTTP OPTIONS request method and then upon approval from the server sending the actual request Servers can also inform clients whether credentials such as Cookies and HTTP Authentication should be sent with requests CORS failures result in errors but for security reasons specifics about the error are not available to JavaScript All the code knows is that an error occurred The only way to determine what specifically went wrong is to look at the browsers console for details Subsequent sections discuss scenarios as well as provide a breakdown of the HTTP headers usedExamples of access control scenariosWe present three scenarios that demonstrate how CrossOrigin Resource Sharing works All these examples use fetch which can make crossorigin requests in any supporting browserSimple requestsSome requests dont trigger a CORS preflight Those are called simple requests from the obsolete CORS spec though the Fetch spec which now defines CORS doesnt use that term The motivation is that the form element from HTML 40 which predates crosssite fetch and XMLHttpRequest can submit simple requests to any origin so anyone writing a server must already be protecting against crosssite request forgery CSRF Under this assumption the server doesnt have to optin by responding to a preflight request to receive any request that looks like a form submission since the threat of CSRF is no worse than that of form submission However the server still must optin using AccessControlAllowOrigin to share the response with the script A simple request is one that meets all the following conditions One of the allowed methods GET HEAD POST Apart from the headers automatically set by the user agent for example Connection UserAgent or the other headers defined in the Fetch spec as a forbidden header name the only headers which are allowed to be manually set are those which the Fetch spec defines as a CORSsafelisted requestheader which are Accept AcceptLanguage ContentLanguage ContentType please note the additional requirements below Range only with a simple range header value eg bytes256 or bytes127255 The only typesubtype combinations allowed for the media type specified in the ContentType header are applicationxwwwformurlencoded multipartformdata textplain If the request is made using an XMLHttpRequest object no event listeners are registered on the object returned by the XMLHttpRequestupload property used in the request that is given an XMLHttpRequest instance xhr no code has called xhruploadaddEventListener to add an event listener to monitor the upload No ReadableStream object is used in the request Note WebKit Nightly and Safari Technology Preview place additional restrictions on the values allowed in the Accept AcceptLanguage and ContentLanguage headers If any of those headers have nonstandard values WebKitSafari does not consider the request to be a simple request What values WebKitSafari consider nonstandard is not documented except in the following WebKit bugs Require preflight for nonstandard CORSsafelisted request headers Accept AcceptLanguage and ContentLanguage Allow commas in Accept AcceptLanguage and ContentLanguage request headers for simple CORS Switch to a blacklist model for restricted Accept headers in simple CORS requests No other browsers implement these extra restrictions because theyre not part of the spec For example suppose web content at httpsfooexample wishes to fetch JSON content from domain httpsbarother Code of this sort might be used in JavaScript deployed on fooexample jsconst fetchPromise  fetchhttpsbarother fetchPromise thenresponse  responsejson thendata   consolelogdata  This operation performs a simple exchange between the client and the server using CORS headers to handle the privileges Lets look at what the browser will send to the server in this case httpGET resourcespublicdata HTTP11 Host barother UserAgent Mozilla50 Macintosh Intel Mac OS X 1014 rv710 Gecko20100101 Firefox710 Accept texthtmlapplicationxhtmlxmlapplicationxmlq09q08 AcceptLanguage enusenq05 AcceptEncoding gzipdeflate Connection keepalive Origin httpsfooexample The request header of note is Origin which shows that the invocation is coming from httpsfooexample Now lets see how the server responds httpHTTP11 200 OK Date Mon 01 Dec 2008 002353 GMT Server Apache2 AccessControlAllowOrigin  KeepAlive timeout2 max100 Connection KeepAlive TransferEncoding chunked ContentType applicationxml XML Data In response the server returns a AccessControlAllowOrigin header with AccessControlAllowOrigin  which means that the resource can be accessed by any origin httpAccessControlAllowOrigin  This pattern of the Origin and AccessControlAllowOrigin headers is the simplest use of the access control protocol If the resource owners at httpsbarother wished to restrict access to the resource to requests only from httpsfooexample ie no domain other than httpsfooexample can access the resource in a crossorigin manner they would send httpAccessControlAllowOrigin httpsfooexample Note When responding to a credentialed requests request the server must specify an origin in the value of the AccessControlAllowOrigin header instead of specifying the  wildcard Preflighted requestsUnlike simple requests for preflighted requests the browser first sends an HTTP request using the OPTIONS method to the resource on the other origin in order to determine if the actual request is safe to send Such crossorigin requests are preflighted since they may have implications for user data The following is an example of a request that will be preflighted jsconst fetchPromise  fetchhttpsbarotherdoc  method POST mode cors headers  ContentType textxml XPINGOTHER pingpong  body personnameArunnameperson  fetchPromisethenresponse   consolelogresponsestatus  The example above creates an XML body to send with the POST request Also a nonstandard HTTP XPINGOTHER request header is set Such headers are not part of HTTP11 but are generally useful to web applications Since the request uses a ContentType of textxml and since a custom header is set this request is preflighted Note As described below the actual POST request does not include the AccessControlRequest headers they are needed only for the OPTIONS request Lets look at the full exchange between client and server The first exchange is the preflight requestresponse httpOPTIONS doc HTTP11 Host barother UserAgent Mozilla50 Macintosh Intel Mac OS X 1014 rv710 Gecko20100101 Firefox710 Accept texthtmlapplicationxhtmlxmlapplicationxmlq09q08 AcceptLanguage enusenq05 AcceptEncoding gzipdeflate Connection keepalive Origin httpsfooexample AccessControlRequestMethod POST AccessControlRequestHeaders XPINGOTHER ContentType HTTP11 204 No Content Date Mon 01 Dec 2008 011539 GMT Server Apache2 AccessControlAllowOrigin httpsfooexample AccessControlAllowMethods POST GET OPTIONS AccessControlAllowHeaders XPINGOTHER ContentType AccessControlMaxAge 86400 Vary AcceptEncoding Origin KeepAlive timeout2 max100 Connection KeepAlive Lines 1  10 above represent the preflight request with the OPTIONS method The browser determines that it needs to send this based on the request parameters that the JavaScript code snippet above was using so that the server can respond whether it is acceptable to send the request with the actual request parameters OPTIONS is an HTTP11 method that is used to determine further information from servers and is a safe method meaning that it cant be used to change the resource Note that along with the OPTIONS request two other request headers are sent lines 9 and 10 respectively httpAccessControlRequestMethod POST AccessControlRequestHeaders XPINGOTHER ContentType The AccessControlRequestMethod header notifies the server as part of a preflight request that when the actual request is sent it will do so with a POST request method The AccessControlRequestHeaders header notifies the server that when the actual request is sent it will do so with XPINGOTHER and ContentType custom headers Now the server has an opportunity to determine whether it can accept a request under these conditions Lines 12  21 above are the response that the server returns which indicate that the request method POST and request headers XPINGOTHER are acceptable Lets have a closer look at lines 1518 httpAccessControlAllowOrigin httpsfooexample AccessControlAllowMethods POST GET OPTIONS AccessControlAllowHeaders XPINGOTHER ContentType AccessControlMaxAge 86400 The server responds with AccessControlAllowOrigin httpsfooexample restricting access to the requesting origin domain only It also responds with AccessControlAllowMethods which says that POST and GET are valid methods to query the resource in question this header is similar to the Allow response header but used strictly within the context of access control The server also sends AccessControlAllowHeaders with a value of XPINGOTHER ContentType confirming that these are permitted headers to be used with the actual request Like AccessControlAllowMethods AccessControlAllowHeaders is a commaseparated list of acceptable headers Finally AccessControlMaxAge gives the value in seconds for how long the response to the preflight request can be cached without sending another preflight request The default value is 5 seconds In the present case the max age is 86400 seconds  24 hours Note that each browser has a maximum internal value that takes precedence when the AccessControlMaxAge exceeds it Once the preflight request is complete the real request is sent httpPOST doc HTTP11 Host barother UserAgent Mozilla50 Macintosh Intel Mac OS X 1014 rv710 Gecko20100101 Firefox710 Accept texthtmlapplicationxhtmlxmlapplicationxmlq09q08 AcceptLanguage enusenq05 AcceptEncoding gzipdeflate Connection keepalive XPINGOTHER pingpong ContentType textxml charsetUTF8 Referer httpsfooexampleexamplespreflightInvocationhtml ContentLength 55 Origin httpsfooexample Pragma nocache CacheControl nocache personnameArunnameperson HTTP11 200 OK Date Mon 01 Dec 2008 011540 GMT Server Apache2 AccessControlAllowOrigin httpsfooexample Vary AcceptEncoding Origin ContentEncoding gzip ContentLength 235 KeepAlive timeout2 max99 Connection KeepAlive ContentType textplain Some XML payload Preflighted requests and redirects Not all browsers currently support following redirects after a preflighted request If a redirect occurs after such a request some browsers currently will report an error message such as the following The request was redirected to httpsexamplecomfoo which is disallowed for crossorigin requests that require preflight Request requires preflight which is disallowed to follow crossorigin redirects The CORS protocol originally required that behavior but was subsequently changed to no longer require it However not all browsers have implemented the change and thus still exhibit the originally required behavior Until browsers catch up with the spec you may be able to work around this limitation by doing one or both of the following Change the serverside behavior to avoid the preflight andor to avoid the redirect Change the request such that it is a simple request that doesnt cause a preflight If thats not possible then another way is to Make a simple request using Responseurl for the Fetch API or XMLHttpRequestresponseURL to determine what URL the real preflighted request would end up at Make another request the real request using the URL you obtained from Responseurl or XMLHttpRequestresponseURL in the first step However if the request is one that triggers a preflight due to the presence of the Authorization header in the request you wont be able to work around the limitation using the steps above And you wont be able to work around it at all unless you have control over the server the request is being made toRequests with credentials Note When making credentialed requests to a different domain thirdparty cookie policies will still apply The policy is always enforced regardless of any setup on the server and the client as described in this chapter The most interesting capability exposed by both fetch or XMLHttpRequest and CORS is the ability to make credentialed requests that are aware of HTTP cookies and HTTP Authentication information By default in crossorigin fetch or XMLHttpRequest calls browsers will not send credentials To ask for a fetch request to include credentials set the credentials option in the Request constructor to include To ask for an XMLHttpRequest request to include credentials set the XMLHttpRequestwithCredentials property to true In this example content originally loaded from httpsfooexample makes a simple GET request to a resource on httpsbarother which sets Cookies Content on fooexample might contain JavaScript like this jsconst url  httpsbarotherresourcescredentialedcontent const request  new Requesturl  credentials include  const fetchPromise  fetchrequest fetchPromisethenresponse  consolelogresponse This code creates a Request object setting the credentials option to include in the constructor then passes this request into fetch Since this is a simple GET request it is not preflighted but the browser will reject any response that does not have the AccessControlAllowCredentials true header and not make the response available to the invoking web content Here is a sample exchange between client and server httpGET resourcescredentialedcontent HTTP11 Host barother UserAgent Mozilla50 Macintosh Intel Mac OS X 1014 rv710 Gecko20100101 Firefox710 Accept texthtmlapplicationxhtmlxmlapplicationxmlq09q08 AcceptLanguage enusenq05 AcceptEncoding gzipdeflate Connection keepalive Referer httpsfooexampleexamplescredentialhtml Origin httpsfooexample Cookie pageAccess2 HTTP11 200 OK Date Mon 01 Dec 2008 013452 GMT Server Apache2 AccessControlAllowOrigin httpsfooexample AccessControlAllowCredentials true CacheControl nocache Pragma nocache SetCookie pageAccess3 expiresWed 31Dec2008 013453 GMT Vary AcceptEncoding Origin ContentEncoding gzip ContentLength 106 KeepAlive timeout2 max100 Connection KeepAlive ContentType textplain textplain payload Although line 10 contains the Cookie destined for the content on httpsbarother if barother did not respond with an AccessControlAllowCredentials true line 16 the response would be ignored and not made available to the web content Preflight requests and credentials CORSpreflight requests must never include credentials The response to a preflight request must specify AccessControlAllowCredentials true to indicate that the actual request can be made with credentials Note Some enterprise authentication services require that TLS client certificates be sent in preflight requests in contravention of the Fetch specification Firefox 87 allows this noncompliant behavior to be enabled by setting the preference networkcors_preflightallow_client_cert to true Firefox bug 1511151 Chromiumbased browsers currently always send TLS client certificates in CORS preflight requests Chrome bug 775438 Credentialed requests and wildcards When responding to a credentialed request The server must not specify the  wildcard for the AccessControlAllowOrigin responseheader value but must instead specify an explicit origin for example AccessControlAllowOrigin httpsexamplecom The server must not specify the  wildcard for the AccessControlAllowHeaders responseheader value but must instead specify an explicit list of header names for example AccessControlAllowHeaders XPINGOTHER ContentType The server must not specify the  wildcard for the AccessControlAllowMethods responseheader value but must instead specify an explicit list of method names for example AccessControlAllowMethods POST GET The server must not specify the  wildcard for the AccessControlExposeHeaders responseheader value but must instead specify an explicit list of header names for example AccessControlExposeHeaders ContentEncoding KumaRevision If a request includes a credential most commonly a Cookie header and the response includes an AccessControlAllowOrigin  header that is with the wildcard the browser will block access to the response and report a CORS error in the devtools console But if a request does include a credential like the Cookie header and the response includes an actual origin rather than the wildcard like for example AccessControlAllowOrigin httpsexamplecom then the browser will allow access to the response from the specified origin Also note that any SetCookie response header in a response would not set a cookie if the AccessControlAllowOrigin value in that response is the  wildcard rather an actual origin Thirdparty cookies Note that cookies set in CORS responses are subject to normal thirdparty cookie policies In the example above the page is loaded from fooexample but the cookie on line 19 is sent by barother and would thus not be saved if the users browser is configured to reject all thirdparty cookies Cookie in the request line 10 may also be suppressed in normal thirdparty cookie policies The enforced cookie policy may therefore nullify the capability described in this chapter effectively preventing you from making credentialed requests whatsoever Cookie policy around the SameSite attribute would applyThe HTTP response headersThis section lists the HTTP response headers that servers return for access control requests as defined by the CrossOrigin Resource Sharing specification The previous section gives an overview of these in actionAccessControlAllowOriginA returned resource may have one AccessControlAllowOrigin header with the following syntax httpAccessControlAllowOrigin origin   AccessControlAllowOrigin specifies either a single origin which tells browsers to allow that origin to access the resource or else  for requests without credentials  the  wildcard tells browsers to allow any origin to access the resource For example to allow code from the origin httpsmozillaorg to access the resource you can specify httpAccessControlAllowOrigin httpsmozillaorg Vary Origin If the server specifies a single origin that may dynamically change based on the requesting origin as part of an allowlist rather than the  wildcard then the server should also include Origin in the Vary response header to indicate to clients that server responses will differ based on the value of the Origin request headerAccessControlExposeHeadersThe AccessControlExposeHeaders header adds the specified headers to the allowlist that JavaScript such as Responseheaders in browsers is allowed to access httpAccessControlExposeHeaders headername headername For example the following httpAccessControlExposeHeaders XMyCustomHeader XAnotherCustomHeader would allow the XMyCustomHeader and XAnotherCustomHeader headers to be exposed to the browserAccessControlMaxAgeThe AccessControlMaxAge header indicates how long the results of a preflight request can be cached For an example of a preflight request see the above examples httpAccessControlMaxAge deltaseconds The deltaseconds parameter indicates the number of seconds the results can be cachedAccessControlAllowCredentialsThe AccessControlAllowCredentials header indicates whether or not the response to the request can be exposed when the credentials flag is true When used as part of a response to a preflight request this indicates whether or not the actual request can be made using credentials Note that simple GET requests are not preflighted and so if a request is made for a resource with credentials if this header is not returned with the resource the response is ignored by the browser and not returned to web content httpAccessControlAllowCredentials true Credentialed requests are discussed aboveAccessControlAllowMethodsThe AccessControlAllowMethods header specifies the method or methods allowed when accessing the resource This is used in response to a preflight request The conditions under which a request is preflighted are discussed above httpAccessControlAllowMethods method method An example of a preflight request is given above including an example which sends this header to the browserAccessControlAllowHeadersThe AccessControlAllowHeaders header is used in response to a preflight request to indicate which HTTP headers can be used when making the actual request This header is the server side response to the browsers AccessControlRequestHeaders header httpAccessControlAllowHeaders headername headername The HTTP request headersThis section lists headers that clients may use when issuing HTTP requests in order to make use of the crossorigin sharing feature Note that these headers are set for you when making invocations to servers Developers making crossorigin requests do not have to set any crossorigin sharing request headers programmaticallyOriginThe Origin header indicates the origin of the crossorigin access request or preflight request httpOrigin origin The origin is a URL indicating the server from which the request is initiated It does not include any path information only the server name Note The origin value can be null Note that in any access control request the Origin header is always sentAccessControlRequestMethodThe AccessControlRequestMethod is used when issuing a preflight request to let the server know what HTTP method will be used when the actual request is made httpAccessControlRequestMethod method Examples of this usage can be found aboveAccessControlRequestHeadersThe AccessControlRequestHeaders header is used when issuing a preflight request to let the server know what HTTP headers will be used when the actual request is made for example by passing them as the headers option to the Request constructor This browserside header will be answered by the complementary serverside header of AccessControlAllowHeaders httpAccessControlRequestHeaders fieldname fieldname Examples of this usage can be found aboveSpecificationsSpecificationFetch Standard  httpaccesscontrolalloworiginBrowser compatibilityBCD tables only load in the browser with JavaScript enabled Enable JavaScript to view dataSee also CORS errors Enable CORS I want to add CORS support to my server Fetch API XMLHttpRequest Will it CORS  an interactive CORS explainer  generator How to run Chrome browser without CORS Using CORS with All Modern Browsers Stack Overflow answer with how to info for dealing with common problems How to avoid the CORS preflight How to use a CORS proxy to get around No AccessControlAllowOrigin header How to fix AccessControlAllowOrigin header must not be the wildcard Found a content problem with this pageEdit the page on GitHubReport the content issueView the source on GitHubWant to get more involved Learn how to contributeThis page was last modified on Dec 19 2023 by MDN contributors Specification 0 Specification 1 Fetch Standard  httpaccesscontrolalloworiginconst fetchPromise  fetchhttpsbarother fetchPromise thenresponse  responsejson thendata   consolelogdata  GET resourcespublicdata HTTP11 Host barother UserAgent Mozilla50 Macintosh Intel Mac OS X 1014 rv710 Gecko20100101 Firefox710 Accept texthtmlapplicationxhtmlxmlapplicationxmlq09q08 AcceptLanguage enusenq05 AcceptEncoding gzipdeflate Connection keepalive Origin httpsfooexample HTTP11 200 OK Date Mon 01 Dec 2008 002353 GMT Server Apache2 AccessControlAllowOrigin  KeepAlive timeout2 max100 Connection KeepAlive TransferEncoding chunked ContentType applicationxml XML Data AccessControlAllowOrigin  AccessControlAllowOrigin httpsfooexample const fetchPromise  fetchhttpsbarotherdoc  method POST mode cors headers  ContentType textxml XPINGOTHER pingpong  body personnameArunnameperson  fetchPromisethenresponse   consolelogresponsestatus  OPTIONS doc HTTP11 Host barother UserAgent Mozilla50 Macintosh Intel Mac OS X 1014 rv710 Gecko20100101 Firefox710 Accept texthtmlapplicationxhtmlxmlapplicationxmlq09q08 AcceptLanguage enusenq05 AcceptEncoding gzipdeflate Connection keepalive Origin httpsfooexample AccessControlRequestMethod POST AccessControlRequestHeaders XPINGOTHER ContentType HTTP11 204 No Content Date Mon 01 Dec 2008 011539 GMT Server Apache2 AccessControlAllowOrigin httpsfooexample AccessControlAllowMethods POST GET OPTIONS AccessControlAllowHeaders XPINGOTHER ContentType AccessControlMaxAge 86400 Vary AcceptEncoding Origin KeepAlive timeout2 max100 Connection KeepAlive AccessControlRequestMethod POST AccessControlRequestHeaders XPINGOTHER ContentType AccessControlAllowOrigin httpsfooexample AccessControlAllowMethods POST GET OPTIONS AccessControlAllowHeaders XPINGOTHER ContentType AccessControlMaxAge 86400 POST doc HTTP11 Host barother UserAgent Mozilla50 Macintosh Intel Mac OS X 1014 rv710 Gecko20100101 Firefox710 Accept texthtmlapplicationxhtmlxmlapplicationxmlq09q08 AcceptLanguage enusenq05 AcceptEncoding gzipdeflate Connection keepalive XPINGOTHER pingpong ContentType textxml charsetUTF8 Referer httpsfooexampleexamplespreflightInvocationhtml ContentLength 55 Origin httpsfooexample Pragma nocache CacheControl nocache personnameArunnameperson HTTP11 200 OK Date Mon 01 Dec 2008 011540 GMT Server Apache2 AccessControlAllowOrigin httpsfooexample Vary AcceptEncoding Origin ContentEncoding gzip ContentLength 235 KeepAlive timeout2 max99 Connection KeepAlive ContentType textplain Some XML payload const url  httpsbarotherresourcescredentialedcontent const request  new Requesturl  credentials include  const fetchPromise  fetchrequest fetchPromisethenresponse  consolelogresponse GET resourcescredentialedcontent HTTP11 Host barother UserAgent Mozilla50 Macintosh Intel Mac OS X 1014 rv710 Gecko20100101 Firefox710 Accept texthtmlapplicationxhtmlxmlapplicationxmlq09q08 AcceptLanguage enusenq05 AcceptEncoding gzipdeflate Connection keepalive Referer httpsfooexampleexamplescredentialhtml Origin httpsfooexample Cookie pageAccess2 HTTP11 200 OK Date Mon 01 Dec 2008 013452 GMT Server Apache2 AccessControlAllowOrigin httpsfooexample AccessControlAllowCredentials true CacheControl nocache Pragma nocache SetCookie pageAccess3 expiresWed 31Dec2008 013453 GMT Vary AcceptEncoding Origin ContentEncoding gzip ContentLength 106 KeepAlive timeout2 max100 Connection KeepAlive ContentType textplain textplain payload AccessControlAllowOrigin origin   AccessControlAllowOrigin httpsmozillaorg Vary Origin AccessControlExposeHeaders headername headername AccessControlExposeHeaders XMyCustomHeader XAnotherCustomHeader AccessControlMaxAge deltaseconds AccessControlAllowCredentials true AccessControlAllowMethods method method AccessControlAllowHeaders headername headername Origin origin AccessControlRequestMethod method AccessControlRequestHeaders fieldname fieldname ,https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS,Networking,874,3887
Internationalization and Localization, From Wikipedia the free encyclopedia Process of making software accessible to people in different areas of the world Part of a series onTranslation Types Legal Literary Bible Quran Kural Linguistic validation Medical Regulatory Technical Interpretation Cultural Wordforword Senseforsense Homophonic Theory Translation studies Skopos theory Translation project Translation criticism Dynamic and formal equivalence Contrastive linguistics Polysystem theory Technologies CAT Machine translation Mobile translation Translation management system Dubbing Subtitling Preediting Postediting Multimedia translation Localization Glocalization Internationalization and localization Language localization Video game localization Dub localization Website localization Software localization Institutional Associations Awards Organizations Schools Related topics Untranslatability Transcription Transliteration Video relay service VRS Telephone interpreting Language barrier Fan translation of video games Fansub Fandub Scanlation Journalistic translation Books and magazines on translation Bible translations by language Translated books List of most translated works Translators Kural translations by language vte Screenshot of TDE software programs mostly localized to Chinese traditional In computing internationalization and localization American or internationalisation and localisation British often abbreviated i18n and l10n respectively1 are means of adapting computer software to different languages regional peculiarities and technical requirements of a target locale2 Internationalization is the process of designing a software application so that it can be adapted to various languages and regions without engineering changes Localization is the process of adapting internationalized software for a specific region or language by translating text and adding localespecific components Localization which is potentially performed multiple times for different locales uses the infrastructure or flexibility provided by internationalization which is ideally performed only once before localization or as an integral part of ongoing development3 Namingedit The terms are frequently abbreviated to the numeronyms i18n where 18 stands for the number of letters between the first i and the last n in the word internationalization a usage coined at Digital Equipment Corporation in the 1970s or 1980s45 and l10n for localization due to the length of the words16 Some writers have the latter term capitalized L10n to help distinguish the two7 Some companies like IBM and Oracle use the term globalization g11n for the combination of internationalization and localization8 Microsoft defines internationalization as a combination of worldreadiness and localization Worldreadiness is a developer task which enables a product to be used with multiple scripts and cultures globalization and separates user interface resources in a localizable format localizability abbreviated to L12y910 HewlettPackard and HPUX created a system called National Language Support or Native Language Support NLS to produce localizable software2 Scopeedit The internationalization and localization processbased on a chart from the LISA website According to Software without frontiers the design aspects to consider when internationalizing a product are data encoding data and documentation software construction hardware device support and user interaction while the key design areas to consider when making a fully internationalized product from scratch are user interaction algorithm design and data formats software services and documentation2 Translation is typically the most timeconsuming component of language localization2 This may involve For film video and audio translation of spoken words or music lyrics often using either dubbing or subtitles Text translation for printed materials and digital media possibly including error messages and documentation Potentially altering images and logos containing text to contain translations or generic icons2 Different translation lengths and differences in character sizes eg between Latin alphabet letters and Chinese characters can cause layouts that work well in one language to work poorly in others2 Consideration of differences in dialect register or variety2 Writing conventions like Formatting of numbers especially decimal separator and digit grouping Date and time format possibly including the use of different calendars eg the Islamic or the Japanese calendar Standard locale dataedit Computer software can encounter differences above and beyond straightforward translation of words and phrases because computer programs can generate content dynamically These differences may need to be taken into account by the internationalization process in preparation for translation Many of these differences are so regular that a conversion between languages can be easily automated The Common Locale Data Repository by Unicode provides a collection of such differences Its data is used by major operating systems including Microsoft Windows macOS and Debian and by major Internet companies or projects such as Google and the Wikimedia Foundation Examples of such differences include Different scripts in different writing systems use different characters  a different set of letters syllograms logograms or symbols Modern systems use the Unicode standard to represent many different languages with a single character encoding Writing direction is left to right in most European languages righttoleft in Hebrew and Arabic or both in boustrophedon scripts and optionally vertical in some Asian languages2 Complex text layout for languages where characters change shape depending on context Capitalization exists in some scripts and not in others Different languages and writing systems have different text sorting rules Different languages have different numeral systems which might need to be supported if Western Arabic numerals are not used Different languages have different pluralization rules which can complicate programs that dynamically display numerical content11 Other grammar rules might also vary eg genitive Different languages use different punctuation eg quoting text using doublequotes   as in English or guillemets   as in French Keyboard shortcuts can only make use of buttons on the keyboard layout which is being localized for If a shortcut corresponds to a word in a particular language eg Ctrls stands for save in English it may need to be changed12 National conventionsedit Different countries have different economic conventions including variations in Paper sizes Broadcast television systems and popular storage media Telephone number formats Postal address formats postal codes and choice of delivery services Currency symbols positions of currency markers and reasonable amounts due to different inflation histories  ISO 4217 codes are often used for internationalization System of measurement Battery sizes Voltage and current standards In particular the United States and Europe differ in most of these cases Other areas often follow one of these Specific thirdparty services such as online maps weather reports or payment service providers might not be available worldwide from the same carriers or at all Time zones vary across the world and this must be taken into account if a product originally only interacted with people in a single time zone For internationalization UTC is often used internally and then converted into a local time zone for display purposes Different countries have different legal requirements meaning for example Regulatory compliance may require customization for a particular jurisdiction or a change to the product as a whole such as Privacy law compliance Additional disclaimers on a website or packaging Different consumer labelling requirements Compliance with export restrictions and regulations on encryption Compliance with an Internet censorship regime or subpoena procedures Requirements for accessibility Collecting different taxes such as sales tax value added tax or customs duties Sensitivity to different political issues like geographical naming disputes and disputed borders shown on maps eg India has proposed a bill that would make failing to show Kashmir and other areas as intended by the government a crime131415 Governmentassigned numbers have different formats such as passports Social Security Numbers and other national identification numbers Localization also may take into account differences in culture such as Local holidays Personal name and title conventions Aesthetics Comprehensibility and cultural appropriateness of images and color symbolism Ethnicity clothing and socioeconomic status of people and architecture of locations pictured Local customs and conventions such as social taboos popular local religions or superstitions such as blood types in Japanese culture vs astrological signs in other cultures Business process for internationalizing softwareedit To internationalize a product it is important to look at a variety of markets that the product will foreseeably enter2 Details such as field length for street addresses unique format for the address ability to make the postal code field optional to address countries that do not have postal codes or the state field for countries that do not have states plus the introduction of new registration flows that adhere to local laws are just some of the examples that make internationalization a complex project716 A broader approach takes into account cultural factors regarding for example the adaptation of the business process logic or the inclusion of individual cultural behavioral aspects217 Already in the 1990s companies such as Bull used machine translation Systran on a large scale for all their translation activity human translators handled preediting making the input machinereadable and postediting2 Engineeringedit Both in reengineering an existing software or designing a new internationalized software the first step of internationalization is to split each potentially localedependent part whether code text or data into a separate module2 Each module can then either rely on a standard librarydependency or be independently replaced as needed for each locale The current prevailing practice is for applications to place text in resource files which are loaded during program execution as needed2 These strings stored in resource files are relatively easy to translate Programs are often built to reference resource libraries depending on the selected locale data The storage for translatable and translated strings is sometimes called a message catalog2 as the strings are called messages The catalog generally comprises a set of files in a specific localization format and a standard library to handle said format One software library and format that aids this is gettext Thus to get an application to support multiple languages one would design the application to select the relevant language resource file at runtime The code required to manage data entry verification and many other localesensitive data types also must support differing locale requirements Modern development systems and operating systems include sophisticated libraries for international support of these types see also Standard locale data above Many localization issues eg writing direction text sorting require more profound changes in the software than text translation For example OpenOfficeorg achieves this with compilation switches Processedit A globalization method includes after planning three implementation steps internationalization localization and quality assurance2 To some degree eg for quality assurance development teams include someone who handles the basiccentral stages of the process which then enables all the others2 Such persons typically understand foreign languages and cultures and have some technical background Specialized technical writers are required to construct a culturally appropriate syntax for potentially complicated concepts coupled with engineering resources to deploy and test the localization elements Once properly internationalized software can rely on more decentralized models for localization free and open source software usually rely on selflocalization by endusers and volunteers sometimes organized in teams18 The GNOME project for example has volunteer translation teams for over 100 languages19 MediaWiki supports over 500 languages of which 100 are mostly complete as of September 2023update20 When translating existing text to other languages it is difficult to maintain the parallel versions of texts throughout the life of the product21 For instance if a message displayed to the user is modified all of the translated versions must be changed Commercial considerationsedit In a commercial setting the benefit of localization is access to more markets In the early 1980s Lotus 123 took two years to separate program code and text and lost the market lead in Europe over Microsoft Multiplan2 MicroPro found that using an Austrian translator for the West German market caused its WordStar documentation to an executive said not have the tone it should have had22 However there are considerable costs involved which go far beyond engineering Further business operations must adapt to manage the production storage and distribution of multiple discrete localized products which are often being sold in completely different currencies regulatory environments and tax regimes Finally sales marketing and technical support must also facilitate their operations in the new languages to support customers for the localized products Particularly for relatively small language populations it may never be economically viable to offer a localized product Even where large language populations could justify localization for a given product and a products internal structure already permits localization a given software developer or publisher may lack the size and sophistication to manage the ancillary functions associated with operating in multiple locales See alsoedit Subcomponents and standards Bidirectional script support International Components for Unicode Language code Language localization Website localization Related concepts Computer accessibility Computer Russification localization into Russian language Separation of concerns Methods and examples Game localization Globalization Management System Pseudolocalization a software testing method for testing a software products readiness for localization Other Input method editor Language industry Referencesedit  a b Ishida Richard Miller Susan K 20051205 Localization vs Internationalization W3C Archived from the original on 20160403 Retrieved 20230916  a b c d e f g h i j k l m n o p q Hall P A V Hudson R eds 1997 Software without Frontiers A MultiPlatform MultiCultural MultiNation Approach Chichester Wiley ISBN 0471969745  Esselink Bert 2006 The Evolution of Localization PDF In Pym Anthony Perekrestenko Alexander Starink Bram eds Translation Technology and Its Teaching With Much Mention of Localization Tarragona Intercultural Studies Group  URV pp 2129 ISBN 8461111311 Archived from the original PDF on 7 September 2012 In a nutshell localization revolves around combining language and technology to produce a product that can cross cultural and language barriers No more no less  Glossary of W3C Jargon W3C Archived from the original on 2 September 2011 Retrieved 16 September 2023  Origin of the Abbreviation I18n I18nGuy Archived from the original on 27 June 2014 Retrieved 19 February 2022  Concepts GNU gettext utilities gnuorg Archived from the original on 18 September 2019 Retrieved 16 September 2023 Many people tired of writing these long words over and over again took the habit of writing i18n and l10n instead quoting the first and last letter of each word and replacing the run of intermediate letters by a number merely telling how many such letters there are  a b alan 29 March 2011 What is Internationalization i18n Localization L10n and Globalization g11n ccjkcom Archived from the original on 2 April 2015 Retrieved 16 September 2023 The capital L in L10n helps to distinguish it from the lowercase i in i18n  Globalize Your Business IBM Archived from the original on 31 March 2016  Globalization StepbyStep Go Global Developer Center Archived from the original on 12 April 2015  Globalization StepbyStep Understanding Internationalization Go Global Developer Center Archived from the original on 26 May 2015  Plural forms GNU gettext utilities gnuorg Archived from the original on 14 March 2021 Retrieved 16 September 2023  Do We Need to Localize Keyboard Shortcuts Human Translation Services  Language to Language Translation 21 August 2014 Archived from the original on 3 April 2015 Retrieved 19 February 2022  Mateen Haider 17 May 2016 Pakistan Expresses Concern Over Indias Controversial Maps Bill Dawn Archived from the original on 10 May 2018 Retrieved 9 May 2018  Yasser Latif Hamdani 18 May 2016 Changing Maps Will Not Mean Kashmir Is a Part of You India The Express Tribune Retrieved 19 February 2022  An Overview of the Geospatial Information Regulation Bill Madras Courier 24 July 2017 Archived from the original on 29 October 2020 Retrieved 19 February 2022  Appendix V International Address Formats Microsoft Docs 2 June 2008 Archived from the original on 19 May 2021 Retrieved 19 February 2022  Pawlowski Jan M Culture Profiles Facilitating Global Learning and Knowledge Sharing PDF Draft version Archived PDF from the original on 20110716 Retrieved 20091001  Reina Laura Arjona Robles Gregorio GonzálezBarahona Jesús M 2013 A Preliminary Analysis of Localization in Free Software How Translations Are Performed In Petrinja Etiel Succi Giancarlo Ioini Nabil El Sillitti Alberto eds Open Source Software Quality Verification IFIP Advances in Information and Communication Technology Vol 404 Springer Berlin Heidelberg pp 153167 doi1010079783642389283_11 ISBN 9783642389276  GNOME Languages GNOME Archived from the original on 29 August 2023 Retrieved 16 September 2023  TranslatingGroup Statistics translatewikinet Archived from the original on 20230829 Retrieved 20230916  How to Translate a Game Into 20 Languages and Avoid Going to Hell Exorcising the Four Devils of Confusion PocketGamerbiz 4 April 2014 Archived from the original on 7 December 2017 Retrieved 19 February 2022  Schrage Michael 17 February 1985 IBM Wins Dominance in European Computer Market The Washington Post Archived from the original on 29 August 2018 Retrieved 29 August 2018 Further readingedit SmithFerrier Guy 2006 NET Internationalization The Developers Guide to Building Global Windows and Web Applications Upper Saddle River New Jersey Addison Wesley Professional ISBN 0321341384 Esselink Bert 2000 A Practical Guide to Localization Amsterdam John Benjamins ISBN 1588110060 Ash Lydia 2003 The Web Testing Companion The Insiders Guide to Efficient and Effective Tests Indianapolis Indiana Wiley ISBN 0471430218 DePalma Donald A 2004 Business Without Borders A Strategic Guide to Global Marketing Chelmsford Massachusetts Globa Vista Press ISBN 097651690X External linksedit Look up internationalization or localization in Wiktionary the free dictionary FOSS Localization at Wikibooks Localization vs Internationalization by The World Wide Web Consortium Media related to Internationalization and localization at Wikimedia Commons Retrieved from httpsenwikipediaorgwindexphptitleInternationalization_and_localizationoldid1186322401 Categories Internationalization and localizationBusiness termsGlobalizationInformation and communication technologies for developmentInternational tradeNatural language and computingTechnical communicationTranslationTransliterationWord coinageHidden categories Articles with short descriptionShort description is different from WikidataArticles containing potentially dated statements from September 2023All articles containing potentially dated statementsCommons category link from Wikidata The Evolution of Localization BERT ESSELINK Solution Architect Lionbridge Abstract  The evolution of the localization industry since the 1980s has been marked by a move from inhouse localization to internationalization along with marked changes in the na ture of the tools used However the turn of the century has introduced a new view The distinction between content and software is no longer clear and typical software localization projects are being supplanted by new types of localization projects focusing on programming and publishing At the same time open stan dards allow translation vendors to focus on translation Core translation skills and domain expertise thus now seem to be newly appreciated This could bring together two worlds software localization with a strong focus on technical complexity for translators and content localization with a strong focus on technical simplicity for translators The localiza tion industry may now have to face new challenges in the future and rapidly adapt its processes quality standards and resourcing approach  Introduction It seems like ancient history to me so metimes but I entered the world of localization just over ten years ago In 1993 I joined International Software Products in Amsterdam a small and spec ialized localization vendor that still exists under the same name I had recently graduated as a technical translator using an article on the launch of Windows 31 as my thesis subject The seemingly incompatible marriage of language and technology has intrigued me ever since Still this is the core characteristic of what today we have come to know as localization In a nutshell localization revolves around combining language and technology to produce a product that can cross cultural and language barriers No more no less In this article I will explore the fundamentals of localization what it is where it started how it progressed what it is today and what it may be  A first version of this paper was first published in the Guide to Localization edited by Multilingual Computing and Technology 200 3 It is reproduced here with the kind permission of the author 22 The Evolution of Localization tomorrow Against this historical back ground I will discuss developments in the localization services business translation technology and general trends Where It All Started The 1980s Desktop computers were introduced in the 1980s and computer technology slowly started to make its way to users who did not necessarily have a background in computer programming or engineering The early 1980s also saw the first international ventures of USbased computer hardware and software firms Sun Microsystems for example began operations in Europe in 1983 expanding to Asia and Aust ralia in 1986 Microsoft had started international operations earlier openi ng its first overseas sales office in Tokyo in November 1978 and beginning its expansion into Europe in 1979 The shift of computer hardware and software use away from corporate or academic computing departments to normal users desks called for a shift in product features and functionality Not only did desktop computer users now need software that would enable them to do their work more efficiently but the software also had to reflect business processes in tune with local standards and habits in cluding local language Word processors for example needed to support the i nput processing and output of character sets in other languages languagespecific features such as hyphenation and spelling and a user interface in th e users local language The same expectations applied to hardware For example in 1985 the Spanish government decreed that all computer keyboards sold in Spain should have the ñ key Internationalize to localize The international expansion of so ftware and hardware developers automatically triggered the need to localize the products for international markets Initially software vendors d ealt with this new challenge in many different ways Some established inh ouse teams of translators and language engineers to build international suppor t into their products Others simply charged their international offices or di stributors with the task of localizing the products In both cases the localiza tion effort remained separated from the development of the original products Development groups simply handed off the software code and s ource files for supporting documentation to those responsible for localization This separation of development a nd localization proved troublesome in many respects Microsoft for example asked its thendistributor ASCII in Japan to localize Multiplan predecessor of Excel into Japanese According to a Microsoft director responsible for localization at that time wed finish the product ship it in the United Stat es and then turn over the source code library to the folks in Japan wish them luck and go on vacation Bert Esselink 23 Not only was locating the translatable text embedded in the software source code quite difficult but the requirement for additional language versions of the code made update and version management increasingly complex Moreover the localizers ofte n had to return the products to the development teams to first build in su pport for localization or international computing standards With these requests the concept of internationalization was born Internationalization refers to the ad aptation of products to support or enable localization for international ma rkets Key features of internationali zation have always been the suppor t of international natural language character sets separation of localesp ecific features such as translatable strings from the software code base and the addition of functionality or features specific to foreign markets Without internationalization localizing a product can be very challenging Outsourcing localization Initially many software publishers  such as Microsoft and Oracle established inhouse localization teams who had to adapt the products for key international markets A large por tion of this effort was obviously the translation of the software product itself and supporting documentation US companies often decided to place the localization teams in their European headquarters many of which were based in Ireland Even though it seems that localization vendors are now moving activi ties to many locations across the globe Ireland established itself as the leader in the localization industry duri ng the 1990s Over the past 10 to 20 years the Industrial Development Authority IDA a semigovernmental body had the mandate to move Irela nd forward industrially by attracting foreign investment In the 1980s a high concentration of manufacturing companies started in Ireland including some hightech companies The Irish government provided what it called turnkey factories where a large multinational was offered a certain amount of governme nt subsidy per employee plus facilities grants and a corporate tax rate of 10 as an incentive to invest in Ireland After some failed investments and the increased competition from manufacturing in cheap labor markets the Irish government switched its focus to research and development and the hightech bluechip companies that is a more longterm strategy Mo st large software and Web companies now have a presence in Ireland with the bulk of their localization being managed from there including Microsoft Oracle Lotus Development Visio International Sun Microsystems Siebel and FileNET The key benefits they offered these companies included a certain amount of money per employee a 10 corporate tax rate and exemption from valueadded tax VAT All produc ts including software exported to 24 The Evolution of Localization Europe are exempt from VAT in Irela nd In addition competitive labor costs with social costs at approximately 12 to 15 per employee mean that it is cheaper to employ people in Ireland than in many of the European Union countries Compared to the Unit ed States development costs are still lower in Ireland And Ireland offered a young welleducated motivated work force Approximately 50 of the population was under 25 at the beginning of the 1990s The Irish government has invested a gr eat deal of subsidy in education There now is a strong push to offer addi tional computer courses to cope with the growing demand for IT and localization staff This combined with the fact that Ireland is an Englishspeaki ng nation on the edge of Europe that serves as a gateway to Europe and the Euro zone made many USbased companies decide to base their European headquarters or distribution centers in Dublin Translators localization engineers a nd project managers were recruited from all over Europe to be trained and employed as localizers in Ireland For most translators it was their first introduction not only to computers but also to the concepts of software localization Although Dublin in the late 1980s and early 1990s was a very attractive place for localization experts with many job opportunities and a strong social network software publishers began to doubt the validity of the in house localization model Not only did ne w recruits face a steep training curve but the rapid growth of products sold internationally and the content explosion also created large localization departments that were difficult to sustain Business fluctuationsvery busy just before new product releases very quiet aftercontributed to this pr oblem as did the difficulty of keeping translators in another country for a long time because localization really wasnt very exciting imagine two months of translating online help files and not always well paid Software publishers increasingly realiz ed that localization was not part of their core business and should ideally be outsourced to external service providers One of the first companies to reali ze there was a service offering to be built around this need was INK a European translation services network established in 1980 INK became one of the first companies in the world to offer outsourced localization services In addition to translation into all languages required by software publishers  this service included localization engineering and desktop publishing and most importantly the project management of these multilingual localization projects Translation technology INK was also one of the first companies to create desktop translation support tools called the INK TextTools the first technology commercially Bert Esselink 25 developed to support translators As a historical note the present company Lionbridge was spun off from Stream International which itself had emerged from RR Donnelleys acquisition of INK said Lionbridge CEO Rory Cowan in 1997 In 1987 a German translation company called TRADOS was reselling the INK TextTools and a year later released TED the Translation Editor plugin for TextTools Shortly thereafter TRADOS released the first version of its Translators Workbench tran slation memory TM product TRADOS continued to establish itself as the industry leader in TM technology throughout the 1990s boosted by Microsoft taking a 20 stake in 1997 Initially TM technology could only deal with text files Hardly any technology was commercially available for the localization of software user interfaces Most software publishers built proprietary tools which were tailored to their own source code form at and standards and used by their internal teams Development of these tools was often quite ad hoc and unstructured As a result early genera tions of software localization tools were usually quite buggy and unreliable 1990s An Industry Established Throughout the 1990s a large number of localization service providers were born many of which were little more th an rebranded translation firms For the IT industry the sky was the limit the globe was its marketplace and the localization industry followed closely in its footsteps After the initial pioneering efforts of translation companies adapting to the new paradigm of localization the 1990s clearly saw the establishment of a true localization services industry Software and hardware publishers increasingly outsourced translation and localization tasks to focus on their core competencies The need for outsourced fullservice localization suppliers was growing rapidly Within a localization services company localization teams would typically be coordinated by a project manager overseeing schedules and budgets a linguist to monitor any linguis tic issues an engineer to compile and test localized software and on line help and a desktop publisher to produce translated printed or online manuals A typical localization project consistedand often still consistsof a software component an online help component and some printed mate rials such as a getting started guide To localize a software application localization engineers receive a copy of the software build environment extrac t the resource files with translatable text prepare translation kits and support the translators during their work Posttranslation the engineers merge the translated files with the build environments and compile localized copies of the software application This always requires some level of bugfixing user interface resizing and testing A similar approach is taken to produce localized versions of online help 26 The Evolution of Localization systems The source files mostly RTF or HTML documents are translated and a compilation and testing phase follows Most online help systems and printed documents contain screen captures of the software so including pictures of the localized software a pplication can only be done once the application has been fully translat ed built and tested These dependencies and many others have always made th e management of localization projects quite a challenge Consolidation and outsourcing One of the developments that char acterized the localization industry throughout the 1990s was consolidation Localization service providers merged with others in order to eat the competition or to add service offerings to reach a wider geographical spreador they could merge simply because they had some money to burn The list of companies that were acquired seems endless From at least a dozen large multilanguage vendors in localization we are currently down to a handful with the main players being Bowne Global Solutions Lion bridge and SDL International Consolidation also manifested itsel f in the emergence of a relatively standard production outsourcing fra mework The larger multilanguage vendors MLVs took on multilanguage mu ltiservice projects outsourcing the core translation services to singlelanguage vendors SLVs one in each target country SLVs normally work into one target language only from one or more source languages and either work with onsite translators or contractors Throughout the 1990s the localizati on industry further professionalized including industry organizations conferences publications academic interest and generally increased visibility Obviously the increasing number of companies jumping on the localization bandwagon resulted in fierce competition and increased pressure on pricing As a direct result benefits and cost savings from the use of TMs for example quickly shifted from the translators desk to the localization vendor and eventually to the customer Today no localization quote is sent out without a detailed breakdown of full matches fuzzy matches and repetitio n discounts through the use of TM database technology From TM to GMS TM technology plays a dominant role in localization for various reasons First of all most software companies aim for simship simultaneous release of all language versions of their products This means that translation of the software product and supporting online documentation has to start while the English product is still under development Translating subsequent development updates of a pr oduct is then greatly simplified by Bert Esselink 27 the use of TM technology Moreover af ter general release most software products are updated at least once a year These updates usually just add features onto a stable base platform making it all the more important to be able to reuseor leveragepreviously produced content and translations Another type of translation technology commonly used in localization projects is software user interface local ization tools These tools are used to translate software resource files or even binary files and enable the localizer to not only translate but also resize an d test the user interface Examples of localization tools are Alchemys CATALYST and PASS Engineerings PASSOLO By the end of the 1990s the Internet had changed many things in local ization such as the introduction of globalization management systems GMS Riding the dotcom wave vari ous companies offered revolutionary new ways of managing translation and localization projects storing and publishing multilingual content and full y automating localization processes Although this new technology had so me impact on existing outsourcing models and processes in the localization industry it became rapidly clear that although a GMS could be useful fo r content globalization programs for example multilingual Web sites the world of software localization still required a lot of traditional e xpertise and dedicated teamwork With Web sites containing more and more software functionality and software applications increasingly deploying a Web interface we can no longer make a clear distinction betw een software and content when we discuss localization The traditional definition in which localization only refers to software applications and supporting content is no longer valid Today even producing a multilingual vers ion of an online support system ebusiness portal or knowledge base could be defined as a localization project In other words the turn of the cen tury also introduced a new view towards localization and translation What Lies Ahead So what is so different now in localiza tion compared to what we got used to during the 1990s Not as much as you might expect After all many localization projects fit the profile that we have grown accustomed to over the past years Windowsbased desktop software products with some translatable resource files basic engineering and compilation requirements HTML files to use for the online help and possibly some product collateral or manuals to be printed or published in PDF format Even though these typical software localization projects may still be the bulk of the work for many localization service providers they are quickly being supplanted by new types of locali zation projects where the focus is on 28 The Evolution of Localization programming and publishing environments such as XML Java and NET Also content translation projects are now often considered as localization projects simply because of the complex environments in which the content is authored managed stored and published Most of todays Web sites contain so much scripting and software functionality that Web localization requires a wide range of engineering skills Fo r Web sites based on content manage ment systems CMSs the story gets even more complex when content is continuously updated and published in multiple languages the translation process must be truly integrated with the overall content lifecycle Apart from a renewed focus on content localization we have also seen various other important developments over the past few years such as the growing importance of open standards Examples of open standards in the localization industry are Translation Memory eXchange TMX and XML Localization Interchange File Form at XLIFF Many TM tools support TMX for the exchange of TM database s between different tools and XLIFF is being adopted by companies such as Sun Microsystems and Oracle A Sun Microsystems manager recently said XLIFF allows our interaction with translation vendors to be much more efficient There is less need for translators to become engineering experts in the many different source file formats that are currently being u sedSGML HTML MIF RTF and the numerous software message file formats Instead XLIFF allows translation vendors to concentrate on their core competency translation of words Back to basics Does the popularity of XLIFF signal a trend Throughout the 1990s the localization industry tried to turn tran slators into semiengineers Is it now expecting them to just translate again It certainly looks that way For the past decades content authors and translators may simply have been distracted by the possibilities and the features the new technologies had to offerall those file formats all those compilers all these new tools all the output formats all those cool graphics and layout features If content management fulfills all its promises content creators may in a few years be writing text in a browser template with fields predefined by the CMS and translators may all be working in a TM tool interface that only shows them long lists of translatable segments po ssibly partly pretranslated We have come full circle authors author and translators translate Is this a bad thing Not necessar ily Throughout the 1990s one of the biggest linguistic challenges was to maintain consistency with the Microsoft glossaries but today we see a new appreciation of all the core translation skills and domain expertise that we often considered no longer critical in localization A localization service provider translating an ERP software package or an SAP support do cument had better make sure to use translators who know these domains inside out and should not rely on Bert Esselink 29 translators just looking at some glo ssaries Localization companies now need to face these new challenges and higher customer demands New Kids on the Block The year 2002 included one of the largest mergers in the history of localization as Bowne Global Solutions acquired Berlitz GlobalNET to become the largest localization servi ce provider Various new localization organizations were launched And on the technology side the main developments can be seen in serverbased TM systems TRADOS for example recently released its TM Se rver product a new technology that offers centralized TM for client se rver environments Telelingua also introduced TRemote Memory a distributed computing architecture using Web services Software user interface localiza tion tools now all offer support for Microsofts NET programming environm ent According to a white paper released by Alchemy Software w hile fundamental approaches to application design remain somewhat consistent with the approach traditionally chosen by desktop appl ication developers the localization service provider community faces a daunting challenge of upskilling and retooling their localization teams while embracing this new Microsoft technology Coming to grips with the new open standards and learning the nuances of translating NET technology will present both a financial and an educational challenge Based on this comment and other signals from experts in the field it looks likely that while translators will be able and expected to increasingly focus on their linguistic tasks in localiza tion the bar of technical complexity will be raised considerably as well This applies not just to software localization but also to the wider context of content localization So the question remains what have we learned over the past 20 years of localization and do the lessons that we have learned still apply to todays new realities of content localization It almost seems like two worlds are now colliding software localization with a strong focus on technical skills and technical complexity for translators on the one hand and content localization with a strong focus on lingui stic skills and technical simplicity for translators on the other With the Internet increasingly merging platform and content the localization industry will have to rapidly adapt its processes quality standards and resourcing approach to these new requirements Draft Version Final Version in Pawlowski JM 2008 Culture Profiles Facilita ting Global Learning and Knowledge Sharing Proc of ICCE 2008 Taiwan Nov 2008 Culture Profiles Facilit ating Global Learning and Knowledge Sharing Jan M Pawlowski Information Technology Research Institute University of Jyväskylä Finland janpawlowskititujyufi Abstract The paper describes the concept of Culture Profiles to facilitate globally distributed work groups The concept describes a representation for cultural characteristics for groups and individuals and relates this concept to existing standards Hence it is embedded in the landscape of learning technology standards A sample implementation for social communities  Culture Clouds  shows the feasibility of the concept It leads to improved cultural awareness and better mutu al understanding in international groups of knowledge workers and learners Keywords Culture Profile learning technology standards Leaner Information Cultural Awareness global learning global knowledge management Culture Clouds 1 Introduction In this paper the approach of Culture Profil es is shown as a tool to improve cultural awareness in global knowledge sharing and learning processes Culture Profiles describe cultural characteristics on different levels su ch as national organizational or individual characteristics The concept is related to existing specifications and standards in order to implement an innovative concept in an interoperable way Global knowledge sharing is still a challenging but highly significant task Global organizations or temporary partnerships work distributed all over the globe  more and more study programs include learners from all over the world in ELearning study programs This means that globally distributed teams need to be supported to work effectively and efficiently The main question of this article is how to facilitate global teams in particular teams in knowledge intensive processes such as knowledge management or learning processes The paper describes the concept of cultural awaren ess and Culture Profiles to facilitate those groups with easy to use tools However there are already many standards to describe actor characteristics Therefore this paper extends standards like IMS Leaner Information Package Smyth Tansey  Robson 2001 IMS EPortfolio Cambridge Smythe  McKell 2005 and provides a conceptual embedding In the first section I will describe and analyze existing models to describe and represent cultural characteristics Based on this analysis the need for cultural awareness and Culture Profiles is derived This concept is embedded into a framework of existing standards and specifications The article conc ludes with a sample implementation and an outlook on future activities 2 Culture and Knowledge Sharing Global work settings are changing rapidly internationally distributed teams face an increasing emphasis on knowledge intensive work while technology enables new connections and interactions E ffective collaboration within international networks is one of the most important competencies for actors In this chapter I will briefly discuss two aspects Models and representations of culture and awareness on cultural aspects as a critical success factor 21 Culture Models and Representations Cultural differences are currently discussed from different angles and fo r different scopes in order to understand their influence on working and learning processes Generally culture can be defined and analyzed on different levels  National  regional aspects define characteristics and attributes common to actors coming from or living in a certain geographic location  Organizational aspects define characte ristics and attributes for a certain organization such as companies or teams  Professional aspects define characteristics and attributes for actors in a certain profession or with a similar educational background  Individual aspects define characteristics and attributes for actors which describe their personality as well as individual preferences and interests Figure 1 Culture Levels One approach is to identify models that represent national cultures with a controllable set of attributes cf Hall  Hall 1990 Hofstede  Hofstede 2005 Henderson 2007 Trompenaars  HampdenTurner 1997 Additionally many studies have analyzed specific aspects of cultural influences for kno wledge intensive domains  professional fields such as education Edmundson 2007 Henderson 2007 or software development Dafoulas  Macaulay 2001 Karolak 1998 Other studies have researched the cultural impact of certain geographical locations eg Gulovsen et al 2006 Gunawardana 2005 Mabawonku 2003 Most of the studies clearly emphasize the importance of identifying and recognizing the differences and similarities when cooperating to reduce the resulting barriers To work together successfully it is highly necessary to reflect about ones own and the collaborators cultural characteristics The above mentione d cultural models can support this reflection process 22 Culture awareness One critical success factor of successful knowle dge exchange in collaboration settings is the awareness about cultural characteristics Byram 1997 In the field of globally distributed learning processes this can play a crucial role In international scenarios many barriers arise such as misunderstandings and miscon ceptions regarding culture communication and cooperation cf Seufert 2001 MacDermott  ODell 2001 Different solutions have been proposed for inte rcultural settings to address those issues Awareness about cultural issues Pedersen 1988 Byram 1997 and the teams  fellow colleagues Redmiles et al 2007 Sarma  van der Hoek 2002 seems to play an important role Therefore an approach is necessary to cover both levels awareness regarding culture and presence We use the concept of culture profiling Dafoulas  Macaulay 2001 and support by the facilitator cf Michie 2003 to achieve awareness Culture Profiles describe cultural and individual characteristics on differe nt levels cf Henderson 2007 Dafoulas  Macaulay 2001 Pawlowski Richter 2008 to increase knowledge about collaborators 23 Standards For the field of learning education and traini ng a variety of standards has been developed to enable and ensure interoperability such as Learning Object Metadata LOM IEEE 2002 Sharable Content Object Reference Model SCORM Dodds  Thropp 2004 or IMS Learning Design IMS LD Koper Olivier  Anderson 2002 One group of standards deals with the descri ption and modeling of actors  learners in learning processes cf Sgouropoulou 2006 The objective of this class of standards is to provide a specification for user profiles whic h can be transferred across institutions and systems An example is the specification IMS Learner Information Package IMS LIP Smythe Tensey  Robson 2001 Another important development to represent and exchange user information are eportfolios This specification describes outcomes from a learner such as achievements works skills or goals Finally a specification to represent competencies has been developed The specification IMS RCDEO Reusable Definition of Competency or Educational Objective Cooper  Ostyn 2001 describes competencies of an individual in an interoperable way Those three mentioned standards can support the interoperable description of actor characteristics from different perspectives However none of the above discussed specifications contain information  attributes regarding cultural characteristics Therefore it is necessary to extend thos e regarding cultural issues 3 Culture Profiles A Culture Profile can be defined as the characteristics of an entity determined by its culture An entity in most cases is an individual However this profile can also be defined for a larger entity such as an organization organ izational culture group professional culture or even a society national culture 31 Concept A Culture Profile cannot be defined as a fixed or prescribed specification The concept proposed is only a basic outline to cover important cultural attributes in knowledge intensive processes The specification should be extended and dynamically improved based on the context The idea of a culture profile is to represent cultural characteristics from different perspectives It is based on previous research work in which we have identified cultural influence factors which affect learning and knowledge processes Richter  Pawlowski 2007 Pawlowski  Richter 2008 Those characteristics are not intended to completely represent a cultural background of an individual but to provide a guideline for selfreflection and comparisons The following table illustrates Culture Profiles Table 1 Culture Profile Category Description Sample Attributes General General profile description Name Creator Date of creation Type organizational individual national Reference References to other profiles Vcard reference LIP reference eportfolio reference Europassreference other references Experiences Culture related experiences Country visit situations conflicts attitudes cases Culture Description of the cultural context Society type individualism masculinity power distance rituals language gender differences behavioral norms Educational Description of educational preferences Common pedagogical approaches teaching style relation to teachers  fellow learners group work Communication Description of communication preferences Electronic communication face to face communication communication in groups feedback preferences Technical Description of technical infrastructure Network speed bandwidth operating systems LMS accessibility Legal Description of legal background Intellectual property rights internet security Historical Historical influences Historical milestones symbols heroes Political Political situation Political system parties persons Religion Influence of religion System confession group religious leaders influence on society Development Status of development Infrastructure GNP This specification can be used as a start to represent the cultural characteristics of individuals as well as groups and organization However it is necessary to embed this specification with other specifications in the field 32 Conceptual Embedding with Learning Technology Standards The concept of culture profiles should be embedded with other representations of user data being used Most of the aspects in the specification are not yet covered in other specifications However certain relations need to be specified From a technical point of view the relations are specified by explicit refere nces to other profiles see table 1 From a conceptual level different relations are possible  IMS Learner Information Package This sp ecification covers educational aspects qualifications or preferences The above mentioned elements of Culture Profiles should be added to this specification in an application profile  EPortfolio This specification covers outcomes of a learner biography Several relations are possible A complete culture profile for example specified on a web page see chapter 4 can be added to an individual eportfolio as an outcome Additionally culturerelated experiences shoul d be added to a portfolio eg visits and experiences in foreign countri es or international projects  IMS RCDEO This specification covers competencies of individuals The main relation is that an actor should specify culturerelated competencies and experiences such as communication or management competencies in global settings The following figure illustrates the relations Figure 2 Conceptual Embedding of Culture Profiles By creating those relations the culture profile has a clear and well defined relation to other standards without conceptual overlaps 4 Implementation and Usage The main idea of Culture Profiles is the us age in globally distributed work and learning processes Therefore it is necessary to define the intended usage process as well as showing potential implementations 41 Using Culture Profiles Culture Awareness Processes In global working and learning processes problems are solved in a cooperative setting Those working and learning processes should be combined with an awareness process integrating the use of Culture Profiles The main aim is to facilitate cultural understanding and improving cooperation processes In a collaborative work process  problems are to be solved in a globally distributed team  this can be for example a common programming task or a common group assessment in Higher Education A culture awareness process should be integrated in at least two phases Once a project is initiated project members should initiate a culture awareness process in order to be prepared for the common task Ad ditionally the process s hould be initiated once problems or conflicts occur In the culture profiling phase  a group or individuals start to create and instantiate Culture Profiles This means that also a selfreflecti on process is initiated The Culture Profile is used as a guideline to reflect on cultural characteristics This means that actors are in many cases not aware of cultural factors affecting their behavior and acting In parallel actors should compare their profiles and detect similarities as well as differences Based on this comparison all participants should state their observations to summarize their experience Finally actors should develop stra tegies and rules how to deal with differences eg regarding communication negotiation or learning styles leading to a better understanding and group integration However conflicts and misunderstandings might still occur during a project  in this case a facilitator should initiate the Culture Awareness process again The processes and their relations are illustrated in the figure below Figure 3 Culture Awareness Process This process outlines the main steps and relation s how Culture Profiles can be integrated in work and learning processes using a culture awareness process The Culture Profiles serve as a basis for analysis as well as for discourse on culturerelated characteristics 42 Implementation with standard tools The main idea of Culture Profiles based on stan dards is to integrate cultural characteristics in learning or knowledge management systems In this case the specification can be easily added to user profiles eg using IMS LIP However Culture Profiles can also serve as a guideline for other easytouse implementations As Culture Profiles serve as a base for comparing and discussing cultural characteristics it is not useful to solely rely on user profiles which are in most cases static Culture Profiles should be used in a more dynamic way One option is the integration in communities In this case the attributes of a Culture Profile can serve as a base for individualized questionnaires to be integrated in user profiles As an example many professional as well as le isure communities provide tools for generating individual questionnaires This option could also be used to present cultural characteristics A second implementation is the use of tag cl ouds Culture Clouds to represent and connect cultural knowledge In our implementation for each category and attribute of a Culture Profile a tag is created This tag points to a more elaborated description of the cultural characteristic This elaboration was either do ne by the users themselves or pointed to external web links eg to descriptions of culture artifacts or symbols Figure 4 Culture Clouds By adding further tags users create extensions of the Culture Profile  this means that they add categories and attributes which are of importance for their context This usage shows the nature of Culture Profiles It is not a static specification but a tool for dynamic selfreflection and discourse Culture Cl ouds are a tool enabling users to describe themselves and to connect cultural descriptions and external resources The resulting Culture Clouds are continuously extended modified and prioritized This dynamic process is embedded in knowledge processes in order to improve cultural awareness and mutual understanding In our first experiences the profile helped users to describe themselves and to structure the debate on cultural differences and similarities As a next step we will perform an indepth analysis how the usage of these profiles will increase cultural awareness and understanding 5 Conclusion and Future Research The concept of Culture Profiles is a basic tool to describe cultural characteristics of actors and groups The concept can be easily implemen ted Either existing user profiles can be extended using the specification as an applica tion profile or using standard tools such as communities or social software tools As a next step the usage of the profiles and the inclusion into current standards should be realized One specific focus should be the inclusion in learner related standards such as IMS LIP The next challenge is the large scale adoptio n in communities such as professional and learning communities to analyze the longt erm consequences of this approach Those profiles and the inclusion into existing profiles will contribute towards better group work in globally distributed workgroups Acknowledgements Parts of this work have been done in the project COSMOS An Advanced Scientific Repository for Science Teaching and Learning funded by the European Union reference number 410025 References Dodds P Thropp SE 2004 Advanced Distributed Learni ng Initiative  Sharable Content Object Reference Model  2004 Overview Koper R Olivier B Anderson T 2002 IMS Learning Design Information Model Version 10 Cambridge D Smythe C McKell M 2005 IMS ePortfolio Information Model Version 10 Cooper A Ostyn C 2001 IMS Reusable Definition of Competency or Educational Objective Version 10 Dafoulas G Macaulay L 2001 Investigating Cultural Di fferences in Virtual Software Teams The Electronic Journal on Information Systems in Developing Countries EJISDC 74 pp 114 Edmundson A 2007 The Cultural Adaptation Process C AP Model Designing ELearning for Another Culture In Edmundson A Ed 2007 Globalized ELearning Cultural Challenges Idea Group US pp 267290 Gulovsen R J Bhatti T Hassal P J et al 2006 Cross cultural media usage and attitudes in the United Arab Emirates In Sudweeks F Hrachovaec H Ess C e ds CATaC06 Proceedings Cultural Attitudes towards Technology and Communication 2006 pp 142157 Gunawardana K D 2005 An Empirical Study of potential challenges and Benefits of Implementing Elearning in Sri Lanka In Proceedings of the Second International Conference on eLearning for KnowledgeBased Society Bangkok Thailand August 2005 pp 331338 Hall E T Hall M R 1990 Understanding cultural differences Yarmouth ME Intercultural Press Henderson L 2007 Theorizing a Multiple Cultures Inst ructional Design Model for E Learning and ETeaching In Edmundson A Ed 2007 Globalized ELearning Cultural Challenges Idea Group US pp 130154 Hofstede G Hofstede G J 2005 Cultures and Orga nizations Intercultu ral Cooperation and Its Importance for Survival USA revised an d expanded 2nd edition McGrawHill Publishers IEEE Learning Technology Standards Co mmittee 2002 Learning Object Meta data Standard IEEE 14841212002 Karolak DW 1998 Global Software Development Managing Virtual Teams and Environments Los Alamitos IEEE Computer Society USA Mabawonku A O 2003 Cultural framework for the development of science and technology in Africa Science and Public Policy 302 pp 117125 MacDermott R ODell C 2001 Overcoming cultural barriers to sharing knowledge Journal of Knowledge Management 51 pp 7685 Michie M 2003 The role of culture brokers in intercultural science education A research proposal 34th Annual Conference of the Australasian Science Education Research Association held in Melbourne July 2003 Pawlowski JM Richter T 2008 A Methodology to Co mpare and Adapt ELearning in the Global Context MKWI Munich Feb 2008 Pedersen PB 1988 A Handbook for Developing Multic ultural Awareness Alexandria VA American Counseling Association 1988 Redmiles D van der Hoek A AlAni B Hildenbrand T Quirk S Sarma A Silveira Silva Filho R de Souza C Trainer E 2007 Continuous Coordination A New Paradigm to Support Globally Distributed Software Development Projects In Wirtschaftsinformatik Special Issue on the Industrialization of Software Development 49 Special Issue pp 2838 Richter T Pawlowski JM 2007 The Need for Standard ization of Context Metadata for eLearning Environments Proc of eASEM Conference Seoul Korea Oct 2007 Sarma A van der Hoek A 2002 Palantír Increasing Awa reness in Distributed Software Development ICSE 2002 Workshop on Global Software Development Florida USA May 2002 pp 2832 Seufert S 2001 Cultural Perspectives In Adelsberger HH Collis B Pawlowski JM Eds Handbook of Information Technologies for Education and Training Berlin et al Springer Sgouropoulou C 2006 Developing and handling learner profiles for European learner information systems In Ehlers UD Pawlowski JM Eds 2006 Handbook on Quality and Standardisation in E Learning Springer Berlin Smythe C Tansey F Robson R 2001 IMS Learner Information Package Inform ation Model Version 10 Trompenaars F HampdenTurner C 1997 Riding the waves of culture Understanding cultural diversity in business Nicholas Brealey Publishing Draft Version Final Version in Pawlowski JM 2008 Culture Profiles Facilita ting Global Learning and Knowledge Sharing Proc of ICCE 2008 Taiwan Nov 2008 Culture Profiles Facilit ating Global Learning and Knowledge Sharing Jan M Pawlowski Information Technology Research Institute University of Jyväskylä Finland janpawlowskititujyufi Abstract The paper describes the concept of Culture Profiles to facilitate globally distributed work groups The concept describes a representation for cultural characteristics for groups and individuals and relates this concept to existing standards Hence it is embedded in the landscape of learning technology standards A sample implementation for social communities  Culture Clouds  shows the feasibility of the concept It leads to improved cultural awareness and better mutu al understanding in international groups of knowledge workers and learners Keywords Culture Profile learning technology standards Leaner Information Cultural Awareness global learning global knowledge management Culture Clouds 1 Introduction In this paper the approach of Culture Profil es is shown as a tool to improve cultural awareness in global knowledge sharing and learning processes Culture Profiles describe cultural characteristics on different levels su ch as national organizational or individual characteristics The concept is related to existing specifications and standards in order to implement an innovative concept in an interoperable way Global knowledge sharing is still a challenging but highly significant task Global organizations or temporary partnerships work distributed all over the globe  more and more study programs include learners from all over the world in ELearning study programs This means that globally distributed teams need to be supported to work effectively and efficiently The main question of this article is how to facilitate global teams in particular teams in knowledge intensive processes such as knowledge management or learning processes The paper describes the concept of cultural awaren ess and Culture Profiles to facilitate those groups with easy to use tools However there are already many standards to describe actor characteristics Therefore this paper extends standards like IMS Leaner Information Package Smyth Tansey  Robson 2001 IMS EPortfolio Cambridge Smythe  McKell 2005 and provides a conceptual embedding In the first section I will describe and analyze existing models to describe and represent cultural characteristics Based on this analysis the need for cultural awareness and Culture Profiles is derived This concept is embedded into a framework of existing standards and specifications The article conc ludes with a sample implementation and an outlook on future activities 2 Culture and Knowledge Sharing Global work settings are changing rapidly internationally distributed teams face an increasing emphasis on knowledge intensive work while technology enables new connections and interactions E ffective collaboration within international networks is one of the most important competencies for actors In this chapter I will briefly discuss two aspects Models and representations of culture and awareness on cultural aspects as a critical success factor 21 Culture Models and Representations Cultural differences are currently discussed from different angles and fo r different scopes in order to understand their influence on working and learning processes Generally culture can be defined and analyzed on different levels  National  regional aspects define characteristics and attributes common to actors coming from or living in a certain geographic location  Organizational aspects define characte ristics and attributes for a certain organization such as companies or teams  Professional aspects define characteristics and attributes for actors in a certain profession or with a similar educational background  Individual aspects define characteristics and attributes for actors which describe their personality as well as individual preferences and interests Figure 1 Culture Levels One approach is to identify models that represent national cultures with a controllable set of attributes cf Hall  Hall 1990 Hofstede  Hofstede 2005 Henderson 2007 Trompenaars  HampdenTurner 1997 Additionally many studies have analyzed specific aspects of cultural influences for kno wledge intensive domains  professional fields such as education Edmundson 2007 Henderson 2007 or software development Dafoulas  Macaulay 2001 Karolak 1998 Other studies have researched the cultural impact of certain geographical locations eg Gulovsen et al 2006 Gunawardana 2005 Mabawonku 2003 Most of the studies clearly emphasize the importance of identifying and recognizing the differences and similarities when cooperating to reduce the resulting barriers To work together successfully it is highly necessary to reflect about ones own and the collaborators cultural characteristics The above mentione d cultural models can support this reflection process 22 Culture awareness One critical success factor of successful knowle dge exchange in collaboration settings is the awareness about cultural characteristics Byram 1997 In the field of globally distributed learning processes this can play a crucial role In international scenarios many barriers arise such as misunderstandings and miscon ceptions regarding culture communication and cooperation cf Seufert 2001 MacDermott  ODell 2001 Different solutions have been proposed for inte rcultural settings to address those issues Awareness about cultural issues Pedersen 1988 Byram 1997 and the teams  fellow colleagues Redmiles et al 2007 Sarma  van der Hoek 2002 seems to play an important role Therefore an approach is necessary to cover both levels awareness regarding culture and presence We use the concept of culture profiling Dafoulas  Macaulay 2001 and support by the facilitator cf Michie 2003 to achieve awareness Culture Profiles describe cultural and individual characteristics on differe nt levels cf Henderson 2007 Dafoulas  Macaulay 2001 Pawlowski Richter 2008 to increase knowledge about collaborators 23 Standards For the field of learning education and traini ng a variety of standards has been developed to enable and ensure interoperability such as Learning Object Metadata LOM IEEE 2002 Sharable Content Object Reference Model SCORM Dodds  Thropp 2004 or IMS Learning Design IMS LD Koper Olivier  Anderson 2002 One group of standards deals with the descri ption and modeling of actors  learners in learning processes cf Sgouropoulou 2006 The objective of this class of standards is to provide a specification for user profiles whic h can be transferred across institutions and systems An example is the specification IMS Learner Information Package IMS LIP Smythe Tensey  Robson 2001 Another important development to represent and exchange user information are eportfolios This specification describes outcomes from a learner such as achievements works skills or goals Finally a specification to represent competencies has been developed The specification IMS RCDEO Reusable Definition of Competency or Educational Objective Cooper  Ostyn 2001 describes competencies of an individual in an interoperable way Those three mentioned standards can support the interoperable description of actor characteristics from different perspectives However none of the above discussed specifications contain information  attributes regarding cultural characteristics Therefore it is necessary to extend thos e regarding cultural issues 3 Culture Profiles A Culture Profile can be defined as the characteristics of an entity determined by its culture An entity in most cases is an individual However this profile can also be defined for a larger entity such as an organization organ izational culture group professional culture or even a society national culture 31 Concept A Culture Profile cannot be defined as a fixed or prescribed specification The concept proposed is only a basic outline to cover important cultural attributes in knowledge intensive processes The specification should be extended and dynamically improved based on the context The idea of a culture profile is to represent cultural characteristics from different perspectives It is based on previous research work in which we have identified cultural influence factors which affect learning and knowledge processes Richter  Pawlowski 2007 Pawlowski  Richter 2008 Those characteristics are not intended to completely represent a cultural background of an individual but to provide a guideline for selfreflection and comparisons The following table illustrates Culture Profiles Table 1 Culture Profile Category Description Sample Attributes General General profile description Name Creator Date of creation Type organizational individual national Reference References to other profiles Vcard reference LIP reference eportfolio reference Europassreference other references Experiences Culture related experiences Country visit situations conflicts attitudes cases Culture Description of the cultural context Society type individualism masculinity power distance rituals language gender differences behavioral norms Educational Description of educational preferences Common pedagogical approaches teaching style relation to teachers  fellow learners group work Communication Description of communication preferences Electronic communication face to face communication communication in groups feedback preferences Technical Description of technical infrastructure Network speed bandwidth operating systems LMS accessibility Legal Description of legal background Intellectual property rights internet security Historical Historical influences Historical milestones symbols heroes Political Political situation Political system parties persons Religion Influence of religion System confession group religious leaders influence on society Development Status of development Infrastructure GNP This specification can be used as a start to represent the cultural characteristics of individuals as well as groups and organization However it is necessary to embed this specification with other specifications in the field 32 Conceptual Embedding with Learning Technology Standards The concept of culture profiles should be embedded with other representations of user data being used Most of the aspects in the specification are not yet covered in other specifications However certain relations need to be specified From a technical point of view the relations are specified by explicit refere nces to other profiles see table 1 From a conceptual level different relations are possible  IMS Learner Information Package This sp ecification covers educational aspects qualifications or preferences The above mentioned elements of Culture Profiles should be added to this specification in an application profile  EPortfolio This specification covers outcomes of a learner biography Several relations are possible A complete culture profile for example specified on a web page see chapter 4 can be added to an individual eportfolio as an outcome Additionally culturerelated experiences shoul d be added to a portfolio eg visits and experiences in foreign countri es or international projects  IMS RCDEO This specification covers competencies of individuals The main relation is that an actor should specify culturerelated competencies and experiences such as communication or management competencies in global settings The following figure illustrates the relations Figure 2 Conceptual Embedding of Culture Profiles By creating those relations the culture profile has a clear and well defined relation to other standards without conceptual overlaps 4 Implementation and Usage The main idea of Culture Profiles is the us age in globally distributed work and learning processes Therefore it is necessary to define the intended usage process as well as showing potential implementations 41 Using Culture Profiles Culture Awareness Processes In global working and learning processes problems are solved in a cooperative setting Those working and learning processes should be combined with an awareness process integrating the use of Culture Profiles The main aim is to facilitate cultural understanding and improving cooperation processes In a collaborative work process  problems are to be solved in a globally distributed team  this can be for example a common programming task or a common group assessment in Higher Education A culture awareness process should be integrated in at least two phases Once a project is initiated project members should initiate a culture awareness process in order to be prepared for the common task Ad ditionally the process s hould be initiated once problems or conflicts occur In the culture profiling phase  a group or individuals start to create and instantiate Culture Profiles This means that also a selfreflecti on process is initiated The Culture Profile is used as a guideline to reflect on cultural characteristics This means that actors are in many cases not aware of cultural factors affecting their behavior and acting In parallel actors should compare their profiles and detect similarities as well as differences Based on this comparison all participants should state their observations to summarize their experience Finally actors should develop stra tegies and rules how to deal with differences eg regarding communication negotiation or learning styles leading to a better understanding and group integration However conflicts and misunderstandings might still occur during a project  in this case a facilitator should initiate the Culture Awareness process again The processes and their relations are illustrated in the figure below Figure 3 Culture Awareness Process This process outlines the main steps and relation s how Culture Profiles can be integrated in work and learning processes using a culture awareness process The Culture Profiles serve as a basis for analysis as well as for discourse on culturerelated characteristics 42 Implementation with standard tools The main idea of Culture Profiles based on stan dards is to integrate cultural characteristics in learning or knowledge management systems In this case the specification can be easily added to user profiles eg using IMS LIP However Culture Profiles can also serve as a guideline for other easytouse implementations As Culture Profiles serve as a base for comparing and discussing cultural characteristics it is not useful to solely rely on user profiles which are in most cases static Culture Profiles should be used in a more dynamic way One option is the integration in communities In this case the attributes of a Culture Profile can serve as a base for individualized questionnaires to be integrated in user profiles As an example many professional as well as le isure communities provide tools for generating individual questionnaires This option could also be used to present cultural characteristics A second implementation is the use of tag cl ouds Culture Clouds to represent and connect cultural knowledge In our implementation for each category and attribute of a Culture Profile a tag is created This tag points to a more elaborated description of the cultural characteristic This elaboration was either do ne by the users themselves or pointed to external web links eg to descriptions of culture artifacts or symbols Figure 4 Culture Clouds By adding further tags users create extensions of the Culture Profile  this means that they add categories and attributes which are of importance for their context This usage shows the nature of Culture Profiles It is not a static specification but a tool for dynamic selfreflection and discourse Culture Cl ouds are a tool enabling users to describe themselves and to connect cultural descriptions and external resources The resulting Culture Clouds are continuously extended modified and prioritized This dynamic process is embedded in knowledge processes in order to improve cultural awareness and mutual understanding In our first experiences the profile helped users to describe themselves and to structure the debate on cultural differences and similarities As a next step we will perform an indepth analysis how the usage of these profiles will increase cultural awareness and understanding 5 Conclusion and Future Research The concept of Culture Profiles is a basic tool to describe cultural characteristics of actors and groups The concept can be easily implemen ted Either existing user profiles can be extended using the specification as an applica tion profile or using standard tools such as communities or social software tools As a next step the usage of the profiles and the inclusion into current standards should be realized One specific focus should be the inclusion in learner related standards such as IMS LIP The next challenge is the large scale adoptio n in communities such as professional and learning communities to analyze the longt erm consequences of this approach Those profiles and the inclusion into existing profiles will contribute towards better group work in globally distributed workgroups Acknowledgements Parts of this work have been done in the project COSMOS An Advanced Scientific Repository for Science Teaching and Learning funded by the European Union reference number 410025 References Dodds P Thropp SE 2004 Advanced Distributed Learni ng Initiative  Sharable Content Object Reference Model  2004 Overview Koper R Olivier B Anderson T 2002 IMS Learning Design Information Model Version 10 Cambridge D Smythe C McKell M 2005 IMS ePortfolio Information Model Version 10 Cooper A Ostyn C 2001 IMS Reusable Definition of Competency or Educational Objective Version 10 Dafoulas G Macaulay L 2001 Investigating Cultural Di fferences in Virtual Software Teams The Electronic Journal on Information Systems in Developing Countries EJISDC 74 pp 114 Edmundson A 2007 The Cultural Adaptation Process C AP Model Designing ELearning for Another Culture In Edmundson A Ed 2007 Globalized ELearning Cultural Challenges Idea Group US pp 267290 Gulovsen R J Bhatti T Hassal P J et al 2006 Cross cultural media usage and attitudes in the United Arab Emirates In Sudweeks F Hrachovaec H Ess C e ds CATaC06 Proceedings Cultural Attitudes towards Technology and Communication 2006 pp 142157 Gunawardana K D 2005 An Empirical Study of potential challenges and Benefits of Implementing Elearning in Sri Lanka In Proceedings of the Second International Conference on eLearning for KnowledgeBased Society Bangkok Thailand August 2005 pp 331338 Hall E T Hall M R 1990 Understanding cultural differences Yarmouth ME Intercultural Press Henderson L 2007 Theorizing a Multiple Cultures Inst ructional Design Model for E Learning and ETeaching In Edmundson A Ed 2007 Globalized ELearning Cultural Challenges Idea Group US pp 130154 Hofstede G Hofstede G J 2005 Cultures and Orga nizations Intercultu ral Cooperation and Its Importance for Survival USA revised an d expanded 2nd edition McGrawHill Publishers IEEE Learning Technology Standards Co mmittee 2002 Learning Object Meta data Standard IEEE 14841212002 Karolak DW 1998 Global Software Development Managing Virtual Teams and Environments Los Alamitos IEEE Computer Society USA Mabawonku A O 2003 Cultural framework for the development of science and technology in Africa Science and Public Policy 302 pp 117125 MacDermott R ODell C 2001 Overcoming cultural barriers to sharing knowledge Journal of Knowledge Management 51 pp 7685 Michie M 2003 The role of culture brokers in intercultural science education A research proposal 34th Annual Conference of the Australasian Science Education Research Association held in Melbourne July 2003 Pawlowski JM Richter T 2008 A Methodology to Co mpare and Adapt ELearning in the Global Context MKWI Munich Feb 2008 Pedersen PB 1988 A Handbook for Developing Multic ultural Awareness Alexandria VA American Counseling Association 1988 Redmiles D van der Hoek A AlAni B Hildenbrand T Quirk S Sarma A Silveira Silva Filho R de Souza C Trainer E 2007 Continuous Coordination A New Paradigm to Support Globally Distributed Software Development Projects In Wirtschaftsinformatik Special Issue on the Industrialization of Software Development 49 Special Issue pp 2838 Richter T Pawlowski JM 2007 The Need for Standard ization of Context Metadata for eLearning Environments Proc of eASEM Conference Seoul Korea Oct 2007 Sarma A van der Hoek A 2002 Palantír Increasing Awa reness in Distributed Software Development ICSE 2002 Workshop on Global Software Development Florida USA May 2002 pp 2832 Seufert S 2001 Cultural Perspectives In Adelsberger HH Collis B Pawlowski JM Eds Handbook of Information Technologies for Education and Training Berlin et al Springer Sgouropoulou C 2006 Developing and handling learner profiles for European learner information systems In Ehlers UD Pawlowski JM Eds 2006 Handbook on Quality and Standardisation in E Learning Springer Berlin Smythe C Tansey F Robson R 2001 IMS Learner Information Package Inform ation Model Version 10 Trompenaars F HampdenTurner C 1997 Riding the waves of culture Understanding cultural diversity in business Nicholas Brealey Publishing ,https://en.wikipedia.org/wiki/Internationalization_and_localization,Localization,2902,12829
Automated Web Testing Tools,Contents ToggleOpen source frameworks for automated testing of web appsLowcode tools for automated testing of web appsNocode tools for automated testing of web appsIf youre interested in automating the testing of your web application there are three categories of tools to understandOpensource frameworks like Selenium and CypressLowcode toolsNocode toolsThe best automated testing solution for your web application will depend largely on the resources you have and the tradeoffs youre willing to makeIn this piece Im going to help you understand the strengths and shortcomings that come with each of these types of testing tools as well as who theyre each bestsuited forIf youre a startup ready to transition away from manual testing into automation check out Rainforest QAUnlike other tools its both nocode and intuitive so anyone can start using it to automate web tests right away without any trainingTalk to us about setting up a Rainforest plan that fits your needsContents ToggleOpen source frameworks for automated testing of web appsLowcode tools for automated testing of web appsNocode tools for automated testing of web appsOpen source frameworks for automated testing of web appsBefore we get into the benefits and challenges of these tools heres a handful of the most popular open source frameworks for endtoend automated testing of web apps SeleniumSelenium supports all major browsers runs on all major operating systems Windows MacOS and Linux and supports test creation via any one of a number of programming languages including JavaScript Groovy Java C PHP Python Perl and Ruby Its quite complex to configure and use relative to other frameworks so its good for teams who can QA engineers and dont necessarily need to move fastA short Selenium test script in PythonCypressCypress is popular among some frontend developers since its tests are written in JavaScript its tests execute very fast especially relative to Selenium and theres builtin support for other compelling features like stubbing APIs and simulating network conditions But it comes with notable limitations For example it only works with Firefox and Chromium browsers no compatibility with Safari or Internet Explorer and tests cant run across multiple browsers or tabs You cant execute tests in parallel without paying for Cypress Cloud the premium version of CypressAppiumAppium is derived from Selenium Webdriver the core component of Selenium and specializes in native mobile app and web app tests for iOS and Android devices Similar to Selenium it supports multiple programming languagesPlaywrightPlaywright is a Microsoftbacked project thats quickly grown in popularity since its release in 2020 It can do several things Cypress cant including do crossbrowser test execution across all major browsers perform parallel testing without a paid upgrade and support multiple languages JavaScript Java Python and NETThe benefits of open source automated testing frameworksPower and flexibilityIf youre a developer or QA engineer whos familiar with an open source framework and one of its supported scripting languages you can create automated scripts for any number of test cases including complex ones First the inherent versatility of code makes codebased test scripting flexible and powerfulPlus many thirdparty developers have created plugins open source and otherwise to extend the functionality of these frameworksIn addition to endtoend testing you can also use frameworks like Selenium and Cypress for unit testingFree support The frameworks Ive mentioned have large and active communities where you can get troubleshooting help at no cost but of course the consistency and reliability of responses will varyThe challenges of open source testing frameworks Technical barriersWhat all of the open source software testing frameworks have in common is that they require coding skills and knowledge of a testing framework to use Only personnel who can interpret code and understand the way the tests are structured can write or update testsThese personnel are usually either QA engineers or frontend developers who split their time between shipping code and maintaining the test suite So if you cant afford to hire additional specialized QA headcount or to take developer time away from shipping code these tools arent going to be a good fit for youLimited costeffectivenessTechnically open source frameworks are free to use as long as your configuration doesnt require premium addons For example Selenium is basically just a framework for automating browsers If you want to get insightful test results test management tools visual regression testing and other table stakes testing features youll need to integrate third party plugins some of which will require payment If you want to run tests in parallel youll either need to provision real or virtual machines or pay for a testing grid from BrowserStack Sauce Labs or similarPlus these tools require expensive technical headcount to operate them Expensive specialized headcountQA engineers and developers are expensive In fact the expense of these roles is usually the biggest financial cost of working with an open source framework when youre testing a web appEven if you dont hire QA engineers and instead use your existing developers to manage your test suite theres the opportunity cost of having them create and maintain endtoend tests instead of shipping code Trading between bottlenecks and product quality risksWorking with test scripts written in code is a doubleedged sword theyre versatile but they take longer to create and update than test scripts created with low or no code Every time a purposeful or unintended change in your web app causes your automated tests to fail someone has to dig around in your Selenium code for example to find the affected strings Then that someone has to update the code in the affected tests based on the expected behavior of the app which they may or may not be familiar with And this all assumes anyone with the right expertise is available when you need themThe usual result is either 1 code doesnt get shipped as the software development team waits for tests to get updated to a passing state or 2 the team gets tired of being blocked and ships code without updating the automated test suite The test suite becomes less reliable making the software development team even less inclined to invest in its maintenance creating a vicious cycle where the automated tests ultimately fail to do their job in protecting the quality of the productNo visual regression testing by defaultOpen source automated testing frameworks can miss bugs that make your web app unusableThats because by default these tools focus on testing the functionality of your web app while ignoring its visual layout and appearance So for example a test meant to validate the presence and functionality of a button could pass even if the button was obscured by a popup or accidentally colored to blend in with the backgroundThe only way to add automated visual regression testing to these tools is via a 3rdparty paid plugin like ApplitoolsWho are open source testing tools forOpen source tools are a good fit for teams who can afford the expensive technical headcount required to manage these complex tools and their coded test suites Youll need to hire dedicated QA engineers andor to take the time of your frontend developers away from shipping codeThese tools are also a good fit for large complex web apps that require the versatility of automated test scripts written in codeBetween the expense of headcount and the difficulty of creating and maintaining tests quickly theyre typically not a good fit for resourceconstrained startups that prioritize shipping fast Lowcode tools for automated testing of web appsMost lowcode test automation tools are record and playback tools they record your actions as you interact with your web app and then automatically transform those actions into automated test steps Its an easy way for anyone to quickly create tests without using any codeThe majority of recordandplayback tools can record basic tests with no coding but require coding skills to create complex test steps For instanceSelenium IDE TestCompleteTestimmablKatalon StudioRapiseGhost InspectorTelerik Test StudioSome recordandplayback tools can create morecomplex tests than others using just the recording feature But generally speaking youll need technical skills to create test steps that cover software testing scenarios like validating the contents of a download or confirming an email was receivedWith Rainforest you dont need to know code to quickly create test steps that validate file downloads or confirm emailsMost of these tools support JavaScript for creating test steps but there are exceptions Katalon supports Groovy and JAVA for example and TestComplete supports JavaScript Python VBScript Jscript DelphiScript C and CA test script written in Groovy in KatalonOnce youve recorded your tests these tools differ in terms of how much you have to use code to update and maintain your automated testsFor example at least one tool Squish requires coding skills to interpret and update any recorded tests Once you record test actions with Squish it creates a test in one of its supported scripting languages Python Perl Ruby JavaScript or TclA test script recorded with Squish Click image to expandWith other recording tools you could conceivably avoid using coding skills to create and maintain your test suite But theres a catch that no one really talks aboutThe majority of recordandplayback tools force you to interact with code even if you dont need to use coding skills per se This slows down the test automation process whether youve got technical skills or notMost people would identify a web application element like a button or headline by its visual appearance the big green login button or content the headline that says generate test scripts without code But these testing tools identify and interact with elements in your web app via behindthescenes locators in your web apps frontend code the DOM These locators could include CSS classes Xpaths or custom element IDs for instanceYoull typically encounter locators once a test is recorded and you want to review andor edit the recorded test stepsLocators in a test script recorded by Ghost InspectorIn some cases youll even have to translate locator code when youre recording a testmabl prompting the user to select the appropriate locator to identify an elementEven recordandplayback tools that dont allow any coded test scripting at all  like Screenster and DataDog Continuous Testing  require you to interact with locatorsThe benefits of lowcode test automationFaster test creationCoding automated tests by hand in an open source framework can be slow andor difficult Lowcode tools make it easier to create automated tests more quickly with a recorder while still offering the versatility of coding to cover more complex test cases In fact tools like Katalon are basically a frontend for open source frameworks like Selenium and AppiumMore than just web application testingSome lowcode test automation tools have been built to offer more than just endtoend functional testing of web applications TestComplete and Katalon can both also test Windows desktop applications and native mobile applications mabl offers performance testingKatalon mabl and Rapise do API testingTestComplete supports behaviordriven development BDD scenarios via Gherkin syntax Other tools are compatible with Cucumber The challenges of lowcode test automationLocators slow things downHaving to dig around in the DOM to figure out which locator belongs to which element in your web app adds pretty annoying overhead to test creation and maintenanceUnnecessarily complexMany of these tools have complicated user interfaces and workflows that require training and familiarity to use with any success Their tests are written with proprietary commands and vernacular that feel like they might as well be written in code Testim is probably the best of the bunch in terms of ease of useThe TestComplete user interfaceCompanies often have just one or two people on the team who have developed the skills to use these tools Having a limited number of specialists can create bottlenecks in the release process when demands for test creation and maintenance are highNo visual regression testing by defaultLike open source tools lowcode testing tools focus on functional testing not visual regression testing Most of these tools except for Katalon feature unsophisticated exactmatch algorithms that compare baseline screenshots of your app to screenshots captured during tests Unless the screenshots match pixelforpixel the tool will throw an alert or fail the relevant test So even minor and expected updates to your app could cause disruptive falsepositive test failures that need to be debugged Other tools like Testim require that you integrate a thirdparty tool like Applitools for any sort of visual testingRegardless youll need to configure additional steps for every verification of a screen or app element you want to perform in the testing processWho are lowcode testing tools forLowcode tools are for teams who want to move more quickly than they can with open source tools but who have the technical headcount available to maintain tests andor create test coverage for complex cases Since lowcode testing tools are quite complex despite requiring less coding skill than an open source tool they typically require specialized headcount who can bottleneck the release process So theyre not a good fit for resourceconstrained startups or for teams interested in sharing responsibility for managing the test suite across different roles Nocode tools for automated testing of web appsThere are very few automated testing tools that can truly claim to be nocode Most testing tools  even some that claim to be codeless  require interacting with code to one extent or anotherFor example Virtuoso highlights that you can write its tests in natural language But you still have to deal with locators when maintaining its tests which isnt very natural Locators in VirtuosoOn the other hand TestRigor is a genuine nocode natural language solution You can write tests in plain English PlainEnglish test steps in TestRigorBut its not like ChatGPT  you cant just write whatever you want and expect TestRigors automation to understand You need to learn its 40 different test actions click type scroll and how to use them in correctlyformatted expressions that TestRigor can interpretFor example if you want a test to click on an element anywhere other than the center of the element the default then you need to specify an offset which isnt intuitiveClick on Delete with offset 2010As you can see nocode doesnt necessarily mean easy to useRainforest QA is the only trulynocode test automation tool thats so simple and intuitive anyone on your team can start writing and maintaining automated tests right away without any trainingAdding a test step in Rainforest is a simple as selecting a test action eg Click Fill Scroll and then draganddropping a box around the element to apply the action to Rainforest previews your web app on a Windows 10 virtual machinePlus youll never have to look at  let alone decipher  locator code when youre using Rainforest You can easily interpret and update test steps because theyre all in plain English An example of an automated test script created in RainforestRainforest doesnt have to use locators because it identifies elements in your web app not by their underlying code but by their visual appearance just like a real user would And Rainforest interacts with those buttons links form fields and other elements via the visual layer of your application just like a real end user wouldThat means unlike the vast majority of other automated testing tools Rainforest does both functional testing and visual testing by default in every test Intelligent AIpowered imagematching algorithms ignore minor visual changes in your app that a human tester wouldnt notice or care about so youre not constantly debugging falsepositive test failuresThis UI testing approach means Rainforest is uniquely able to test anything that appears onscreen  not just within the browser window So your Rainforest tests can for example download and verify the contents of files edit browser extension settings and do just about anything else a real user could on a Windows 10 machine For example heres a recording of a test that downloads and then installs Brave BrowserFinally unlike open source tools and many lowcode tools Rainforest includes everything you need to get started with and scale automated testing of web applications Theres no need to integrate any plugins or pay for any 3rdparty services It includesA proprietary nocode automation framework for creating and maintaining endtoend testsCloudbased Windows 10 virtual machines VMs running Chrome browsers Our Unlimited plan includes multiple operating systems and browsersTest results that include everything you need for test debugging video recordings plainEnglish test steps HTTP logs and browser logsIntegrations with email Slack and MS Teams for notifications and with JIRA so you can autogenerate tickets for bugsTest scheduling plus an API CLI and CI integrations for continuous testingTalk to us about setting up a Rainforest account See how you can create and run your first test within minutesThe benefits of Rainforests nocode test automation Rainforest is more intuitive than other test automation solutions so its easy for anyone to get started automating a test suite right away without any training regardless of their coding skills And you wont get slowed down dealing with any element locators  all tests are written in plain English so theyre easy to interpret and maintainSince Rainforest uniquely does both functional and visual testing by default youll have the confidence that your automated UI tests are protecting the enduser experience of your web app not just its behindthescenes functionality It tests what your end users will see not what a computer sees Rainforest is an allinone testing platform so you dont need to worry about provisioning any additional machines or services to get everything you need to create and run an automated test suiteThe challenges of nocode test automationNocode test automation tools like Rainforest are generally flexible enough to cover the majority of test cases However in some cases a technical person might prefer the versatility of code available via an open source framework to address edge cases or particularly complex test casesWhile some lowcode software testing tools can also test mobile applications and Windows desktop applications Rainforest has been optimized specifically for testing web applications So if youre interested in a solution for testing mobile apps and not just a web testing tool Rainforest might not be a good fit for youWho is Rainforest forRainforest is ideal for startup teams ready to transition away from manual testing They want to move faster but dont want to or cant hire expensive QA headcount to manage complex testing tools Rainforest is also perfect for teams who dont want to put the full burden of managing endtoend test automation on developers because the devs need to stay focused on shipping code These teams want anyone to be able to contribute to test maintenance without training or handholding so web app updates can keep getting shipped fastTalk to us about setting up a Rainforest account from selenium import webdriver from seleniumwebdrivercommonby import By def test_eight_components driver  webdriver Chrome driver gethttpsww selenium devseleniumwebwebform htmL title  drivertitle assert title  Web form driver implicitly_wait5 text_box  driver find_elementbyByNAME valuemytext submit_button  driver find_eLementbyByCSS_SELECTOR valuebutton text_boxsend_keysSelenium submit_buttonclick message  driver find_elementbyByID valuemessage  value  message text assert value  Received driver quit  Welcome 1 import static comkmskataloncorecheckpoint CheckpointFactory findCheckpoint 422 WebUI 24 WebUI 26 WebUI 28 WebUI 3 WebUI 32 WebUI 34 WebUI 36 WebUI 38 WebUI TC1_Verify Successful Login 5 comment Story Login to CURA system commentGiven that the user has the valid login information openBrowserGlobalVariable G_SiteURL clickfindTestObject Page_CuraHomepagebtn_MakeAppointment  setText findTestObjectPage_Logintxt_UserName Username setText findTest0bject Page_Logintxt_Password Password commentWhen he logins to CURA system clickfindTestObject Page_Loginbtn_Login commentThen he should be able to login successfullv W Manual  Script X Variables  Variables Script mode 8 Data Binding Wi Integration Properties 2 Cseriseneieuie dena 0 ae Fle it Refactoring Source Navigate Search Run Window Help startApplicationaddressbook cLickButton waitFordb ject nanesaddress_Book_New_QTool8utton cLickButtonwaitFordbject names address_Book_Unnamed_Adé_QToolButton typewaitFordbjectnanes forename_LineEdit sivo typewaitFordbject names forenane_LineEdit Tob Fordbjectnanes surname _LineEdit S Fordbjectnanes surname _LineEdit Tob I typewaitFordbject nanesenail_LineEdit sivaimeteoniccon typewaitForObject names email Linedit Tad Br daulevinieicesapierincwecer so ake RAGS py  Tt Onoong Test Suites  O Bitest tstcaset   tst an aia  sue 24 gesit Test caes SDH 3 snort noes best cases Sedef main eee wel  Test Case Resources 7a8e itForObject names phone_Linefdit 99999999 Scips Test Data VPs Gestures cLickButtonwaitFordbject names address Book_Add_Ok_QPushButton compare waitFordbjectExists nanesFile__QodelIndextext sivd compare strwaitFordbjectExists nanesFile___Qiodelindexfontfanily MS Shell Dlg 2 compare waitForobjectExists nanesfi compare waitFordbjectExists nanesfi compare waitForobjectExists names paso aoe 3600 compare waitFordbjectExists names font fixeaPitch False Scripts Test Data VPs Gestures Dames py Best Rests 5 Recent Test Resuts 760 G el mes P occu Rest Message Time   TestSuite site demo24 Jun 282019 51811 PM  Weblo on wn Edit Steps Test steps allow you to perform actions within the browser They are executed sequentially 1 v Passing  Move 3 Add Above 1 Add Below x Delete btnstart  4 Click  CMake this step optional Continue on failure Add notes LD 2 v Passing  Move 3 Add Above Add Below  Delete inputnanetitle  4 Click  CMake this step optional Continue on failure Add notes L 3 v Passing b Move 3 Add Above 1Add Below x Delete inputnanetitle   Assign  Sample Value J CMake this step optional Continue on failure Upload a file for use witha file input element CO Make this value private Hide in display Upload File Add notes 4 mab sandbox x   sandboxmablcom Chrome is being controled by automated test software Welcome to the mabl sandbox Use this site to practice creating tests using the mabl trainer Once you have the trainer installed and recording you can click on any link below to test a sample Ul control Sample components Sowaioas mo eors   SRAGANDORGR Prerere Looring Sicoat wind iewand SapiouuTrong  SuLATeDLOGIN Se mabi Trainer master  Similar elements found  Providing more context wll reduce the number of elements found and improve test accuracy Ta elements found low confidence Wy did you pick this element This helps mabl keep tack ofit as your app changes You can choose mukiple answers Its innerTextis MAILBOX its las is MuiButtonlabel MAILBOX tes inthe container wth class MuiButtonBaseroot MuiButtonroot MuiButton outlined jss15 MuiButton outlinedsizeLarge MuiButton sizeLarge Show me more options Skip BB testcompiete  CUsersPublicDocumentsTestComplete 12 SemplesWebWebStoreWebsStore_ Semple Project Suite pis  o x fle Et View Tet Debug Too Ty Hep  a ew ERB  BARB BB so B stowmtie seen ret Werk hj rer RS Se cy ass G orders KOT Xx  NameMapping Xp Orders KOT_1 x iG NameMapping x oo Testi x pl Teatt x ji Notepad VideoRecord x o Tew x Gh Script Test Log UntiVoo 102 X  ol rventame ia Di ee ry Geen Frequent Used B a  ee Eorenk ST Trem Ao Orscmen Aton os Drier er Moth re cert me ten cd and hen Site  Cp Tendon eenine a hew con woes sees Sst de 6205 nh Da dine ee keene Np Pen Aton owe Se re Ses de 180208 nt Da ne ce yes 5 ented at Sete tran htt in Cane et de  Reasriead esteem ci Bt ten aie rane Warneg Thing Tn a Fo arg two  eg acca ni A REED Sows ck wher hc math toca cin nth Fy Icmcues ence On eat fares ine et lero oamact eed ch OmaLoop Sample i Object ee etna nd on arto   Deseree 3 Test Senos 3 Variables 3 Parameters re pl Tea Vaate  an Stone Ute entree ae  nate Sade Pr ne Gtr Se roe 72008 246127 Cire se re 9208 240447 Cy Keyword Test Log DataLoop_ Sample 10262018 Py Keyword Test Log SimpleTest Sample 1026201 Cnr Sr on 157089057 Pret Cle lew Sinai Sem bebe fans Screenshot Healing  Tickets Step timeline t Found Sticker Comet Integration 4EUR ee  eee  Added selectors  Xpath ID idprod_4553divaspanspan2  CSS cls_3308 Removed broken selectors  Xpath ID idprod_2719divaspanspan2  CSS cls_ 5009 Element code changes truncate cls_5009 truncate cls_3308 Comet Integration span ee es  tostRigor testing from end co apptestrigorcom 1 testRigor testing from endu x   Checkout Best Buy Edit custom steps test case Please enter testcase description and steps Description Carit buy a Kindle without email CCustom steps new line separated type enter cick Kindle lick Addt cart roughly on the right of Amazon Kindle EReader clickGoto Can mmonthe right of Kindle EReader 2 nto Phone Nummbe liek Continue to payment information check that page contains Please enter an email addres Single tine should contain step in format ation value Validate nd Save  Documentation Update and Retest   1  tcognito Start at  hetpsihww bom com Click  leftmouse on_ Start building Fill  Work email address with Click  leftmouse on Continue Fill  Create new password with Click   leftmouse  on Create account cb cb cb cb cb CMAS CALIFORNIA MULTIPLE AWARD SCHEDULES GSA TYPE 2 l on  CJ Click on Delete with offset 2010,https://www.rainforestqa.com/blog/web-application-automated-testing-tools,Testing and Debugging,1503,4053
Virtual DOM in Web Development, The virtual DOM is a fundamental React concept if youve written any React code within the last few years youve probably heard of it However you might not understand how it works and why React uses it In this article well cover what the virtual DOM is exploring its benefits in React and reviewing a practical example Lets get started Jump ahead What is the React DOM How rerendering impacts performance Exploring the React virtual DOM How does the React virtual DOM differ from the real DOM The virtual DOM object How React implements the virtual DOM The React diffing process How React diffs lists React virtual DOM vs shadow DOM React virtual DOM vs real DOM Comparison chart Real DOM vs virtual DOM vs shadow DOM What is the React DOM To understand the virtual DOM and learn why React implements it lets first refresh our knowledge of what the actual browser DOM is Normally whenever a user requests a webpage the browser receives an HTML document for that page from the server The browser then constructs a logical treelike structure from the HTML to show the user the requested page in the client This treelike structure is called the Document Object Model also known as the DOM It is a structural representation of the web document as nodes and objects in this case an HTML document The DOM serves as an interface for the web document so that JavaScript and other scripting languages can access manipulate and programmatically interact with the documents content For example developers can use DOM APIs to add or remove elements modify their appearance and perform user actions on web elements How rerendering impacts performance DOM operations are very fast light operations However when the app data changes and triggers an update rerendering can be expensive Lets simulate rerendering a page with the JavaScript code below const update     const element   h3JavaScripth3 form input typetext form spanTime new DatetoLocaleTimeStringspan  documentgetElementByIdroot1innerHTML  element  setIntervalupdate 1000 You can find the complete code on CodeSandbox The DOM tree representing the document looks like the following The setInterval callback in the code lets us trigger a simulated rerender of the UI after every second As seen in the GIF below the document DOM elements are rebuilt and repainted on each update The text input in the UI also loses its state due to this rerendering As seen above the text field loses the input value when an update occurs in the UI which calls for optimization Different JavaScript frameworks offer different solutions and strategies to optimize rerendering However React implements the concept of the virtual DOM Exploring the React virtual DOM As the name implies the virtual DOM is a much lighter replica of the actual DOM in the form of objects The virtual DOM can be saved in the browser memory and doesnt directly change what is shown on the users browser Implemented by several other frontend frameworks like Vue Reacts declarative approach is unique Over 200k developers use LogRocket to create better digital experiences Learn more  How is the virtual DOM different from the real DOM A common misconception is that the virtual DOM is faster than or rivals the actual DOM however this is untrue In fact the virtual DOMs operations support and add on to those of the actual DOM Essentially the virtual DOM provides a mechanism that allows the actual DOM to compute minimal DOM operations when rerendering the UI For example when an element in the real DOM is changed the DOM will rerender the element and all of its children When it comes to building complex web applications with a lot of interactivity and state changes this approach is slow and inefficient Instead in the rendering process React employs the concept of the virtual DOM which conforms with its declarative approach Therefore we can specify what state we want the UI to be in after which React makes it happen After the virtual DOM is updated React compares it to a snapshot of the virtual DOM taken just before the update determines what element was changed and then updates only that element on the real DOM This is one method the virtual DOM employs to optimize performance Well go into more detail later The virtual DOM abstracts manual DOM manipulations away from the developer helping us to write more predictable and unruffled code so that we can focus on creating components Thanks to the virtual DOM you dont have to worry about state transitions Once you update the state React ensures that the DOM matches that state For instance in our last example React ensures that on every rerender only Time gets updated in the actual DOM Therefore we wont lose the value of the input field while the UI update happens The virtual DOM object Lets consider the following render code representing the React version of our previous JavaScript example   const update     const element    h3Reacth3 form input typetext  form spanTime new DatetoLocaleTimeStringspan   rootrenderelement  For brevity we have removed some of the code You can see the complete code on CodeSandbox We can also write JSX code in plain React as follows const element  ReactcreateElement ReactFragment null ReactcreateElementh3 null React ReactcreateElement form null ReactcreateElementinput  type text   ReactcreateElementspan null Time  new DatetoLocaleTimeString  Keep in mind that you can get the React equivalent of JSX code by pasting the JSX elements in a Babel REPL editor Now if we log the React element in the console well end up with something like in the following image const element    h3Reacth3 form input typetext  form spanTime new DatetoLocaleTimeStringspan   consolelogelement The object as seen above is the virtual DOM It represents the user interface How React implements the virtual DOM To understand the virtual DOM strategy we need to understand the two major phases that are involved rendering and reconciliation When we render an application user interface React creates a virtual DOM tree representing that UI and stores it in memory On the next update or in other words when the data that renders the app changes React will automatically create a new virtual DOM tree for the update To further explain this we can visually represent the virtual DOM as follows The image on the left is the initial render As the Time changes React creates a new tree with the updated node as seen on the right side Remember the virtual DOM is just an object representing the UI so nothing gets drawn on the screen After React creates the new virtual DOM tree it compares it to the previous snapshot using a diffing algorithm called reconciliation to figure out what changes are necessary After the reconciliation process React uses a renderer library like ReactDOM which takes the differ information to update the rendered app This library ensures that the actual DOM only receives and repaints the updated node or nodes As seen in the image above only the node whose data changes gets repainted in the actual DOM The GIF below further proves this statement When a state change occurs in the UI were not losing the input value In summary on every render React compares the virtual DOM tree with the previous version to determine which node gets updated ensuring that the updated node matches up with the actual DOM The React diffing process When React diffs two virtual DOM trees it begins by comparing whether or not both snapshots have the same root element If they have the same elements like in our case where the updated nodes are of the same span element type React moves on and recurses on the attributes In both snapshots no attribute is present or updated on the span element React then repeats the procedure on the children Upon seeing that the Time text node has changed React will only update the actual node in the real DOM On the other hand if both snapshots have different element types which is rare in most updates React will destroy the old DOM nodes and build a new one For instance going from span to div as shown in the respective code snippets below spanTime 043635span divTime 043638div In the following example we render a simple React component that updates the component state after a button click import  useState  from react const App     const open setOpen  useStatefalse return  div classNameApp button onClick  setOpenprev  prevtogglebutton div classNameopen  open  close Im open  opened  closed div div   export default App Updating the component state rerenders the component However as shown below on every rerender React knows only to update the class name and the text that changed This update will not hurt unaffected elements in the render See the code and demo on CodeSandbox How React diffs lists When we modify a list of items how React diffs the list depends on whether the items are added at the beginning or the end of the list Consider the following list ul liitem 3li liitem 4li liitem 5li ul On the next update lets append an item 6 at the end like so ul liitem 3li liitem 4li liitem 5li liitem 6li ul React compares the items from the top It matches the first second and third items and knows only to insert the last item This computation is straightforward for React However lets insert item 2 at the beginning as follows ul liitem 2li liitem 3li liitem 4li liitem 5li ul Similarly React compares from the top and immediately realizes that item 3 doesnt match item 2 of the updated tree It therefore sees the list as an entirely new one that needs to be rebuilt Instead of rebuilding the entire list we want the DOM to compute minimal operations by only prepending item 2 React lets us add a key prop to uniquely identify the items as follows ul li key3item 3li li key4item 4li li key5item 5li ul ul li key2item 2li li key3item 3li li key4item 4li li key5item 5li li key6item 6li ul With the implementation above React would know that we have prepended item 2 and appended item 6 As a result it would work to preserve the items that are already available and add only the new items in the DOM If we omit the key prop whenever we map to render a list of items React is kind enough to alert us in the browser console How is the virtual DOM different from the shadow DOM Before we wrap up heres a question that often comes up Is the shadow DOM the same as the virtual DOM The short answer is that their behavior is different The shadow DOM is a tool for implementing web components Take for instance the HTML input element range input typerange  This gives us the following result If we inspect the element using the browsers developer tools well see only a simple input element However internally browsers encapsulate and hide other elements and styles that make up the input slider Using Chrome DevTools we can enable the Show user agent shadow DOM option from Settings to see the shadow DOM In the image above the structured tree of elements from the shadowroot inside the input element is called the shadow DOM tree It provides a way to isolate components including styles from the actual DOM Therefore were sure that a widget or components style like the input range above is preserved no matter where it is rendered In other words their behavior or appearance is never affected by other elements styles from the real DOM Comparison chart Real DOM vs virtual DOM vs shadow DOM The table below summarizes the differences between the real DOM the virtual DOM and the shadow DOM Real DOM Virtual DOM Shadow DOM Description An interface for web documents allows scripts to interact with the document An inmemory replica of the actual DOM A tool for implementing web components or an isolated DOM tree within an actual DOM for scoping purposes Relevance to developers Developers manually perform DOM operations to manipulate the DOM Developers dont have to worry about state transitions the virtual DOM abstracts DOM manipulation away from the developer Developers can create reusable web components without worrying about style conflicts from the hosting document Who uses them Implemented in browsers Used by libraries and frameworks like React Vue etc Used by web components Project complexity Suitable for simple small to mediumscale projects without complex interactivity Suitable for complex projects with a high level of interactivity Suitable for simple to medium scale projects with less complex interactivity CPU and memory usage When compared to virtual DOM updates real DOM uses less CPU and memory When compared to real DOM updates virtual DOM uses more CPU and memory When compared to virtual DOM updates shadow DOM uses less CPU and memory Encapsulation Does not support encapsulation since components can be modified outside of its scope Supports encapsulation as components cannot be modified outside of its scope Supports encapsulation as components cannot be modified outside of its scope Conclusion React uses the virtual DOM as a strategy to compute minimal DOM operations when rerendering the UI It is not in rivalry with or faster than the real DOM The virtual DOM provides a mechanism that abstracts manual DOM manipulations away from the developer helping us to write more predictable code It does so by comparing two render trees to determine exactly what has changed only updating what is necessary on the actual DOM Like React Vue also employs this strategy However Svelte proposes another approach to ensure that an application is optimized compiling all components into independent tiny JavaScript modules making the script very light and fast to run I hope you enjoyed reading this article Be sure to share your thoughts in the comment section if you have questions or contributions Get set up with LogRockets modern React error tracking in minutes Visit httpslogrocketcomsignup to get an app ID Install LogRocket via npm or script tag LogRocketinit must be called clientside not serverside npm Script tag  npm i save logrocket  Code import LogRocket from logrocket LogRocketinitappid  Add to your HTML script srchttpscdnlringestcomLogRocketminjsscript scriptwindowLogRocket  windowLogRocketinitappidscript Optional Install plugins for deeper integrations with your stack Redux middleware NgRx middleware Vuex plugin Get started now Share thisClick to share on Twitter Opens in new windowClick to share on Reddit Opens in new windowClick to share on LinkedIn Opens in new windowClick to share on Facebook Opens in new window react LogRo OC Ket User Struggle Atiaue pees Last Weeky Severe Untriaged 222 High pact 12 Low impact 7 ignored Users unable to create list due to unresponsive button Users cant add membership numbers on website seuonsAK Sevety me Users unable to consistently add items to lists Seniom 690 Sey am Taster owe Fea co Users unable to continue shopping without signing in Users struggling to use Find function due to loading issues seuion22K Sevety am User encountered error modal cant complete checkout dropped oft L DOCTYPE html HTML HEAD BODY Lprv idroot1 text H3 Lgtext JavaScript text FORM text INPUT typetext text text SPAN Lgeext Time 193457 text Oe Ali Moiz  wv  ali_moiz  Follow Just going to say it LogRocket is the greatest new tool Ive used in the last year m_arbesfeld and team have built something amazing 4 1221 PM  Jun 23 2023 6  7  Reply  Copylink Read 3 replies y Object  Stypeof symbolreactelement type Symbolreactfragment key null ref null props _ conner null store    stypeof Symbolreactelement owner null Tsel null Tsource null  store object  _ ey null props object  children 3   children array3   1  1 Object  Stypeot symbolreactelement type h3 key null   Object  Stypeot symbolreactelement type form key null   Object  Stypeof Symbolreactelement type span key null   length 3  prototype array 1  prototype object    ref null type symbolreactfragnent Initial virtual DOM Updated virtual DOM Updated virtual DOM Actual DOM Initial virtual DOM vinput typerange vshadowroot useragent vdiv flex div pseudowebkitsliderrunnabletrack div idthumbdiv div div input LogRo OC Ket Real DOM Virtual DOM Shadow DOM 0 Real DOM Virtual DOM Shadow DOM 1 Description An interface for web documents allows scripts to interact with the document An inmemory replica of the actual DOM A tool for implementing web components or an isolated DOM tree within an actual DOM for scoping purposes 2 Relevance to developers Developers manually perform DOM operations to manipulate the DOM Developers dont have to worry about state transitions the virtual DOM abstracts DOM manipulation away from the developer Developers can create reusable web components without worrying about style conflicts from the hosting document 3 Who uses them Implemented in browsers Used by libraries and frameworks like React Vue etc Used by web components 4 Project complexity Suitable for simple small to mediumscale projects without complex interactivity Suitable for complex projects with a high level of interactivity Suitable for simple to medium scale projects with less complex interactivity 5 CPU and memory usage When compared to virtual DOM updates real DOM uses less CPU and memory When compared to real DOM updates virtual DOM uses more CPU and memory When compared to virtual DOM updates shadow DOM uses less CPU and memory 6 Encapsulation Does not support encapsulation since components can be modified outside of its scope Supports encapsulation as components cannot be modified outside of its scope Supports encapsulation as components cannot be modified outside of its scope ,https://blog.logrocket.com/virtual-dom-react/,Front-End Development,847,2894
State Management in Web Apps,State Management in Web Components Crafting Cohesive and Scalable SolutionsSudheer Kumar Reddy GowrigariFollow3 min readOct 3ListenShareState management is the heartbeat of any dynamic web application influencing its functionality responsiveness and user experience While Web Components provide encapsulation and modularity managing state within and across these components can be intricate This article delves deep into the realm of state management in Web Components exploring methodologies best practices and practical solutions to ensure cohesive and scalable applicationsThe Essence of State ManagementState management refers to the practice of handling storing and reacting to changes in the data that drives an applications behavior and UI Effective state management ensures that components remain in sync data flow remains unidirectional and predictable and the application remains maintainable as it scalesState Management in Web Components1 Component Local StateOverview Each Web Component can maintain its internal state which influences its behavior and rendered outputBest PracticesUse Class Properties Utilize class properties to store local state and react to changesLeverage Getters and Setters Implement getters and setters to observe and react to state changes triggering rerenders or side effects2 Shared State Across ComponentsOverview When multiple components need to access or modify the same state a shared state mechanism becomes essentialBest PracticesUse Custom Events Propagate state changes using custom events to inform parent components or other listenersImplement a Global Store For larger applications consider implementing a global state management system or store3 Integrating with State Management LibrariesOverview Several state management libraries can be integrated with Web Components to streamline state handlingBest PracticesConsider Lightweight Libraries Libraries like MobX or Zustand can be integrated with Web Components for efficient state managementIntegrate with Redux While traditionally used with React Redux can also be employed with Web Components ensuring a predictable state containerPractical Insights and RealWorld ExamplesExample Component Local State with Getters and Settersclass CounterComponent extends HTMLElement  constructor  super this_count  0 thisrender  get count  return this_count  set countvalue  this_count  value thisrender  render  thisinnerHTML   button onclickthiscountDecrementbutton spanthiscountspan button onclickthiscountIncrementbutton  customElementsdefinecountercomponent CounterComponentIn this example the internal state _count of the CounterComponent is observed and controlled using getters and setters Any changes in state trigger a rerender of the componentExample Shared State with Custom Eventsclass ChildComponent extends HTMLElement  constructor  super thisattachShadow mode open  thisshadowRootinnerHTML   button idnotifyBtnNotify Parentbutton  thisshadowRootquerySelectornotifyBtnaddEventListenerclick thisnotifyParent  notifyParent     thisdispatchEventnew CustomEventstateChange  detail  message State changed in child   customElementsdefinechildcomponent ChildComponentHere the ChildComponent dispatches a custom event stateChange to notify the parent or other listeners of a state changeConclusionState management is the linchpin in developing dynamic and interactive web applications with Web Components By adopting robust strategies understanding the intricacies of local and shared states and leveraging modern state management libraries developers can craft Web Components that are cohesive maintainable and scalableThe fusion of practical examples insightful strategies and best practices offers a comprehensive roadmap for developers navigating the complexities of state management in Web Components As we continue to explore the multifaceted world of Web Components our journey will encompass other dimensions like event handling optimization and the evolving trends in the web development landscapeStay connected for more enlightening dives into the nuances of Web Components as we aim to equip developers with the knowledge and tools to craft exceptional web experiences ,"https://medium.com/@sudheer.gowrigari/state-management-in-web-components-crafting-cohesive-and-scalable-solutions-f4bbeb6c74d2#:~:text=State%20management%20refers%20to%20the,remains%20maintainable%20as%20it%20scales.",Front-End Development,289,524
Serverless Architecture, What is serverless computing Serverless computing is a cloud computing execution model that lets software developers build and run applications and servers without having to provision or manage the backend infrastructure With serverless the cloud vendor takes care of all routine infrastructure management and maintenance including updating the operating system OS applying patches managing security system monitoring and planning capacity With serverless computing developers purchase backend services from cloud services vendors on a payasyougo basis which means they pay only for the services used The main goal of serverless computing is to make it simpler for developers to write code designed to run on cloud platforms and to perform a specific role How serverless computing works With serverless computing developers dont have to deal with managing machine instances in the cloud Instead they can run code on cloud servers without having to configure or maintain the servers Pricing is based on the actual amount of resources consumed by an application rather than on prepurchased units of capacity Typically if developers host their applications on virtual servers based in the cloud they must set up and manage those servers install OSes on them monitor them and continually update the software This article is part of What is public cloud Everything you need to know Which also includes 8 key characteristics of cloud computing Top public cloud providers of 2023 A brief comparison 8 ways to reduce cloud costs Download1 Download this entire guide for FREE now With a serverless model developers can write a function in their favorite programming language and post it to a serverless platform The cloud service provider manages the infrastructure and the software and maps the function to an application programming interface API endpoint transparently scaling function instances on demand Advantages and disadvantages of serverless computing The advantages of serverless computing include the following Costeffectiveness Users and developers pay only for the time when code runs on a serverless compute platform They dont pay for idle virtual machines VMs Easy deployment Developers can deploy apps in hours or days rather than weeks or months Autoscaling Cloud providers handle scaling up or spinning down resources or instances when the code isnt running Increased developer productivity Developers can spend most of their time writing and developing apps instead of dealing with servers and runtimes The disadvantages of serverless computing include the following Vendor lockin Switching cloud providers might be difficult because the way serverless services are delivered can vary from one vendor to another Inefficient for longrunning apps Sometimes using longrunning tasks can cost much more than running a workload on a VM or dedicated server Latency Theres a delay in the time it takes for a scalable serverless platform to handle a function for the first time often known as a cold start Debugging is more difficult Because a serverless instance creates a new version of itself each time it spins up its hard to amass the data needed to debug and fix a serverless function Serverless computing use cases There are numerous use cases for serverless computing Eventtriggered computing For scenarios that involve numerous devices accessing various file types such as mobile phones and PCs uploading videos text files and images Internet of things IoT data processing Serverless computing provides a way to combine and analyze data from a variety of devices and then trigger the desired events offering a highly functional less expensive way to manage IoT Backend tasks for mobile apps or websites A serverless function can take a request  such as for information from a user database  from the front end of the site or application retrieve the information and hand it back to the front end Highvolume background processes Serverless can be used to transfer data to longterm storage convert process and analyze the data and move metrics to an analytics service Microservices support Supporting microservices architectures is one of the most common uses of serverless computing Although developers can use containers or platform as a service PaaS to build and operate microservices they can also use serverless computing because of its inherent and automatic scaling rapid provisioning attributes around small bits of code and pricing model that only charges for the capacity used Building RESTful APIs Serverless computing makes it easier to build RESTful APIs developers can scale up on demand Video and image manipulation Serverless computing enables developers to modify video transcoding for different devices and to resize images dynamically Writing multilanguage apps When developers create applications one of the first factors to consider is what language to use Since serverless is a polyglot environment developers can write code in any language or framework they choose including Python Nodejs Java and JavaScript Continuous integrationcontinuous delivery CICD CICD pipelines let developers ship small bits of code which means they can ship bug fixes and other updates every day Serverless architectures can automate many of the workflows in developers CICD pipelines  for example pull requests triggering automated tests Serverless vs other cloud backend models There are numerous differences between serverless computing and other cloud backend models such as infrastructure as a service IaaS backend as a service BaaS and PaaS Serverless vs IaaS Under the IaaS cloud computing model developers prepurchase units of capacity rather than on demand as with serverless computing This means organizations pay public cloud vendors for server components that are always on to run the main components of their applications Consequently an organizations server administrator and tech team are responsible for estimating how much capacity the company uses on average per month to select a pricing plan that meets its needs However serverless architecture applications are deployed only when necessary as an event triggers the application code to run The public cloud vendor allocates the resources needed for that operation to run and the company stops paying when the code finishes running Serverless vs BaaS One of the primary differences between BaaS and serverless computing is scalability With serverless the scale of the application automatically increases depending on app use The cloud providers infrastructure automatically assigns the servers or containers needed to initiate this increase BaaS might not automatically scale an application because some BaaS platforms have a requestpersecond limitation to prevent automated scaling However many BaaS vendors offer platforms that work much like serverless computing and scale apps automatically In addition since serverless architectures are eventdriven they run in response to events But BaaS apps are typically not eventdriven which means they need more server resources Serverless vs PaaS Scaling up and down is easy with serverless apps because it depends on demand and doesnt require developer intervention While a PaaS offering also enables scalability developers are required to set up the scaling parameters In general PaaS provides developers better control over their deployment environments than serverless computing With serverless developers only pay for what they use With PaaS developers typically pay a monthly fee for services  no matter how much they use  which is much more predictable and might end up being less expensive For more on public cloud read the following articles 10 FAQs about cloud computing 8 key characteristics of cloud computing The pros and cons of cloud computing explained Top public cloud providers of 2023 A brief comparison Breaking Down the Cost of Cloud Computing Role of serverless computing in digital transformation Serverless computing plays an important part in digital transformation First it enables developers to be more productive by helping them focus on writing code that has business value without having to worry about the underlying infrastructure that will support the code Regardless of vertical industry or company size a serverless computing strategy can help increase developer productivity by eliminating management overhead Features of a serverless computing software development environment include the following zero server management autoscaling to meet changing traffic demands and managed integrated security What to look for in a serverless architecture Organizations should look for serverless platforms that help them develop applications end to end tapping services across databases storage messaging data analytics machine learning and smart assistants Some serverless cloud services provide scalability and cost savings but they can create additional complexities  such as constrained runtimes or vendor lockin  so thats also an important consideration when choosing a serverless architecture Developers often face a hard tradeoff between the ease and velocity of serverless computing and the flexibility and portability of containers This is why most organizations benefit from a fullstack approach rather than limiting serverless to compute functions Serverless computing vendors and languages The major serverless computing vendors include the following Google Cloud Functions Released by Google in 2017 it supports Nodejs JavaScript Python and Go but allows for unlimited execution time for functions Google Cloud Functions can also interact with many other Google services enabling developers to quickly create and manage complex enterpriseclass applications with almost no consideration of the underlying servers IBM Cloud Functions Based on Apache OpenWhisk it supports JavaScript Nodejs Swift and Cloudflare Workers which runs functions written in JavaScript and any language that can be compiled to WebAssembly Amazon Web Services AWS Lambda Introduced in 2014 its a function as a service FaaS offering from AWS AWS Lambda functions can be written in Java Go PowerShell Nodejs JavaScript C Python and Ruby Microsoft Azure Functions Microsoft rolled out Azure Functions in 2016 to compete with AWS Lambda It supports Bash Batch C F Java JavaScript Nodejs PHP PowerShell Python and TypeScript Cloudflare Workers Released in 2018 Cloudflare Workers combines edge computing with the FaaS model It supports JavaScript and WebAssemblycompatible languages Netlify Functions Rolled out in 2018 Netlify Functions which is built on top of AWS Lambda lets developers deploy serverside code as API endpoints Developers can write functions in JavaScript TypeScript and Go Vercel Serverless Functions Vercel Serverless Functions aims to simplify the serverless experience for web app developers It supports Nodejs Go Python and Ruby Oracle Functions Released in 2019 Oracle Functions integrates with Oracle Cloud Infrastructure platform services and SaaS applications Oracle Functions is based on the open source Fn Project It supports Java Python Nodejs Go Ruby and C for advanced use cases developers can bring their own Dockerfiles and GraalVM Development tools There are numerous thirdparty vendor tools developers can use when theyre working with serverless computing including the following LambCI A package that can be uploaded to AWS Lambda to bring CI to serverless Dashbird A monitoring debugging and intelligence platform to help developers build operate improve and scale apps on AWS Slsdevtools A set of open source tools that make it easy for developers to interact with their serverless functions Serverlessiamrolesperfunction An open source tool that lets developers easily and quickly define access roles for different serverless functions Thundra A platform that enables developers to monitor debug and test their serverless applications Future of serverless computing The global serverless computing market is expected to increase by more than 2317 between 2021 and 2026 according to a report from Mordor Intelligence Advancements in computing technology are enabling organizations to incorporate a serverless environment thereby augmenting the market the report said The benefits of Serverless Computing such as unconditional development and deployment builtin scalability among others are playing an important role in supporting the rapid adoption of Serverless Computing thereby fueling the growth of the market v Ci yh  ry we i ,https://www.techtarget.com/searchitoperations/definition/serverless-computing,Cloud Computing,688,1883
"Web APIs (Geolocation, Web Storage, etc.)",Introduction to web APIs Overview Clientside web APIs Next First up well start by looking at APIs from a high level  what are they how do they work how to use them in your code and how are they structured Well also take a look at what the different main classes of APIs are and what kind of uses they have Prerequisites Basic computer literacy a basic understanding of HTML and CSS JavaScript basics see first steps building blocks JavaScript objects Objective To gain familiarity with APIs what they can do and how you can use them in your code What are APIsApplication Programming Interfaces APIs are constructs made available in programming languages to allow developers to create complex functionality more easily They abstract more complex code away from you providing some easier syntax to use in its place As a realworld example think about the electricity supply in your house apartment or other dwellings If you want to use an appliance in your house you plug it into a plug socket and it works You dont try to wire it directly into the power supply  to do so would be really inefficient and if you are not an electrician difficult and dangerous to attempt Image source Overloaded plug socket by The Clear Communication People on Flickr In the same way if you want to say program some 3D graphics it is a lot easier to do it using an API written in a higherlevel language such as JavaScript or Python rather than try to directly write lowlevel code say C or C that directly controls the computers GPU or other graphics functions Note See also the API glossary entry for further description APIs in clientside JavaScriptClientside JavaScript in particular has many APIs available to it  these are not part of the JavaScript language itself rather they are built on top of the core JavaScript language providing you with extra superpowers to use in your JavaScript code They generally fall into two categories Browser APIs are built into your web browser and are able to expose data from the browser and surrounding computer environment and do useful complex things with it For example the Web Audio API provides JavaScript constructs for manipulating audio in the browser  taking an audio track altering its volume applying effects to it etc In the background the browser is actually using some complex lowerlevel code eg C or Rust to do the actual audio processing But again this complexity is abstracted away from you by the API Thirdparty APIs are not built into the browser by default and you generally have to retrieve their code and information from somewhere on the Web For example the Twitter API allows you to do things like displaying your latest tweets on your website It provides a special set of constructs you can use to query the Twitter service and return specific information Relationship between JavaScript APIs and other JavaScript toolsSo above we talked about what clientside JavaScript APIs are and how they relate to the JavaScript language Lets recap this to make it clearer and also mention where other JavaScript tools fit in JavaScript  A highlevel scripting language built into browsers that allows you to implement functionality on web pagesapps Note that JavaScript is also available in other programming environments such as Node Browser APIs  constructs built into the browser that sits on top of the JavaScript language and allows you to implement functionality more easily Thirdparty APIs  constructs built into thirdparty platforms eg Twitter Facebook that allow you to use some of those platforms functionality in your own web pages for example display your latest Tweets on your web page JavaScript libraries  Usually one or more JavaScript files containing custom functions that you can attach to your web page to speed up or enable writing common functionality Examples include jQuery Mootools and React JavaScript frameworks  The next step up from libraries JavaScript frameworks eg Angular and Ember tend to be packages of HTML CSS JavaScript and other technologies that you install and then use to write an entire web application from scratch The key difference between a library and a framework is Inversion of Control When calling a method from a library the developer is in control With a framework the control is inverted the framework calls the developers code What can APIs doThere are a huge number of APIs available in modern browsers that allow you to do a wide variety of things in your code You can see this by taking a look at the MDN APIs index pageCommon browser APIsIn particular the most common categories of browser APIs youll use and which well cover in this module in greater detail are APIs for manipulating documents loaded into the browser The most obvious example is the DOM Document Object Model API which allows you to manipulate HTML and CSS  creating removing and changing HTML dynamically applying new styles to your page etc Every time you see a popup window appear on a page or some new content displayed for example thats the DOM in action Find out more about these types of API in Manipulating documents APIs that fetch data from the server to update small sections of a webpage on their own are very commonly used This seemingly small detail has had a huge impact on the performance and behavior of sites  if you just need to update a stock listing or list of available new stories doing it instantly without having to reload the whole entire page from the server can make the site or app feel much more responsive and snappy The main API used for this is the Fetch API although older code might still use the XMLHttpRequest API You may also come across the term Ajax which describes this technique Find out more about such APIs in Fetching data from the server APIs for drawing and manipulating graphics are widely supported in browsers  the most popular ones are Canvas and WebGL which allow you to programmatically update the pixel data contained in an HTML canvas element to create 2D and 3D scenes For example you might draw shapes such as rectangles or circles import an image onto the canvas and apply a filter to it such as sepia or grayscale using the Canvas API or create a complex 3D scene with lighting and textures using WebGL Such APIs are often combined with APIs for creating animation loops such as windowrequestAnimationFrame and others to make constantly updating scenes like cartoons and games Audio and Video APIs like HTMLMediaElement the Web Audio API and WebRTC allow you to do really interesting things with multimedia such as creating custom UI controls for playing audio and video displaying text tracks like captions and subtitles along with your videos grabbing video from your web camera to be manipulated via a canvas see above or displayed on someone elses computer in a web conference or adding effects to audio tracks such as gain distortion panning etc Device APIs enable you to interact with device hardware for example accessing the device GPS to find the users position using the Geolocation API Clientside storage APIs enable you to store data on the clientside so you can create an app that will save its state between page loads and perhaps even work when the device is offline There are several options available eg simple namevalue storage with the Web Storage API and more complex database storage with the IndexedDB API Common thirdparty APIsThirdparty APIs come in a large variety some of the more popular ones that you are likely to make use of sooner or later are The Twitter API which allows you to do things like displaying your latest tweets on your website Map APIs like Mapquest and the Google Maps API which allow you to do all sorts of things with maps on your web pages The Facebook suite of APIs which enables you to use various parts of the Facebook ecosystem to benefit your app such as by providing app login using Facebook login accepting inapp payments rolling out targeted ad campaigns etc The Telegram APIs which allows you to embed content from Telegram channels on your website in addition to providing support for bots The YouTube API which allows you to embed YouTube videos on your site search YouTube build playlists and more The Pinterest API which provides tools to manage Pinterest boards and pins to include them in your website The Twilio API which provides a framework for building voice and video call functionality into your app sending SMSMMS from your apps and more The Mastodon API which enables you to manipulate features of the Mastodon social network programmatically How do APIs workDifferent JavaScript APIs work in slightly different ways but generally they have common features and similar themes to how they workThey are based on objectsYour code interacts with APIs using one or more JavaScript objects which serve as containers for the data the API uses contained in object properties and the functionality the API makes available contained in object methods Note If you are not already familiar with how objects work you should go back and work through our JavaScript objects module before continuing Lets return to the example of the Web Audio API  this is a fairly complex API which consists of a number of objects The most obvious ones are AudioContext which represents an audio graph that can be used to manipulate audio playing inside the browser and has a number of methods and properties available to manipulate that audio MediaElementAudioSourceNode which represents an audio element containing sound you want to play and manipulate inside the audio context AudioDestinationNode which represents the destination of the audio ie the device on your computer that will actually output it  usually your speakers or headphones So how do these objects interact If you look at our simple web audio example see it live also youll first see the following HTML htmlaudio srcoutfoxingmp3audio button classpausedPlaybutton br  input typerange min0 max1 step001 value1 classvolume  We first of all include an audio element with which we embed an MP3 into the page We dont include any default browser controls Next we include a button that well use to play and stop the music and an input element of type range which well use to adjust the volume of the track while its playing Next lets look at the JavaScript for this example We start by creating an AudioContext instance inside which to manipulate our track jsconst AudioContext  windowAudioContext  windowwebkitAudioContext const audioCtx  new AudioContext Next we create constants that store references to our audio button and input elements and use the AudioContextcreateMediaElementSource method to create a MediaElementAudioSourceNode representing the source of our audio  the audio element will be played from jsconst audioElement  documentquerySelectoraudio const playBtn  documentquerySelectorbutton const volumeSlider  documentquerySelectorvolume const audioSource  audioCtxcreateMediaElementSourceaudioElement Next up we include a couple of event handlers that serve to toggle between play and pause when the button is pressed and reset the display back to the beginning when the song has finished playing js playpause audio playBtnaddEventListenerclick     check if context is in suspended state autoplay policy if audioCtxstate  suspended  audioCtxresume   if track is stopped play it if playBtngetAttributeclass  paused  audioElementplay playBtnsetAttributeclass playing playBtntextContent  Pause  if track is playing stop it  else if playBtngetAttributeclass  playing  audioElementpause playBtnsetAttributeclass paused playBtntextContent  Play    if track ends audioElementaddEventListenerended    playBtnsetAttributeclass paused playBtntextContent  Play  Note Some of you may notice that the play and pause methods being used to play and pause the track are not part of the Web Audio API they are part of the HTMLMediaElement API which is different but closelyrelated Next we create a GainNode object using the AudioContextcreateGain method which can be used to adjust the volume of audio fed through it and create another event handler that changes the value of the audio graphs gain volume whenever the slider value is changed js volume const gainNode  audioCtxcreateGain volumeSlideraddEventListenerinput    gainNodegainvalue  volumeSlidervalue  The final thing to do to get this to work is to connect the different nodes in the audio graph up which is done using the AudioNodeconnect method available on every node type jsaudioSourceconnectgainNodeconnectaudioCtxdestination The audio starts in the source which is then connected to the gain node so the audios volume can be adjusted The gain node is then connected to the destination node so the sound can be played on your computer the AudioContextdestination property represents whatever is the default AudioDestinationNode available on your computers hardware eg your speakersThey have recognizable entry pointsWhen using an API you should make sure you know where the entry point is for the API In The Web Audio API this is pretty simple  it is the AudioContext object which needs to be used to do any audio manipulation whatsoever The Document Object Model DOM API also has a simple entry point  its features tend to be found hanging off the Document object or an instance of an HTML element that you want to affect in some way for example jsconst em  documentcreateElementem  create a new em element const para  documentquerySelectorp  reference an existing p element emtextContent  Hello there  give em some text content paraappendChildem  embed em inside para The Canvas API also relies on getting a context object to use to manipulate things although in this case its a graphical context rather than an audio context Its context object is created by getting a reference to the canvas element you want to draw on and then calling its HTMLCanvasElementgetContext method jsconst canvas  documentquerySelectorcanvas const ctx  canvasgetContext2d Anything that we want to do to the canvas is then achieved by calling properties and methods of the context object which is an instance of CanvasRenderingContext2D for example jsBallprototypedraw  function   ctxbeginPath ctxfillStyle  thiscolor ctxarcthisx thisy thissize 0 2  MathPI ctxfill  Note You can see this code in action in our bouncing balls demo see it running live also They often use events to handle changes in stateWe already discussed events earlier on in the course in our Introduction to events article which looks in detail at what clientside web events are and how they are used in your code If you are not already familiar with how clientside web API events work you should go and read this article first before continuing Some web APIs contain no events but most contain at least a few The handler properties that allow us to run functions when events fire are generally listed in our reference material in separate Event handlers sections We already saw a number of event handlers in use in our Web Audio API example above js playpause audio playBtnaddEventListenerclick     check if context is in suspended state autoplay policy if audioCtxstate  suspended  audioCtxresume   if track is stopped play it if playBtngetAttributeclass  paused  audioElementplay playBtnsetAttributeclass playing playBtntextContent  Pause  if track is playing stop it  else if playBtngetAttributeclass  playing  audioElementpause playBtnsetAttributeclass paused playBtntextContent  Play    if track ends audioElementaddEventListenerended    playBtnsetAttributeclass paused playBtntextContent  Play  They have additional security mechanisms where appropriateWebAPI features are subject to the same security considerations as JavaScript and other web technologies for example sameorigin policy but they sometimes have additional security mechanisms in place For example some of the more modern WebAPIs will only work on pages served over HTTPS due to them transmitting potentially sensitive data examples include Service Workers and Push In addition some WebAPIs request permission to be enabled from the user once calls to them are made in your code As an example the Notifications API asks for permission using a popup dialog box The Web Audio and HTMLMediaElement APIs are subject to a security mechanism called autoplay policy  this basically means that you cant automatically play audio when a page loads  youve got to allow your users to initiate audio play through a control like a button This is done because autoplaying audio is usually really annoying and we really shouldnt be subjecting our users to it Note Depending on how strict the browser is such security mechanisms might even stop the example from working locally ie if you load the local example file in your browser instead of running it from a web server At the time of writing our Web Audio API example wouldnt work locally on Google Chrome  we had to upload it to GitHub before it would work SummaryAt this point you should have a good idea of what APIs are how they work and what you can do with them in your JavaScript code You are probably excited to start actually doing some fun things with specific APIs so lets go Next up well look at manipulating documents with the Document Object Model DOM Overview Clientside web APIs Next Found a content problem with this pageEdit the page on GitHubReport the content issueView the source on GitHubWant to get more involved Learn how to contributeThis page was last modified on Dec 5 2023 by MDN contributors Prerequisites Objective 0 Prerequisites Basic computer literacy a basic understanding ofn HTML andn CSS JavaScript basics seen first stepsn building blocksn JavaScript objects 1 Objective To gain familiarity with APIs what they can do and how you can usen them in your codeaudio srcoutfoxingmp3audio button classpausedPlaybutton br  input typerange min0 max1 step001 value1 classvolume  const AudioContext  windowAudioContext  windowwebkitAudioContext const audioCtx  new AudioContext const audioElement  documentquerySelectoraudio const playBtn  documentquerySelectorbutton const volumeSlider  documentquerySelectorvolume const audioSource  audioCtxcreateMediaElementSourceaudioElement  playpause audio playBtnaddEventListenerclick     check if context is in suspended state autoplay policy if audioCtxstate  suspended  audioCtxresume   if track is stopped play it if playBtngetAttributeclass  paused  audioElementplay playBtnsetAttributeclass playing playBtntextContent  Pause  if track is playing stop it  else if playBtngetAttributeclass  playing  audioElementpause playBtnsetAttributeclass paused playBtntextContent  Play    if track ends audioElementaddEventListenerended    playBtnsetAttributeclass paused playBtntextContent  Play   volume const gainNode  audioCtxcreateGain volumeSlideraddEventListenerinput    gainNodegainvalue  volumeSlidervalue  audioSourceconnectgainNodeconnectaudioCtxdestination const em  documentcreateElementem  create a new em element const para  documentquerySelectorp  reference an existing p element emtextContent  Hello there  give em some text content paraappendChildem  embed em inside para const canvas  documentquerySelectorcanvas const ctx  canvasgetContext2d Ballprototypedraw  function   ctxbeginPath ctxfillStyle  thiscolor ctxarcthisx thisy thissize 0 2  MathPI ctxfill   playpause audio playBtnaddEventListenerclick     check if context is in suspended state autoplay policy if audioCtxstate  suspended  audioCtxresume   if track is stopped play it if playBtngetAttributeclass  paused  audioElementplay playBtnsetAttributeclass playing playBtntextContent  Pause  if track is playing stop it  else if playBtngetAttributeclass  playing  audioElementpause playBtnsetAttributeclass paused playBtntextContent  Play    if track ends audioElementaddEventListenerended    playBtnsetAttributeclass paused playBtntextContent  Play  ,https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Client-side_web_APIs/Introduction,APIs,874,3053
Browser Developer Tools,What are browser developer toolsEvery modern web browser includes a powerful suite of developer tools These tools do a range of things from inspecting currentlyloaded HTML CSS and JavaScript to showing which assets the page has requested and how long they took to load This article explains how to use the basic functions of your browsers devtools Note Before you run through the examples below open the Beginners example site that we built during the Getting started with the Web article series You should have this open as you follow the steps below How to open the devtools in your browserThe devtools live inside your browser in a subwindow that looks roughly like this depending on what browser you are using How do you pull it up Three ways Keyboard Windows Ctrl  Shift  I or F12 macOS     I Menu bar Firefox Menu  Web Developer  Toggle Tools or Tools  Web Developer  Toggle Tools Chrome More tools  Developer tools Safari Develop  Show Web Inspector If you cant see the Develop menu go to Safari  Preferences  Advanced and check the Show Develop menu in menu bar checkbox Opera Developer  Developer tools Context menu Pressandholdrightclick an item on a webpage Ctrlclick on the Mac and choose Inspect Element from the context menu that appears An added bonus this method straightaway highlights the code of the element you rightclicked The Inspector DOM explorer and CSS editorThe developer tools usually open by default to the inspector which looks something like the following screenshot This tool shows what the HTML on your page looks like at runtime as well as what CSS is applied to each element on the page It also allows you to instantly modify the HTML and CSS and see the results of your changes reflected live in the browser viewport If you dont see the inspector Tapclick the Inspector tab In Chrome Microsoft Edge or Opera tapclick Elements In Safari the controls are not so clearly presented but you should see the HTML if you havent selected something else to appear in the window Press the Style button to see the CSS Exploring the DOM inspectorFor a start rightclick Ctrlclick an HTML element in the DOM inspector and look at the context menu The available menu options vary among browsers but the important ones are mostly the same Delete Node sometimes Delete Element Deletes the current element Edit as HTML sometimes Add attributeEdit text Lets you change the HTML and see the results on the fly Very useful for debugging and testing hoveractivefocus Forces element states to be toggled on so you can see what their styling would look like CopyCopy as HTML Copy the currently selected HTML Some browsers also have Copy CSS Path and Copy XPath available to allow you to copy the CSS selector or XPath expression that would select the current HTML element Try editing some of your DOM now Doubleclick an element or rightclick it and choose Edit as HTML from the context menu You can make any changes youd like but you cannot save your changesExploring the CSS editorBy default the CSS editor displays the CSS rules applied to the currently selected element These features are especially handy The rules applied to the current element are shown in order of mosttoleastspecific Click the checkboxes next to each declaration to see what would happen if you removed the declaration Click the little arrow next to each shorthand property to show the propertys longhand equivalents Click a property name or value to bring up a text box where you can key in a new value to get a live preview of a style change Next to each rule is the file name and line number the rule is defined in Clicking that rule causes the dev tools to jump to show it in its own view where it can generally be edited and saved You can also click the closing curly brace of any rule to bring up a text box on a new line where you can write a completely new declaration for your page Youll notice a number of clickable tabs at the top of the CSS Viewer Computed This shows the computed styles for the currently selected element the final normalized values that the browser applies Layout In Firefox this area includes two sections Box Model represents visually the current elements box model so you can see at a glance what padding border and margin is applied to it and how big its content is Grid If the page you are inspecting uses CSS Grid this section allows you to view the grid details Fonts In Firefox the Fonts tab shows the fonts applied to the current element Find out moreFind out more about the Inspector in different browsers Firefox Page inspector Chrome DOM inspector Operas inspector works the same as this Safari DOM inspector and style explorer The JavaScript debuggerThe JavaScript debugger allows you to watch the value of variables and set breakpoints places in your code that you want to pause execution and identify the problems that prevent your code from executing properly To get to the debugger Firefox Select  Web Developer  Debugger or press Ctrl  Shift  S to open the JavaScript Debugger If the tools are already displayed click on the Debugger tab Chrome Open the Developer tools and then select the Sources tab Opera works the same way Safari Open the Developer Tools and then select the Debugger tabExploring the debuggerThere are three panes in the JavaScript Debugger on Firefox File list The first pane on the left contains the list of files associated with the page you are debugging Select the file you want to work with from this list Click on a file to select it and view its contents in the center pane of the Debugger Source code Set breakpoints where you want to pause execution In the following image the highlight on the number 18 shows that the line has a breakpoint set Watch expressions and breakpoints The righthand pane shows a list of the watch expressions you have added and breakpoints you have set In the image the first section Watch expressions shows that the listItems variable has been added You can expand the list to view the values in the array The next section Breakpoints lists the breakpoints set on the page In examplejs a breakpoint has been set on the statement listItemspushinputNewItemvalue The final two sections only appear when the code is running The Call stack section shows you what code was executed to get to the current line You can see that the code is in the function that handles a mouse click and that the code is currently paused on the breakpoint The final section Scopes shows what values are visible from various points within your code For example in the image below you can see the objects available to the code in the addItemClick function Find out moreFind out more about the JavaScript debugger in different browsers Firefox JavaScript Debugger Microsoft Edge Debugger Chrome Debugger Safari Debugger The JavaScript consoleThe JavaScript console is an incredibly useful tool for debugging JavaScript that isnt working as expected It allows you to run lines of JavaScript against the page currently loaded in the browser and reports the errors encountered as the browser tries to execute your code To access the console in any browser If the developer tools are already open click or press the Console tab If not Firefox allows you to open the console directly using Ctrl  Shift  K or using the menu command Menu  Web Developer  Web Console or Tools  Web Developer  Web Console On other browser open the developer tools and then click the Console tab This will give you a window like the following To see what happens try entering the following snippets of code into the console one by one and then pressing Enter jsalerthello jsdocumentquerySelectorhtmlstylebackgroundColor  purple jsconst loginImage  documentcreateElementimg loginImagesetAttribute src httpsrawgithubusercontentcommdnlearningareamasterhtmlformsimagetypeexampleloginpng  documentquerySelectorh1appendChildloginImage Now try entering the following incorrect versions of the code and see what you get jsalerthello jsdocumentcheeseSelectorhtmlstylebackgroundColor  purple jsconst loginImage  documentcreateElementimg bananasetAttribute src httpsrawgithubusercontentcommdnlearningareamasterhtmlformsimagetypeexampleloginpng  documentquerySelectorh1appendChildloginImage Youll start to see the kind of errors that the browser returns Often these errors are fairly cryptic but it should be pretty simple to figure these problems outFind out moreFind out more about the JavaScript console in different browsers Firefox Web Console Chrome JavaScript Console Operas inspector works the same as this Safari Console See also Debugging HTML Debugging CSS Found a content problem with this pageEdit the page on GitHubReport the content issueView the source on GitHubWant to get more involved Learn how to contributeThis page was last modified on Aug 2 2023 by MDN contributors alerthello documentquerySelectorhtmlstylebackgroundColor  purple const loginImage  documentcreateElementimg loginImagesetAttribute src httpsrawgithubusercontentcommdnlearningareamasterhtmlformsimagetypeexampleloginpng  documentquerySelectorh1appendChildloginImage alerthello documentcheeseSelectorhtmlstylebackgroundColor  purple const loginImage  documentcreateElementimg bananasetAttribute src httpsrawgithubusercontentcommdnlearningareamasterhtmlformsimagetypeexampleloginpng  documentquerySelectorh1appendChildloginImage ,https://developer.mozilla.org/en-US/docs/Learn/Common_questions/Tools_and_setup/What_are_browser_developer_tools,Development Tools,513,1468
Code Quality and Refactoring, 1445 readsHow To Improve Code Quality With Code Reviews and RefactoringApril 9th 20216m by alexomeyer 1445 readsToo Long Didnt Read There are lots of ways you can improve your code quality make it easier to review and test and reduce the pain later of having to fix all of the errors The earlier you find errors the faster easier and cheaper they are to resolve Code reviews are of paramount importance to ensuring good code and providing a way to locate problems so that they can be fixed as early as possible For companies who have adopted a DevOps way of life code reviews are par for the course and are already embedded in the processPeople MentionedCompanies Mentionedprogramming programming codequalityalexomeyerAlex OmeyerCofounder  CEO at stepsizecom creating the AI companion for software projectsReceive Stories from alexomeyerSUBSCRIBE SUBSCRIBE TO RECEIVE THIS WRITERS CONTENT STRAIGHT TO YOUR INBOXby Alex Omeyer alexomeyerCofounder  CEO at stepsizecom creating the AI companion for software projectsGet the AI companion for software projects Never miscommunicate again RELATED STORIESGet Rid Of Technical Debt In 10 VS Code ExtensionsPublished at Nov 04 2021 by alexomeyer programming The Noonification Craig Wright is Satoshi Nakamoto 12242023Published at Dec 24 2023 by noonification noonification Redesigning Apps Using Ruby On Rails The Risks and The RiskFree ApproachesPublished at Dec 22 2023 by ka8725 rubyonrails ProtocolOriented Programming and Modifying UIKit Components Mimicking SwiftUIPublished at Dec 20 2023 by bugorbn programming Find Your Crew in 2024 With These 16 Developer Communities Published at Dec 20 2023 by madzadev webdevelopment Boost Your Productivity in 2024 With These 17 Chrome Extensions Published at Dec 20 2023 by madzadev webdevelopment L O A D I N G   comments  more 0 HACKERNOON ,https://hackernoon.com/how-to-improve-code-quality-with-code-reviews-and-refactoring-bc5135mp,Code Quality,186,280
Progressive Enhancement and Graceful Degradation, Home Guide Progressive Enhancement vs Graceful Degradation Progressive Enhancement vs Graceful Degradation By Neha Bharati Community Contributor  July 1 2022 Websites on the internet across different domains each serving a specific purpose Some are gaming websites some are for ecommerce some are blogs and some are for social media The primary purpose of every website is only fulfilled if it garners customer attention Any website should be able to deliver its purpose effectively to the user No user will revisit if a travel website fails to show the correct hotel information or has a bad payment platformDelivering a bugfree user experience is the primary purpose of web applications but sometimes it becomes tough to ensure performance uniformity across platforms and browsers So came the concept of Progressive Enhancement and Graceful Degradation In this article well understand the concepts in detail and differentiate between progressive enhancement and graceful degradationTable of ContentsWhat is Progressive EnhancementWhat is Graceful DegradationDifference between Progressive Enhancement and Graceful DegradationChoosing between Progressive Enhancement and Graceful DegradationExamples of Progressive Enhancement and Graceful DegradationProgressive Enhancement ExampleGraceful Degradation ExampleWhat is Progressive EnhancementProgressive Enhancement is when one builds a basic functional web application and progressively adds features to it when required to enhance its functionality The following illustration clearly displays the idea of what we mean by progressive enhancement It is similar to how we make a cakeSourceWe prepare the cake with the basic ingredients first Once its done we add frosting to it In the end we enhance the cake with more frosting colors and candles Progressive Enhancement starts with the base and keeps enhancing the product with featuresRead More Setting Goals for Software QualityWhat is Graceful DegradationGraceful Degradation is where a customer is provided with an application with all the features but also makes the user aware of the shortcomings of a product to make the product still usable So in this practice the user gets an application that works on all modern browsers to provide a certain level of user experience but itll gradually degrade to a lower level of user experienceFollowUp Read How To Test Website in Different Screen SizesDifference between Progressive Enhancement and Graceful DegradationWhy is it necessary to go for these approaches Isnt it wrong to degrade an application gradually if you want customer attraction Why would one launch an application providing basic features and not all the functionality Lets answer these questions better The reasoning behind progressive enhancement is that the developers can build a viable product with basic features that supports all browsers that still make the app usable Once they know what features the app requires in the future through usability testing and feedback they can gradually add them into the app and enhance it By doing this users are guaranteed a uniform experience across browsers and platforms making the product futureproofIn the case of graceful degradation say there is an application that works great with modern browsers but what if you wanted it to work on older browser versions Then you would have to fix the code for older browsers or in other words gracefully degrade it It is quite the opposite of progressive enhancementKey Takeaway  While Progressive Enhancement assumes simplicity and builds for complexity Graceful Degradation takes the complexity and solves for clarity in the applicationPS  BrowserStack allows seamless crossbrowser testing on legacy browsers  the latest browser versionsChoosing between Progressive Enhancement and Graceful DegradationProgressive enhancement is usually the more widely used approach because it solves for clarity and works towards complexity That means it is compatible with all browsers from the start The graceful degradation approach doesnt work satisfactorily in older browser versions but builds towards it gradually This means that at the beginning of the application it doesnt work well on older browsersSuppose you want to build something from scratch In that case progressive enhancement is preferred for the following reasonsThe users are guaranteed a product that works across platformsIf any new features are to be added its good to go without altering the existing codeIf you want to make a website accessible and compliant with newer standards then graceful degradation is the way to goDid you know that HTML and CSS have been designed to degrade gracefully Graceful degradation builds an app that is compatible with modern browsers And for older browsers the app is still functional but with fewer features or display visuals If a browser doesnt support CSS properties like borderradius the browser will skip it and use angled borders instead You may think that delivering an uglylooking website with fewer features may be less pleasing to users but they may not notice it more often than not So as long as there is a functional website that users can use without any hassle it wont make much differenceLearn More How to Create BrowserSpecific CSS CodeExamples of Progressive Enhancement and Graceful DegradationProgressive Enhancement ExampleLet us understand Progressive Enhancement by taking CSS as an example and how it has progressed through the yearsNot all the CSS properties that exist work on every browser That is why some websites may look the slightest way on different browsers CSS3 is the latest version of CSS used today on modern browsers There are older browser versions that support CSS1 and CSS2 So to maintain uniformity across browser versions developers need to write CSS that is compatible with them One can directly write some HTML and CSS and run it in each browser or use some available tools that provide a range of browsers to test code onRather than focusing on making CSS compatible with all browsers through hacks and scripts we can rely on the browsers to display CSS styles according to their capabilitiesIf any browser doesnt support some CSS style like borderradiuswhich gives rounded corners then instead of having rounded corners theyll display square corners But this still wont affect the webpages functionality rather it would make the page look a bit differentThe key is to make a baseline design that works on all browsers as much as possible and if some properties are unsupported then there are always some CSS hacks or workarounds that can be managedFollowUp Read CSS Techniques for Cross Browser CompatibilityNow lets look at how to use progressive enhancement to implement some awesome CSS3 techniquesBackground SizeBackgroundsize is a property in CSS3 that lets you size the background images applied to div body or html tags in your HTML Here is how it can be used for different browsersSafariThe above snippet shows how backgroundimage works on safari using webkitbackgroundsizeOpera 88The above snippet shows how backgroundimage works on opera using obackgroundsizeSimilarly using cssprefixes the same property can work across browsersMultiple BackgroundsThere is a way to render multiple background images simultaneously using the backgroundimage propertyAlternatively this syntax is also acceptablemultiplebgimages  background urlhttpdomaincompathlayer01png norepeat 0 0 backgroundimage urlhttpdomaincompathlayer01png urlhttpdomaincompathlayer02png urlhttpdomaincompathlayer03png urlhttpdomaincompathlayer04png backgroundrepeat norepeat norepeat norepeat norepeat backgroundposition 0 0 0 0 0 0 0 0 The above snippet shows how the multiple backgrounds are displayed on a browser The way the images will be displayed is because every subsequent image will appear beneath the previous one For unsupported browsers it will ignore the second background property since thats the way CSS3 is used as we learned beforeGraceful Degradation ExampleIf you want a website to degrade then one gracefully would want to focus on building for modern browsers and then degrade them for older browsers depending on the use cases For example if many users use a certain older browser then it would be wise to focus on building for those browsers If you have a customer base that uses modern browsers then its not advised to focus much on older browsers that require enough time and effort to build compatible featuresMustRead How to Test on Older Browser Versions EasilyIt is best to follow certain rules for graceful degradationWrite standard semantic HTML In the below snippet the code is structured semantically Instead of using ambiguous div elements specific tags are used wherever necessaryUse external stylesheets for layouts and designUse externally linked scripts for functionality Build websites that are accessible to older browsers even without CSS and Javascript This is because users can turn off CSS and Javascript on their browsers resulting in a bad user experienceWrapping UpProgressive Enhancement and Graceful Degradation have been used for a long time It is all to do with browser compatibility in the end There are still people who use very old browsers and modern browsers and as developers we are responsible for building compatible websites that work across all browsers The easiest way to test across popular and mostused browsers such as Chrome Firefox and Safari is by using BrowserStack Be a part of the testing infrastructure that redefines the way you develop and test your online user experiencesTry BrowserStack for Free Cross browser testing Fragmentation Types of Testing Was this post useful Yes Thanks Not Really Were sorry to hear that Please share your feedback so we can do better Thanks a lot for your feedback Tags Cross browser testing Fragmentation Types of Testing Related Articles Cross Browser Compatibility Testing beyond Chrome Why perform cross browser compatibility testing only on Chrome Learn about browser usage patterns  Learn More Cross Browser Compatibility Issues to Avoid A consolidated list of 9 most common cross browser testing issues and how to solve them Read the ar Learn More Cross Browser Compatible Websites  3 Easy Ways to Make Learn how to perform cross browser compatibility tests and evaluate how your website looks on differ Learn More Featured Articles Cross Browser Compatibility Testing beyond Chrome Cross Browser Compatibility Issues to Avoid Curated for all your Testing Needs Actionable Insights Tips  Tutorials delivered in your Inbox By subscribing  you agree to our Privacy Policy Thank you for Subscribing Expect a curated list of guides shortly 3 Ways to Develop Cross Browser Compatible Websites oO BrowserStack A  ,https://www.browserstack.com/guide/difference-between-progressive-enhancement-and-graceful-degradation,UI/UX Design,607,1636
Web Development Project Management,Website Development Project Plan Meaning Steps and ExecutionThey say every outstanding website development process begins with a project plan and we 100 agree Developing a website is just like constructing a building You must start with a solid foundation and architectural plans before people begin using it or it wont live up to its expectationsA lot of developers are not aware of what goes into a website development project plan In this article Techosquare  the leading ecommerce website development firm in India  will tell you about crucial steps to plan and deliver web development projectsLets understand the meaning and importance of web development planning firstMeaning of plan in website development projectWe bet most of you are aware of this abbreviation called PLAN Those who arent plan in a web development project basically stands forPrepare Spot your target visitors website aspirations and primarysecondary goalsLandscape How do you want the website to perform To be more precise what sort of features do you want for your websiteAesthetics How do you want your website to look Select the color palette and imagery that meet your aesthetic goalsNavigation Think what will make browsing quick and amazing for your visitorsImportance of website development planAccording to a report by Cision PR Newswire more than 60 of small and mediumsized businesses spend their money in designing and developing a website every year yet many fail to earn profits and generate business value due to poor performance design issues and bad functionality Need more facts Here you go73 of mobile internet users reported that they encountered websites that were either too slow to load or were not responsive at all 70 of business websites lack the most basic element of website design development called CTA call to action on their homepageBut guess what Issues like these can be avoided completely with proper website development planning and project management With the help of a website development project plan developers are able to build websites that delight visitors and deliver superb experiencesWebsite development project plan Steps involvedNow that we understand the importance of a web development plan for a business website its time to learn about the steps involved in it But first make sure to have these three factors in placeProject manager Managers act as bridges between team members and make sure that project progresses at the decided pace For a website development project you need a person who can lead the development team Hire a fulltime project manager if your business operates on an adequate level You can also ask someone from your existing team to leadProject management platform A good project management platform will help your project manager and development team lay out a solid foundation for your website while providing tools to scope out the milestones key deliverables and roles before executing the website development plan It will also keep it up to date and let you track progress every once in a while Evaluate platform characteristics cautiously to estimate their suitability for your web development teamProject management methodology For those who dont know a project management methodology is a set of principles and practices that help organize a web development project to ensure optimal performance Some popular project management methodologies for delivering websites are XP and PRINCE2 Train your website development team in chosen management methodology before starting work on planned projects Explain it within your project management platformDid you take care of the above aspects Great Its time to execute your website development planWebsite development plan ExecutionThe following are the steps to carry out the process of website programming1 PlanningPhase 1 Client collaborationPlanning with your client will help achieve site goals and allows for efficient use of time and development resources Ask your client to define what customers want in the clearest terms possible Ask questions likeWhat type of website is requiredWho is the target audienceHow many web pages are requiredHow often will the content be updatedIs CMS required content management systemAre there any references worth checking outWhats the web development budgetWhich thirdparty integrations are requiredOnce you find answers to these questions write them down They will help you formulate goals for your website development project and define its scopePhase 2 Team discussionThe next phase involves discussing your clients website specification with your project team This phase is important as it will help you translate the client requirements into a foolproof website project planAddress the following questions with your crewWhat needs to be done for the clientHow does the project break down into tasksWhich team member will perform which taskHow much of the clients budget will the web development project requireWhere are the dependencies in the projectWith these primary questions answered you will be able to lay out a basic project plan describing when and how the website development project plan will be carried out Discuss it with your client and wait for the approvalOnce your client gives a green signal move to the next step2 BuildingThe building phase is the most crucial phase of any website development project Why Because its the part where you and your team will create things your client wished existed It is the part where your clients site will be brought to reality From the information gathered to this point you have to determine the layout content look and functionalities of the sitePhase 1 Branding infrastructure and layoutA good branding infrastructure and layout will not only make the website look attractive but will also help the visitors understand the core message and connect with the brand Long story short you will be planning and setting up the foundation of your website development projectSome popular activities involved within this phase are Define the website name and taglineConclude logo color palette fonts and page layoutsBuying a domain name or hosting serviceBuild a sitemap to display web pages and their relations Note Some of these are already present with client and shared with the teamPhase 2 ContentImagine going to a painting exhibition and looking at an 11 x 14 painting canvas with absolutely nothing in it You might feel baffled and angry at the same time Your clients reaction will be the same if a website with no content gets deliveredGather all the content needed for the website You will be working on the following aspects during this phase of your web development projectIdentify content needed for web pages testimonials privacy policy terms of use FAQs etcArrange stock images and graphicsOrganize content in a content repositoryProofread and finalize contentNote Some clients share imagery and text on their own and delegate the task of arranging the same to the web design and development companyPhase 3 Design and developmentHere comes the most important phase of your web development project After deciding on branding infrastructure layout and content for your client start planning designing and developing the website pages The following are some important activities that will happen during this phaseWeb pages designing based on layout styles and contentSetting up a sandbox serverDesigning page elements such as buttons CTAs and testimonialsHTML CSS and Javascript authenticationDeveloping functionalities like a blog ecommerce store or content management systemOrganizing web pages based on the sitemapReviewing design and making changes based on clients approvalWe suggest you do regular team meetings during the build phase This will keep your website development and management team on top of all deliberationsEverything you need to know about PHP website development in India3 OptimizationAccording to Alan Perlis optimization hinders revolution Website optimization after the designing and development process is important because it can help visitors feel more fortunate with their visits to your clients website In other words people who come to your clients site hoping to find the answer to a question will find a solution to their problem using different platformsFrom minifying scripts and CSS to improving crossbrowser performance and enabling gzip compression to optimizing images this is the phase where your website development team will plan and bring the clients site up to the highest gradeIn case you have no idea of how you can improve the sites performance Techoquare suggests checking out different website speed optimization checklists on the internet Assign optimization tasks to a relevant team member if needed4 FinalizationBy the heading you might have guessed what our next step of the website development project plan is going to be about During the finalization crucial steps will be taken from beginning to end in order to complete the clients web project Relatively complex it covers the following phasesPhase 1 Initial testingInitial testing is the phase where your web development team will authenticate website functionality and confirm if it matches the clients demand On the basis of his requirements certain tests may be conducted Some of the known activities performed during this phase areChecking if the website matches current web standardsMaking sure if the functionality is working as expectedFixing issues that arise during testingCheck if the website design is responsive and work fine on all devicesImproving the website loading speedEnsuring accessibility for differentlyabled peoplePhase 2 Go liveDone with testing and fixing website problems Great Now its time to make the clients website and support systems operational In simple words it is time to GO LIVEHere are some activities that will be planned and performed during this phase of the website development projectUploading site to the clients hosting serverRemoving robotstxt file to allow bots to crawl webpagesCreating and submitting an XML sitemap to search enginesTraining client team to create and update websiteWriting and passing the websites documentation to the clientPhase 3 Staff trainingIf you read the above point carefully we mentioned training the client team to create and update the website Well this point is all about that It is obvious that website problems will occur at some point in the future A staff training and development program will make your team more allrounded and better skilled to address those weaknesses at every factor of their jobTrain people who are going to manage the website after its launch This not only includes your staff but also your client and her team members5 Create a project scheduleThe last step of creating a website development project plan is to create a project schedule It involves mapping the activities and phases to specific dates Remember all the activities we talked about above During this phase they will become your project tasks with start and end datesSince project management scheduling process may feel a bit foreign to some teams we have curated a list of steps you can take to build yoursDefine your project goalsIdentify all stakeholdersDetermine your final deadlineList each step or task to cover all basesAssign a team member responsible for each taskWork backward to set due dates for each taskOrganize your project schedule using a specific tool and share it with your teamThere you goWe told you about all the crucial steps of the website development project plan Making a plan for your clients business website is crucial as it will help you and your team make sure that the end product comes out the right wayWe hope this blog will help developers and business owners learn the critical steps involved in creating a plan for a website project Thinking of taking your brickandmortar business online Send us an email at infotechosquarecom to start a discussionCheck out these blog resources for more web design and development insightsEcommerce website development cost in 2021Custom web development company in IndiaLearn how to hire offshore PHP developers in IndiaHiring a Developer for Your Startup  StepbyStep Guide Launch Your Online Store with SwiftKart 70 ECOMMERCE STORE FEATURES TO START  SCALE Complete list of features deployed by online shops of all sizes An ecommerce store that doesnt pack the right features is extremely hard to scale and turn commercially successful  This is the reason why small as well as big ecommerce platforms continuously work on investing new features and enhancements To help entrepreneurs build sturdy online stores and make radical feature enhancements Techosquare  leading ecommerce development company of India  has curated this list of 70 online store features To make things simple we have divided the features into cornerstone and game chang ing  Cornerstone online shop features  These are the online store features that are almost essential to launch an online Without these there is very little chance of success Whether you have 1000 monthly visitors or 1000k these features are must have  Game changing ecommerce store features  These are the online store features that are not critical to run ecommerce operation s but add huge value in terms of audience engagement and process improvement These features are usually integra ted in estores that are already big  Lets look at the cornerstone features first and later address the game  changing ones Cornerstone online store features 1 Search bar Over 70 of consumers use the s earch bar to navigate through e commerce websites Adding this feature will help shoppers discover products quickly and correctly While having a search bar is a nobrainer for a decent sized online store creating a feature rich one is not easy Make sure that your search functionality c aptures long searches correctly suggests recommendations and tackles spelling errors 2 IA focused navigation An intuitive navigation bar makes it easy for shoppers to quickly discover what they are looking for This is crucial for online stores selling thousands of products to diverse audience groups Collaboration between an information architect copywriter and developer is crucial to create the perfect navigation 3 Shopping cart and checkout process Shopping cart is by far the most integral feature of ec ommerce websites Once the shopper decides what to buy the shopping cart assists them in finishing the purchase From calculating the total amount to facilitating payments it handles everything necessary before making a ch eckout Hence a powerful shopping cart and checkout process are critical to selling 4 Engaging sliders Slider is the easiest way to display new arrivals best  selling products and even discounted items to direct the attention of customers to specific pr oducts An engaging slider supports video embedding video smooth transitions and design diversity to deliver engaging experiences throughout the website 5 Social media sharing Social media is currently the most powerful medium to generate traffic  even sell products Therefore social sharing capabilities are critical to success Bring social sharing capabilities to your product images as well so that people share them in their network This is valuable for fashion stores 6 Multiple payment method s A lot of new digital payment methods were introduced in the past decade Hence an e commerce store that packs most of them brings ease of shopping for customers and bigger sales for store owners Make sure that your online store supports payments through ewallets credit cards debit cards smart cards and net banking to give shoppers the freedom to pay the way they want 7 Popular searches module Festivals seasons and special occasions trigger the demand for specific products Thats why it makes pe rfect sense to add a po pular searches module to your e commerce website Adding this feature will make it easy for shoppers to reach popular items on your online store Pretty simple online store feature but creates a lot of value 8 Image slider  Since ima ges are critical to the mod ern shopping experience your e commerce store cannot do without an image slider It allows us to display multiple product images in an easy toview arrangement and show the product from different angles Your slider functionalit y should function smoothly clearly show navigation buttons and feature a zoom in option on product pages 9 High quality photo zoom With no physical contact with the products on sale until we purchase them the ability to zoom and examine different aspec ts of the product through photos is something every shopper wants Smooth functioning zoom functionality is especially critical for online stores selling clothing art handicrafts beauty products jewelry shoes and designer products 10 Breadcrumb nav igation Breadcrumb navigation helps the customers keep track of the path taken to reach a specific product It minimizes the need for making drasti c scope jumps throughout your e commerce store Breadcrumb navigation is a very simple website navigation tra it but it is critical from UX and SEO point of view So make sure that your online store has it 11 Product filtering  sorting Finding a product that fits your size color price and other tens of specifications can be tough on a mega store This is where product filtering  sorting features come handy Powerful product filters let customers shortlist products based on generic an d industry specific attributes Sorting on the other hand allows them to view products either in ascending or descending order of factors like price and rating 12 Informative product pages We all know that the purpose of a product page is to provide c ustomers with all the vital information about its features capabilities and benefits Thats why finalizing product page design thats visual yet highly informative focused is critical for your online stores success 13 Customer support column Shoppers often struggle to find information that helps them with returns refunds FAQs order tracking and other aspects of customer support Hence it makes perfect sense to create a customer support column in the footer and add critical links to it Also integ rate a Get in Touch form to help visitors quickly get in touch with the support team 14 Prominent call to action buttons Sales critical buttons like Add to Cart and Buy Now ought to be designed the right way for the obvious reasons Using bigger button s ize positive colors like green and easy to understand labeling will greatly help in improving sales Ace design and copywriting talent will help you master this 15 Trust signal s Even though ec ommerce shopping has grown humongous in the last decade first time shoppers are apprehensive of making purchases online especially from lesser known online stores This is where trust signals come into action Showing data security certifications and safe payment reminders during the checkout process greatly eases shoppers worries 16 Product datasheets module When it comes to smart devices electronic appliances  other gadgets lengthy descriptions dont make much sense Hence your online store should bring a feature of creating technical datasheetstables  embedding them in product pages Such datasheets make it easy for consumers to go through their specs and greatly improves user experience 17 Reviews module Reviews help customers learn about product quality and performance When it comes to internet shopping very small purchases are made without reading reviews Thats why you need to integrate a review management module in your online store Make it easy f or shoppers to read write and share reviews Show the average rating and review count also make it for buyers to make a decision 18 Related products Ecommerce stores that focus on simplifying product discovery for customers to gain a huge advantage Related products module is an amazing way to introduce shoppers to products that resemble their recent product searches This module usually appears at the end of product pages and delivers recommendations to upsell  cross sell Make sure you get it 19 Intuitive checkout page We all know how checkout pages work We have to enter personal shipping and payment information to complete the purchase All this takes time and becomes highly irritating if the checkout page is not planned with user experience in mind Features like field validation and intelligent form help a great deal in quickly completing the shopping 20 Featured posts ticker The latest blog s and trending posts need a place on your blog to grab the attention of readers and direct traffic on the relevant piece of content In case you are deploying a Wordpress like CMS for your e commerce store to make blogging easy make sure that you pick a t heme that promises featured posts ticker Ecommerce ideas 2021 to register big sales and profits 21 Recommended posts module If you plan on creating awesome content for your shoppers they will probably ask for more after going through one of them With the help of the recommended posts module you can introduc e visitors to your best content In place of this feature online stores sometimes go for previous and next blog functionality Thats equally good 22 Blog search  categories A blog search bar helps your loyal readers navigate through your blog and discover specific content In the absence of a blog search visitors will have a hard time discovering content related to specific topics Categories are helpful in the same manner Both these features are not technically challenging So make sure that they make it to your online stores blog 23 Powerful admin dashboard When it comes to growth little can be accomplished in the absence of data insights From the audience to demographics and sales to revenue the admin dashboard brings everything that will help you with decision making In addition to that it should be easy touse so that partner merchants can also utilize its capabilities with ease This is something highly recommended by top web app development firms of India  24 Comments box People love to share their thoughts and feedback after going through a good piece of content In the absence of a comments box it is almost impossible to do that Comments module in the blog creates a lot of value in terms of visitor engagement another non  complex feature that must be part of your online stores blog 25 Powerful CMS Ecommerce stores are highly dynamic platforms that are continuously updated with new product listings Hence it should be easy to alter product descriptions photos and other technical details with ease and little programming know how This is why you need a powerful CMS Content Management System for your online store 26 Responsive design From shopping to ent ertainment  everything is happening on smart devices Hence an enhanced mobile experience is vital to make your online store succeed Since it also doesnt make a lot of sense to launch a mobile application for your new online shop right away you need a responsive design to rank higher on Google and deliver an optimal experience  27 Order management system Growing online stores handle thousands of product orders every day Since there are different stages of shipment it is critical to have an order management module that keeps you updated at all times so that impeccable management and customer support is possible This feature is usually fitted in the admin dashboard Understand web app development process in 10 minutes 28 SEO optimized platform Google is a critical source of traffic for online store owners Ranking on the largest search engine in the world however is not an easy task if your platform is n ot optimized for it From search friendly URLs to Meta structure heading tags and structured data there should be a provision of everything critical for SEO 29 High level security Since shoppers are supposed to share card information on your website  security is something that cant be compromised on Apart from SSL certificate and PCI compliance your site should have a strong firewall and multiple layers of security for critical areas like checkout dashboard and cart This will help you keep away your site from hackers 30 SSL certification Websites that dont have the SSL certification flash the not secure message alongside the search bar Some browsers dont even open such websites citing security concerns Therefore it is of utmost importance to make sure that your online store has the SSL certification 31 Automatic website backup When you are doing business on the internet there are tons of things that can go wrong Automatic w ebsite backup helps save your e commerce store from data loss and major outage in case of malfunction Make sure that your online store automates the process of taking backups 32 Returns process  There can be tens of reasons why a shopper no longer wants something she ordered Hence you have to make justified return s as simple as possible A practical return module helps gather information about the returns simplifies decision making and facilitates faster returns 33 Popup module Popups are highly effective to introduce visitors to new discounts notify about upcoming sales and gather emails Thats why its highly important to add a popup module that makes it super easy for you to create and edit popups that can be flashed at spe cific pages or throughout the website Pretty simple feature but must be presence in your ecommerce website features list Learn everything about multivendor marketplace business plan 34 Customer dashboard Wishlist feature will only work if you have added a customer dashboard to your e commerce website It will let sho ppers register as customers by signing up and creating a space from where they can easily access Orders Shopping History Wishlist and a lot of other details Enable signup through social media as well email to simply the process  give quick access to t he customer dashboard 35 Wishlist There are an N number of reasons why someone can decide to postpone a purchase Therefore adding a Wishlist feature to your online store is a must It will help your customers create a list of desired products that can be purchased sometime in the future Discounts and special offers can also be planned around products in Wishlist to encourage purchase Game changing estore features 36 Store finder Are you a brand with your physical stores or pick up partners in different locations Integrating the Store Finder feature will make it easy for your customers to find nearest pick up locations and identify stores for an off line shopping experience This feature is highly relevant for emerging and big sellers 37 Language option Businesses and sellers with international visio n can benefit greatly from an ec ommerce website with multilingual capabilities Tailoring the shopping experience through unique language preferences brings a lot of personalization that directly pushes sales as well as profits This is a must have in the e commerce website features list of big stores 38 Loyalty programs module Having a loyalty program in pl ace plays a crucial role in increasing the count of returning customers to yo ur e  commerce store A loyalty program module uses the concept of reward points to keep shoppers hooked to your platform and return to redeem rewards Offline as well as online st ores are currently using this strategy to push sales numbers So consider adding this to your online store 39 Personalized experiences Browsing behavior purchase history and cart abandonment data brings amazing opportunities to personalize shopping exp eriences With this feature you can make product recommendations on a wide range of data sets This feature is widely deployed by fashion stores 40 Live chat support Modern shoppers value instant supports greatly and since research has proven that peop le prefer to chat over phone calls your online store can benefit hugely from live chat support Lifestyle stores are also nowadays offering virtual shopper support through chat to their loyal customer base to enhance the shopping experience 41 Newslette r functionality Newsletters are a great way to stay connected with all your shoppers and share valuable information about new arrivals discounts special sales and also company updates An in  built newsletter module creates attractive mailers and helps dispatch it to specific groups of shoppers  In short a powerful ecommerce website feature for marketing  growth Learn everything about cash back website development in 10 minutes 42 Currency switcher Nurturing the dream of running an online store with international operations The currency switcher feature is a must have for you It auto matically changes the product pricing to your local currency by taking your location into account For those on a small budget can opt for the manual version of the currency switcher 43 Multi vendor panel A multi vendor panel allows multiple merchants to sell their products on your online store This complex feature will bring Amazon like merchant capabilities to your online store and open the possibilities of becoming a mega online store Very few online store builders guarantee this feature So confi rm this beforehand if your goal is to host multiple merchants on your platform Consult top custom developers of India for cost estimation of multivendor platform 44 Push notification s Push notifications are a powerful tool to stay connected with your customers through their desktop  mobile devices Push notifications are small message like alerts that help engage customers through updates related to discounts sales new arrivals a nd whatnot However Push notifications are to be triggered cautiously since too many of them can irritate the shoppers and drive them away 45 Advertising module An advertising module provides site owners with the ability to advertise specific products t hroughout their e commerce website Whether you want to push the latest products through in store ads or want third party websites to advertise their offerings everything is possible with a powerful advertising module Add this to you ecommer ce website features list to make big money 46 Feedback module Nothing triggers growth and improvements like customer feedback Thats why your online store can benefit greatly from a feedback module From complex shopper surveys to simple site feedback forms a powerful feedback gathering module can accomplish a lot by helping gather critical insights 47 Discount timer Discount timer has the power to create urgency in the shoppers mind and generate sales that could have been postponed It is widely used by online stores across the world to clear seasonal stock create product hype and push product sales in a specific category A discount timer is widely deployed on homepage and category pages 48 Urgency messaging While discount clock capitalizes on savings mentality of shoppers urgency messaging uses scarcity psychology to encourage the shoppers to quickly complete the purchase Such messaging is usually displayed below the Buy Now button on product pages Only 2 items left is the perfect example of urgency messaging 49 Product sharing via email Peers are nowadays playing a crucial role in digital shopping This is probably why the share viaemail feature has gained huge popularity over the past few years It lets shoppers share products via email with friends and family giving them a wider reach Add this capability to your ecommerce website features list 50 Promo codes module Promotional codes are a great way to attract price conscious shoppers to your website However if your online store doesnt have the featu re to support this popular marketing practice there is no way you can implement it on a large scale Therefore ask your e commerce store builder to build a promo code module Ecommerce website development cost estimate for 2021 22 51 Compare products When it comes to products with a lot of technical specifications a feature wise comparison is critical to decision making A powerful product comparison feature lets shoppers run multiple product comparisons  confirm purchase quickly This e store feature is promised by very few online store builders Want to build something truly unique Email infotechosquarecom to consult our ecommerce store developers  52 Payment taxes  location management International ecommerce stores should be able to handle different payment processes calculate  apply taxes and update pricing according to locations All of these can be easily handled by adding a PTL manager in the backend of your online shopping website 53 Config urable restocking alerts Restock alert notification lets you announce the re availability of certain products so that customers interested in them can complete their purchase Such alerts create a lot of value for online stores dealing with artwork desig ner products and fashion items 54 Inventory valuation  management Inventory measurement  tracking is critical to make sure that correct product availability data goes on the website In the absence of a powerful inventory valuation feature you will ha ve to spend a lot of time understanding availability  site updates This feature is especially critical for megastores 55 W3C compliance W3C Compliance in its essence means that your websites HTML and CSS code complies with standards set by the World Wide Web Consortium It is extremely hard to generate zero compliance errors the idea to have a minimal number of errors and a strong overall structure 56 Backend activity tracker For big online stores with multiple administrators transparency is a bi g thing The backend activity tracker helps site owners keep track of every change or task performed by the administrators This is the easiest way to have documentation of site changes  updates for future reference 57 Mark as a favorite While Wishlist h as strong purchase intent Favorite is a casual way to mark  safe keep products that appeal to you While the purchase intent is weak with Favorite the data can be used to make product recommendations and personalize the shopping experience for certain s hoppers 58 Sale report Product sales are what site owners are most concerned about Sales reports help you glance at daily weekly monthly or annual sales numbers to understand the pace of growth From weekly sales volume to top performing products everything sales critical is shown a t one place Every ecommerce website features list must have this 59 Reward points  coupons  Competition amongst online stores is truly brutal In such a scenario you simply cannot skip any opportunity to engage customers Reward points  coupons are being used by big offline stores for many years now to m ake customers come back again and again Embed the rewards feature in your online store to give away small rewards for more shopping Worried by cost of developing a powerful e store Learn how to hire offshore developers for big cost savings 60 Inspiration page  Online shops dealing in fashion accessories makeup and lifestyle products host inspiration pages to engage visitors with the latest designs upcoming products and inspirational content These pages are integrated with powerful search visual media comments functionality and sometimes voting capabilities Its highly recommended if you are catering to fashion able women and high net worth individuals 61 360 product viewer 360 product viewer is the most advanced feature introduced to the e commerce market It lets shoppers see your products from any angle with incredible detail giving them a rich virtual expe rience in terms of quality an d design check Modern e stores are integrating this feature into their stores to improve customer experience 62 User generated content capabilities  Online stores that cater to youth especially women go to great lengths to build engagement and garner loyalty User generated content plays a crucial role in that The simplest way to understand this is through an example A fashion store launches a feature where people can upload their summer look to the website and get votes share it on social media and win prizes Such features go a long way in creating brand awareness building loyalty and also generating sales 63 Merchant management  Online stor es that are aiming to become marketplaces like Amazon need a merchant management module through which they can keep track of all the merchant activities and moderate their status accordingly From making new merchants live to give special privileges every thing can be managed from a merchant management module if developed correctly 64 Premium memberships  Store m embership s bring special privileges like faster delivery special discounts and offers for the shoppers Think on the lines of Amazon Prime Integrating the same requires enhancements in the customer dashboard as well as admin dashboard Since such memberships are usually renewed on a yearly basis it also requires a payment process that supports auto deductions from credit card  65 Timesaving features  There should be nothing more important than your shoppers time for you The quicker they can decide on a product and successfully place an order the higher will be your profits Hence time saving features like Quick View and CoD Check can be r eally helpful in speeding up the shopping and saving disappointment on the checkout page So your goal should be to keep thinking about timesaving features 66 Subscriptions  Subscription driven ecommerce stores are gaining popularity amongst businesses that deal in product s that are required on a daily basis One of the most popular startups in this segment is Dollar Shave Club a grooming brand that delivers razors and personal grooming products to subscribers Its also relevant for online stores deali ng in digital content and monthly pro duct subscriptions like Netf lix Therefore the feature of subscribing can be a great addition to your ecommerce platform 67 Advanced product search  Sometimes shoppers know very specific product details and regular search fails to furnish the relevant results Advanced search helps greatly on such occasions since it brings the capability to locate the desired item on vast range of factors such as keywords item number location shipping duration sale items  etc An online store that attracts millions of visitors can surely benefit greatly from this feature 68 Mobile applications  Not exactly a feature for an ecommerce store but very critical for growth of online stores with growing traff ic Mobile applications tailor the complete shopping experience and are really valuable for online shops dealing in lifestyle  fashion products If you cater to women then having a mobile app is almost obligatory Wondering how much a powerful estore costs Learn about ecommerce website development cost  69 Infrastructure  Your website can be the Ferrari of online stores but without the right hosting plan setup management and CDN infrastructure it will lag behind others and face performance issues So infrastructure is really crucial to bring out the best from your ecommerce website 70 Auto detect location  An online store capable of detecting shoppers geographical region has the power to customize the whole store experience This feature is widely used by online shops to deliver unique shopping experiences suggest better recommendations and improve conv ersions Add this online store feature to your must have list if your audience makes up diverse set of people Phew We are done with our list of 70 ecommerce store features to launch and grow your online store While cornerstone are relevant for most ecommerce stores and must be considered for inclusion game changing features can be added to further improve store experience conversions and engagement Team Techos quare has been building powerful online stores for over a decade now Swiftk art is our game changing online store builder that promises a scalable ecommerce solution to entrepreneu rs who want to sell online Swiftkart packages start at 499 USD only If you are planning to launch an online store and need any kind of help send us an email at infotechosquarecom to schedule a free consultation session  ,https://www.techosquare.com/blog/website-development-project-plan,Project Management,1923,6466
User Feedback and Usability Testing, What is User Feedback User feedback is collecting opinions of real users about their experience of using the product that designers want to create or already created After people use the product they share what they like about it or what was confusing Such information helps designers understand the users perception of the product and make it more enjoyable and useful for the people who use it Get accurate user feedback using advanced prototypes during the design process to iterate and improve before the product development phase Create your first interactive prototype with UXPin Sign up for a free trial Build advanced prototypes Design better products with States Variables Auto Layout and more Try UXPin What is User Feedback User feedback in UX design is direct user input about a products design functionality and overall experience This feedback informs product managers about what works what doesnt and potential improvements Rather than relying on assumptions or theoretical models UX or product designers use this feedback as a foundation to refine and enhance designs ensuring they align with user needs and expectations Why is User Feedback Important User feedback guides the design process ensuring the teams solutions align with user needs and expectations Here are several reasons why feedback is essential Informed Decisions Instead of relying on guesswork designers use real insights from users to make design decisions keeping the process rooted in reality Enhanced Usability User feedback highlights areas where users struggle allowing designers to promptly address and rectify usability issues Elevated Customer Experience When designers understand users likes dislikes and preferences they can craft delightful experiences that resonate with the target audience reducing churn while increasing retention Promotion of Inclusive Design Diverse feedback ensures that design solutions cater to a wider audience making products more accessible and inclusive When to Ask for User Feedback User feedback is not a onetime event its a continuous process that guides and influences the design process from the initial concept to the final product Here are some typical scenarios at various stages of the UX design process Ideation Stage Initially designers seek feedback on general concepts or ideas to identify potential user needs and pain points Its about understanding users and framing the correct problems to solve Prototyping Stage When rough drafts or prototypes exist designers gather user responses to validate or challenge their design assumptions This stage aims to minimize usability issues early saving resources and time Testing Stage Designers implement user feedback to refine prototypes improving usability and functionality The goal is to catch any remaining issues before a broader rollout Postlaunch Stage Collecting user feedback is crucial even after the product launch Combined with a UX audit this feedback reveals realworld usage patterns and issues that may not have surfaced during testing Insights gathered here drive future iterations and enhancements How to Collect User Feedback These are the common types of user feedback methods designers use throughout the design process User interviews When During the ideation and prototyping stages User interviews dive deep into users needs behaviors and experiences Designers engage in oneonone discussions to gain insights beyond surfacelevel responses uncovering nuanced details that quantitative methods might miss Surveys and questionnaires When During the ideation and postlaunch stages Surveys and questionnaires offer a way to efficiently gather feedback from larger user groups Designers pose targeted questions to pinpoint specific areas of interest or concern making it easier to chart refinements Usability testing When During the prototyping and testing stages Usability testing allows designers to observe users interacting with a product or prototype This method offers a clear view into where users struggle succeed or get confused giving designers actionable feedback to enhance functionality and flow Feedback buttons and forms When Utilized postlaunch Inapp feedback buttonsNet Promoter Score NPS Customer Satisfaction Score CSAT etcand feedback forms embedded within a product offer users an easy avenue to share their thoughts in realtime This continuous feedback loop helps designers address pain points and make iterative improvements Analyzing user behavior When Across all stages especially postlaunch Understanding user behavior through inproduct tracking and analytics tools Hotjar Google Analytics etc becomes vital By observing how users navigate what features they use most and where they drop off designers gain a holistic view of user patterns informing design choices and revealing areas for improvement How to Analyze and Incorporate User Feedback Step 1 Prioritizing user feedback Prioritizing user research requires a systematic approach to figure out what to tackle first Weigh feedback against your product roadmap and objectives Not all feedback aligns with the projects intended direction or vision Consider the volume and frequency If multiple users highlight the same issue it demands immediate attention Evaluate the impact Assess if addressing the feedback will significantly enhance the user experience or if its a minor tweak Step 2 Identifying patterns and trends Spotting patterns in user feedback is essential for refining UX design effectively Group similar feedback Clustering product feedback into categories can help understand broader user sentiment and needs Use analytics tools User behavior metrics can reinforce or challenge identified patterns along with direct feedback Engage with the team Regular feedback sessions with the design and development teams can help connect the dots and unveil deeper trends Step 3 Iterating Based on User Feedback Once youve prioritized feedback and identified patterns its time to incorporate feedback Make changes rooted in user requirements Ensure that your iterations address the genuine concerns and needs of your users Test your changes Before fully implementing adjustments test them using a prototyping tool with a subset of users to validate their effectiveness Continuously collect feedback from customer support interviews social media feature requests and user reviews The feedback loop doesnt end with one round of changes Keep the channels open for users to share their thoughts on the new iterations Tips for Asking the Right Questions Openended vs closedended questions Openended questions allow users to express their feelings perceptions and experiences in their own words These questions delve deeper extracting qualitative feedback that helps designers grasp the why behind user behaviors For example instead of asking Did you find the navigation easy a closedended question you could ask How did you feel about the navigation experience This framing allows users to elaborate share nuances and provide richer feedback Avoiding leading questions Leading questions nudge users towards a particular response contaminating genuine feedback They often introduce bias making it challenging for designers to capture unbiased opinions Its vital to phrase questions neutrally to ensure the feedback remains unbiased by any presuppositions For example instead of asking Do you think our new homepage looks better a neutral question would be How do you feel about the changes to our homepage Encouraging honest feedback Creating an environment where users feel comfortable sharing both positive and negative feedback is crucial Assure users that their opinions whether good or bad are valuable and will improve the product Its beneficial to emphasize that constructive criticism is welcome For example instead of asking How was your experience with our platform you could frame it as Were looking for ways to improve Could you share what you liked and where we can improve Being specific in queries Precise questions can lead to more actionable insights Vague questions might leave users confused or unsure about how to answer You can extract detailed feedback that directly informs your design decisions by targeting specific aspects or functionalities of your design For example rather than asking Do you like our website a more specific query might be What are your thoughts on the checkout process on our website This framing narrows the focus and prompts users to think about that feature Example of User Feedback in UX Design A music streaming app was facing consistent dropoffs on its signup page User conversion remained suboptimal despite an intuitive interface and a compelling value proposition The UX team initiated user interviews and usability testing sessions to get to the root of the issue During these sessions a recurring theme emerged users felt overwhelmed by the many data fields they had to fill in on the registration page Additionally they were uncertain about how the company would use or share their data leading to trust concerns The product team took several steps to incorporate this feedback Simplified the Signup Process The team reduced the number of mandatory fields during onboarding asking only for essential information They moved secondary user details to the profile completion stage postsignup Added Tooltips and Information Designers added tooltips to input fields explaining why the company needed specific data and assured users of its confidentiality Implemented Progressive Disclosure Instead of presenting all information at once designers used progressive disclosure techniques The interface shows users just enough content to complete the immediate task offering more details when requestedie accordions dropdowns popups etc Postimplementation the app saw a significant rise in successful signups with a 30 increase in conversions from the registration page Feedback loops with real users highlighted the pain points and the swift incorporation of this feedback led to tangible improvements in user experience and conversion rates Incorporating Feedback With UXPin UXPins advanced design features enable design teams to create prototype experiences that look and feel like the final product These immersive prototypes elicit highquality actionable feedback for designers to make accurate adjustments and fixes during the design process With UXPins Comments designers can share feedback from users and stakeholders and assign them to specific team members for action As designers make changes they can resolve comments for further testing and iterating Collect accurate feedback with UXPins advanced prototypes to enhance your products user experience faster than traditional design tools Sign up for a free trial to build your first interactive prototype with UXPin Try UXPin for free Build prototypes that are as interactive as the end product Try UXPin Found this useful Share with by UXPin on 22nd August 2023 UXPin is a webbased design collaboration tool Were pleased to share our knowledge here Song Title 25 bum anit This looks great Lets move to the next step Song Title Qo ,https://www.uxpin.com/studio/blog/user-feedback/,UI/UX Design,721,1679
Accessibility Testing, Accessibility testing From W3C Wiki Jump to navigation search This page is outdated Some of the information is still relevant Some is not Current information is available from Evaluating Web Accessibility Overview Contents 1 Introduction 2 When should testing be done 3 Understanding your requirements 31 External requirements 32 The details of conformance 33 Exceeding expectations 34 The importance of the user interface 35 Personas with disabilities 36 Choosing an accessibility standard 37 The spirit of the law 4 Who should test 5 Expert testing 51 Semiautomated accessibility checkers 52 Structural inspectors 53 Screening and using enduser assistive technology 54 Detailed inspection 541 Perceivability 542 Operability 543 Understandability 544 Robustness 6 User testing 61 Recruiting testers 62 Practical considerations 63 Choosing tasks 64 Interpreting the results 7 Communicating the results of accessibility testing 8 Summary 9 Exercise questions This page is outdated Some of the information is still relevant Some is not Current information is available from Evaluating Web Accessibility Overview Introduction Web accessibility testing is a subset of usability testing where the users under consideration have disabilities that affect how they use the web The end goal in both usability and accessibility is to discover how easily people can use a web site and feed that information back into improving future designs and implementations Accessibility evaluation is more formalized than usability testing generally Laws and public opinion frown upon discriminating against people with disabilities In order to be fair to all governments and other organizations try to adhere to various web accessibility standards such as the US federal governments Section 508 legislation and the W3Cs Web Content Accessibility Guidelines WCAG However it is important to distinguish between complying with a standard and maximizing the accessibility of a web site Ideally the two would be the same but any given standard may fail to address the needs of people with all disabilities balance the needs of people with differing disabilities match those needs to optimal techniques use clear language to express needs or techniques Such weaknesses can lead those with good intentions astray and may be exploited by those seeking to rubberstamp inaccessible products Moreover web accessibility is a goal not a yesno setting It is a nexus of human needs and technology As our understanding of human needs evolves and as technology adapts to those needs accessibility requirements will change as well and current standards will be outdated Different websites and different webs serve different needs with different technology Voice chat like Skype is great for the blind whereas video chat is a boon for sign language users Disabilities pose special challenges when working out how easy a product is to use because they can introduce additional experience gaps between users and evaluators Accessibility evaluation must take account of what it is like to experience the web with different senses and cognitive abilities and of the various unusual configuration options and specialist software that enable web access to people with particular disabilities If you are trying to evaluate the usability or accessibility of your web site putting yourself in the place of a filmloving teenager or a 50year old bank manager using your site is difficult even before disabilities are considered But what if the filmloving teenager is deaf and needs captions for the films she watches What if the 50year old bank manager is blind and uses special technology like a screen reader which is unfamiliar to the evaluator in order to interact with his desktop environment and web browser Accessibility guidelines and tools help bridge these experience gaps However they are a supplement not a replacement for empathic imagination technical ingenuity and talking to users In this article of the Web Standards Curriculum I will discuss approaches to evaluating web accessibility both from the perspective of establishing formal compliance and from the perspective of maximizing accessibility When should testing be done Test early test often is an old software engineering saying Tacking on testing at the end of the development process has two risks Projects tend to run overtime and overbudget Testing is often rushed omitted or ignored thanks to such pressures It is more work to fix problems discovered late in a process than to do things right from the start So to ensure quality and save time and money accessibility evaluations should start right at the beginning of product design and be included in subsequent development iterations through to final delivery Understanding your requirements Before you begin to evaluate a project for accessibility you need to determine what the key requirements are for that project given its environment intended audience and resources Some requirements will be set by third parties like governments and clients some you may be able to choose for yourself External requirements Often requirements come from external sources such as Governments This typically takes the form of general legislation against discriminating against people with disabilities rather than mandating a particular standard or enumerating precise conformance requirements An important exception is when legislation enforces a particular standard for public sector For example Section 508 is a piece of US federal legislation which mandates that websites produced for federal agencies must conform to at least a specific set of defined requirements WAIs Policies Relating to Web Accessibility page provides a partial list of similar legislation But to get an authoritative statement of the obligations in your jurisdiction consult a lawyer Customer policies For example Shell currently try to ensure their websites conform to the DoubleA conformance level of WCAG 10 so if you were developing a website for Shell you would need to meet at least the same standard Marketing utility Compliance with a particular standard such as Section 508 might help sell a project to clients concerned about accessibility Internal accessibility policies at your organization For example projects produced by the BBC need to comply with the BBCs Accessibility Guidelines v13 The details of conformance It is important to get as much clarity about external requirements as possible Some accessibility standards have more than one possible level or type of conformance so it is particularly important to nail down which is required For example WCAG 10 has three conformance levels People with some disabilities will find it impossible to access information in a document that does not pass level A People with some disabilities will find it difficult to access information in a document that does not pass level DoubleA People with some disabilities will find it somewhat difficult to access information in a document that does not pass level TripleA Draft WCAG 20 has three levels too but the conformance possibilities are more complicated Where a resource is part of a series of resources presenting a process eg product discovery selection checkout and purchase confirmation for an online store the conformance level for all resources in the series is that of the resource with the lowest level Conformance claims must be based on accessibilitysupported content technology To be an accessibilitysupported content technology a technology must Have been demonstrated to work with users assistive technology Have user agents browsers plugins etc that work with the users assistive technology and are available to users with disabilities at no cost above that for a user without a disability Note that within an intranet setting you might be able to guarantee that such user agents would be available to users whereas you cannot guarantee the same thing on the World Wide Web For example an application might be usable without any commercial technology but only be accessible to screen readers with a commercial plugin for which the organization has a site licence That application could conform to WCAG 20 when deployed on the organizations intranet but not when deployed on the public Web WCAG 20 also allows more limited statements of conformance An inaccessible resource can conform if an accessible alternative is provided Publishers can make a statement of partial conformance where content is aggregated from other sources Exceeding expectations Determining external requirements should only be the beginning of the process they should be treated as a minimum set of requirements to which further goals should be added to maximize accessibility As the person evaluating accessibility it is your role to raise additional accessibility concerns as you are the subject expert You may need to distinguish the two when delivering a final report For example a customer brief for an online supermarket might mention that they want a store accessible to blind users Given the intended audience you should also evaluate whether the store is accessible to users with other disabilities Note that external requirements for compliance with a particular standard do not necessarily prevent best practice guidelines from other standards being applied For example you might be evaluating a website for a web federal agency intended for use by senior citizens and be required to comply with Section 508 Section 508 stipulates that  119422 c Web pages shall be designed so that all information conveyed with color is also available without color for example from context or markup This provision helps users who know how to customize the presentation of web content but doesnt maximize the accessibility of the default presentation of that content to the target audience by ensuring that there is sufficient contrast between suggested colors Fortunately theres nothing stopping a web site from fulfilling this requirement but also meeting the following Level provisions from the Web Content Accessibility Guidelines 20 draft 143 Contrast Minimum Text and images of text have a contrast ratio of at least 51 except for the following Level AA Large Print Largescale text and largescale images of text have a contrast ratio of at least 31 Incidental Text or images of text that are part of an inactive user interface component that are pure decoration that are incidental text in an image or that are not visible to anyone have no minimum contrast requirement Note Success Criteria 143 and 146 can be met via a contrast control available on or from the page 146 Contrast Enhanced Text and images of text have a contrast ratio of at least 71 except for the following Level AAA Large Print Largescale text and largescale images of text have a contrast ratio of at least 51 Incidental Text or images of text that are part of an inactive user interface component that are pure decoration that are incidental text in an image or that are not visible to anyone have no minimum contrast requirement Note Success Criteria 143 and 146 can be met via a contrast control available on or from the page By contrast control the criteria means that you should provide a way of changing the colours to a highcontrast variation To test the contrast of colour schemes you can use the colour contrast analyser from Juicystudio WCAG 20 is being designed to have a high degree of backwards compatibility with other standards especially WCAG 10 and Section 508 The importance of the user interface Consider the special importance of making the user interface of a web site accessible Even if content is not available in a suitable form an accessible user interface may help users identify content of interest and seek external help in converting it to a form they can use For example a hardofhearing individual might be pointed to a video of a talk on a videosharing site without captions Because the URL uniquely identifies that video and because they can still use the player to see the video however they could submit it to a third party such as the free Project readOn service for captioning Personas with disabilities An ideal approach is to build key disabilities for your project right into your other user personas fictional users that act as archetypes for how particular types of users would use a web site Let us say you are evaluating prototypes for a video sharing site and your personas include 23yearold James Smith who is footballmad and especially wants to share sporting highlights with friends 34yearold Sarah Maddison is a working mom who might not normally have time for a video sharing site But her threeyear old daughter is really keen on watching videos and Sarah wants to sit and help her find suitable videos she wants to watch You can take these personas and incorporate disabilities including for example Impaired vision Colorblindness Blindness Deafness Hardofhearing Deafblindness Epilepsy Dyslexia For example you might decide that James is also deaf and wants commentary on match videos to be captioned and Sarah has poor eyesight and struggles to read fancy fonts and tiny text These personas guide your rejection of prototypes that fail to include the facility for closed captions in the video player or use elaborate text headings that would require images The WAIs How People with Disablities Use the Web and Shawn Lawton Henrys Just Ask Integrating Accessibility Throughout Design contain some more example disabilityinflected personas to get you started It shouldnt need saying but dont assume people with disabilities are interchangeable Disability is an incredibly varied phenomenon and on top of that people with disabilities have all the variety that people without disabilities have differing for example in gender age interests values and skills perhaps most relevantly in their computing expertise Again comparing products against accessibility guidelines can help fill in the gaps that your personas do not cover For example perhaps youre following WCAG 20 with the video sharing site but your personas dont include a user with epilepsy Nonetheless you read Guideline 23 Seizures Do not design content in a way that is known to cause seizures and decide that the system needs to be able to screen uploaded videos for flashing before displaying them Choosing an accessibility standard If you need to choose an accessibility standard in order to manage web accessibility concerns across a team or in simply to guide you while testing Id advise looking at WCAG 20 because it is designed around core human needs that are applicable to technologies other than HTML and CSS such as Flash carefully documents the reasoning for each conformance criterion suggests practical techniques for meeting conformance criteria using current technologies ensures each provision is testable incorporates more recent research than current alternatives is designed to be broadly compatible with existing accessibility standards will be an international standard You can cite compliance with a specific draft of WCAG 20 for marketing purposes however it is best to also seek compliance with finished standards like Section 508 and WCAG 10 as well as that draft The spirit of the law When testing against guidelines its important to keep in mind the underlying rationale for any specific technical guidance to comply with the spirit not just the letter of the law Heres a cautionary tale Section 508  119422 includes a requirement that says A text equivalent for every nontext element shall be provided eg via alt longdesc or in element content Likewise WCAG 10 includes a checkpoint that reads Provide a text equivalent for every nontext element eg via alt longdesc or in element content This includes images graphical representations of text including symbols image map regions animations eg animated GIFs applets and programmatic objects ascii art frames scripts images used as list bullets spacers graphical buttons sounds played with or without user interaction standalone audio files audio tracks of video and video Unfortunately many people reading such guidance misunderstand what a genuine text equivalent for a spacer and decorative elements should be and produce markup like this img altfancy border srcfancybordergif border0 In fact since these images convey no new information and have no functionality the right text equivalent for those images would be an empty string alt which causes the screenreader to just skip over the alt attribute and not read it out It is very annoying for a screenreader user to have to listen to text such as fancy border read out over and over again when it does not provide them with any useful information WCAG 20 tries to be clearer The equivalent guideline says All nontext content has a text alternative that presents equivalent information except for the situations listed below One of those situations is Decoration Formatting Invisible If it is pure decoration or used only for visual formatting or if it is not presented to users then it is implemented in a way that it can be ignored by assistive technology Equally importantly WCAG 20 tries to detail the reasoning behind the guideline The purpose of this guideline is to ensure that all nontext content is also available in text Text refers to electronic text not an image of text Electronic text has the unique advantage that it is presentation neutral That is it can be rendered visually auditorily tactilely or by any combination As a result information rendered in electronic text can be presented in whatever form best meets the needs of the user It can also be easily enlarged spoken in a voice that is easy to understand or rendered in whatever tactile form best meets the needs of a user Who should test There are basically two groups who conduct testing experts and users Expert testing is important because experts understand how the underlying web technologies interact can act as a clearing house for knowledge about different user groups and have the inclination to learn dedicated testing tools User testing is crucial because users are the real experts in their own abilities and their own assistive technology User testing can also reveal usability gaps between more and less technical users and between people who are familiar with the web site in question such as the expert testers themselves and people who arent new users A web developer who knows how to use a screen reader is unlikely to explore a site the same as a regular screen reader user screen reader users who program their own scripts are unlikely to explore the site using the same strategies as screen reader users who just do ordinary computing tasks like writing emails Knowledge gained in user testing is fed back into the expert testing process the next time testing is performed either in another testing iteration on the same project or a different project entirely User testing also has a more subtle advantage By humanizing accessibility and bringing developers together with end users it can increase the motivation to build accessible websites Expert testing There are four components to expert testing Toolguided evaluation where a tool looks for accessibility problems and presents them to the evaluator this would include accessibility checkers and code linters Screening where the expert simulates an enduser experience of the web site Often you dont need to look very far to find accessibility problems You might do no more than load the page in your browser and notice the text is very hard to read Toolbased inspection where the evaluator uses a tool to probe how the various bits of a web site are working together Code review where the evaluator looks directly at the code and assets of a web site to scour for problems While beginners may be especially dependent on toolguided evaluation evaluators of all levels of experience can benefit from each component Even beginners can spot img elements without text equivalents in HTML markup and as you get more experienced you will get quicker at spotting problems before you progress to more rigorous testing For experts on larger projects it may not be feasible to manually review all clientside code or inspect all parts of a website but a toolguided evaluation can find areas of particular trouble that deserve a closer look Also human evaluators may overlook things that a machine evaluation would have caught Unfortunately although there are lots of accessibility tools most of them are flawed in one way or another For example one tool that lists headings in HTML documents makes the error of not including alt text from img elements Just as you should keep the spirit of the law in mind with standards compliance so you should keep it in mind when using tools Before complaining to someone about an accessibility problem make sure it is a genuine issue not a tool error Semiautomated accessibility checkers Once the firstglance problems have been fixed a good next step is to throw the page at a semiautomated accessibility checker tool If you are evaluating compliance with a particular standard you will probably want to pick one that is designed for use with that standard If youre evaluating compliance with Section 508 or WCAG 10 Cynthia Says is a reasonable choice If youre testing against German BITV 10 Level 2 the Italian Stanca Act or the WCAG 20 draft the only current option is the experimental ATRC Web Accessibility Checker Such tools have significant limitations There is no such thing as fully automated accessibility testing For example given the primitive nature of current artificial intelligence a computer program cannot have the final say in whether some text is a genuine equivalent for a photograph in context Even with areas that can theoretically be fully automated checker programmers may err in their interpretation of accessibility guidelines and lose the spirit of the law amongst its letters Good tools inspect the page for accessibility problems and produce a list of things they judge to be errors and other things they judge worth human investigation For example if Cynthia Says finds an img element with alt it will issue a warning not an error instructing the user to verify that this image is only used for spacing or design and has no meaning If the correct text equivalent for that image is an empty string you should move on to the next error or warning Perhaps the biggest advantage of accessibility checkers is that if you choose one such as TAW 3 which can be run against multiple URLs you can find pages in large collections that are likely to require closer inspection Structural inspectors Many inspection tools are designed to probe structures of web content Structures in simple terms define what the components of a web site are and how they relate to one another For example in the HTML document object model DOM text can be designated as a label for a form field using the label element Browsers parse the HTML into a document object model The browser associates various behaviour with particular components For example if you click the label of a checkbox it will normally get checked Desktop environments and applications support interactivity with screen readers speech recognition software and other assistive technology by providing a similar structure that represents the content and functionality available in the visual presentation On Windows the main structural system is called Microsoft Active Accessibility MSAA or UI Automation on Vista For example a dialog has a series of related children such as its title its fields its buttons and their labels Typical assistive technology mostly deals with the browsers and plugins representation of web content in terms of these structural systems rather than processing web document object models directly There are inspectors for both desktoplevel structures and weblevel object models On the desktoplevel side of things OS X comes with Accessibility Inspector and Accessibility Verifier Microsoft provides inspector tools for Microsoft Active Accessibility 20 and Microsoft Active Accessibility 13 Accerciser is available for the GNOME assistive technologySPI API Tools for poking at the XHTML document object model include DOM Inspectors as seen in Opera Dragonfly and Firebug and accessibility tool bundles like the Web Accessibility Toolbar for Internet Explorer and Opera and the ICITA Firefox Accessibility Toolbar DOM inspectors show you the tree of elements and attributes and text constructed out of the XHTML serialization whereas web accessibility inspectors abstract particular components or relationships and list them For example they might list all fields with their labels or all headings or all links Digging into the accessibility model should not normally be necessary for XHTML though you might also want to investigate that layer if you think a browser is representing a correct XHTML structure incorrectly to assistive technology Instead you will normally be checking XHTML structures directly Not all content can be inspected with DOM or web accessibility inspectors Inspecting what is exposed to the desktoplevel accessibility structures is important for checking what plugin content media players Flash content and Java applets is being exposed to assistive technology that uses those accessibility models In general you should check that all controls are exposed in the model with the appropriate role eg text boxes are text boxes buttons are buttons and the necessary properties Screening and using enduser assistive technology Screening involves emulating the experiences of people with disabilities while testing This might take the form of using assistive technology to interact with a site or attempting to restrict ones abilities in some manner For example Using a mouthstick to press keys while testing keyboard accessibility Viewing a page with the Vischeck simulator which attempts to present the page images included as people with different forms of colorblindness see it Turning off a monitor while using a screen reader in conjunction with a browser Screening can help build developer appreciation for the needs of people with disabilities and can reveal fundamental design flaws Use of assistive technology can clear up certain misconceptions about how they do and dont support and interact with web standards For example popular screen readers do not use styles suggested for the aural or braille CSS media types instead attempting to represent the screen type presented by the visual browsers with which they interact Using assistive technology is not a task to be taken lightly since a good understanding of how to use such systems may require a degree of immersion and training Theres a serious risk of creating new misconceptions Developers might struggle to do something with a screen reader and assume that reflects a failing in the screen reader when it really reflects their inexpertise with the tool They might try to use the tool the wrong way for example trying to read a page in sequence where a real screen reader user would hop around it using headings and other elements looking for points of interest Or alternatively they might fail to read the screen properly Reading through a page you can see or know well with a screen reader is very different from exploring a brand new site you cannot see Use of assistive technology needs to be accompanied by experience of how everyday users employ the technology and conclusions drawn from such use should ideally be confirmed with expert users On the whole beginners are better off leaving use of assistive technology to user testers Detailed inspection Once all genuine problems identified by your chosen checker tool have been fixed you can move on to manual testing probing and review of the project WCAG 20 splits its best practice criterion into four principles Content and functionality must be Perceivable for example images should have text equivalents Operable for example it should be possible to interact with a web site without a mouse and navigate it with a screen reader Understandable for example copy should not be more complicated than it needs to be and the web site should operate in a predictable manner Robust for example web sites should work interoperably with different user agents and navigation should be consistent In this section I shall present some examples of how expert testers can evaluate how far content matches up to these principles Please note this section is not intended as a substitute for a review of WCAG and its techniques Perceivability One subset of perceivability problems revolves around the provision of alternative media of various types You can test for text equivalents by turning off images and multimedia in your browser and looking at the page But youll need to take special care with the img and input elements Normally you are advised to give all purely decorative images blank alt attributes alt so that the screenreader will just skip them However in the case of Images that are the sole content of links Form buttons When these elements are given alt attributes screen readers will commonly treat the image or button as if the alt attribute is missing and attempt to provide one for example by reading out the URL of the image Therefore in these particular circumstances you must ensure that images inside links or buttons have an alt attribute that describes the link destination or button action even though this is slightly repetitive Testing for equivalents synchronized with multimedia such as captions and audio descriptions can be done by digging into the preferences for your media player to turn on accessibility settings Another group of perceivability problems concerns the styling of the page There are three areas to investigate here Is the suggested presentation of the page reasonably accessible For example is there sufficient color contrast Is the text comfortably large In addition to squinting at the page yourself you can use a tool such as Juicy Studio CSS Analyser to check background and foreground color combinations against formulae that purport to measure legibility Can publisher suggestions for presentation be safely mixed with common user preferences aimed at making content more legible like increased font size zoom and different default colors Try increasing the text size by about 25 steps dont worry if the results are not pixel perfect but do worry if the layout is so broken it renders the content hard to read Try changing your color preferences and see what happens If publisher CSS sets colors it should explicitly set background and foreground together to ensure that the combination of unusual preferences and publisher styles do not result in unreadable or invisible text Popular browsers allow users to enforce their own color preferences and turn off CSS background images When you try this yourself it can reveal misconceived CSS image replacement techniques that hide text offscreen since the image will not be loaded but the text will still be invisible If publisher suggestions for presentation are discarded is all the information communicated by such suggestions preserved in the web content for use by the default stylings of the user agent or user styling Try turning off CSS and inspecting the document object model to check that headings are marked as headings and tables are used for tabulated data not layout Operability Health and safety is a crucial though rarely considered part of making a website operable But flashing content risks triggering fits in photosensitive epileptics You can take a screen capture of your website in use and feed it into the Trace Center Photosensitive Epilepsy Analysis Tool PEAT to test if it has flashing content likely to pose a danger to your users Obviously this is an especially big concern if you are creating a video sharing website At the product design stage you might look at including an automated screening process for uploads Beyond that a good way to test the operability of websites is simply to try to see if you can access all essential content and functionality with different devices Try using your site with just the keyboard Is current focus always clearly indicated Can all functionality be accessed by keyboard Try using your site with a touchscreen device Try navigating your webpage with voice commands using Opera for Windows and its Voice addon or Windows Vista Speech Recognition and Internet Explorer Note dictationquality commercial speech recognition has recently been introduced to Mac OS X in the form of MacSpeech Dictate but there is currently no equivalent on the free nix platforms Screen readers and other assistive technology can make use of the semantic structure of XHTML to correctly associate content and to enable navigation of content For example screen readers can allow users to jump to the next occurrence of headings or other element type or they can list all occurrences of a certain type Correct use of label and legend elements allows assistive technology to associate labels with the correct form fields correct use of th elements and header scope and axis attributes allows it to associate table headings with table data cells Semantic structure may be evaluated with a document object model DOM inspector like the one found in Opera Dragonfly Accessibility inspection tools like the Firefox Accessibility Extension can make such tasks easier by for example listing the headings on the page or listing the attributes of form fields quickly showing which ones are missing associated labels See Figure 1 for an example Figure 1 Screenshot of Firefox Accessibility Extensions forms information window with the new BBC homepage Understandability Assessing comprehensibility is even more subjective that testing legibility Unless an evaluator is new to a project or is a professional editor they are probably not the best person to evaluate whether copy is as understandable as possible You can however use Juicy Studios Readability Test tool to get a rough idea of how simple your sites copy is Some aspects are highly objectively testable however such as whether content has language metadata that allows for example screen readers and voice browsers to read content with the correct pronunciation With HTML you could use a DOM inspector to check for the presence of a lang attribute for the document and each change of language Keep an eye out for inconsistencies in web sites both in terms of internal consistency and predictability from common web conventions Screen magnifier users who only see part of a page at a time rely heavily on such consistency in order to know where to look to find given content and functionality Robustness Testing whether content is robust involves checking that technologies are being correctly used At a very basic level you can run markup and code through linters such as WDG HTML Validator with warnings enabled W3C CSS Validator JSLint JavaScript linter Next you can review code in depth to check that features are used correctly For example you can check that HTML native controls are used rather than faking controls with meaningless elements and JavaScript and that JavaScript uses feature detection rather than browser sniffing where possible Then you can test in multiple user agents and assistive technologies checking the site is perceivable operable and understandable whatever combination of publisher CSS JavaScript and plugins are enabled or disabled The most common problem is probably obtrusive JavaScript like anchors and buttons that are in the unscripted markup of the page but depend on JavaScript to actually do anything But there are more subtle problems that arise from overly close coupling of JavaScript with other layers in the technology stack For example JavaScript might apply CSS display none to hide content but what happens when publisher CSS is not applied Another example is multimedia controls Often when plugin content is included the plugins native user interface is disabled and the plugin is instead controlled by scripted HTML widgets When the plugin content is only added via JavaScript after JavaScriptbased plugin detection this is fine But sometimes plugin content is included in the prescripted state of the page In such cases it is worth checking not only that a fallback has been included in case a handling plugin is not available but also that the native user interface of the plugin is not disabled unless JavaScript is available If the former is not the case then users will not see the fallback content at all if the latter is not true then users will see the plugin but not be able to control it User testing No amount of developer inspection and screening can substitute for the raw clash between a user and a web site Given the difficulties of understanding all the subtle interactions between web content and assistive technology and the difficulties of approximating the experience of users with disabilities this goes double for users with disabilities If at all possible you should test your site with real users with disabilities This can be done on a large and expensive scale but do not underestimate the benefits of doing even smallscale user testing Recruiting testers Testers can be found in the same way as you find candidates for usability testing generally eg through advertising and recruitment agencies Your local disability organizations should be able to suggest appropriate forums for recruiting test subjects Testing is real work and should ideally be compensated as such A rate of around 70 USD for an hours testing is fairly common for user testing Having said that you may be able to find people who will test smaller projects for free There will be people with disabilities among your friends relatives and colleagues In addition there are online discussion groups dedicated to software accessibility issues such as WebAIM Accessibility Discussion List Web Accessibility Initative Interest Group Mailing List a forum for discussion of issues relating to Web accessibility British Computer Association of the Blind mailing list for discussing Information Communication Technologies ICT for visually impaired people Magnifiers Yahoo Group jfwfreelistsorg A mailing list for users of the JAWS screen reader GWInfo A mailing list for users of the GW Micro WindowEyes screen reader Dolphin software users Yahoo Group NVDA users mailing list Thunder users mailing list discussmacvisionariescom A list about use of OS X by the blind macvoiceoverfreelistsorg Apple VoiceOver users Blinuxlist A list about the use of Linux by people who are blind and visually impaired GNOME Orca users Ai Squared Forums Including users of the popular ZoomText magnifier DeafMacs Yahoo Group For deaf hardofhearing and Usher or deafblind Mac Users deafuktechnology Yahoo Group Deafrelated technology discussion Such groups typically welcome questions from web developers about the accessibility of their sites or particular techniques Practical considerations Remember that the test environment itself needs to be accessible For example if you are preparing written test materials you need to be prepared to offer these in alternative forms The logistics of replicating the users browsing environment at your normal testing location are complicated so it may be more realistic to test at the users home Failing that even completely remote testing can be valuable One particular consideration that is probably even more important for users with disabilities than other users is what technology they are familiar with Assistive technology can add many layers of complexities to their computing experience creating a big divide between novice computer users and oldhands and dividing users into communities who might be very adept with their own setup but highly disorientated by unfamiliar technology Think of how hard users without disabilities that affect their use of computers find it to switch between Mac and PC If you take a longtime user of the WindowEyes screen reader sit him in front of an unfamiliar machine with the JAWS screen reader installed and ask him to test a website its going to be very difficult to distinguish his problems with JAWS from his problems with your website Given the significant differences between versions and given how users often customize their setup it may be difficult even if you provide WindowEyes For this reason unless you are specifically testing how well your websites accessibility will hold up in unfamiliar settings eg in libraries or friends computers it is best to allow users to test with their own setup or something as close as possible to it Likewise unless you specifically want to test novice users or expert users you should aim to select users who have around a years familiarity with using their current setup to access the web Both assistive technology and the conventions of the web itself are nontrivial to learn With novice users you will not know whether problems arise from your site or are intrinsic to the learning process and experts may have tricks up their sleeves that others dont Choosing tasks Its incredibly instructive even to observe users simply exploring a website As with any other user testing Try setting the users some specific tasks to accomplish Ask them what they think and listen to what they say Pay attention to what they do because that may differ from what they say stated preference is a poor guide to performance When you design a site you need to focus on the transactions users want to make with your site rather than the particular controls they need to use Likewise when accessibility testing the tasks you set should at least initially reflect the real goals of a visitor using the site rather than being focused on their interactions with particular controls These transactions will typically be similar for people with and without disabilities For example if you are testing a video sharing site for accessibility do not begin by asking them if they can use particular controls Thats the volume slider Can you adjust the volume Instead give them scenarios and ask them to achieve key user tasks For example Browse videos and choose one to play Search for a video Upload a video Pause the video play the video mute the video unmute the video rewind the video and play it again Rate a video Share a video with a friend This way you are likely to uncover lots of problems you had not anticipated For example a screen reader user might not be able to find the search box or the controls for the video Conversely users might have navigational strategies for dealing with the web you do not even know about Interpreting the results In an ideal world we could test every possible combination and get feedback from everybody But in reality time and money will limit user testing Given this feedback can be a doubleedged sword While it can teach you an enormous amount there is a real danger of attaching too much weight to one persons view which may not be representative of the greater target audience For example some screen reader users tend to be looking for an experience streamlined for blind users others are keen to know everything about the site that their sighted friends and colleagues see This is where accessibility standards like WCAG really come into their own By following such guidelines you can increase your chances of getting a foundation of accessibility even for user groups you are not able to test When you do observe a problem analyse its causes For example your video sharing site includes a page showing popular videos in a data table with columns including a still a title uploaded date last played date and overall rating and arranged in row groups by category of video In user testing a screen reader user has trouble using the data table This could reflect A problem with the site code For example maybe the developers constructed a data table from meaningless div elements rather than using proper data table markup Here the appropriate action would be to recode the table Inexpertise on the part of the user For example a JAWS user might be unfamiliar with JAWSs features for navigating and reading data tables Here an appropriate action might be to provide additional documentation or hints for less expert users If expert users do not make ideal test subjects they make great consultants on points such as this A problem with the user agent For example Safari exposes data tables to the Apple accessibility model as a series of layout boxes rather than as a set of data relationships Here appropriate actions would include reporting the bug to the user agent vendor or developers researching a technique that does work in the user agent or noting the limitation in documentation and suggesting alternative user agents that do work with your web site A problem with the screen reader For example the developers might have shortened long table headers using the abbr attribute but the screen reader might not provide a user interface for reading the shortened version Here appropriate actions would include reporting the bug to the screen reader vendor or developers and might be to find a technique that does work in the screen reader or to note the limitation in documentation and suggest an alternative tool or navigation strategy that does work Communicating the results of accessibility testing When communicating the results of accessibility evaluation document precisely what was evaluated If you tested conformance with a particular standard be specific about exactly where conformance has succeeded and failed Whenever raising a problem make sure to put it in real human terms and explain how the problem might adversely affect users Describe how to reproduce the problem and test for its resolution Suggest practical techniques for achieving conformance or improving accessibility For example you might report a problem with the video sharing website like this Problem The dropdown menu cannot be opened without using a mouse to hover over top menu items and the keyboard focus disappears offscreen as you tab through the menu How to reproduce Open the page in your browser and attempt to reach a subitem of the menu using the keyboard alone Explanation Web navigation should be deviceindependent so that users using devices other than micesuch as blind users or users with motor disabilitiescan access content and functionality Currently such users can not access the items in submenus and sighted users using the keyboard may be confused when the focus indicator disappears Conformance implications Keyboard operability is a requirement for WCAG 10 and WCAG 20 Level A compliance see WCAG 10 Guideline 9 and WCAG 20 Guideline 21 Suggested remedies When JavaScript is not available use a simple list of links to subpages for each sublist of navigation On sub pages present the main navigation followed by the sublist When JavaScript is available remove the sublist from the DOM and add sublists for each menu item on the click event which can be triggered by keyboards mice speech recognition and touch screens alike Summary Not every webpage will receive an accessibility evaluation by experts and a suite of paid test subjects But any web developer can learn the principles of accessibility attempt to implement those principles in their code and submit the results of their labours to user mailing lists to learn of further problems and so feed new knowledge back into future development Exercise questions Try navigating a complex site of your choice without using the mouse What difficulties do you encounter How could the developers of the site help you Turn off CSS and do your normal browsing for a day What problems do you encounter Turn off JavaScript and do your normal browsing for a day What problems do you encounter Pick a favourite site design some personas for the site then evaluate its conformance with WCAG 10 and general accessibility as an expert tester Design a user testing plan for a site and include recruit requirements and tasks to test Write up a report on how it could improve its accessibility Note This material was originally published as part of the Opera Web Standards Curriculum available as 26 Accessibility testing written by Benjamin HawkesLewis Like the original it is published under the Creative Commons Attribution Non Commercial  Share Alike 25 license Next CSS CSS basics Retrieved from httpswwww3orgwikiindexphptitleAccessibility_testingoldid109192 Categories TutorialsWSC ,https://www.w3.org/wiki/Accessibility_testing,UI/UX Design,1939,7877
Ethical and Legal Aspects of Web Development,Ethical Considerations in Web DevelopmentcorewaveFollow4 min readOct 29ListenShareIn an increasingly digital world web development plays a pivotal role in shaping our online experiences Whether youre a seasoned developer at a Mobile App Development Company an Android app development company or an iOS app development company ethical considerations in web development are more critical than ever Developers hold the keys to not only the functionality but also the ethics of the websites and applications they create In this blog well explore the ethical side of web development its profound impact and how developers can make responsible choices in their workThe Digital GuardiansWeb developers arent just coders and designers they are the guardians of the online realm Each line of code and design choice they make can have farreaching effects on privacy society and even democracy Lets dive into some of the key ethical considerations in web development1 Privacy and Data SecurityIn a world rife with data breaches and privacy concerns ethical web development is all about safeguarding user data Developers must implement stringent security measures follow data encryption best practices and ensure that user information is handled with care and never mishandled misused or sold without consent2 AccessibilityWebsites and applications should be open to all regardless of their physical or cognitive abilities Ethical developers ensure that their creations are compatible with screen readers keyboard navigation and other assistive technologies creating an inclusive online environment3 User Consent and TransparencyTransparency is paramount in ethical web development Users need to know how their data is collected stored and used Ethical developers obtain unambiguous consent for data collection and provide userfriendly privacy policies4 Content and Information QualityThe accuracy and reliability of information presented on websites are ethical imperatives Developers must consider the potential impact of the content they display and be cautious about spreading false information hate speech or harmful ideologies5 Digital InclusivityWeb development should strive for digital inclusivity reaching underserved and marginalized communities This means building websites and applications that are accessible affordable and available to people from all walks of life6 Environmental ImpactThe digital world leaves an environmental footprint Large data centres energy consumption and electronic waste contribute to environmental degradation Ethical web development means considering the environmental consequences of digital projects and adopting ecofriendly practices7 Open Source and CollaborationMany developers embrace opensource principles by sharing code and collaborating with others This fosters innovation and knowledge sharing Ethical web development involves being part of a community that aims to benefit society rather than just corporate interestsThe Ripple Effect of Ethical ChoicesEthical considerations in web development have profound consequences1 Trust and ReputationEthical web development builds trust among users and clients When users feel that their data is secure their privacy is respected and the content they encounter is reliable they are more likely to engage with websites and apps2 Legal ComplianceEthical development ensures legal compliance Failure to respect user data privacy can lead to legal penalties and damage a companys reputation3 User SatisfactionEthical web development creates a more satisfying user experience Accessible and inclusive websites appeal to a broader audience and transparent data policies build trust4 Social ImpactWebsites and applications have the power to influence society Ethical developers can choose to create projects that promote positive social values inclusivity and diversity5 Environmental ResponsibilityConsidering the environmental impact of digital projects contributes to a more sustainable future Reducing energy consumption and electronic waste helps address environmental challengesHow to Make Ethical Choices in Web DevelopmentDevelopers can take several steps to ensure ethical web development1 Stay InformedStay uptodate with ethical guidelines legal requirements and industry standards Understand the evolving landscape of online ethics2 Prioritize User PrivacyPlace user privacy at the forefront of your development process Minimize data collection and storage and obtain explicit consent for any data you collect3 Test for AccessibilityConduct accessibility testing on your websites and applications Ensure they can be used by individuals with disabilities4 Promote DiversityEncourage diversity and inclusion in your projects both in terms of content and design Avoid discrimination and bias in your work5 Contribute to Open SourceParticipate in opensource projects and collaborate with other developers Share knowledge and contribute to the greater good of the developer community6 Consider the Environmental ImpactThink about the environmental consequences of your work Adopt ecofriendly hosting practices and energyefficient coding techniquesIn ConclusionWeb development is a powerful force in the digital world with farreaching ethical implications Developers have a responsibility to prioritize ethics data privacy accessibility inclusivity and environmental sustainability in their work By doing so they can create a digital landscape that is both functional and morally responsible As the guardians of the online realm web developers have the power to shape a digital world that is both innovative and ethical ,https://medium.com/@corewave/ethical-considerations-in-web-development-7015bac034cb,Ethics,388,775
